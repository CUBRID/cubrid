/*
 * Copyright 2008 Search Solution Corporation
 * Copyright 2016 CUBRID Corporation
 *
 *  Licensed under the Apache License, Version 2.0 (the "License");
 *  you may not use this file except in compliance with the License.
 *  You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 *  Unless required by applicable law or agreed to in writing, software
 *  distributed under the License is distributed on an "AS IS" BASIS,
 *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *  See the License for the specific language governing permissions and
 *  limitations under the License.
 *
 */

/*
 * btree.c - B+-Tree manager
 */

#ident "$Id$"

#include "btree.h"

#include "btree_load.h"
#include "config.h"
#include "db_value_printer.hpp"
#include "file_manager.h"
#include "slotted_page.h"
#include "log_append.hpp"
#include "log_manager.h"
#include "overflow_file.h"
#include "xserver_interface.h"
#include "scan_manager.h"
#include "fetch.h"
#include "locator_sr.h"
#include "network_interface_sr.h"	/* TODO: remove; used for xcallback_console_print */
#include "utility.h"
#include "transform.h"
#include "partition_sr.h"
#include "porting_inline.hpp"
#include "query_executor.h"
#include "query_opfunc.h"
#include "object_primitive.h"
#include "object_representation.h"
#include "perf_monitor.h"
#include "regu_var.hpp"
#include "fault_injection.h"
#include "dbtype.h"
#include "thread_manager.hpp"

#include <assert.h>
#include <algorithm>
#include <cinttypes>
#include <stdlib.h>
#include <string.h>

#define BTREE_HEALTH_CHECK

#define BTREE_DEBUG_DUMP_SIMPLE		0x0001	/* simple message in SMO */
#define BTREE_DEBUG_DUMP_FULL		0x0002	/* full dump in insert or delete */

#define BTREE_DEBUG_HEALTH_SIMPLE	0x0010	/* simple health check in SMO */
#define BTREE_DEBUG_HEALTH_FULL		0x0020	/* full health check (traverse all slot in page) */

#define BTREE_DEBUG_TEST_SPLIT		0x0100	/* full split test */

#define BTREE_SPLIT_LOWER_BOUND 0.20f
#define BTREE_SPLIT_UPPER_BOUND (1.0f - BTREE_SPLIT_LOWER_BOUND)

#define BTREE_SPLIT_MIN_PIVOT 0.05f
#define BTREE_SPLIT_MAX_PIVOT (1.0f - BTREE_SPLIT_MIN_PIVOT)

#define BTREE_SPLIT_DEFAULT_PIVOT 0.5f
#define DISK_PAGE_BITS  (DB_PAGESIZE * CHAR_BIT)	/* Num of bits per page */

#define BTREE_NODE_MAX_SPLIT_SIZE(thread_p, page_ptr) \
  (db_page_size() - spage_header_size() - spage_get_space_for_record(thread_p, (page_ptr), HEADER))

#define OID_MSG_BUF_SIZE 64

#define MIN_KEY_SIZE DB_ALIGN (1, BTREE_MAX_ALIGN)
#define MIN_LEAF_REC_SIZE (OR_OID_SIZE + MIN_KEY_SIZE)
#define MAX_LEAF_REC_NUM (IO_MAX_PAGE_SIZE / MIN_LEAF_REC_SIZE)

#define MAX_MERGE_ALIGN_WASTE \
  ((DB_PAGESIZE/MIN_LEAF_REC_SIZE) * (BTREE_MAX_ALIGN - 1))

/* Merge two nodes when a page containing both is this empty. */
#define CAN_MERGE_WHEN_EMPTY \
  (MAX (DB_PAGESIZE * 0.33, MAX_MERGE_ALIGN_WASTE * 1.3))
/* Force merging two node when a page containing bot is this empty. */
#define FORCE_MERGE_WHEN_EMPTY \
  (MAX (DB_PAGESIZE * 0.66, MAX_MERGE_ALIGN_WASTE * 1.3))

/*
 * Page header information related defines
 */
#define NOT_FOUND -1

/* B'0001 0000 0000 0000' */
#define BTREE_LEAF_RECORD_FENCE ((short) 0x1000)
/* B'0010 0000 0000 0000' */
#define BTREE_LEAF_RECORD_OVERFLOW_OIDS ((short) 0x2000)
/* B'0100 0000 0000 0000' */
#define BTREE_LEAF_RECORD_OVERFLOW_KEY ((short) 0x4000)
/* B'1000 0000 0000 0000' */
#define BTREE_LEAF_RECORD_CLASS_OID ((short) 0x8000)
/* B'1111 0000 0000 0000' */
#define BTREE_LEAF_RECORD_MASK ((short) 0xF000)

/* B'0100 0000 0000 0000' */
#define BTREE_OID_HAS_MVCC_INSID ((short) 0x4000)
/* B'1000 0000 0000 0000' */
#define BTREE_OID_HAS_MVCC_DELID ((short) 0x8000)
/* B'1100 0000 0000 0000' */
#define BTREE_OID_MVCC_FLAGS_MASK ((short) 0xC000)

#define BTREE_OID_HAS_MVCC_INSID_AND_DELID \
  (BTREE_OID_HAS_MVCC_INSID | BTREE_OID_HAS_MVCC_DELID)

/* The maximum number of OID's in a page */
#define BTREE_MAX_OID_COUNT IO_MAX_PAGE_SIZE / OR_OID_SIZE

/* Clear MVCC flags from object OID */
#define BTREE_OID_CLEAR_MVCC_FLAGS(oid_ptr) \
  ((oid_ptr)->volid &= ~BTREE_OID_MVCC_FLAGS_MASK)
/* Clear record flags from object OID */
#define BTREE_OID_CLEAR_RECORD_FLAGS(oid_ptr) \
  ((oid_ptr)->slotid &= ~BTREE_LEAF_RECORD_MASK)
/* Clear all flags (mvcc & record) from object OID. */
#define BTREE_OID_CLEAR_ALL_FLAGS(oid_ptr) \
  do \
    { \
      BTREE_OID_CLEAR_MVCC_FLAGS (oid_ptr); \
      BTREE_OID_CLEAR_RECORD_FLAGS (oid_ptr); \
    } \
  while (0)
/* Check if MVCC flags are set into b-tree object OID. */
#define BTREE_OID_IS_MVCC_FLAG_SET(oid_ptr, mvcc_flag) \
  (((oid_ptr)->volid & (mvcc_flag)) == (mvcc_flag))
/* Check if record flags are set into b-tree object OID. */
#define BTREE_OID_IS_RECORD_FLAG_SET(oid_ptr, mvcc_flag) \
  (((oid_ptr)->slotid & (mvcc_flag)) == (mvcc_flag))

/* Set b-tree flags into an OID. */
#define BTREE_OID_SET_MVCC_FLAG(oid_ptr, mvcc_flag) \
  ((oid_ptr)->volid |= (mvcc_flag))
#define BTREE_OID_SET_RECORD_FLAG(oid_ptr, mvcc_flag) \
  ((oid_ptr)->slotid |= (mvcc_flag))

/* Get b-tree flags from an OID. */
#define BTREE_OID_GET_MVCC_FLAGS(oid_ptr) \
  ((oid_ptr)->volid & BTREE_OID_MVCC_FLAGS_MASK)
#define BTREE_OID_GET_RECORD_FLAGS(oid_ptr) \
  ((oid_ptr)->slotid & BTREE_LEAF_RECORD_MASK)

/* Check MVCC flags in an b-tree MVCC info. */
#define BTREE_MVCC_INFO_HAS_INSID(mvcc_info) \
  (((mvcc_info)->flags & BTREE_OID_HAS_MVCC_INSID) != 0)
#define BTREE_MVCC_INFO_HAS_DELID(mvcc_info) \
  (((mvcc_info)->flags & BTREE_OID_HAS_MVCC_DELID) != 0)

/* CLear MVCC flags in a b-tree MVCC info. */
#define BTREE_MVCC_INFO_CLEAR_INSID(mvcc_info) \
  ((mvcc_info)->flags &= ~BTREE_OID_HAS_MVCC_INSID)
#define BTREE_MVCC_INFO_CLEAR_DELID(mvcc_info) \
  ((mvcc_info)->flags &= ~BTREE_OID_HAS_MVCC_DELID)

/* Check if insert MVCCID is valid but not visible to everyone. */
#define BTREE_MVCC_INFO_IS_INSID_NOT_ALL_VISIBLE(mvcc_info) \
  (BTREE_MVCC_INFO_HAS_INSID (mvcc_info) && MVCCID_IS_NOT_ALL_VISIBLE ((mvcc_info)->insert_mvccid))

/* Check if delete MVCCID is valid. */
#define BTREE_MVCC_INFO_IS_DELID_VALID(mvcc_info) \
  (BTREE_MVCC_INFO_HAS_DELID (mvcc_info) && (mvcc_info)->delete_mvccid != MVCCID_NULL)

/* Insert MVCCID based on b-tree mvcc info. */
#define BTREE_MVCC_INFO_INSID(mvcc_info) \
  (BTREE_MVCC_INFO_HAS_INSID (mvcc_info) ? (mvcc_info)->insert_mvccid : MVCCID_ALL_VISIBLE)

/* Delete MVCC based on b-tree mvcc info. */
#define BTREE_MVCC_INFO_DELID(mvcc_info) \
  (BTREE_MVCC_INFO_HAS_DELID (mvcc_info) ? (mvcc_info)->delete_mvccid : MVCCID_NULL)

/* Set b-tree MVCC info as if it has fixed size (it includes both insert and
 * delete MVCCID.
 */
#define BTREE_MVCC_INFO_SET_FIXED_SIZE(mvcc_info) \
  do \
    { \
      if (!BTREE_MVCC_INFO_HAS_INSID (mvcc_info)) \
	{ \
	  (mvcc_info)->insert_mvccid = MVCCID_ALL_VISIBLE; \
	} \
      if (!BTREE_MVCC_INFO_HAS_DELID (mvcc_info)) \
	{ \
	  (mvcc_info)->delete_mvccid = MVCCID_NULL; \
	} \
      (mvcc_info)->flags = BTREE_OID_HAS_MVCC_INSID_AND_DELID; \
    } \
  while (false)

/* Clear unnecessary flags from b-tree MVCC info. */
#define BTREE_MVCC_INFO_CLEAR_FIXED_SIZE(mvcc_info) \
  do \
    { \
      if (!BTREE_MVCC_INFO_IS_INSID_NOT_ALL_VISIBLE (mvcc_info)) \
	{ \
	  BTREE_MVCC_INFO_CLEAR_INSID(mvcc_info); \
	} \
      if (!BTREE_MVCC_INFO_IS_DELID_VALID (mvcc_info)) \
	{ \
	  BTREE_MVCC_INFO_CLEAR_DELID(mvcc_info); \
	} \
    } \
  while (false)

/* Set insert MVCCID into b-tree mvcc info. */
#define BTREE_MVCC_INFO_SET_INSID(mvcc_info, insid) \
  do \
    { \
      (mvcc_info)->flags |= BTREE_OID_HAS_MVCC_INSID; \
      (mvcc_info)->insert_mvccid = insid; \
    } \
  while (false)

/* Set delete MVCCID into b-tree mvcc info. */
#define BTREE_MVCC_INFO_SET_DELID(mvcc_info, delid) \
  do \
    { \
      (mvcc_info)->flags |= BTREE_OID_HAS_MVCC_DELID; \
      (mvcc_info)->delete_mvccid = delid; \
    } \
  while (false)

/* Get an object OID from a b-tree record. If MVCC is enabled, mvcc flags are
 * cleared.
 */
#define BTREE_GET_OID(buf, oid_ptr) \
  do \
    { \
      OR_GET_OID (buf, oid_ptr); \
      BTREE_OID_CLEAR_MVCC_FLAGS (oid_ptr); \
    } \
  while (0)

/* Initialize OR_BUF to process a b-tree record. */
#define BTREE_RECORD_OR_BUF_INIT(buf, btree_rec) \
  do \
    { \
      int size = (btree_rec)->length; \
      if (btree_leaf_is_flaged (btree_rec, BTREE_LEAF_RECORD_OVERFLOW_OIDS)) \
	{ \
	  size -= DB_ALIGN (DISK_VPID_SIZE, BTREE_MAX_ALIGN); \
	} \
      OR_BUF_INIT (buf, (btree_rec)->data, size); \
    } \
  while (false)

/* Get MVCC size from leaf record flags */
/* Size is:
 * 2 * OR_MVCCID_SIZE if both MVCC flags are set
 * 0 if no MVCC flags are set
 * OR_MVCCID_SIZE otherwise (one flag is set).
 */
#define BTREE_GET_MVCC_INFO_SIZE_FROM_FLAGS(mvcc_flags) \
  (((mvcc_flags) & BTREE_OID_HAS_MVCC_INSID_AND_DELID) == BTREE_OID_HAS_MVCC_INSID_AND_DELID \
   ? 2 * OR_MVCCID_SIZE : ((mvcc_flags) == 0 ? 0 : OR_MVCCID_SIZE))

/* Check if page is a valid b-tree leaf node. Usually called after unfix and
 * re-fix without validation.
 */
/* TODO: Is this expensive? Can we find a faster way to check it?
 *	 (e.g. save last deallocation page LSA - it will be then enough to
 *	 compare with an LSA saved before unfixing).
 */
#define BTREE_IS_PAGE_VALID_LEAF(thread_p, page) \
  ((page) != NULL \
   && pgbuf_get_page_ptype (thread_p, page) == PAGE_BTREE \
   && spage_get_slot (page, HEADER) != NULL \
   && spage_get_slot (page, HEADER)->record_length == sizeof (BTREE_NODE_HEADER) \
   && (btree_get_node_header (thread_p, page))->node_level == 1)

typedef struct recset_header RECSET_HEADER;
struct recset_header
{				/* Recovery set of recdes structure */
  INT16 rec_cnt;		/* number of RECDESs stored */
  INT16 first_slotid;		/* first slot id */
};

typedef enum
{
  LEAF_RECORD_REGULAR = 1,
  LEAF_RECORD_OVERFLOW
} LEAF_RECORD_TYPE;

typedef enum
{
  BTREE_BOUNDARY_FIRST = 1,
  BTREE_BOUNDARY_LAST,
} BTREE_BOUNDARY;

typedef enum
{
  BTREE_MERGE_NO = 0,
  BTREE_MERGE_TRY,
  BTREE_MERGE_FORCE,
} BTREE_MERGE_STATUS;

/* RECINS_STRUCT - redo b-tree insert recovery structure.
 */
typedef struct recins_struct RECINS_STRUCT;
struct recins_struct
{				/* Recovery leaf record oid insertion structure */
  OID class_oid;		/* class oid only in case of unique index */
  OID oid;			/* oid to be inserted to the record */
  VPID ovfl_vpid;		/* Next Overflow pageid */
  INT16 flags;			/* Flags to describe different context of recovered insert object: - oid inserted - is
				 * overflow changed - is new overflow - record type (regular or overflow) - insert OID
				 * mode */
};
#define RECINS_STRUCT_INITIALIZER \
  { OID_INITIALIZER, OID_INITIALIZER, VPID_INITIALIZER, 0 }

/* Redo recovery of insert delete MVCCID */
#define BTID_DOMAIN_CHECK_MAX_SIZE 1024

/* Offset of the fields in the Leaf/NonLeaf Record Recovery Log Data */
#define OFFS1  0		/* Node Type Offset: Leaf/NonLeaf Information */
#define OFFS2  2		/* RECDES Type Offset */
#define OFFS3  4		/* RECDES Data Offset */

/* for Leaf Page Key Insertions */
#define LOFFS1  0		/* Key Len Offset */
#define LOFFS2  2		/* Node Type Offset: Leaf/NonLeaf Information */
#define LOFFS3  4		/* RECDES Type Offset */
#define LOFFS4  6		/* RECDES Data Offset */

/* B+tree statistical information environment */
typedef struct btree_stats_env BTREE_STATS_ENV;
struct btree_stats_env
{
  BTREE_SCAN btree_scan;	/* BTS */
  BTREE_STATS *stat_info;
  int pkeys_val_num;
  DB_VALUE pkeys_val[BTREE_STATS_PKEYS_NUM];	/* partial key-value */
};

/* Structure used by btree_range_search to initialize and handle variables
 * needed throughout the process.
 */
typedef struct btree_range_search_helper BTREE_RANGE_SEARCH_HELPER;
struct btree_range_search_helper
{
  OID *mem_oid_ptr;		/* Pointer to OID memory storage */
  int pg_oid_cnt;		/* The capacity of OID memory storage */
  int oids_cnt;			/* Current count of stored OID's */
  int oid_size;			/* Size of one OID */
  int cp_oid_cnt;		/* The OID count that can be stored in the current step */
  int rec_oid_cnt;		/* The OID count in current record */
  char *rec_oid_ptr;		/* Pointer in record to current OID */
  bool swap_key_range;		/* Swaps key range if true */
  bool is_key_range_satisfied;	/* Does current key satisfy range */
  bool is_key_filter_satisfied;	/* Does current key satisfy filter */
  bool is_condition_satisfied;	/* Does current key satisfy range and filter */
  RECDES rec;			/* Current record */
  LEAF_REC leaf_pnt;		/* Leaf record pointer OID overflows */
  int offset;			/* Offset in record to the first OID */
  OID class_oid;		/* Class identifier for current object */
  OID inst_oid;			/* Current object identifier */
  BTREE_NODE_TYPE node_type;	/* Current node type: leaf or overflow */
  bool iss_get_first_result_only;	/* Index skip scan special case */
  bool restart_on_first;	/* restart after first OID */
  int CLS_satisfied;		/* All conditions are satisfied */
  OID saved_class_oid;		/* Saved class identifier */
  OID saved_inst_oid;		/* Saved object identifier */
  char oid_space[2 * OR_OID_SIZE];	/* OID buffer to store "last" index key */
  DB_VALUE prev_key;		/* Previous key */
  bool clear_prev_key;		/* Previous key needs clear if true */
  LOG_LSA prev_leaf_lsa;	/* LSA of previous page */
  LOG_LSA ovfl_page_lsa;	/* LSA of overflow page */
  bool keep_on_copying;		/* True when OID storage exceeds it's default maximum size and need to stop current
				 * iteration of range search after this key */
  OID ck_pseudo_oid;		/* Current key pseudo identifier */
  OID saved_ck_pseudo_oid;	/* Saved current key pseudo identifier */
  OID nk_pseudo_oid;		/* Next key pseudo identifier */
  OID saved_nk_pseudo_oid;	/* Saved next key pseudo identifier */
  OID saved_nk_class_oid;	/* Saved class oid for next key */

  bool end_of_leaf_level;	/* True if end of leaf level was reached */
  bool curr_key_locked;		/* Is current key locked */
  bool next_key_locked;		/* Is next key locked */
  bool current_lock_request;	/* Current key needs locking */
  bool read_prev_key;		/* Previous key is read */
};

typedef struct show_index_scan_ctx SHOW_INDEX_SCAN_CTX;
struct show_index_scan_ctx
{
  int indexes_count;		/* The total of indexes */
  bool is_all;			/* Get all indexes or get a specified index */
  char *index_name;		/* Index name which user specified */
  OID *class_oids;		/* Class oids array */
  int class_oid_count;		/* The count of above oids array */
  int show_type;		/* Show type */
};

/* BTREE_SEARCH_KEY_HELPER -
 * Structure usually used to return the result of search key functions.
 */
typedef struct btree_search_key_helper BTREE_SEARCH_KEY_HELPER;
struct btree_search_key_helper
{
  enum fence_key_presence
  {
    NO_FENCE_KEY = 0,
    HAS_FENCE_KEY
  };

  BTREE_SEARCH result;		/* Result of key search. */
  PGSLOTID slotid;		/* Slot ID of found key or slot ID of the biggest key smaller then key (if not found). */

  fence_key_presence has_fence_key;
};
/* BTREE_SEARCH_KEY_HELPER static initializer. */
// *INDENT-OFF*
#define BTREE_SEARCH_KEY_HELPER_INITIALIZER \
  { BTREE_KEY_NOTFOUND, NULL_SLOTID, btree_search_key_helper::NO_FENCE_KEY }
// *INDENT-ON*

/* BTREE_FIND_UNIQUE_HELPER -
 * Structure used by find unique functions.
 *
 * Functions:
 * btree_key_find_unique_version_oid.
 * btree_key_find_and_lock_unique.
 * btree_key_find_and_lock_unique_of_unique.
 * btree_key_find_and_lock_unique_of_non_unique.
 */
typedef struct btree_find_unique_helper BTREE_FIND_UNIQUE_HELPER;
struct btree_find_unique_helper
{
  OID oid;			/* OID of found object (if found). */
  OID match_class_oid;		/* Object is only considered if its class OID matches this class OID. */
  LOCK lock_mode;		/* Lock mode for found unique object. */
  MVCC_SNAPSHOT *snapshot;	/* Snapshot used to filter objects not visible. If NULL, objects are not filtered. */
  bool found_object;		/* Set to true if object was found. */

  PERF_UTIME_TRACKER time_track;

#if defined (SERVER_MODE)
  OID locked_oid;		/* Locked object. */
  OID locked_class_oid;		/* Locked object class OID. */
#endif				/* SERVER_MODE */
};
/* BTREE_FIND_UNIQUE_HELPER static initializer. */
#if defined (SERVER_MODE)
#define BTREE_FIND_UNIQUE_HELPER_INITIALIZER \
  { OID_INITIALIZER, /* oid */ \
    OID_INITIALIZER, /* match_class_oid */ \
    NULL_LOCK, /* lock_mode */ \
    NULL, /* snapshot */ \
    false, /* found_object */ \
    PERF_UTIME_TRACKER_INITIALIZER, /* time_track */ \
    OID_INITIALIZER, /* locked_oid */ \
    OID_INITIALIZER /* locked_class_oid */ \
  }
#else	/* !SERVER_MODE */		   /* SA_MODE */
#define BTREE_FIND_UNIQUE_HELPER_INITIALIZER \
  { OID_INITIALIZER, /* oid */ \
    OID_INITIALIZER, /* match_class_oid */ \
    NULL_LOCK, /* lock_mode */ \
    NULL, /* snapshot */ \
    false, /* found_object */ \
    PERF_UTIME_TRACKER_INITIALIZER /* time_track */ \
  }
#endif /* !SA_MODE */

/* BTREE_REC_SATISFIES_SNAPSHOT_HELPER -
 * Structure used as helper for btree_record_satisfies_snapshot function.
 */
typedef struct btree_rec_satisfies_snapshot_helper BTREE_REC_SATISFIES_SNAPSHOT_HELPER;
struct btree_rec_satisfies_snapshot_helper
{
  MVCC_SNAPSHOT *snapshot;	/* Input: MVCC snapshot used to filter objects not visible for current transaction. */
  OID match_class_oid;		/* Object class OID must match this class OID. Can be applied only to unique indexes. */
  OID *oid_ptr;			/* OID buffer used to output OID's of visible objects. */
  int oid_cnt;			/* Visible OID counter. */
  int oid_capacity;		/* OID buffer capacity. */
};
/* BTREE_REC_SATISFIES_SNAPSHOT_HELPER static initializer. */
#define BTREE_REC_SATISFIES_SNAPSHOT_HELPER_INITIALIZER \
  { NULL /* snapshot */, OID_INITIALIZER /* match_class_oid */, \
    NULL /* oid_ptr */, 0 /* oid_cnt */, 0 /* oid_capacity */ }

/*
 * btree_search_key_and_apply_functions () argument functions.
 */

/* BTREE_ROOT_WITH_KEY_FUNCTION -
 * btree_search_key_and_apply_functions internal function called on root page,
 * before starting to advance on pages.
 *
 * Arguments:
 * thread_p (in)       : Thread entry.
 * btid (in)	       : B-tree identifier.
 * btid_int (out)      : Output b-tree info.
 * key (in)	       : Key value.
 * is_leaf (out)       : Output true if root is leaf node.
 * key_slotid (out)    : Output slotid of key if found, NULL_SLOTID otherwise.
 * stop (out)	       : Output true when advancing in b-tree should be
 *			 stopped.
 * restart (out)       : Output true when advancing in b-tree must be
 *			 restarted starting with root.
 * other_args (in/out) : Function specific arguments.
 *
 * List of functions:
 * btree_get_root_with_key.
 * btree_fix_root_for_insert.
 */
typedef int BTREE_ROOT_WITH_KEY_FUNCTION (THREAD_ENTRY * thread_p, BTID * btid, BTID_INT * btid_int, DB_VALUE * key,
					  PAGE_PTR * root_page, bool * is_leaf, BTREE_SEARCH_KEY_HELPER * search_key,
					  bool * stop, bool * restart, void *other_args);

/* BTREE_ADVANCE_WITH_KEY_FUNCTION -
 * btree_search_key_and_apply_functions internal function called to advance
 * from root to leaf level of b-tree by following the key. The function can
 * modify the structure of b-tree, will advance one level at each call and
 * it will ultimately stop at the leaf page were the key belongs or would
 * belong if it existed.
 *
 * Arguments:
 * thread_p (in)       : Thread entry.
 * btid_int (int)      : B-tree info.
 * key (in)	       : Key value.
 * is_leaf (out)       : Output true if root is leaf node.
 * key_slotid (out)    : Output slotid of key if found, NULL_SLOTID otherwise.
 * stop (out)	       : Output true when advancing in b-tree should be
 *			 stopped.
 * restart (out)       : Output true when advancing in b-tree must be
 *			 restarted starting with root.
 * other_args (in/out) : Function specific arguments.
 *
 * List of functions:
 * btree_advance_and_find_key.
 * btree_split_node_and_advance.
 */
typedef int BTREE_ADVANCE_WITH_KEY_FUNCTION (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
					     PAGE_PTR * crt_page, PAGE_PTR * advance_to_page, bool * is_leaf,
					     BTREE_SEARCH_KEY_HELPER * search_key, bool * stop, bool * restart,
					     void *other_args);

/* BTREE_PROCESS_KEY_FUNCTION -
 * btree_search_key_and_apply_functions internal function called after
 * advancing in leaf page. It should process or manipulate data for the given
 * key.
 *
 * Arguments:
 * thread_p (in)   : Thread entry.
 * btid_int (int)  : B-tree info.
 * key (in)	   : Key value.
 * key_slotid (in) : Slot ID of key if it was found, NULL_SLOTID otherwise.
 * restart (out)   : Output true when advancing in b-tree must be restarted
 *		     starting with root.
 * args (in/out)   : Function specific arguments.
 *
 * Functions:
 * btree_key_find_unique_version_oid.
 * btree_key_find_and_lock_unique
 * btree_key_find_and_lock_unique_of_unique.
 * btree_key_find_and_lock_unique_of_non_unique
 * btree_key_insert_new_object.
 * btree_key_find_and_insert_delete_mvccid.
 */
typedef int BTREE_PROCESS_KEY_FUNCTION (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
					PAGE_PTR * leaf_page, BTREE_SEARCH_KEY_HELPER * search_key, bool * restart,
					void *other_args);

/* BTREE_PROCESS_OBJECT_FUNCTION -
 * btree_record_process_objects internal function called for each object found
 * in b-tree leaf/overflow records. It should process or manipulate object
 * data in record.
 *
 * Functions:
 * btree_record_satisfies_snapshot.
 * btree_select_visible_object_for_range_scan.
 * btree_fk_object_does_exist.
 */
typedef int BTREE_PROCESS_OBJECT_FUNCTION (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * record,
					   char *object_ptr, OID * oid, OID * class_oid, BTREE_MVCC_INFO * mvcc_info,
					   bool * stop, void *args);

/* Type of b-tree scans. */
/* Covering index. */
#define BTS_IS_INDEX_COVERED(bts) \
  ((bts) != NULL && (bts)->index_scan_idp != NULL && SCAN_IS_INDEX_COVERED ((bts)->index_scan_idp))
/* Multiple ranges optimization. */
#define BTS_IS_INDEX_MRO(bts) \
  ((bts) != NULL && (bts)->index_scan_idp != NULL && SCAN_IS_INDEX_MRO ((bts)->index_scan_idp))
/* Index skip scan. */
#define BTS_IS_INDEX_ISS(bts) \
  ((bts) != NULL && (bts)->index_scan_idp != NULL && SCAN_IS_INDEX_ISS ((bts)->index_scan_idp))
/* Index loose scan. */
#define BTS_IS_INDEX_ILS(bts) \
  ((bts) != NULL && (bts)->index_scan_idp != NULL && SCAN_IS_INDEX_ILS ((bts)->index_scan_idp) \
   && BTS_IS_INDEX_COVERED(bts))
#define BTS_NEED_COUNT_ONLY(bts) \
  ((bts) != NULL && (bts)->index_scan_idp != NULL && (bts)->index_scan_idp->need_count_only)

/* Increment read OID counters for b-tree scan. */
#define BTS_INCREMENT_READ_OIDS(bts) \
  do \
    { \
      (bts)->n_oids_read++; \
      (bts)->n_oids_read_last_iteration++; \
    } \
  while (false)

/* Soft capacity of OID buffer. It is used to stop one scan iteration as a
 * general rule. There is an exception when hard capacity is applied.
 */
#define BTS_IS_SOFT_CAPACITY_ENOUGH(bts, count) \
  ((count) <= (BTS_IS_INDEX_COVERED (bts) \
   ? /* Covering index: use max tuples as soft limit. */ (bts)->index_scan_idp->indx_cov.max_tuples \
   : /* Normal scan: use max_oid_cnt as soft limit. */ (bts)->index_scan_idp->oid_list->max_oid_cnt))

/* Hard capacity is the maximum number that can fit the OID buffer. It is
 * used when the number of objects in a single key does not fit the soft
 * capacity.
 * This key objects will be selected from leaf and overflows as long as they
 * fit the hard capacity. This provides enough space for at least one leaf
 * and one overflow page or for two full overflow pages.
 * There is no limit as hard capacity for covering index. Since it uses a
 * list file, its capacity is considered infinite.
 */
#define BTS_IS_HARD_CAPACITY_ENOUGH(bts, count) \
  (BTS_IS_INDEX_COVERED (bts) \
   ? /* Covering index: no hard limit. */ true \
   : /* Normal scan: use buffer capacity as hard limit. */ (count) <= (bts)->index_scan_idp->oid_list->capacity)

/* Save an object selected during scan into object buffer. This can only be
 * used by two types of scans:
 * 1. Regular range scans.
 * 2. Index skip scan, if current operations is ISS_OP_DO_RANGE_SEARCH.
 */
#define BTS_SAVE_OID_IN_BUFFER(bts, oid) \
  do \
    { \
      /* Assert this is not used in an inappropriate context. */ \
      assert (!BTS_IS_INDEX_COVERED (bts)); \
      assert (!BTS_IS_INDEX_MRO (bts)); \
      assert (!BTS_IS_INDEX_ISS (bts) || bts->index_scan_idp->iss.current_op == ISS_OP_DO_RANGE_SEARCH); \
      COPY_OID ((bts)->oid_ptr, oid); \
      (bts)->oid_ptr++; \
      BTS_INCREMENT_READ_OIDS (bts); \
      assert ((bts)->n_oids_read_last_iteration <= (bts)->index_scan_idp->oid_list->capacity); \
      assert (((bts)->oid_ptr - (bts)->index_scan_idp->oid_list->oidp) <= (bts)->index_scan_idp->oid_list->capacity); \
      /* Should we also increment (bts)->index_scan_idp->oid_list.oid_cnt? */ \
    } \
  while (false)

//
// bts_reset_scan - reset b-tree scan (clear progress)
//
// thread_p (in) : thread entry
// bts (in)      : b-tree scan
static void
bts_reset_scan (THREAD_ENTRY * thread_p, BTREE_SCAN * bts)
{
  /* Reset bts->is_scan_started. */
  bts->is_scan_started = false;
  /* No current leaf node. */
  VPID_SET_NULL (&(bts)->C_vpid);
  if (bts->C_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, bts->C_page);
    }
}

/* BTREE_FIND_FK_OBJECT -
 * Structure used to find if a key of foreign key index has any objects.
 */
typedef struct btree_find_fk_object BTREE_FIND_FK_OBJECT;
struct btree_find_fk_object
{
  OID found_oid;
#if defined (SERVER_MODE)
  OID locked_object;
  LOCK lock_mode;
#endif				/* SERVER_MODE */
};
/* BTREE_FIND_FK_OBJECT static initializer */
#if defined (SERVER_MODE)
#define BTREE_FIND_FK_OBJECT_INITIALIZER \
  { OID_INITIALIZER, OID_INITIALIZER, NULL_LOCK }
#else	/* !SERVER_MODE */		   /* SA_MODE */
#define BTREE_FIND_FK_OBJECT_INITIALIZER \
  { OID_INITIALIZER }
#endif /* SA_MODE */

/* BTREE_INSERT_HELPER -
 * Structure used inside btree_insert_internal functions to group required
 * data into one argument.
 */
typedef struct btree_insert_helper BTREE_INSERT_HELPER;
struct btree_insert_helper
{
  BTREE_OBJECT_INFO obj_info;	/* B-tree object info. Keeps old version for mvcc update same key. */
  BTREE_OP_PURPOSE purpose;	/* Purpose/context for calling btree_insert_internal. */
  int op_type;			/* Single-multi insert/modify operation type. */
  btree_unique_stats *unique_stats_info;	/* Unique statistics kept when operation type is not single. */
  int key_len_in_page;		/* Packed length of key being inserted. */

  PGBUF_LATCH_MODE nonleaf_latch_mode;	/* Default page latch mode while advancing through non-leaf nodes. */

  bool is_first_try;		/* True if this is first attempt to fix root page. B-tree information is loaded only
				 * first time. */
  bool need_update_max_key_len;	/* Set to true when a node max key length must be updated. All children nodes will also
				 * update max key length. */
  bool is_crt_node_write_latched;	/* Set to true when a node is latched exclusively. Then promotion will not be
					 * required. */
  bool is_root;			/* True if current node is root. */

  bool is_unique_key_added_or_deleted;	/* Set to true when keys are inserted for the first time or when they are
					 * deleted. */
  bool is_unique_multi_update;	/* Multi-update of unique index. More than one visible object may be allowed, as long
				 * as at the end of execution, unique constraint is not violated. */
  bool is_ha_enabled;		/* An exception to above rule. If HA is enabled, no unique constraint violation is
				 * allowed at any time. */

  bool log_operations;		/* er_log. */
  bool is_null;			/* is key NULL. */
  char *printed_key;		/* Printed key. */
  SHA1Hash printed_key_sha1;	/* SHA1 of printed key - useful for very large keys */

  btree_insert_list *insert_list;

  /* Recovery data. */
  LOG_DATA_ADDR leaf_addr;
  LOG_RCVINDEX rcvindex;
  char *rv_keyval_data;
  int rv_keyval_data_length;
  char *rv_redo_data;
  char *rv_redo_data_ptr;
  LOG_LSA compensate_undo_nxlsa;
  bool is_system_op_started;

  /* Performance tracker. */
  PERF_UTIME_TRACKER time_track;

#if defined (SERVER_MODE)
  OID saved_locked_oid;		/* Save locked object from unique index key. */
  OID saved_locked_class_oid;	/* Save class of locked object. */
#endif				/* SERVER_MODE */

  // *INDENT-OFF*
  btree_insert_helper ();
  // *INDENT-ON*
};

// *INDENT-OFF*
btree_insert_helper::btree_insert_helper ()
  : obj_info (BTREE_OBJECT_INFO_INITIALIZER)
  , purpose (BTREE_OP_NO_OP)
  , op_type (0)
  , unique_stats_info (NULL)
  , key_len_in_page (0)
  , nonleaf_latch_mode (PGBUF_LATCH_READ)
  , is_first_try (true)
  , need_update_max_key_len (false)
  , is_crt_node_write_latched (false)
  , is_root (false)
  , is_unique_key_added_or_deleted (true)
  , is_unique_multi_update (false)
  , is_ha_enabled (false)
  , log_operations (false)
  , is_null (false)
  , printed_key (NULL)
  , printed_key_sha1 (SHA1_HASH_INITIALIZER)
  , insert_list (NULL)
  , leaf_addr (LOG_DATA_ADDR_INITIALIZER)
  , rcvindex (RV_NOT_DEFINED)
  , rv_keyval_data (NULL)
  , rv_keyval_data_length (0)
  , rv_redo_data (NULL)
  , rv_redo_data_ptr (NULL)
  , compensate_undo_nxlsa (LSA_INITIALIZER)
  , is_system_op_started (false)
  , time_track (PERF_UTIME_TRACKER_INITIALIZER)
#if defined (SERVER_MODE)
  , saved_locked_oid (OID_INITIALIZER)
  , saved_locked_class_oid (OID_INITIALIZER)
#endif
{
}
// *INDENT-ON*

#define BTREE_INSERT_OID(ins_helper) \
  (&((ins_helper)->obj_info.oid))
#define BTREE_INSERT_CLASS_OID(ins_helper) \
  (&((ins_helper)->obj_info.class_oid))
#define BTREE_INSERT_MVCC_INFO(ins_helper) \
  (&((ins_helper)->obj_info.mvcc_info))

/* BTREE_DELETE_HELPER -
 * Structure used inside btree_delete_internal functions to group required
 * data into one argument.
 */
typedef struct btree_delete_helper BTREE_DELETE_HELPER;
struct btree_delete_helper
{
  BTREE_OBJECT_INFO object_info;	/* Object info required for b-tree. */
  BTREE_OBJECT_INFO second_object_info;	/* Object info required for undo insert to unique index. */
  BTREE_OP_PURPOSE purpose;	/* Purpose of delete operation. */
  PGBUF_LATCH_MODE nonleaf_latch_mode;	/* Latch mode used to for non-leaf nodes. */
  int op_type;			/* Operation type. */
  btree_unique_stats *unique_stats_info;	/* Used to collect statistics of multi-row operations in unique
						 * indexes. */
  BTREE_MVCC_INFO match_mvccinfo;	/* Used to match MVCC information when searching for object in index key. */
  OR_BUF *buffered_key;		/* Buffered key value. */
  char *printed_key;		/* Key printed value. */
  SHA1Hash printed_key_sha1;	/* SHA1 of printed key - useful for very large keys */
  bool log_operations;		/* Debugging purpose logging. */
  bool is_root;			/* True if current node is root. */
  bool is_first_search;		/* True for the first b-tree traversal. */
  bool check_key_deleted;	/* Set to true if it is possible to have more than one visible object in unique key
				 * (MULTI_ROW_UPDATE). */
  bool is_key_deleted;		/* Used to correct collected statistics when key is not actually deleted. */

  /* Recovery structures. */
  LOG_DATA_ADDR leaf_addr;
  char *rv_keyval_data;
  int rv_keyval_data_length;
  char *rv_redo_data;
  char *rv_redo_data_ptr;
  LOG_LSA reference_lsa;
  bool is_system_op_started;

  /* Performance tracker. */
  PERF_UTIME_TRACKER time_track;

  // *INDENT-OFF*
  btree_delete_helper ();
  // *INDENT-ON*
};

// *INDENT-OFF*
btree_delete_helper::btree_delete_helper ()
  : object_info (BTREE_OBJECT_INFO_INITIALIZER)
  , second_object_info (BTREE_OBJECT_INFO_INITIALIZER)
  , purpose (BTREE_OP_NO_OP)
  , nonleaf_latch_mode (PGBUF_LATCH_READ)
  , op_type (SINGLE_ROW_DELETE)
  , unique_stats_info (NULL)
  , match_mvccinfo (BTREE_MVCC_INFO_INITIALIZER)
  , buffered_key (NULL)
  , printed_key (NULL)
  , printed_key_sha1 (SHA1_HASH_INITIALIZER)
  , log_operations (false)
  , is_root (false)
  , is_first_search (true)
  , check_key_deleted (false)
  , is_key_deleted (false)
  , leaf_addr (LOG_DATA_ADDR_INITIALIZER)
  , rv_keyval_data (NULL)
  , rv_keyval_data_length (0)
  , rv_redo_data (NULL)
  , rv_redo_data_ptr (NULL)
  , reference_lsa (LSA_INITIALIZER)
  , is_system_op_started (false)
  , time_track (PERF_UTIME_TRACKER_INITIALIZER)
{
}
// *INDENT-ON*

#define BTREE_DELETE_OID(helper) \
  (&((helper)->object_info.oid))
#define BTREE_DELETE_CLASS_OID(helper) \
  (&((helper)->object_info.class_oid))
#define BTREE_DELETE_MVCC_INFO(helper) \
  (&((helper)->object_info.mvcc_info))

// Performance tracking template functions
// Helper is either BTREE_INSERT_HELPER or BTREE_DELETE_HELPER
template < typename Helper > static inline void
btree_perf_track_time (THREAD_ENTRY * thread_p, Helper * helper)
{
  PERF_UTIME_TRACKER_TIME (thread_p, &helper->time_track, PSTAT_BT_LEAF);
  switch (helper->purpose)
    {
    case BTREE_OP_INSERT_NEW_OBJECT:
    case BTREE_OP_ONLINE_INDEX_IB_INSERT:
    case BTREE_OP_ONLINE_INDEX_TRAN_INSERT:
    case BTREE_OP_ONLINE_INDEX_TRAN_INSERT_DF:
      PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, &helper->time_track, PSTAT_BT_INSERT);
      break;
    case BTREE_OP_INSERT_MVCC_DELID:
      PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, &helper->time_track, PSTAT_BT_MVCC_DELETE);
      break;
    case BTREE_OP_INSERT_MARK_DELETED:
      PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, &helper->time_track, PSTAT_BT_MARK_DELETE);
      break;
    case BTREE_OP_INSERT_UNDO_PHYSICAL_DELETE:
    case BTREE_OP_ONLINE_INDEX_UNDO_TRAN_DELETE:
      PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, &helper->time_track, PSTAT_BT_UNDO_DELETE);
      break;
    case BTREE_OP_DELETE_OBJECT_PHYSICAL:
    case BTREE_OP_DELETE_OBJECT_PHYSICAL_POSTPONED:
    case BTREE_OP_ONLINE_INDEX_TRAN_DELETE:
      PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, &helper->time_track, PSTAT_BT_DELETE);
      break;
    case BTREE_OP_DELETE_UNDO_INSERT:
    case BTREE_OP_ONLINE_INDEX_UNDO_TRAN_INSERT:
      PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, &helper->time_track, PSTAT_BT_UNDO_INSERT);
      break;
    case BTREE_OP_DELETE_UNDO_INSERT_DELID:
      PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, &helper->time_track, PSTAT_BT_UNDO_MVCC_DELETE);
      break;
    case BTREE_OP_DELETE_VACUUM_OBJECT:
      PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, &helper->time_track, PSTAT_BT_VACUUM);
      break;
    case BTREE_OP_DELETE_VACUUM_INSID:
      PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, &helper->time_track, PSTAT_BT_VACUUM_INSID);
      break;
    default:
      assert (false);
    }
}

template < typename Helper > static inline void
btree_perf_track_traverse_time (THREAD_ENTRY * thread_p, Helper * helper)
{
  PERF_UTIME_TRACKER_TIME (thread_p, &helper->time_track, PSTAT_BT_TRAVERSE);
  switch (helper->purpose)
    {
    case BTREE_OP_INSERT_NEW_OBJECT:
    case BTREE_OP_ONLINE_INDEX_IB_INSERT:
    case BTREE_OP_ONLINE_INDEX_TRAN_INSERT:
    case BTREE_OP_ONLINE_INDEX_UNDO_TRAN_DELETE:
    case BTREE_OP_ONLINE_INDEX_TRAN_INSERT_DF:
      PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, &helper->time_track, PSTAT_BT_INSERT_TRAVERSE);
      break;
    case BTREE_OP_INSERT_MVCC_DELID:
      PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, &helper->time_track, PSTAT_BT_MVCC_DELETE_TRAVERSE);
      break;
    case BTREE_OP_INSERT_MARK_DELETED:
      PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, &helper->time_track, PSTAT_BT_MARK_DELETE_TRAVERSE);
      break;
    case BTREE_OP_INSERT_UNDO_PHYSICAL_DELETE:
      PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, &helper->time_track, PSTAT_BT_UNDO_DELETE_TRAVERSE);
      break;
    case BTREE_OP_DELETE_OBJECT_PHYSICAL:
    case BTREE_OP_DELETE_OBJECT_PHYSICAL_POSTPONED:
    case BTREE_OP_ONLINE_INDEX_TRAN_DELETE:
      PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, &helper->time_track, PSTAT_BT_DELETE_TRAVERSE);
      break;
    case BTREE_OP_DELETE_UNDO_INSERT:
    case BTREE_OP_ONLINE_INDEX_UNDO_TRAN_INSERT:
      PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, &helper->time_track, PSTAT_BT_UNDO_INSERT_TRAVERSE);
      break;
    case BTREE_OP_DELETE_UNDO_INSERT_DELID:
      PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, &helper->time_track, PSTAT_BT_UNDO_MVCC_DELETE_TRAVERSE);
      break;
    case BTREE_OP_DELETE_VACUUM_OBJECT:
      PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, &helper->time_track, PSTAT_BT_VACUUM_TRAVERSE);
      break;
    case BTREE_OP_DELETE_VACUUM_INSID:
      PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, &helper->time_track, PSTAT_BT_VACUUM_INSID_TRAVERSE);
      break;
    default:
      assert (false);
    }
}

static inline void
btree_perf_ovf_oids_fix_time (THREAD_ENTRY * thread_p, PERF_UTIME_TRACKER * track)
{
  PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, track, PSTAT_BT_FIX_OVF_OIDS);
}

static inline void
btree_perf_unique_lock_time (THREAD_ENTRY * thread_p, PERF_UTIME_TRACKER * track, LOCK lock)
{
  if (lock == S_LOCK)
    {
      PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, track, PSTAT_BT_UNIQUE_RLOCKS);
    }
  else
    {
      PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, track, PSTAT_BT_UNIQUE_WLOCKS);
    }
}

/* B-tree redo recovery flags. They are additional to
 * LOG_RV_RECORD_MODIFY_MASK.
 */
/* Flag record belongs to overflow node. */
#define BTREE_RV_OVERFLOW_FLAG		0x2000
/* Flag redo data contains debugging info. */
#define BTREE_RV_DEBUG_INFO_FLAG		0x1000
/* Exclusive b-tree redo flags mask. */
#define BTREE_RV_EXCLUSIVE_FLAGS_MASK	0x3C00
/* The available flags are 0x0800 and 0x0400. B-tree recovery needs 10 bits
 * for around 820 maximum possible slots.
 * IO_MAX_PAGE_SIZE / (slot size + min record size) = 16k/20 ~= 820.
 *
 * NOTE: 0x0800 flag is already used for insert new key and MVCC delete recovery.
 */

/* B-tree redo recovery flags mask. */
#define BTREE_RV_FLAGS_MASK \
  (LOG_RV_RECORD_MODIFY_MASK | BTREE_RV_EXCLUSIVE_FLAGS_MASK)

/* Set overflow flag for redo. */
#define BTREE_RV_SET_OVERFLOW_NODE(addr) \
  ((addr)->offset |= BTREE_RV_OVERFLOW_FLAG)

#if !defined (NDEBUG)
/* Set debug info for redo.*/
#define BTREE_RV_REDO_SET_DEBUG_INFO(addr, rv_ptr, btid_int, id) \
  do \
    { \
      assert ((addr) != NULL); \
      assert ((rv_ptr) != NULL); \
      assert ((btid_int) != NULL); \
      assert (!BTREE_RV_HAS_DEBUG_INFO ((addr)->offset)); \
      if (or_packed_domain_size (btid_int->key_type, 0) > BTID_DOMAIN_CHECK_MAX_SIZE) \
        { \
	  /* Too much space required. Give up packing debug info. */ \
	  break; \
	} \
      /* Put debug ID. */ \
      OR_PUT_INT (rv_ptr, id); \
      (rv_ptr) += OR_INT_SIZE; \
      /* Put unique_pk */ \
      OR_PUT_INT (rv_ptr, (btid_int)->unique_pk); \
      (rv_ptr) += OR_INT_SIZE; \
      if (BTREE_IS_UNIQUE ((btid_int)->unique_pk)) \
	{ \
	  /* Put topclass_oid. */ \
	  OR_PUT_OID (rv_ptr, &(btid_int)->topclass_oid); \
	  (rv_ptr) += OR_OID_SIZE; \
	} \
      /* Put key type. */ \
      (rv_ptr) = or_pack_domain (rv_ptr, btid_int->key_type, 0, 0); \
      (rv_ptr) = PTR_ALIGN (rv_ptr, INT_ALIGNMENT); \
      (addr)->offset |= BTREE_RV_DEBUG_INFO_FLAG; \
    } \
  while (false)

/* Save debug info for redo and possible undo. Expected rv_undo_pptr is a
 * char** argument (that can be NULL).
 */
#define BTREE_RV_UNDOREDO_SET_DEBUG_INFO(addr, rv_redo_ptr, rv_undo_ptr, btid_int, id) \
  do \
    { \
      char *save_rv_redo_ptr = (rv_redo_ptr); \
      BTREE_RV_REDO_SET_DEBUG_INFO (addr, rv_redo_ptr, btid_int, id); \
      if ((rv_undo_ptr) != NULL) \
	{ \
	  memcpy (rv_undo_ptr, save_rv_redo_ptr, CAST_BUFLEN ((rv_redo_ptr) - save_rv_redo_ptr)); \
	  (rv_undo_ptr) += CAST_BUFLEN ((rv_redo_ptr) - save_rv_redo_ptr); \
	} \
    } \
  while (false)


#define BTREE_RV_DEBUG_INFO_MAX_SIZE \
  (OR_INT_SIZE /* Debug ID. */ \
   + OR_INT_SIZE /* unique_pk */ \
   + OR_OID_SIZE /* topclass_oid */ \
   + BTID_DOMAIN_CHECK_MAX_SIZE /* key_type. */)
#endif /* !NDEBUG */

/* Is flag for overflow node set? */
#define BTREE_RV_IS_OVERFLOW_NODE(flags) \
  ((flags & BTREE_RV_OVERFLOW_FLAG) != 0)
/* Is flag for debug info set? */
#define BTREE_RV_HAS_DEBUG_INFO(flags) \
  ((flags & BTREE_RV_DEBUG_INFO_FLAG) != 0)

/* Flag used only in context of insert new key. */
/* The flag is used to update page maximum key length. */
#define BTREE_RV_UPDATE_MAX_KEY_LEN			0x0800
#define BTREE_RV_SET_UPDATE_MAX_KEY_LEN(addr) \
  ((addr)->offset |= BTREE_RV_UPDATE_MAX_KEY_LEN)
#define BTREE_RV_IS_UPDATE_MAX_KEY_LEN(flags) \
  ((flags & BTREE_RV_UPDATE_MAX_KEY_LEN) != 0)

/* Flag used only in context of MVCC delete. */
/* The flag is used to undo delete object inserted by same transaction. The insert ID must also match. */
#define BTREE_RV_UNDO_MVCCDEL_MYOBJ			0x0800
#define BTREE_RV_SET_UNDO_MVCCDEL_MYOBJ(addr) \
  ((addr)->offset |= BTREE_RV_UNDO_MVCCDEL_MYOBJ)
#define BTREE_RV_IS_UNDO_MVCCDEL_MYOBJ(flags) \
  ((flags & BTREE_RV_UNDO_MVCCDEL_MYOBJ) != 0)

/* Default buffer size of redo recovery changes. Should cover all cases. */
/* Just a rough estimation */
const size_t BTREE_RV_BUFFER_SIZE =
#if defined (NDEBUG)
  (3 * LOG_RV_RECORD_UPDPARTIAL_ALIGNED_SIZE (BTREE_OBJECT_MAX_SIZE));
#else /* !NDEBUG */
  (4 * LOG_RV_RECORD_UPDPARTIAL_ALIGNED_SIZE (BTREE_OBJECT_MAX_SIZE) + BTREE_RV_DEBUG_INFO_MAX_SIZE);
#endif /* !NDEBUG */

static void
BTREE_RV_GET_DATA_LENGTH (const char *rv_ptr, const char *rv_start, int &rv_length)
{
  assert (rv_ptr != NULL);
  assert (rv_start != NULL);
  rv_length = CAST_BUFLEN (rv_ptr - rv_start);
  assert (0 <= rv_length && (size_t) rv_length <= BTREE_RV_BUFFER_SIZE);
}

/* Debug identifiers to help with detecting recovery issues. */
enum btree_rv_debug_id
{
  BTREE_RV_REDO_NO_ID = 0,
  BTREE_RV_DEBUG_ID_INSERT_DELID,
  BTREE_RV_DEBUG_ID_START_OVF,
  BTREE_RV_DEBUG_ID_INS_NEW_OVF,
  BTREE_RV_DEBUG_ID_INS_OLD_OVF,
  BTREE_RV_DEBUG_ID_UNIQUE,
  BTREE_RV_DEBUG_ID_NON_UNIQUE,
  BTREE_RV_DEBUG_ID_REM_INSID,
  BTREE_RV_DEBUG_ID_REM_DELID_UNIQUE,
  BTREE_RV_DEBUG_ID_REM_DELID_NON_UNIQUE,
  BTREE_RV_DEBUG_ID_OVF_REPLACE,
  BTREE_RV_DEBUG_ID_SWAP_LEAF,
  BTREE_RV_DEBUG_ID_OVF_LINK,
  BTREE_RV_DEBUG_ID_LAST_OID,
  BTREE_RV_DEBUG_ID_REM_OBJ,
  BTREE_RV_DEBUG_ID_INS_KEY,
  BTREE_RV_DEBUG_ID_UNDO_INS_UNQ_MUPD,
  BTREE_RV_DEBUG_ID_INS_REM_LEAF_LAST
};
typedef enum btree_rv_debug_id BTREE_RV_DEBUG_ID;

/* b-tree debug logging */
#define btree_log_if_enabled(...) \
  if (prm_get_bool_value(PRM_ID_LOG_BTREE_OPS)) _er_log_debug (ARG_FILE_LINE, __VA_ARGS__)
#define btree_log(prefix, msg, ...) \
  _er_log_debug (ARG_FILE_LINE, prefix LOG_THREAD_TRAN_MSG ": " msg "\n", \
                 LOG_THREAD_TRAN_ARGS (thread_get_thread_entry_info ()), __VA_ARGS__)
#define btree_insert_log(helper, msg, ...) \
  if ((helper)->log_operations) btree_log ("BTREE_INSERT ", msg, __VA_ARGS__)
#define btree_delete_log(helper, msg, ...) \
  if ((helper)->log_operations) btree_log ("BTREE_DELETE ", msg, __VA_ARGS__)

/* logging btid */
#define BTREE_ID_MSG "index = %d, %d|%d"

/* logging b-tree mvcc info */
#define BTREE_MVCC_INFO_AS_ARGS(mvcc_info) \
  (unsigned long long) BTREE_MVCC_INFO_INSID (mvcc_info), (unsigned long long) BTREE_MVCC_INFO_DELID (mvcc_info)

/* logging b-tree object info */
#define BTREE_OBJINFO_MSG(name) \
  name " { OID = %d|%d|%d, CLASS = %d|%d|%d, MVCC_INFO = %llu|%llu } "
#define BTREE_OBJINFO_AS_ARGS(objinfo) \
  OID_AS_ARGS (&((objinfo)->oid)), \
  OID_AS_ARGS (&((objinfo)->class_oid)), \
  BTREE_MVCC_INFO_AS_ARGS (&((objinfo)->mvcc_info))

/* logging a key value (stored as char *) */
#define BTREE_PRINT_KEY_MSG(key) key " = %.32s"
#define BTREE_PRINT_KEY_ARGS(key) (key) != NULL ? (key) : "** UNKNOWN KEY **"

/* logging insert helper */
#define BTREE_INSERT_HELPER_MSG(tabs) \
  tabs "INSERT HELPER: \n" \
  tabs "\t" BTREE_OBJINFO_MSG("obj_info") "\n" \
  tabs "\t" "purpose = %s \n" \
  tabs "\t" "op_type = %s \n" \
  tabs "\t" BTREE_PRINT_KEY_MSG("printed_key") "... (sha1 = %08x | %08x | %08x | %08x | %08x) \n"
#define BTREE_INSERT_HELPER_AS_ARGS(helper) \
  BTREE_OBJINFO_AS_ARGS (&(helper)->obj_info), \
  btree_purpose_to_string ((helper)->purpose), \
  btree_op_type_to_string ((helper)->op_type), \
  BTREE_PRINT_KEY_ARGS((helper)->printed_key), SHA1_AS_ARGS (&(helper)->printed_key_sha1)

/* logging delete helper */
#define BTREE_DELETE_HELPER_MSG(tabs) \
  tabs "DELETE HELPER: \n" \
  tabs "\t" BTREE_OBJINFO_MSG("object_info") "\n" \
  tabs "\t" "purpose = %s \n " \
  tabs "\t" "op_type = %s \n" \
  tabs "\t" BTREE_PRINT_KEY_MSG("printed_key") "... (sha1 = %08x | %08x | %08x | %08x | %08x) \n" \
  tabs "\t" "match_mvccinfo = %llu|%llu \n"
#define BTREE_DELETE_HELPER_AS_ARGS(helper) \
  BTREE_OBJINFO_AS_ARGS (&(helper)->object_info), \
  btree_purpose_to_string ((helper)->purpose), \
  btree_op_type_to_string ((helper)->op_type), \
  BTREE_PRINT_KEY_ARGS((helper)->printed_key), SHA1_AS_ARGS (&(helper)->printed_key_sha1), \
  BTREE_MVCC_INFO_AS_ARGS (&(helper)->match_mvccinfo)

/* log changes during insert */
#define BTREE_INSERT_MODIFY_MSG(desc) \
  desc ": \n" \
  BTREE_INSERT_HELPER_MSG("\t") \
  "\t" PGBUF_PAGE_MODIFY_MSG("%s page") "\n" \
  "\t" "slot = %d \n" \
  "\t" "record new size = %d \n" \
  "\t" BTREE_ID_MSG "\n"
#define BTREE_INSERT_MODIFY_ARGS(thread_p, helper, page, save_lsa, is_leaf, slotid, new_size, btid) \
  BTREE_INSERT_HELPER_AS_ARGS (helper), \
  (is_leaf) ? "leaf" : "overflow", PGBUF_PAGE_MODIFY_ARGS(page, save_lsa), \
  slotid, \
  new_size, \
  BTID_AS_ARGS (btid)

/* log changes during delete */
#define BTREE_DELETE_MODIFY_MSG(desc) \
  desc ": \n" \
  BTREE_DELETE_HELPER_MSG("\t") \
  "\t" PGBUF_PAGE_MODIFY_MSG("%s page") "\n" \
  "\t" "slot = %d \n" \
  "\t" "record new size = %d \n" \
  "\t" BTREE_ID_MSG "\n"
#define BTREE_DELETE_MODIFY_ARGS(thread_p, helper, page, save_lsa, is_leaf, slotid, new_size, btid) \
  BTREE_DELETE_HELPER_AS_ARGS (helper), \
  (is_leaf) ? "leaf" : "overflow", PGBUF_PAGE_MODIFY_ARGS(page, save_lsa), \
  slotid, \
  new_size, \
  BTID_AS_ARGS (btid)

/*
 * Online index loading
 */

/* Online index states */
/* Include MVCCID_ALL_VISIBLE when we set a flag. */
const MVCCID BTREE_ONLINE_INDEX_NORMAL_FLAG_STATE = MVCCID_ALL_VISIBLE;
const MVCCID BTREE_ONLINE_INDEX_INSERT_FLAG_STATE = 0x4000000000000000 | MVCCID_ALL_VISIBLE;
const MVCCID BTREE_ONLINE_INDEX_DELETE_FLAG_STATE = 0x8000000000000000 | MVCCID_ALL_VISIBLE;
const MVCCID BTREE_ONLINE_INDEX_FLAG_MASK = 0xC000000000000000;
const MVCCID BTREE_ONLINE_INDEX_MVCCID_MASK = ~0xC000000000000000;

typedef struct btree_helper BTREE_HELPER;
struct btree_helper
{
  BTREE_INSERT_HELPER insert_helper;
  BTREE_DELETE_HELPER delete_helper;
};

/*
 * Static functions
 */

STATIC_INLINE PAGE_PTR btree_fix_root_with_info (THREAD_ENTRY * thread_p, BTID * btid, PGBUF_LATCH_MODE latch_mode,
						 VPID * root_vpid_p, BTREE_ROOT_HEADER ** root_header_p,
						 BTID_INT * btid_int_p) __attribute__ ((ALWAYS_INLINE));

STATIC_INLINE bool btree_is_fence_key (PAGE_PTR leaf_page, PGSLOTID slotid) __attribute__ ((ALWAYS_INLINE));

STATIC_INLINE int btree_count_oids (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * record, char *object_ptr,
				    OID * oid, OID * class_oid, MVCC_REC_HEADER * mvcc_header, bool * stop, void *args)
  __attribute__ ((ALWAYS_INLINE));

static int btree_store_overflow_key (THREAD_ENTRY * thread_p, BTID_INT * btid, DB_VALUE * key, int size,
				     BTREE_NODE_TYPE node_type, VPID * firstpg_vpid);
static int btree_load_overflow_key (THREAD_ENTRY * thread_p, BTID_INT * btid, VPID * firstpg_vpid, DB_VALUE * key,
				    BTREE_NODE_TYPE node_type);
static int btree_delete_overflow_key (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR page_ptr, INT16 slot_id,
				      BTREE_NODE_TYPE node_type);
static void btree_write_fixed_portion_of_non_leaf_record (RECDES * rec, NON_LEAF_REC * nlf_rec);
static void btree_read_fixed_portion_of_non_leaf_record (RECDES * rec, NON_LEAF_REC * nlf_rec);
static void btree_write_fixed_portion_of_non_leaf_record_to_orbuf (OR_BUF * buf, NON_LEAF_REC * nlf_rec);
static int btree_read_fixed_portion_of_non_leaf_record_from_orbuf (OR_BUF * buf, NON_LEAF_REC * nlf_rec);
static void btree_append_oid (RECDES * rec, OID * oid);
STATIC_INLINE void btree_add_mvccid (RECDES * rec, int oid_offset, int mvccid_offset, MVCCID mvccid, short flag,
				     char **rv_undo_data_ptr, char **rv_redo_data_ptr) __attribute__ ((ALWAYS_INLINE));
STATIC_INLINE void btree_set_mvccid (RECDES * rec, int mvccid_offset, MVCCID * p_mvccid,
				     char **rv_undo_data_ptr, char **rv_redo_data_ptr) __attribute__ ((ALWAYS_INLINE));
static inline void btree_remove_mvccid (RECDES * record, int oid_offset, int mvccid_offset, short flag,
					char **rv_undo_data_ptr, char **rv_redo_data_ptr);
static void btree_record_append_object (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * record,
					BTREE_NODE_TYPE node_type, BTREE_OBJECT_INFO * object_info,
					char **rv_undo_data_ptr, char **rv_redo_data_ptr);
static void btree_insert_object_ordered_by_oid (THREAD_ENTRY * thread_p, RECDES * record, BTID_INT * btid_int,
						BTREE_OBJECT_INFO * object_info, char **rv_undo_data_ptr,
						char **rv_redo_data_ptr, int *offset_to_objptr);
static int btree_start_overflow_page (THREAD_ENTRY * thread_p, BTID_INT * btid_int, BTREE_OBJECT_INFO * object_info,
				      VPID * first_overflow_vpid, VPID * near_vpid, VPID * new_vpid,
				      PAGE_PTR * new_page_ptr);
static int btree_read_record_without_decompression (THREAD_ENTRY * thread_p, BTID_INT * btid, RECDES * Rec,
						    DB_VALUE * key, void *rec_header, BTREE_NODE_TYPE node_type,
						    bool * clear_key, int *offset, int copy);
static PAGE_PTR btree_get_new_page (THREAD_ENTRY * thread_p, BTID_INT * btid, VPID * vpid, VPID * near_vpid);
static int btree_search_nonleaf_page (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR page_ptr, DB_VALUE * key,
				      INT16 * slot_id, VPID * child_vpid, page_key_boundary * page_bounds);
static int btree_search_leaf_page (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR page_ptr, DB_VALUE * key,
				   BTREE_SEARCH_KEY_HELPER * search_key);
static int btree_leaf_is_key_between_min_max (THREAD_ENTRY * thread_p, BTID_INT * btid_int, PAGE_PTR leaf,
					      DB_VALUE * key, BTREE_SEARCH_KEY_HELPER * search_key);
static int xbtree_test_unique (THREAD_ENTRY * thread_p, BTID * btid);
#if defined(ENABLE_UNUSED_FUNCTION)
static int btree_get_subtree_stats (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR pg_ptr, BTREE_STATS_ENV * env);
#endif
static int btree_get_stats_midxkey (THREAD_ENTRY * thread_p, BTREE_STATS_ENV * env, DB_MIDXKEY * midxkey);
static int btree_get_stats_key (THREAD_ENTRY * thread_p, BTREE_STATS_ENV * env, MVCC_SNAPSHOT * mvcc_snapshot);
static int btree_get_stats_with_AR_sampling (THREAD_ENTRY * thread_p, BTREE_STATS_ENV * env);
static int btree_get_stats_with_fullscan (THREAD_ENTRY * thread_p, BTREE_STATS_ENV * env);
static DISK_ISVALID btree_check_page_key (THREAD_ENTRY * thread_p, const OID * class_oid_p, BTID_INT * btid,
					  const char *btname, PAGE_PTR page_ptr, VPID * page_vpid);
static DISK_ISVALID btree_check_pages (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR pg_ptr, VPID * pg_vpid);
static DISK_ISVALID btree_verify_subtree (THREAD_ENTRY * thread_p, const OID * class_oid_p, BTID_INT * btid,
					  const char *btname, PAGE_PTR pg_ptr, VPID * pg_vpid, BTREE_NODE_INFO * INFO);
static int btree_get_subtree_capacity (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR pg_ptr, BTREE_CAPACITY * cpc);
static void btree_print_space (FILE * fp, int n);
static int btree_delete_meta_record (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR page_ptr, int slot_id);
static int btree_merge_root (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR P, PAGE_PTR Q, PAGE_PTR R);
static int btree_merge_node (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR P, PAGE_PTR Q, PAGE_PTR R,
			     INT16 p_slot_id, VPID * child_vpid, BTREE_MERGE_STATUS status);
static int btree_node_size_uncompressed (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR page_ptr);
static BTREE_MERGE_STATUS btree_node_mergeable (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR L, PAGE_PTR R);
static DB_VALUE *btree_find_split_point (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR page_ptr, int *mid_slot,
					 DB_VALUE * key, BTREE_INSERT_HELPER * helper, bool * clear_midkey);
static int btree_split_next_pivot (BTREE_NODE_SPLIT_INFO * split_info, float new_value, int max_index);
static int btree_split_find_pivot (int total, BTREE_NODE_SPLIT_INFO * split_info);
static int btree_split_node (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR P, PAGE_PTR Q, PAGE_PTR R,
			     VPID * P_vpid, VPID * Q_vpid, VPID * R_vpid, INT16 p_slot_id, BTREE_NODE_TYPE node_type,
			     DB_VALUE * key, BTREE_INSERT_HELPER * helper, VPID * child_vpid);
static int btree_split_root (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR P, PAGE_PTR Q, PAGE_PTR R,
			     VPID * P_vpid, VPID * Q_vpid, VPID * R_vpid, BTREE_NODE_TYPE node_type, DB_VALUE * key,
			     BTREE_INSERT_HELPER * helper, VPID * child_vpid);
static int btree_find_lower_bound_leaf (THREAD_ENTRY * thread_p, BTREE_SCAN * BTS, BTREE_STATS * stat_info_p);
static PAGE_PTR btree_find_leftmost_leaf (THREAD_ENTRY * thread_p, BTID * btid, VPID * pg_vpid,
					  BTREE_STATS * stat_info_p);
static PAGE_PTR btree_find_rightmost_leaf (THREAD_ENTRY * thread_p, BTID * btid, VPID * pg_vpid,
					   BTREE_STATS * stat_info_p);
static PAGE_PTR btree_find_AR_sampling_leaf (THREAD_ENTRY * thread_p, BTID * btid, VPID * pg_vpid,
					     BTREE_STATS * stat_info_p, bool * found_p);
static PAGE_PTR btree_find_boundary_leaf (THREAD_ENTRY * thread_p, BTID * btid, VPID * pg_vpid, BTREE_STATS * stat_info,
					  BTREE_BOUNDARY where);
static int btree_find_next_index_record (THREAD_ENTRY * thread_p, BTREE_SCAN * bts);
static int btree_find_next_index_record_holding_current (THREAD_ENTRY * thread_p, BTREE_SCAN * bts, RECDES * peek_rec);
static int btree_find_next_index_record_holding_current_helper (THREAD_ENTRY * thread_p, BTREE_SCAN * bts,
								PAGE_PTR first_page);
static int btree_apply_key_range_and_filter (THREAD_ENTRY * thread_p, BTREE_SCAN * bts, bool is_iss,
					     bool * key_range_satisfied, bool * key_filter_satisfied,
					     bool need_to_check_null);
static int btree_dump_curr_key (THREAD_ENTRY * thread_p, BTREE_SCAN * bts, FILTER_INFO * filter, OID * oid,
				INDX_SCAN_ID * iscan_id);
static DISK_ISVALID btree_find_key_from_leaf (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR pg_ptr, int key_cnt,
					      OID * oid, DB_VALUE * key, bool * clear_key);
static DISK_ISVALID btree_find_key_from_nleaf (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR pg_ptr, int key_cnt,
					       OID * oid, DB_VALUE * key, bool * clear_key);
static DISK_ISVALID btree_find_key_from_page (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR pg_ptr, OID * oid,
					      DB_VALUE * key, bool * clear_key);

/* Dump & verify routines */
static void btree_dump_root_header (THREAD_ENTRY * thread_p, FILE * fp, PAGE_PTR page_ptr);
static void btree_dump_leaf_record (THREAD_ENTRY * thread_p, FILE * fp, BTID_INT * btid, RECDES * rec, int n);
static void btree_dump_non_leaf_record (THREAD_ENTRY * thread_p, FILE * fp, BTID_INT * btid, RECDES * rec, int n,
					int print_key);
static void btree_dump_page (THREAD_ENTRY * thread_p, FILE * fp, const OID * class_oid_p, BTID_INT * btid,
			     const char *btname, PAGE_PTR page_ptr, VPID * pg_vpid, int depth, int level);

static void btree_dump_page_with_subtree (THREAD_ENTRY * thread_p, FILE * fp, BTID_INT * btid, PAGE_PTR pg_ptr,
					  VPID * pg_vpid, int depth, int level);

#if !defined(NDEBUG)
static DB_VALUE *btree_set_split_point (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR page_ptr, INT16 mid_slot,
					DB_VALUE * key, bool * clear_midkey);
static void btree_split_test (THREAD_ENTRY * thread_p, BTID_INT * btid, DB_VALUE * key, VPID * S_vpid, PAGE_PTR S_page,
			      BTREE_NODE_TYPE node_type);
static int btree_verify_node (THREAD_ENTRY * thread_p, BTID_INT * btid_int, PAGE_PTR page_ptr);
static int btree_verify_nonleaf_node (THREAD_ENTRY * thread_p, BTID_INT * btid_int, PAGE_PTR page_ptr);
static int btree_verify_leaf_node (THREAD_ENTRY * thread_p, BTID_INT * btid_int, PAGE_PTR page_ptr);
#endif

static void btree_set_unknown_key_error (THREAD_ENTRY * thread_p, BTID * btid, DB_VALUE * key, const char *debug_msg);
static int btree_rv_write_log_record_for_key_insert (char *log_rec, int *log_length, INT16 key_len, RECDES * recp);

static int btree_rv_write_log_record (char *log_rec, int *log_length, RECDES * recp, BTREE_NODE_TYPE node_type);

static int btree_find_oid_and_its_page (THREAD_ENTRY * thread_p, BTID_INT * btid_int, OID * oid, PAGE_PTR leaf_page,
					BTREE_OP_PURPOSE purpose, BTREE_MVCC_INFO * match_mvccinfo,
					RECDES * leaf_record, LEAF_REC * leaf_rec_info, int after_key_offset,
					PAGE_PTR * found_page, PAGE_PTR * prev_page, int *offset_to_object,
					BTREE_MVCC_INFO * object_mvcc_info);
static int btree_find_oid_does_mvcc_info_match (THREAD_ENTRY * thread_p, BTREE_MVCC_INFO * mvcc_info,
						BTREE_OP_PURPOSE purpose, BTREE_MVCC_INFO * match_mvccinfo,
						bool * is_match);
static int btree_find_oid_from_leaf (THREAD_ENTRY * thread_p, BTID_INT * btid, RECDES * leaf_record,
				     int after_key_offset, OID * oid, BTREE_MVCC_INFO * match_mvccinfo,
				     BTREE_OP_PURPOSE purpose, int *offset_to_object, BTREE_MVCC_INFO * mvcc_info);
static int btree_find_oid_from_ovfl (THREAD_ENTRY * thread_p, BTID_INT * btid_int, PAGE_PTR overflow_page, OID * oid,
				     BTREE_OP_PURPOSE purpose, BTREE_MVCC_INFO * match_mvccinfo, int *offset_to_object,
				     BTREE_MVCC_INFO * mvcc_info);
static int btree_leaf_get_vpid_for_overflow_oids (RECDES * rec, VPID * vpid);
static int btree_record_get_last_object (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * recp,
					 BTREE_NODE_TYPE node_type, int after_key_offset, OID * oidp, OID * class_oid,
					 BTREE_MVCC_INFO * mvcc_info, int *last_oid_mvcc_offset);
static void btree_record_remove_last_object (THREAD_ENTRY * thread_p, BTID_INT * btid, RECDES * recp,
					     BTREE_NODE_TYPE node_type, int last_oid_mvcc_offset,
					     char **rv_undo_data_ptr, char **rv_redo_data_ptr);
static char *btree_leaf_get_nth_oid_ptr (BTID_INT * btid, RECDES * recp, BTREE_NODE_TYPE node_type, int oid_list_offset,
					 int n);
static void btree_leaf_set_flag (RECDES * recp, short record_flag);
static void btree_leaf_clear_flag (RECDES * recp, short record_flag);
static short btree_leaf_get_flag (RECDES * recp);
static bool btree_leaf_is_flaged (RECDES * recp, short record_flag);
static void btree_record_object_set_mvcc_flags (char *data, short mvcc_flags);
static void btree_record_object_clear_mvcc_flags (char *rec_data, short mvcc_flags);
static INLINE short btree_record_object_get_mvcc_flags (char *data) __attribute__ ((ALWAYS_INLINE));
static INLINE bool btree_record_object_is_flagged (char *data, short mvcc_flag) __attribute__ ((ALWAYS_INLINE));
static void btree_leaf_record_handle_first_overflow (THREAD_ENTRY * thread_p, RECDES * recp, BTID_INT * btid_int,
						     char **rv_undo_data_ptr, char **rv_redo_data_ptr);
static int btree_record_get_num_oids (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * rec, int offset,
				      BTREE_NODE_TYPE node_type);
static int btree_record_get_num_visible_oids (THREAD_ENTRY * thread_p, BTID_INT * btid, RECDES * rec, int oid_offset,
					      BTREE_NODE_TYPE node_type, int *max_visible_oids,
					      MVCC_SNAPSHOT * mvcc_snapshot, int *num_visible);
static int btree_get_num_visible_oids_from_all_ovf (THREAD_ENTRY * thread_p, BTID_INT * btid, VPID * first_ovfl_vpid,
						    int *num_visible_oids, int *max_visible_oids,
						    MVCC_SNAPSHOT * mvcc_snapshot);
static void btree_write_default_split_info (BTREE_NODE_SPLIT_INFO * info);
static int btree_set_vpid_previous_vpid (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR page_p, VPID * prev);
static int btree_compare_individual_key_value (DB_VALUE * key1, DB_VALUE * key2, TP_DOMAIN * key_domain);
static int btree_get_next_page_vpid (THREAD_ENTRY * thread_p, PAGE_PTR leaf_page, VPID * next_vpid);
static PAGE_PTR btree_get_next_page (THREAD_ENTRY * thread_p, PAGE_PTR page_p);
static int btree_range_opt_check_add_index_key (THREAD_ENTRY * thread_p, BTREE_SCAN * bts,
						MULTI_RANGE_OPT * multi_range_opt, OID * p_new_oid, bool * key_added);
static int btree_top_n_items_binary_search (RANGE_OPT_ITEM ** top_n_items, int *att_idxs, TP_DOMAIN ** domains,
					    bool * desc_order, DB_VALUE * new_key_values, int num_keys, int first,
					    int last, int *new_pos);
static int btree_iss_set_key (BTREE_SCAN * bts, INDEX_SKIP_SCAN * iss);
static int btree_insert_mvcc_delid_into_page (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR page_ptr,
					      BTREE_NODE_TYPE node_type, DB_VALUE * key,
					      BTREE_INSERT_HELPER * insert_helper, PGSLOTID slot_id, RECDES * rec,
					      int oid_offset);
static int btree_key_append_object_as_new_overflow (THREAD_ENTRY * thread_p, BTID_INT * btid_int, PAGE_PTR leaf_page,
						    BTREE_OBJECT_INFO * object_info,
						    BTREE_INSERT_HELPER * insert_helper,
						    BTREE_SEARCH_KEY_HELPER * search_key, RECDES * leaf_rec,
						    VPID * first_ovfl_vpid);
static int btree_key_append_object_to_overflow (THREAD_ENTRY * thread_p, BTID_INT * btid_int, PAGE_PTR ovfl_page,
						BTREE_OBJECT_INFO * object_info, BTREE_INSERT_HELPER * insert_helper);
static int btree_find_free_overflow_oids_page (THREAD_ENTRY * thread_p, BTID_INT * btid, VPID * first_ovfl_vpid,
					       PAGE_PTR * overflow_page);

static int btree_delete_key_from_leaf (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR leaf_pg,
				       LEAF_REC * leafrec_pnt, BTREE_DELETE_HELPER * delete_helper,
				       BTREE_SEARCH_KEY_HELPER * search_key);
static int btree_replace_first_oid_with_ovfl_oid (THREAD_ENTRY * thread_p, BTID_INT * btid, DB_VALUE * key,
						  BTREE_DELETE_HELPER * delete_helper, PAGE_PTR leaf_page,
						  BTREE_SEARCH_KEY_HELPER * search_key, RECDES * leaf_rec,
						  VPID * ovfl_vpid);
static int btree_modify_leaf_ovfl_vpid (THREAD_ENTRY * thread_p, BTID_INT * btid_int,
					BTREE_DELETE_HELPER * delete_helper, PAGE_PTR leaf_page, RECDES * leaf_record,
					BTREE_SEARCH_KEY_HELPER * search_key, VPID * next_ovfl_vpid);
static int btree_modify_overflow_link (THREAD_ENTRY * thread_p, BTID_INT * btid_int,
				       BTREE_DELETE_HELPER * delete_helper, PAGE_PTR ovfl_page, VPID * next_ovfl_vpid);

static DISK_ISVALID btree_repair_prev_link_by_btid (THREAD_ENTRY * thread_p, BTID * btid, bool repair,
						    char *index_name);
static DISK_ISVALID btree_repair_prev_link_by_class_oid (THREAD_ENTRY * thread_p, OID * oid, BTID * idx_btid,
							 bool repair);
static bool btree_node_is_compressed (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR page_ptr);
static int btree_node_common_prefix (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR page_ptr);
static int btree_recompress_record (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * record, DB_VALUE * fence_key,
				    int old_prefix, int new_prefix);
static int btree_compress_node (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR page_ptr);
static const char *node_type_to_string (short node_type);
static char *key_type_to_string (char *buf, int buf_size, TP_DOMAIN * key_type);
static int index_attrs_to_string (char *buf, int buf_size, OR_INDEX * index_p, RECDES * recdes);
static SCAN_CODE btree_scan_for_show_index_header (THREAD_ENTRY * thread_p, DB_VALUE ** out_values, int out_cnt,
						   const char *class_name, OR_INDEX * index_p, OID * class_oid_p);
static SCAN_CODE btree_scan_for_show_index_capacity (THREAD_ENTRY * thread_p, DB_VALUE ** out_values, int out_cnt,
						     const char *class_name, OR_INDEX * index_p);
static bool btree_leaf_lsa_eq (THREAD_ENTRY * thread_p, LOG_LSA * a, LOG_LSA * b);

#if !defined(NDEBUG)
static int btree_get_node_level (THREAD_ENTRY * thread_p, PAGE_PTR page_ptr);
#endif

static BTREE_SEARCH btree_key_find_first_visible_row (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * rec,
						      int offset, BTREE_NODE_TYPE node_type, OID * oid, OID * class_oid,
						      int max_oids);
static BTREE_SEARCH btree_key_find_first_visible_row_from_all_ovf (THREAD_ENTRY * thread_p, BTID_INT * btid_int,
								   VPID * first_ovfl_vpid, OID * oid, OID * class_oid);

static int btree_or_put_mvccinfo (OR_BUF * buf, BTREE_MVCC_INFO * mvcc_info);
static int btree_or_get_mvccinfo (OR_BUF * buf, BTREE_MVCC_INFO * mvcc_info, short btree_mvcc_flags);
static int btree_or_put_object (OR_BUF * buf, BTID_INT * btid_int, BTREE_NODE_TYPE node_type,
				BTREE_OBJECT_INFO * object_info);
static int btree_or_get_object (OR_BUF * buf, BTID_INT * btid_int, BTREE_NODE_TYPE node_type, int after_key_offset,
				OID * oid, OID * class_oid, BTREE_MVCC_INFO * mvcc_info);
static char *btree_unpack_object (char *ptr, BTID_INT * btid_int, BTREE_NODE_TYPE node_type, RECDES * record,
				  int after_key_offset, OID * oid, OID * class_oid, BTREE_MVCC_INFO * mvcc_info);
static char *btree_pack_object (char *ptr, BTID_INT * btid_int, BTREE_NODE_TYPE node_type, RECDES * record,
				BTREE_OBJECT_INFO * object_info);

static int btree_search_key_and_apply_functions (THREAD_ENTRY * thread_p, BTID * btid, BTID_INT * btid_int,
						 DB_VALUE * key, BTREE_ROOT_WITH_KEY_FUNCTION * root_fnct,
						 void *root_args, BTREE_ADVANCE_WITH_KEY_FUNCTION * advance_fnct,
						 void *advance_args, BTREE_PROCESS_KEY_FUNCTION * leaf_fnct,
						 void *process_key_args, BTREE_SEARCH_KEY_HELPER * search_key,
						 PAGE_PTR * leaf_page_ptr);
static int btree_get_root_with_key (THREAD_ENTRY * thread_p, BTID * btid, BTID_INT * btid_int, DB_VALUE * key,
				    PAGE_PTR * root_page, bool * is_leaf, BTREE_SEARCH_KEY_HELPER * search_key,
				    bool * stop, bool * restart, void *other_args);
static int btree_advance_and_find_key (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
				       PAGE_PTR * crt_page, PAGE_PTR * advance_to_page, bool * is_leaf,
				       BTREE_SEARCH_KEY_HELPER * search_key, bool * stop, bool * restart,
				       void *other_args);
static int btree_key_find_unique_version_oid (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
					      PAGE_PTR * leaf_page, BTREE_SEARCH_KEY_HELPER * search_key,
					      bool * restart, void *other_args);
static int btree_key_find_and_lock_unique (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
					   PAGE_PTR * leaf_page, BTREE_SEARCH_KEY_HELPER * search_key, bool * restart,
					   void *other_args);
static int btree_key_find_and_lock_unique_of_unique (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
						     PAGE_PTR * leaf_page, BTREE_SEARCH_KEY_HELPER * search_key,
						     bool * restart, void *other_args);
static int btree_key_find_and_lock_unique_of_non_unique (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
							 PAGE_PTR * leaf_page, BTREE_SEARCH_KEY_HELPER * search_key,
							 bool * restart, void *other_args);
#if defined (SERVER_MODE)
static int btree_key_lock_object (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key, PAGE_PTR * leaf_page,
				  PAGE_PTR * overflow_page, OID * oid, OID * class_oid, LOCK lock_mode,
				  BTREE_SEARCH_KEY_HELPER * search_key, bool try_cond_lock, bool * restart,
				  bool * was_page_refixed);
#endif /* SERVER_MODE */

static int btree_key_process_objects (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * leaf_record,
				      int after_key_offset, LEAF_REC * leaf_info, BTREE_PROCESS_OBJECT_FUNCTION * func,
				      void *args);
static int btree_record_process_objects (THREAD_ENTRY * thread_p, BTID_INT * btid_int, BTREE_NODE_TYPE node_type,
					 RECDES * record, int after_key_offset, bool * stop,
					 BTREE_PROCESS_OBJECT_FUNCTION * func, void *args);
static int btree_record_satisfies_snapshot (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * record,
					    char *object_ptr, OID * oid, OID * class_oid, BTREE_MVCC_INFO * mvcc_info,
					    bool * stop, void *args);

static int btree_range_scan_read_record (THREAD_ENTRY * thread_p, BTREE_SCAN * bts);
static int btree_range_scan_advance_over_filtered_keys (THREAD_ENTRY * thread_p, BTREE_SCAN * bts);
static int btree_range_scan_descending_fix_prev_leaf (THREAD_ENTRY * thread_p, BTREE_SCAN * bts, int *key_count,
						      BTREE_NODE_HEADER ** node_header_ptr, VPID * next_vpid);
static int btree_range_scan_start (THREAD_ENTRY * thread_p, BTREE_SCAN * bts);
static int btree_range_scan_resume (THREAD_ENTRY * thread_p, BTREE_SCAN * bts);
static int btree_range_scan_count_oids_leaf_and_one_ovf (THREAD_ENTRY * thread_p, BTREE_SCAN * bts);
static int btree_scan_update_range (THREAD_ENTRY * thread_p, BTREE_SCAN * bts, key_val_range * kv_range);
static int btree_ils_adjust_range (THREAD_ENTRY * thread_p, BTREE_SCAN * bts);

static int btree_select_visible_object_for_range_scan (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * record,
						       char *object_ptr, OID * oid, OID * class_oid,
						       BTREE_MVCC_INFO * mvcc_info, bool * stop, void *args);
static int btree_range_scan_find_fk_any_object (THREAD_ENTRY * thread_p, BTREE_SCAN * bts);
static int btree_fk_object_does_exist (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * record, char *object_ptr,
				       OID * oid, OID * class_oid, BTREE_MVCC_INFO * mvcc_info, bool * stop,
				       void *args);

static int btree_insert_internal (THREAD_ENTRY * thread_p, BTID * btid, DB_VALUE * key, OID * class_oid, OID * oid,
				  int op_type, btree_unique_stats * unique_stat_info, int *unique,
				  BTREE_MVCC_INFO * mvcc_info, LOG_LSA * undo_nxlsa, BTREE_OP_PURPOSE purpose);
static int btree_undo_delete_physical (THREAD_ENTRY * thread_p, BTID * btid, DB_VALUE * key, OID * class_oid, OID * oid,
				       BTREE_MVCC_INFO * mvcc_info, LOG_LSA * undo_nxlsa);
static int btree_fix_root_for_insert (THREAD_ENTRY * thread_p, BTID * btid, BTID_INT * btid_int, DB_VALUE * key,
				      PAGE_PTR * root_page, bool * is_leaf, BTREE_SEARCH_KEY_HELPER * search_key,
				      bool * stop, bool * restart, void *other_args);
static int btree_split_node_and_advance (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
					 PAGE_PTR * crt_page, PAGE_PTR * advance_to_page, bool * is_leaf,
					 BTREE_SEARCH_KEY_HELPER * search_key, bool * stop, bool * restart,
					 void *other_args);
static int btree_get_max_new_data_size (THREAD_ENTRY * thread_p, BTID_INT * btid_int, PAGE_PTR page,
					BTREE_NODE_TYPE node_type, int key_len, BTREE_INSERT_HELPER * helper,
					bool known_to_be_found);
static int btree_key_insert_new_object (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
					PAGE_PTR * leaf_page, BTREE_SEARCH_KEY_HELPER * search_key, bool * restart,
					void *other_args);
static int btree_key_online_index_IB_insert_list (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
						  PAGE_PTR * leaf_page, BTREE_SEARCH_KEY_HELPER * search_key,
						  bool * restart, void *other_args);
static int btree_key_online_index_IB_insert (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
					     PAGE_PTR * leaf_page, BTREE_SEARCH_KEY_HELPER * search_key, bool * restart,
					     void *other_args);
static int btree_key_insert_new_key (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key, PAGE_PTR leaf_page,
				     BTREE_INSERT_HELPER * insert_helper, BTREE_SEARCH_KEY_HELPER * search_key);
static int btree_key_find_and_insert_delete_mvccid (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
						    PAGE_PTR * leaf_page, BTREE_SEARCH_KEY_HELPER * search_key,
						    bool * restart, void *other_args);
static int btree_key_insert_delete_mvccid (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
					   PAGE_PTR leaf_page, BTREE_SEARCH_KEY_HELPER * search_key,
					   BTREE_INSERT_HELPER * insert_helper, RECDES * leaf_record,
					   PAGE_PTR object_page, int offset_to_found_object);
static int btree_key_lock_and_append_object_unique (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
						    PAGE_PTR * leaf, bool * restart,
						    BTREE_SEARCH_KEY_HELPER * search_key,
						    BTREE_INSERT_HELPER * insert_helper, RECDES * leaf_record);
static int btree_key_append_object_unique (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key, PAGE_PTR leaf,
					   BTREE_SEARCH_KEY_HELPER * search_key, RECDES * leaf_record,
					   LEAF_REC * leaf_record_info, int offset_after_key,
					   BTREE_INSERT_HELPER * insert_helper, BTREE_OBJECT_INFO * first_object);
static int btree_key_append_object_non_unique (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
					       PAGE_PTR leaf, BTREE_SEARCH_KEY_HELPER * search_key,
					       RECDES * leaf_record, int offset_after_key, LEAF_REC * leaf_info,
					       BTREE_OBJECT_INFO * btree_obj, BTREE_INSERT_HELPER * insert_helper);
static int btree_key_relocate_last_into_ovf (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
					     PAGE_PTR leaf, BTREE_SEARCH_KEY_HELPER * search_key, RECDES * leaf_record,
					     LEAF_REC * leaf_record_info, int offset_after_key,
					     BTREE_INSERT_HELPER * insert_helper);
static int btree_key_append_object_into_ovf (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
					     PAGE_PTR leaf, BTREE_SEARCH_KEY_HELPER * search_key, RECDES * leaf_record,
					     LEAF_REC * leaf_record_info, BTREE_INSERT_HELPER * insert_helper,
					     BTREE_OBJECT_INFO * append_object);
#if defined (SERVER_MODE)
static bool btree_key_insert_does_leaf_need_split (THREAD_ENTRY * thread_p, BTID_INT * btid_int, PAGE_PTR leaf_page,
						   BTREE_INSERT_HELPER * insert_helper,
						   BTREE_SEARCH_KEY_HELPER * search_key);
#endif /* SERVER_MODE */
#if !defined (NDEBUG)
static void btree_key_record_check_no_visible (THREAD_ENTRY * thread_p, BTID_INT * btid_int, PAGE_PTR leaf_page,
					       PGSLOTID slotid);
#endif /* !NDEBUG */

static int btree_delete_internal (THREAD_ENTRY * thread_p, BTID * btid, OID * oid, OID * class_oid,
				  BTREE_MVCC_INFO * mvcc_info, DB_VALUE * key, OR_BUF * buffered_key, int *unique,
				  int op_type, btree_unique_stats * unique_stat_info, BTREE_MVCC_INFO * match_mvccinfo,
				  LOG_LSA * undo_nxlsa, BTREE_OBJECT_INFO * second_obj_info, BTREE_OP_PURPOSE purpose);
static int btree_fix_root_for_delete (THREAD_ENTRY * thread_p, BTID * btid, BTID_INT * btid_int, DB_VALUE * key,
				      PAGE_PTR * root_page, bool * is_leaf, BTREE_SEARCH_KEY_HELPER * search_key,
				      bool * stop, bool * restart, void *other_args);
static int btree_merge_node_and_advance (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
					 PAGE_PTR * crt_page, PAGE_PTR * advance_to_page, bool * is_leaf,
					 BTREE_SEARCH_KEY_HELPER * search_key, bool * stop, bool * restart,
					 void *other_args);
static int btree_key_delete_remove_object (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
					   PAGE_PTR * leaf_page, BTREE_SEARCH_KEY_HELPER * search_key, bool * restart,
					   void *other_args);
static int btree_key_remove_object_and_keep_visible_first (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
							   PAGE_PTR * leaf_page, BTREE_SEARCH_KEY_HELPER * search_key,
							   bool * restart, void *other_args);
static int btree_leaf_record_replace_first_with_last (THREAD_ENTRY * thread_p, BTID_INT * btid_int,
						      BTREE_DELETE_HELPER * delete_helper, PAGE_PTR leaf_page,
						      RECDES * leaf_record, BTREE_SEARCH_KEY_HELPER * search_key,
						      OID * last_oid, OID * last_class_oid,
						      BTREE_MVCC_INFO * last_mvcc_info, int offset_to_last_object);
static int btree_record_remove_object (THREAD_ENTRY * thread_p, BTID_INT * btid_int,
				       BTREE_DELETE_HELPER * delete_helper, PAGE_PTR page, RECDES * record,
				       BTREE_SEARCH_KEY_HELPER * search_key, BTREE_NODE_TYPE node_type,
				       int offset_to_object, LOG_DATA_ADDR * addr);
static void btree_record_remove_object_internal (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * record,
						 BTREE_NODE_TYPE node_type, int offset_to_object, char **rv_undo_data,
						 char **rv_redo_data, int *displacement);
static int btree_key_remove_object (THREAD_ENTRY * thread_p, DB_VALUE * key, BTID_INT * btid_int,
				    BTREE_DELETE_HELPER * delete_helper, PAGE_PTR leaf_page, RECDES * leaf_record,
				    LEAF_REC * leaf_info, int offset_after_key, BTREE_SEARCH_KEY_HELPER * search_key,
				    PAGE_PTR * overflow_page, PAGE_PTR prev_page, BTREE_NODE_TYPE node_type,
				    int offset_to_object);
static int btree_overflow_remove_object (THREAD_ENTRY * thread_p, DB_VALUE * key, BTID_INT * btid_int,
					 BTREE_DELETE_HELPER * delete_helper, PAGE_PTR * overflow_page,
					 PAGE_PTR prev_page, PAGE_PTR leaf_page, RECDES * leaf_record,
					 BTREE_SEARCH_KEY_HELPER * search_key, int offset_to_object);
static int btree_leaf_remove_object (THREAD_ENTRY * thread_p, DB_VALUE * key, BTID_INT * btid_int,
				     BTREE_DELETE_HELPER * delete_helper, PAGE_PTR leaf_page, RECDES * leaf_record,
				     LEAF_REC * leaf_rec_info, int offset_after_key,
				     BTREE_SEARCH_KEY_HELPER * search_key, int offset_to_object);
static int btree_key_remove_insert_mvccid (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
					   PAGE_PTR * leaf_page, BTREE_SEARCH_KEY_HELPER * search_key, bool * restart,
					   void *other_args);
static void btree_record_remove_insid (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * record,
				       BTREE_NODE_TYPE node_type, int offset_to_object, char **rv_undo_data,
				       char **rv_redo_data, int *displacement);
static int btree_key_remove_delete_mvccid (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
					   PAGE_PTR * leaf_page, BTREE_SEARCH_KEY_HELPER * search_key, bool * restart,
					   void *other_args);
static void btree_record_remove_delid (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * record,
				       BTREE_NODE_TYPE node_type, int offset_to_object, char **rv_undo_data,
				       char **rv_redo_data);
static void btree_record_add_delid (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * record,
				    BTREE_NODE_TYPE node_type, int offset_to_object, MVCCID delete_mvccid,
				    char **rv_undo_data, char **rv_redo_data);
static int btree_undo_mvcc_delete (THREAD_ENTRY * thread_p, BTID * btid, OR_BUF * buffered_key, OID * oid,
				   OID * class_oid, BTREE_MVCC_INFO * match_mvccinfo, LOG_LSA * undo_nxlsa);
static int btree_undo_insert_object (THREAD_ENTRY * thread_p, BTID * btid, OR_BUF * buffered_key, OID * oid,
				     OID * class_oid, MVCCID insert_mvccid, LOG_LSA * undo_nxlsa);
static int btree_undo_insert_object_unique_multiupd (THREAD_ENTRY * thread_p, BTID * btid, OR_BUF * buffered_key,
						     BTREE_OBJECT_INFO * inserted_object,
						     BTREE_OBJECT_INFO * second_object, MVCCID insert_mvccid,
						     LOG_LSA * undo_nxlsa);
static int btree_key_remove_delete_mvccid_unique (THREAD_ENTRY * thread_p, BTID_INT * btid_int,
						  BTREE_DELETE_HELPER * delete_helper,
						  BTREE_SEARCH_KEY_HELPER * search_key, PAGE_PTR leaf_page,
						  RECDES * leaf_record, PAGE_PTR overflow_page,
						  RECDES * overflow_record, BTREE_NODE_TYPE node_type,
						  int offset_to_object);
static int btree_remove_delete_mvccid_unique_internal (THREAD_ENTRY * thread_p, BTID_INT * btid_int,
						       BTREE_DELETE_HELPER * helper, PAGE_PTR leaf_page,
						       RECDES * leaf_record, BTREE_NODE_TYPE node_type,
						       PAGE_PTR overflow_page, RECDES * overflow_record,
						       int offset_to_object, char **rv_undo_data, char **rv_redo_data);
static int btree_key_remove_delete_mvccid_non_unique (THREAD_ENTRY * thread_p, BTID_INT * btid_int,
						      BTREE_DELETE_HELPER * delete_helper, PAGE_PTR page,
						      RECDES * record, PGSLOTID slotid, BTREE_NODE_TYPE node_type,
						      int offset_to_object);
static int btree_overflow_record_replace_object (THREAD_ENTRY * thread_p, BTID_INT * btid_int,
						 BTREE_DELETE_HELPER * delete_helper, PAGE_PTR overflow_page,
						 RECDES * overflow_record, int *offset_to_replaced_object,
						 BTREE_OBJECT_INFO * replacing_object);
static void btree_record_replace_object (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * record,
					 BTREE_NODE_TYPE node_type, int *offset_to_replaced,
					 BTREE_OBJECT_INFO * replacement, char **rv_undo_data, char **rv_redo_data);

static int btree_rv_record_modify_internal (THREAD_ENTRY * thread_p, LOG_RCV * rcv, bool is_undo);
static int btree_delete_postponed (THREAD_ENTRY * thread_p, BTID * btid, OR_BUF * buffered_key,
				   BTREE_OBJECT_INFO * btree_obj, MVCCID tran_mvccid, LOG_LSA * reference_lsa);

static MVCCID btree_get_creator_mvccid (THREAD_ENTRY * thread_p, PAGE_PTR root_page);
static int btree_seq_find_oid_from_ovfl (THREAD_ENTRY * thread_p, BTID_INT * btid_int, OID * oid, RECDES * ovf_record,
					 char *initial_oid_ptr, char *oid_ptr_lower_bound, char *oid_ptr_upper_bound,
					 BTREE_OP_PURPOSE purpose, BTREE_MVCC_INFO * match_mvccinfo,
					 int *offset_to_object, BTREE_MVCC_INFO * mvcc_info);

STATIC_INLINE void btree_delete_sysop_end (THREAD_ENTRY * thread_p, BTREE_DELETE_HELPER * helper)
  __attribute__ ((ALWAYS_INLINE));
STATIC_INLINE void btree_insert_sysop_end (THREAD_ENTRY * thread_p, BTREE_INSERT_HELPER * helper)
  __attribute__ ((ALWAYS_INLINE));
STATIC_INLINE const char *btree_purpose_to_string (BTREE_OP_PURPOSE purpose) __attribute__ ((ALWAYS_INLINE));
STATIC_INLINE const char *btree_op_type_to_string (int op_type) __attribute__ ((ALWAYS_INLINE));

static bool btree_is_class_oid_packed (BTID_INT * btid_int, RECDES * record, BTREE_NODE_TYPE node_type, bool is_first);
static bool btree_is_fixed_size (BTID_INT * btid_int, RECDES * record, BTREE_NODE_TYPE node_type, bool is_first);
static bool btree_is_insert_data_purpose (BTREE_OP_PURPOSE purpose);
static bool btree_is_insert_object_purpose (BTREE_OP_PURPOSE purpose);
static bool btree_is_insert_delid_purpose (BTREE_OP_PURPOSE purpose);
static bool btree_is_delete_data_purpose (BTREE_OP_PURPOSE purpose);
static bool btree_is_delete_object_purpose (BTREE_OP_PURPOSE purpose);
static void btree_rv_log_delete_object (THREAD_ENTRY * thread_p, const BTREE_DELETE_HELPER & delete_helper,
					LOG_DATA_ADDR & addr, int undo_length, int redo_length, const char *undo_data,
					const char *redo_data);
static void btree_rv_log_insert_object (THREAD_ENTRY * thread_p, const BTREE_INSERT_HELPER & insert_helper,
					LOG_DATA_ADDR & addr, int undo_length, int redo_length, const char *undo_data,
					const char *redo_data);

static inline void btree_online_index_check_state (MVCCID state);
static inline bool btree_online_index_is_insert_flag_state (MVCCID state);
static inline bool btree_online_index_is_delete_flag_state (MVCCID state);
static inline bool btree_online_index_is_normal_state (MVCCID state);
static inline void btree_online_index_set_insert_flag_state (MVCCID & state);
static inline void btree_online_index_set_delete_flag_state (MVCCID & state);
static inline void btree_online_index_set_normal_state (MVCCID & state);
static void btree_online_index_change_state (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * record,
					     BTREE_NODE_TYPE node_type, int offset_to_object, MVCCID new_state,
					     char **rv_undo_data, char **rv_redo_data);

static int btree_find_oid_with_page_and_record (THREAD_ENTRY * thread_p, BTID_INT * btid_int, OID * oid,
						PAGE_PTR leaf_page, BTREE_OP_PURPOSE purpose,
						BTREE_MVCC_INFO * match_mvccinfo, RECDES * record, LEAF_REC * leaf_info,
						int offset_after_key, PAGE_PTR * found_page, PAGE_PTR * prev_page,
						int *offset_to_object, BTREE_MVCC_INFO * object_mvcc_info,
						RECDES * new_record);

static int btree_key_online_index_tran_insert (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
					       PAGE_PTR * leaf_page, BTREE_SEARCH_KEY_HELPER * search_key,
					       bool * restart, void *other_args);

static int btree_key_online_index_tran_insert_DF (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
						  PAGE_PTR * leaf_page, BTREE_SEARCH_KEY_HELPER * search_key,
						  bool * restart, void *other_args);

static int btree_key_online_index_tran_delete (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
					       PAGE_PTR * leaf_page, BTREE_SEARCH_KEY_HELPER * search_key,
					       bool * restart, void *other_args);

static inline void btree_insert_helper_to_delete_helper (BTREE_INSERT_HELPER * insert_helper,
							 BTREE_DELETE_HELPER * delete_helper);
static inline void btree_delete_helper_to_insert_helper (BTREE_DELETE_HELPER * delete_helper,
							 BTREE_INSERT_HELPER * insert_helper);

static inline bool btree_is_online_index_loading (BTREE_OP_PURPOSE purpose);
static bool btree_is_single_object_key (THREAD_ENTRY * thread_p, BTID_INT * btid_int, BTREE_NODE_TYPE node_type,
					RECDES * record, int offset_after_key);

static bool btree_check_locking_for_insert_unique (THREAD_ENTRY * thread_p, const BTREE_INSERT_HELPER * insert_helper);
static bool btree_check_locking_for_delete_unique (THREAD_ENTRY * thread_p, const BTREE_DELETE_HELPER * delete_helper);

/*
 * btree_fix_root_with_info () - Fix b-tree root page and output its VPID, header and b-tree info if requested.
 *
 * return	       : Root page pointer or NULL if fix failed.
 * thread_p (in)       : Thread entry.
 * btid (in)	       : B-tree identifier.
 * latch_mode (in)     : Page latch mode.
 * root_vpid (out)     : Output VPID of root page if not NULL.
 * root_header_p (out) : Output root header if not NULL.
 * btid_int_p (out)    : Output b-tree data if not NULL.
 */
STATIC_INLINE PAGE_PTR
btree_fix_root_with_info (THREAD_ENTRY * thread_p, BTID * btid, PGBUF_LATCH_MODE latch_mode, VPID * root_vpid_p,
			  BTREE_ROOT_HEADER ** root_header_p, BTID_INT * btid_int_p)
{
  PAGE_PTR root_page = NULL;
  VPID vpid;
  BTREE_ROOT_HEADER *root_header = NULL;

  /* Assert expected arguments. */
  assert (btid != NULL);

  /* Get root page VPID. */
  if (root_vpid_p == NULL)
    {
      root_vpid_p = &vpid;
    }
  root_vpid_p->pageid = btid->root_pageid;
  root_vpid_p->volid = btid->vfid.volid;

  /* Fix root page. */
  root_page = pgbuf_fix (thread_p, root_vpid_p, OLD_PAGE, latch_mode, PGBUF_UNCONDITIONAL_LATCH);
  if (root_page == NULL)
    {
      /* Failed fixing root page. */
      ASSERT_ERROR ();
      return NULL;
    }

  /* Get root header */
  root_header = btree_get_root_header (thread_p, root_page);
  if (root_header == NULL)
    {
      /* Error getting root header. */
      assert (false);
      pgbuf_unfix (thread_p, root_page);
      return NULL;
    }
  if (root_header_p != NULL)
    {
      /* Output root header. */
      *root_header_p = root_header;
    }

  if (btid_int_p != NULL)
    {
      /* Get b-tree info. */
      btid_int_p->sys_btid = btid;
      if (btree_glean_root_header_info (thread_p, root_header, btid_int_p) != NO_ERROR)
	{
	  assert (false);
	  pgbuf_unfix (thread_p, root_page);
	  return NULL;
	}
    }

  /* Return fixed root page. */
  return root_page;
}

/*
 * btree_is_fence_key () - Return whether the key is fence or not.
 *
 * return	  : True if key is fence.
 * leaf_page (in) : Leaf node page.
 * slotid (in)	  : Key slot ID.
 */
STATIC_INLINE bool
btree_is_fence_key (PAGE_PTR leaf_page, PGSLOTID slotid)
{
  SPAGE_SLOT *slotp = NULL;
  OID first_oid;

  assert (leaf_page != NULL);

  /* Get slot. */
  slotp = spage_get_slot (leaf_page, slotid);
  if (slotp == NULL)
    {
      /* Unexpected error. */
      assert (false);
      return false;
    }
  assert (slotp->offset_to_record > 0 && slotp->offset_to_record < (unsigned int) DB_PAGESIZE);
  assert (slotp->record_type == REC_HOME);
  assert (slotp->record_length >= OR_OID_SIZE);

  (void) or_unpack_oid (leaf_page + slotp->offset_to_record, &first_oid);

  /* Return if fence record flag is set. */
  return BTREE_OID_IS_RECORD_FLAG_SET (&first_oid, BTREE_LEAF_RECORD_FENCE);
}

#if !defined(NDEBUG)
/*
 * btree_get_node_level () -
 *
 *   return:
 *   page_ptr(in):
 *
 */
static int
btree_get_node_level (THREAD_ENTRY * thread_p, PAGE_PTR page_ptr)
{
  BTREE_NODE_HEADER *header = NULL;

  header = btree_get_node_header (thread_p, page_ptr);
  if (header == NULL)
    {
      return -1;
    }

  assert (header->node_level > 0);

  return header->node_level;
}
#endif

/*
 * btree_clear_key_value () -
 *   return: cleared flag
 *   clear_flag (in/out):
 *   key_value (in/out):
 */
bool
btree_clear_key_value (bool * clear_flag, DB_VALUE * key_value)
{
  if (*clear_flag == true || key_value->need_clear == true)
    {
      pr_clear_value (key_value);
      *clear_flag = false;
    }
  // also set null
  db_make_null (key_value);
  return *clear_flag;
}

/*
 * btree_init_temp_key_value () -
 *   return: void
 *   clear_flag (in/out):
 *   key_value (in/out):
 */
void
btree_init_temp_key_value (bool * clear_flag, DB_VALUE * key_value)
{
  db_make_null (key_value);
  *clear_flag = false;
}

/*
 * btree_create_overflow_key_file () - Create file for overflow keyes
 *
 * return   : Error code
 * btid (in): B-tree info
 *
 * Note: An overflow key file is created (permanently) and the VFID is written to the root header for the btree.
 */
int
btree_create_overflow_key_file (THREAD_ENTRY * thread_p, BTID_INT * btid)
{
  FILE_DESCRIPTORS des;
  int error_code = NO_ERROR;
  TDE_ALGORITHM tde_algo = TDE_ALGORITHM_NONE;

  VFID_SET_NULL (&btid->ovfid);

  /* initialize description of overflow heap file */
  memset (&des, 0, sizeof (des));
  des.btree_key_overflow.btid = *btid->sys_btid;	/* structure copy */
  des.btree_key_overflow.class_oid = btid->topclass_oid;
  assert (!OID_ISNULL (&des.btree_key_overflow.class_oid));
  /* create file with at least 3 pages */
  error_code = file_create_with_npages (thread_p, FILE_BTREE_OVERFLOW_KEY, 3, &des, &btid->ovfid);
  if (error_code != NO_ERROR)
    {
      return error_code;
    }
  error_code = heap_get_class_tde_algorithm (thread_p, &btid->topclass_oid, &tde_algo);
  if (error_code != NO_ERROR)
    {
      VFID_SET_NULL (&btid->ovfid);
      return error_code;
    }
  error_code = file_apply_tde_algorithm (thread_p, &btid->ovfid, tde_algo);
  if (error_code != NO_ERROR)
    {
      VFID_SET_NULL (&btid->ovfid);
      return error_code;
    }
  return error_code;
}

/*
 * btree_store_overflow_key () -
 *   return: NO_ERROR
 *   btid(in): B+tree index identifier
 *   key(in): Pointer to the overflow key memory area
 *   size(in): Overflow key memory area size
 *   node_type(in): Type of node
 *   first_overflow_page_vpid(out): Set to the first overflow key page identifier
 *
 * Note: The overflow key given is stored in a chain of pages.
 */
static int
btree_store_overflow_key (THREAD_ENTRY * thread_p, BTID_INT * btid, DB_VALUE * key, int size, BTREE_NODE_TYPE node_type,
			  VPID * first_overflow_page_vpid)
{
  RECDES rec;
  OR_BUF buf;
  VFID overflow_file_vfid;
  int ret = NO_ERROR;
  TP_DOMAIN *tp_domain;
  PR_TYPE *pr_type;
  DB_TYPE src_type, dst_type;
  DB_VALUE new_key;
  DB_VALUE *key_ptr = key;

  assert (!VFID_ISNULL (&btid->ovfid));

  if (node_type == BTREE_LEAF_NODE)
    {
      tp_domain = btid->key_type;
    }
  else
    {
      tp_domain = btid->nonleaf_key_type;
    }

  pr_type = tp_domain->type;

  src_type = DB_VALUE_DOMAIN_TYPE (key);
  dst_type = pr_type->id;

  if (src_type != dst_type)
    {
      TP_DOMAIN_STATUS status;

      assert (pr_is_string_type (src_type));
      assert (pr_is_string_type (dst_type));

      key_ptr = &new_key;
      status = tp_value_cast (key, key_ptr, tp_domain, false);
      if (status != DOMAIN_COMPATIBLE)
	{
	  assert (false);
	  goto exit_on_error;
	}

      size = btree_get_disk_size_of_key (key_ptr);
    }

  overflow_file_vfid = btid->ovfid;	/* structure copy */

  rec.area_size = size;
  rec.data = (char *) db_private_alloc (thread_p, size);
  if (rec.data == NULL)
    {
      er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_OUT_OF_VIRTUAL_MEMORY, 1, (size_t) size);
      goto exit_on_error;
    }

  or_init (&buf, rec.data, rec.area_size);

  if (pr_type->index_writeval (&buf, key_ptr) != NO_ERROR)
    {
      goto exit_on_error;
    }

  rec.length = (int) (buf.ptr - buf.buffer);

  if (overflow_insert (thread_p, &overflow_file_vfid, first_overflow_page_vpid, &rec, FILE_BTREE_OVERFLOW_KEY)
      != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto exit_on_error;
    }

  if (rec.data)
    {
      db_private_free_and_init (thread_p, rec.data);
    }

  if (key_ptr != key)
    {
      pr_clear_value (key_ptr);
    }

  return ret;

exit_on_error:

  if (rec.data)
    {
      db_private_free_and_init (thread_p, rec.data);
    }

  if (key_ptr != key)
    {
      pr_clear_value (key_ptr);
    }

  return (ret == NO_ERROR && (ret = er_errid ()) == NO_ERROR) ? ER_FAILED : ret;
}

/*
 * btree_load_overflow_key () -
 *   return: NO_ERROR
 *   btid(in): B+tree index identifier
 *   first_overflow_page_vpid(in): Overflow key first page identifier
 *   key(out): Set to the overflow key memory area
 *
 * Note: The overflow key is loaded from the pages.
 */
static int
btree_load_overflow_key (THREAD_ENTRY * thread_p, BTID_INT * btid, VPID * first_overflow_page_vpid, DB_VALUE * key,
			 BTREE_NODE_TYPE node_type)
{
  RECDES rec;
  OR_BUF buf;
  PR_TYPE *pr_type;
  int ret = NO_ERROR;

  if (node_type == BTREE_LEAF_NODE)
    {
      pr_type = btid->key_type->type;
    }
  else
    {
      pr_type = btid->nonleaf_key_type->type;
    }

  rec.area_size = overflow_get_length (thread_p, first_overflow_page_vpid);
  if (rec.area_size == -1)
    {
      return ER_FAILED;
    }

  rec.data = (char *) db_private_alloc (thread_p, rec.area_size);
  if (rec.data == NULL)
    {
      er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_OUT_OF_VIRTUAL_MEMORY, 1, (size_t) rec.area_size);
      goto exit_on_error;
    }

  if (overflow_get (thread_p, first_overflow_page_vpid, &rec, NULL) != S_SUCCESS)
    {
      goto exit_on_error;
    }

  or_init (&buf, rec.data, rec.length);

  /* we always copy overflow keys */
  if (pr_type->index_readval (&buf, key, btid->key_type, -1, true, NULL, 0) != NO_ERROR)
    {
      goto exit_on_error;
    }

  if (rec.data)
    {
      db_private_free_and_init (thread_p, rec.data);
    }

  return NO_ERROR;

exit_on_error:

  if (rec.data)
    {
      db_private_free_and_init (thread_p, rec.data);
    }

  return (ret == NO_ERROR && (ret = er_errid ()) == NO_ERROR) ? ER_FAILED : ret;
}

/*
 * btree_delete_overflow_key () -
 *   return: NO_ERROR
 *   btid(in): B+tree index identifier
 *   page_ptr(in): Page that contains the overflow key
 *   slot_id(in): Slot that contains the overflow key
 *   node_type(in): Leaf or NonLeaf page
 *
 * Note: The overflow key is deleted. This routine will not delete the btree slot containing the key.
 */
static int
btree_delete_overflow_key (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR page_ptr, INT16 slot_id,
			   BTREE_NODE_TYPE node_type)
{
  RECDES rec;
  VPID page_vpid;
  char *start_ptr;
  OR_BUF buf;
  int rc = NO_ERROR;

  assert (slot_id > 0);

  rec.area_size = -1;

  /* first read the record to get first page identifier */
  if (spage_get_record (thread_p, page_ptr, slot_id, &rec, PEEK) != S_SUCCESS)
    {
      goto exit_on_error;
    }

  /* get first page identifier */
  if (node_type == BTREE_LEAF_NODE)
    {
      int mvccids_size = 0;
      assert (btree_leaf_is_flaged (&rec, BTREE_LEAF_RECORD_OVERFLOW_KEY));

      if (btree_record_object_is_flagged (rec.data, BTREE_OID_HAS_MVCC_INSID))
	{
	  mvccids_size += OR_MVCCID_SIZE;
	}

      if (btree_record_object_is_flagged (rec.data, BTREE_OID_HAS_MVCC_DELID))
	{
	  mvccids_size += OR_MVCCID_SIZE;
	}

      if (btree_leaf_is_flaged (&rec, BTREE_LEAF_RECORD_CLASS_OID))
	{
	  start_ptr = rec.data + (2 * OR_OID_SIZE) + mvccids_size;
	}
      else
	{
	  start_ptr = rec.data + OR_OID_SIZE + mvccids_size;
	}
    }
  else
    {
      start_ptr = rec.data + NON_LEAF_RECORD_SIZE;
    }

  or_init (&buf, start_ptr, DISK_VPID_SIZE);

  page_vpid.pageid = or_get_int (&buf, &rc);
  if (rc == NO_ERROR)
    {
      page_vpid.volid = or_get_short (&buf, &rc);
    }
  if (rc != NO_ERROR)
    {
      goto exit_on_error;
    }

  if (overflow_delete (thread_p, &(btid->ovfid), &page_vpid) == NULL)
    {
      goto exit_on_error;
    }

  return NO_ERROR;

exit_on_error:

  return (rc == NO_ERROR && (rc = er_errid ()) == NO_ERROR) ? ER_FAILED : rc;
}

/*
 * Common utility routines
 */



/*
 * btree_leaf_get_vpid_for_overflow_oids () -
 *   return: error code or NO_ERROR
 *   rec(in):
 *   ovfl_vpid(out):
 */
static int
btree_leaf_get_vpid_for_overflow_oids (RECDES * rec, VPID * ovfl_vpid)
{
  OR_BUF buf;
  int rc = NO_ERROR;

  assert (btree_leaf_is_flaged (rec, BTREE_LEAF_RECORD_OVERFLOW_OIDS));

  or_init (&buf, rec->data + rec->length - DISK_VPID_ALIGNED_SIZE, DISK_VPID_SIZE);

  ovfl_vpid->pageid = or_get_int (&buf, &rc);
  if (rc == NO_ERROR)
    {
      ovfl_vpid->volid = or_get_short (&buf, &rc);
    }

  return rc;
}

/*
 * btree_leaf_record_change_overflow_link () - Modify the link of leaf record.
 *
 * return		  : Void.
 * thread_p (in)	  : Thread entry.
 * btid_int (in)	  : B-tree info.
 * leaf_record (in)	  : Leaf record.
 * new_overflow_vpid (in) : New overflow link.
 * rv_undo_data_ptr (in)  : If not null, outputs undo recovery data for changes made.
 * rv_redo_data_ptr (in)  : If not null, outputs redo recovery data for changes made.
 */
void
btree_leaf_record_change_overflow_link (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * leaf_record,
					VPID * new_overflow_vpid, char **rv_undo_data_ptr, char **rv_redo_data_ptr)
{
  char *ovf_link_ptr = NULL;
  bool undo_logging = false;
  bool redo_logging = false;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (leaf_record != NULL);
  assert (new_overflow_vpid != NULL);

  undo_logging = rv_undo_data_ptr != NULL && *rv_undo_data_ptr != NULL;
  redo_logging = rv_redo_data_ptr != NULL && *rv_redo_data_ptr != NULL;

  if (btree_leaf_is_flaged (leaf_record, BTREE_LEAF_RECORD_OVERFLOW_OIDS))
    {
      /* Leaf record already had overflow link. */
      if (VPID_ISNULL (new_overflow_vpid))
	{
	  /* Undo logging. */
	  if (undo_logging)
	    {
	      /* Log link removal. */
	      ovf_link_ptr = leaf_record->data + leaf_record->length - DISK_VPID_ALIGNED_SIZE;
	      *rv_undo_data_ptr =
		log_rv_pack_undo_record_changes (*rv_undo_data_ptr, leaf_record->length - DISK_VPID_ALIGNED_SIZE,
						 DISK_VPID_ALIGNED_SIZE, 0, ovf_link_ptr);

	      /* Log clear flag. */
	      *rv_undo_data_ptr =
		log_rv_pack_undo_record_changes (*rv_undo_data_ptr, OR_OID_SLOTID, OR_SHORT_SIZE, OR_SHORT_SIZE,
						 leaf_record->data + OR_OID_SLOTID);
	    }
	  /* Remove overflow VPID. */
	  leaf_record->length -= DISK_VPID_ALIGNED_SIZE;

	  /* Both insert and delete MVCCID's should exist. */
	  assert (btree_record_object_is_flagged (leaf_record->data, BTREE_OID_HAS_MVCC_INSID_AND_DELID));
	  /* TODO: Object is no longer fixed size and we may be able to remove unnecessary info. */

	  /* Clear BTREE_LEAF_RECORD_OVERFLOW_OIDS flag. */
	  btree_leaf_clear_flag (leaf_record, BTREE_LEAF_RECORD_OVERFLOW_OIDS);

	  /* Redo logging. */
	  if (redo_logging)
	    {
	      /* Log link removal. */
	      *rv_redo_data_ptr = log_rv_pack_redo_record_changes (*rv_redo_data_ptr, leaf_record->length,
								   DISK_VPID_ALIGNED_SIZE, 0,
								   NULL /* just * remove. */ );

	      /* Log clear flag. */
	      *rv_redo_data_ptr =
		log_rv_pack_redo_record_changes (*rv_redo_data_ptr, OR_OID_SLOTID, OR_SHORT_SIZE, OR_SHORT_SIZE,
						 leaf_record->data + OR_OID_SLOTID);
	    }
	}
      else
	{
	  assert (disk_is_page_sector_reserved (thread_p, new_overflow_vpid->volid, new_overflow_vpid->pageid)
		  != DISK_INVALID);

	  /* Update existing link. */
	  ovf_link_ptr = leaf_record->data + leaf_record->length - DISK_VPID_ALIGNED_SIZE;

	  /* Undo logging. */
	  if (undo_logging)
	    {
	      *rv_undo_data_ptr =
		log_rv_pack_undo_record_changes (*rv_undo_data_ptr, leaf_record->length - DISK_VPID_ALIGNED_SIZE,
						 DISK_VPID_ALIGNED_SIZE, DISK_VPID_ALIGNED_SIZE, ovf_link_ptr);
	    }

	  OR_PUT_VPID_ALIGNED (ovf_link_ptr, new_overflow_vpid);

	  /* Redo logging. */
	  if (redo_logging)
	    {
	      *rv_redo_data_ptr =
		log_rv_pack_redo_record_changes (*rv_redo_data_ptr, leaf_record->length - DISK_VPID_ALIGNED_SIZE,
						 DISK_VPID_ALIGNED_SIZE, DISK_VPID_ALIGNED_SIZE, ovf_link_ptr);
	    }
	}
    }
  else
    {
      /* Leaf record didn't have overflow link. */
      assert (!VPID_ISNULL (new_overflow_vpid));
      assert (disk_is_page_sector_reserved (thread_p, new_overflow_vpid->volid, new_overflow_vpid->pageid)
	      != DISK_INVALID);

      /* Undo logging for added link. */
      if (undo_logging)
	{
	  *rv_undo_data_ptr =
	    log_rv_pack_undo_record_changes (*rv_undo_data_ptr, leaf_record->length, 0, DISK_VPID_ALIGNED_SIZE, NULL);
	}

      /* Add overflow VPID. */
      ovf_link_ptr = leaf_record->data + leaf_record->length;
      OR_PUT_VPID_ALIGNED (ovf_link_ptr, new_overflow_vpid);
      /* Update record length. */
      leaf_record->length += DISK_VPID_ALIGNED_SIZE;

      /* Redo logging for added link. */
      if (redo_logging)
	{
	  *rv_redo_data_ptr =
	    log_rv_pack_redo_record_changes (*rv_redo_data_ptr, leaf_record->length - DISK_VPID_ALIGNED_SIZE, 0,
					     DISK_VPID_ALIGNED_SIZE, ovf_link_ptr);
	}

      /* First object must be fixed size to provide enough space if objects are swapped from overflow. */
      btree_leaf_record_handle_first_overflow (thread_p, leaf_record, btid_int, rv_undo_data_ptr, rv_redo_data_ptr);
    }

#if !defined (NDEBUG)
  (void) btree_check_valid_record (thread_p, btid_int, leaf_record, BTREE_LEAF_NODE, NULL);
#endif /* !NDEBUG */
}

/*
 * btree_leaf_get_first_object () - Get first object of leaf record.
 *
 * return	   : Error code.
 * btid (in)	   : B-tree info.
 * recp (in)	   : Leaf record.
 * oidp (out)	   : First object OID.
 * class_oid (out) : First object class OID.
 * mvcc_info (out) : First object MVCC info.
 */
int
btree_leaf_get_first_object (BTID_INT * btid, RECDES * recp, OID * oidp, OID * class_oid, BTREE_MVCC_INFO * mvcc_info)
{
  OR_BUF record_buffer;
  int error_code = NO_ERROR;
  int dummy_offset = 0;

  /* Assert expected arguments. */
  assert (btid != NULL);
  assert (oidp != NULL);
  /* TODO: consider class_oid and mvcc_info. Should they be required? */

  BTREE_RECORD_OR_BUF_INIT (record_buffer, recp);
  error_code = btree_or_get_object (&record_buffer, btid, BTREE_LEAF_NODE, dummy_offset, oidp, class_oid, mvcc_info);
  /* We expect first object can be successfully obtained. */
  assert (error_code == NO_ERROR);
  return error_code;
}

/*
 * btree_get_num_visible_oids_from_all_ovf () - Get the number of visible objects according to snapshot
 *						in all overflow pages.
 *
 * return		  : Error code.
 * thread_p (in)	  : Thread entry.
 * btid (in)		  : B-tree info.
 * first_ovfl_vpid (in)   : VPID of first overflow page.
 * num_visible_oids (out) : The number of visible objects.
 * max_visible_oids (in)  : Maximum allowed number of visible objects.
 * mvcc_snapshot (in)	  : Snapshot used for visibility check.
 */
static int
btree_get_num_visible_oids_from_all_ovf (THREAD_ENTRY * thread_p, BTID_INT * btid, VPID * first_ovfl_vpid,
					 int *num_visible_oids, int *max_visible_oids, MVCC_SNAPSHOT * mvcc_snapshot)
{
  RECDES ovfl_copy_rec;
  char ovfl_copy_rec_buf[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  VPID next_ovfl_vpid;
  PAGE_PTR ovfl_page = NULL;
  int ret;
  int num_node_visible_oids = 0;
  int max_page_visible_oids = 0, *p_max_page_visible_oids = NULL;

  if (max_visible_oids != NULL)
    {
      max_page_visible_oids = *max_visible_oids;
      p_max_page_visible_oids = &max_page_visible_oids;
    }
  /* not found in leaf page - search in overflow page */
  ovfl_page = NULL;

  ovfl_copy_rec.area_size = DB_PAGESIZE;
  ovfl_copy_rec.data = PTR_ALIGN (ovfl_copy_rec_buf, BTREE_MAX_ALIGN);

  /* Assert expected arguments. */
  assert (btid != NULL);
  assert (num_visible_oids != NULL);
  assert (first_ovfl_vpid != NULL);

  *num_visible_oids = 0;
  ovfl_page = NULL;
  next_ovfl_vpid = *first_ovfl_vpid;
  /* search for OID into overflow page */
  while (!VPID_ISNULL (&next_ovfl_vpid))
    {
      ovfl_page = pgbuf_fix (thread_p, &next_ovfl_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
      if (ovfl_page == NULL)
	{
	  ASSERT_ERROR_AND_SET (ret);
	  goto error;
	}

      (void) pgbuf_check_page_ptype (thread_p, ovfl_page, PAGE_BTREE);

      if (spage_get_record (thread_p, ovfl_page, 1, &ovfl_copy_rec, COPY) != S_SUCCESS)
	{
	  goto error;
	}
      assert (ovfl_copy_rec.length % 4 == 0);

      ret =
	btree_record_get_num_visible_oids (thread_p, btid, &ovfl_copy_rec, 0, BTREE_OVERFLOW_NODE,
					   p_max_page_visible_oids, mvcc_snapshot, num_visible_oids);
      if (ret != NO_ERROR)
	{
	  goto error;
	}
      (*num_visible_oids) += num_node_visible_oids;

      if (max_visible_oids)
	{
	  if ((*num_visible_oids) >= (*max_visible_oids))
	    {
	      pgbuf_unfix_and_init (thread_p, ovfl_page);
	      return NO_ERROR;
	    }

	  /* update remaining visible oids to search for */
	  max_page_visible_oids -= num_node_visible_oids;
	}

      btree_get_next_overflow_vpid (thread_p, ovfl_page, &next_ovfl_vpid);
      pgbuf_unfix_and_init (thread_p, ovfl_page);
    }

  return NO_ERROR;

error:

  if (ovfl_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, ovfl_page);
    }

  ret = er_errid ();
  if (ret == NO_ERROR)
    {
      ret = ER_FAILED;
    }

  return ret;
}

/*
 * btree_get_num_visible_from_leaf_and_ovf () - Get the number of visible objects in record.
 *
 * return		 : error_code .
 * thread_p (in)	 : Thread entry.
 * btid_int (in)	 : B-tree info.
 * leaf_record (in)	 : Leaf record descriptor.
 * offset_after_key (in) : Offset to where packed key is ended.
 * leaf_info (in)	 : Leaf record information (VPID of first overflow).
 * max_visible_oids (in) : Non-null value if there is limit of objects to count.
 * 			   If limit is reached, counting is stopped and current count is returned.
 * mvcc_snapshot (in)	 : Snapshot for visibility test.
 * num_visible(out)      : Number of visible items.
 */
int
btree_get_num_visible_from_leaf_and_ovf (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * leaf_record,
					 int offset_after_key, LEAF_REC * leaf_info, int *max_visible_oids,
					 MVCC_SNAPSHOT * mvcc_snapshot, int *num_visible)
{
  int error_code = NO_ERROR;	/* Error code. */
  int num_ovf_visible = 0;	/* Overflow pages visible objects count. */

  *num_visible = 0;

  /* Get number of visible objects from leaf record. */
  error_code = btree_record_get_num_visible_oids (thread_p, btid_int, leaf_record, offset_after_key, BTREE_LEAF_NODE,
						  max_visible_oids, mvcc_snapshot, num_visible);
  if (error_code != NO_ERROR)
    {
      /* Error occurred */
      ASSERT_ERROR ();
      return error_code;
    }

  if (max_visible_oids != NULL)
    {
      (*max_visible_oids) -= *num_visible;
      if (*max_visible_oids <= 0)
	{
	  /* The maximum count of visible objects has been reached. Stop now. */
	  return NO_ERROR;
	}
    }

  /* Get number of visible objects from overflow. */
  if (!VPID_ISNULL (&leaf_info->ovfl))
    {
      error_code = btree_get_num_visible_oids_from_all_ovf (thread_p, btid_int, &leaf_info->ovfl, &num_ovf_visible,
							    max_visible_oids, mvcc_snapshot);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return error_code;
	}

      /* Safe guard. */
      assert (num_ovf_visible >= 0);
    }

  /* Return result */
  *num_visible = *num_visible + num_ovf_visible;

  return NO_ERROR;
}

/*
 * btree_record_get_num_visible_oids () - get number of visible OIDS
 *   return: error code.
 *   thread_p(in): thread entry
 *   btid(in): B+tree index identifier
 *   rec(in): record descriptor
 *   oid_offset(in):  OID offset
 *   node_type(in): node type
 *   max_visible_oids(in): max visible oids to search for
 *   mvcc_snapshot(in): MVCC snapshot
 *   num_visible(out): Number of visible oids.
 */
static int
btree_record_get_num_visible_oids (THREAD_ENTRY * thread_p, BTID_INT * btid, RECDES * rec, int oid_offset,
				   BTREE_NODE_TYPE node_type, int *max_visible_oids, MVCC_SNAPSHOT * mvcc_snapshot,
				   int *num_visible)
{
  int mvcc_flags = 0, rec_oid_cnt = 0, length = 0;
  MVCC_REC_HEADER mvcc_rec_header;
  BTREE_MVCC_INFO mvcc_info;
  OR_BUF buf;
  bool is_first = true;
  int error_code = NO_ERROR;

  *num_visible = -1;

  /* Assert expected arguments. */
  assert (btid != NULL);
  assert (rec != NULL);
  assert (oid_offset >= 0);
  assert (node_type != BTREE_NON_LEAF_NODE);

  if (mvcc_snapshot == NULL)
    {
      error_code = ER_FAILED;
      return error_code;
    }
  length = rec->length;
  if (btree_leaf_is_flaged (rec, BTREE_LEAF_RECORD_OVERFLOW_OIDS))
    {
      length -= DB_ALIGN (DISK_VPID_SIZE, INT_ALIGNMENT);
    }

  or_init (&buf, rec->data, length);
  while (buf.ptr < buf.endptr)
    {
      /* Get MVCC flags */
      mvcc_flags = btree_record_object_get_mvcc_flags (buf.ptr);

      /* Skip object OID */
      error_code = or_advance (&buf, OR_OID_SIZE);
      if (error_code != NO_ERROR)
	{
	  return error_code;
	}

      if (BTREE_IS_UNIQUE (btid->unique_pk)
	  && (node_type == BTREE_OVERFLOW_NODE || !is_first || btree_leaf_is_flaged (rec, BTREE_LEAF_RECORD_CLASS_OID)))
	{
	  /* Skip class OID */
	  error_code = or_advance (&buf, OR_OID_SIZE);
	  if (error_code != NO_ERROR)
	    {
	      return error_code;
	    }
	}

      /* Get MVCC information */
      error_code = btree_or_get_mvccinfo (&buf, &mvcc_info, mvcc_flags);
      if (error_code != NO_ERROR)
	{
	  return error_code;
	}
      /* TODO */
      /* Isn't it better to create snapshot function for BTREE_MVCC_INFO? */
      btree_mvcc_info_to_heap_mvcc_header (&mvcc_info, &mvcc_rec_header);

      /* Check snapshot */
      if (mvcc_snapshot->snapshot_fnc (thread_p, &mvcc_rec_header, mvcc_snapshot) == SNAPSHOT_SATISFIED)
	{
	  /* Satisfies snapshot so counter must be incremented */
	  rec_oid_cnt++;
	}

      if (max_visible_oids != NULL)
	{
	  if (rec_oid_cnt >= *max_visible_oids)
	    {
	      *num_visible = rec_oid_cnt;
	      return error_code;
	    }
	}

      if (node_type == BTREE_LEAF_NODE && is_first)
	{
	  /* Must skip over the key value to the next object */
	  or_seek (&buf, oid_offset);
	}
      is_first = false;
    }

  *num_visible = rec_oid_cnt;

  return error_code;
}

/*
 * btree_record_get_num_oids () - Compute the total number of objects in a leaf or overflow record.
 *
 * return		 : Number of objects or error code.
 * thread_p (in)	 : Thread entry.
 * btid_int (in)	 : B-tree info.
 * rec (in)		 : Record descriptor.
 * after_key_offset (in) : Offset where packed key ends. Is used only in case of leaf records.
 * node_type (in)	 : Leaf/overflow node type.
 */
static int
btree_record_get_num_oids (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * rec, int after_key_offset,
			   BTREE_NODE_TYPE node_type)
{
  int rec_oid_cnt;
  short mvcc_flag;
  OR_BUF buf;
  int fixed_object_size;

  assert (rec != NULL && after_key_offset >= 0 && node_type != BTREE_NON_LEAF_NODE);

  if (node_type == BTREE_LEAF_NODE)
    {
      /* Leaf record. */

      /* There is one object before key. */
      rec_oid_cnt = 1;

      BTREE_RECORD_OR_BUF_INIT (buf, rec);
      or_seek (&buf, after_key_offset);
      /* Pointing after key. */

      if (BTREE_IS_UNIQUE (btid_int->unique_pk))
	{
	  /* All remaining objects are fixed size. It is enough to divide remaining record size by object size. */
	  fixed_object_size = BTREE_OBJECT_FIXED_SIZE (btid_int);
	  /* Safe guard */
	  assert ((CAST_BUFLEN (buf.endptr - buf.ptr) % fixed_object_size) == 0);
	  rec_oid_cnt += CAST_BUFLEN (buf.endptr - buf.ptr) / fixed_object_size;
	  return rec_oid_cnt;
	}
      /* Not unique. Objects have variable size. Count them manually. */

      /* Count oids */
      while (buf.ptr < buf.endptr)
	{
	  mvcc_flag = btree_record_object_get_mvcc_flags (buf.ptr);
	  buf.ptr += OR_OID_SIZE + BTREE_GET_MVCC_INFO_SIZE_FROM_FLAGS (mvcc_flag);
	  rec_oid_cnt++;
	}
      assert (buf.ptr == buf.endptr);
      return rec_oid_cnt;
    }

  /* Overflow. Object have fixed size. */
  fixed_object_size = BTREE_OBJECT_FIXED_SIZE (btid_int);
  assert (rec->length % fixed_object_size == 0);
  rec_oid_cnt = CEIL_PTVDIV (rec->length, fixed_object_size);
  return rec_oid_cnt;
}

/*
 * btree_leaf_change_first_object () - Replace first object in record with given object.
 *
 * return		  : Void
 * thread_p (in)          : thread entry
 * recp (in/out)	  : B-tree leaf record.
 * btid (in)		  : B-tree info.
 * oidp (in)		  : Replacing instance OID.
 * class_oidp (in)	  : Replacing class OID.
 * mvcc_info (in)	  : Replacing MVCC info.
 * key_offset (in)	  : Output new offset to key.
 * rv_undo_data_ptr (out) : If not NULL, output undo logging of this change.
 * rv_redo_data_ptr (out) : If not NULL, output redo logging of this change.
 */
void
btree_leaf_change_first_object (THREAD_ENTRY * thread_p, RECDES * recp, BTID_INT * btid, OID * oidp, OID * class_oidp,
				BTREE_MVCC_INFO * mvcc_info, int *key_offset, char **rv_undo_data_ptr,
				char **rv_redo_data_ptr)
{
  short old_rec_flag = 0, new_rec_flag = 0, mvcc_flags = 0;
  int old_object_size, new_object_size;
  bool new_has_insid = false, new_has_delid = false;
  bool new_has_class_oid = false;
  OR_BUF buffer;
  BTREE_MVCC_INFO local_mvcc_info;

  /* Get old record flags */
  old_rec_flag = btree_leaf_get_flag (recp);
  /* Initialize new record flags same as old record flags */
  new_rec_flag = old_rec_flag;

  /* Get the size of old object */
  if (BTREE_IS_UNIQUE (btid->unique_pk) && btree_leaf_is_flaged (recp, BTREE_LEAF_RECORD_CLASS_OID))
    {
      /* Also class OID is saved */
      old_object_size = 2 * OR_OID_SIZE;
    }
  else
    {
      old_object_size = OR_OID_SIZE;
    }

  /* Compute the required size for the new object */
  if (BTREE_IS_UNIQUE (btid->unique_pk) && !OID_EQ (&btid->topclass_oid, class_oidp)
      /* NULL class OID is considered topclass_oid. */
      && !OID_ISNULL (class_oidp))
    {
      /* Also class OID is saved */
      new_object_size = 2 * OR_OID_SIZE;
      /* Add BTREE_LEAF_RECORD_CLASS_OID flag */
      new_rec_flag |= BTREE_LEAF_RECORD_CLASS_OID;
      new_has_class_oid = true;
    }
  else
    {
      new_object_size = OR_OID_SIZE;
      /* Clear BTREE_LEAF_RECORD_CLASS_OID flag */
      new_rec_flag &= ~BTREE_LEAF_RECORD_CLASS_OID;
    }

  /* insert/delete MVCCID's may be present or may be added */
  if (mvcc_info == NULL)
    {
      /* Use empty MVCC info */
      mvcc_info = &local_mvcc_info;
      mvcc_info->flags = 0;
    }

  if (old_rec_flag & BTREE_LEAF_RECORD_OVERFLOW_OIDS)
    {
      /* First object must have fixed size */
      old_object_size += 2 * OR_MVCCID_SIZE;
      new_object_size += 2 * OR_MVCCID_SIZE;
      new_has_insid = true;
      new_has_delid = true;
      BTREE_MVCC_INFO_SET_FIXED_SIZE (mvcc_info);
      if (BTREE_IS_UNIQUE (btid->unique_pk) && !new_has_class_oid)
	{
	  /* Fixed size is required, so force adding class OID also */
	  new_rec_flag |= BTREE_LEAF_RECORD_CLASS_OID;
	  new_object_size += OR_OID_SIZE;
	  new_has_class_oid = true;
	}
      new_rec_flag |= BTREE_LEAF_RECORD_OVERFLOW_OIDS;
    }
  else
    {
      /* Check new MVCCID's */
      if (BTREE_MVCC_INFO_HAS_INSID (mvcc_info))
	{
	  new_object_size += OR_MVCCID_SIZE;
	  new_has_insid = true;
	}
      if (BTREE_MVCC_INFO_HAS_DELID (mvcc_info))
	{
	  new_object_size += OR_MVCCID_SIZE;
	  new_has_delid = true;
	}
      /* Check old MVCCID's */
      if (btree_record_object_is_flagged (recp->data, BTREE_OID_HAS_MVCC_INSID))
	{
	  old_object_size += OR_MVCCID_SIZE;
	}
      if (btree_record_object_is_flagged (recp->data, BTREE_OID_HAS_MVCC_DELID))
	{
	  old_object_size += OR_MVCCID_SIZE;
	}
    }

  /* Log undo changes. */
  if (rv_undo_data_ptr != NULL && *rv_undo_data_ptr != NULL)
    {
      *rv_undo_data_ptr =
	log_rv_pack_undo_record_changes (*rv_undo_data_ptr, 0, old_object_size, new_object_size, recp->data);
    }

  /* Key and any other OID's may need to be moved */
  RECORD_MOVE_DATA (recp, new_object_size, old_object_size);
  if (key_offset)
    {
      *key_offset = (new_object_size - old_object_size);
    }

  /* Add new data */
  or_init (&buffer, recp->data, new_object_size);
  /* Object OID first */
  if (or_put_oid (&buffer, oidp) != NO_ERROR)
    {
      assert_release (false);
      return;
    }
  /* Set record flags */
  btree_leaf_set_flag (recp, new_rec_flag);

  if (new_has_class_oid)
    {
      /* Add class OID */
      assert (!OID_ISNULL (class_oidp));
      if (or_put_oid (&buffer, class_oidp) != NO_ERROR)
	{
	  assert_release (false);
	  return;
	}
    }

  /* Add MVCC info */
  if (new_has_insid)
    {
      assert (!btree_online_index_is_normal_state (mvcc_info->insert_mvccid)
	      || (MVCCID_IS_VALID (mvcc_info->insert_mvccid)
		  && MVCC_ID_PRECEDES (mvcc_info->insert_mvccid, log_Gl.hdr.mvcc_next_id)));
      /* Add insert MVCCID */
      if (or_put_mvccid (&buffer, mvcc_info->insert_mvccid) != NO_ERROR)
	{
	  assert_release (false);
	  return;
	}
      mvcc_flags |= BTREE_OID_HAS_MVCC_INSID;
    }
  if (new_has_delid)
    {
      assert (mvcc_info->delete_mvccid == MVCCID_NULL
	      || MVCC_ID_PRECEDES (mvcc_info->delete_mvccid, log_Gl.hdr.mvcc_next_id));
      /* Add delete MVCCID */
      if (or_put_mvccid (&buffer, mvcc_info->delete_mvccid) != NO_ERROR)
	{
	  assert_release (false);
	}
      mvcc_flags |= BTREE_OID_HAS_MVCC_DELID;
    }
  if (mvcc_flags != 0)
    {
      /* Set MVCC flags */
      btree_record_object_set_mvcc_flags (recp->data, mvcc_flags);
    }

  /* Make sure everything was packed correctly */
  assert_release (buffer.ptr == buffer.endptr);

  /* If MVCC is enabled and if b-tree is unique and if the record has overflow OID's, the first oid must have fixed
   * size and should also contain class OID (marked as BTREE_LEAF_RECORD_CLASS_OID). */
  assert (!BTREE_IS_UNIQUE (btid->unique_pk) || !btree_leaf_is_flaged (recp, BTREE_LEAF_RECORD_OVERFLOW_OIDS)
	  || btree_leaf_is_flaged (recp, BTREE_LEAF_RECORD_CLASS_OID));

#if !defined (NDEBUG)
  (void) btree_check_valid_record (thread_p, btid, recp, BTREE_LEAF_NODE, NULL);
#endif

  /* Redo log changes of first object. */
  if (rv_redo_data_ptr != NULL && *rv_redo_data_ptr != NULL)
    {
      *rv_redo_data_ptr =
	log_rv_pack_redo_record_changes (*rv_redo_data_ptr, 0, old_object_size, new_object_size, recp->data);
    }
}

/*
 * btree_leaf_record_handle_first_overflow () - Set fixed size for first object and update record.
 *
 * return		  : Void.
 * thread_p (in)          : Thread entry
 * recp (in)		  : Leaf record.
 * btid_int (in)	  : B-tree info.
 * rv_undo_data_ptr (out) : If not null, outputs undo recovery data for the changes made to record.
 * rv_redo_data_ptr (out) : If not null, outputs redo recovery data for the changes made to record.
 */
static void
btree_leaf_record_handle_first_overflow (THREAD_ENTRY * thread_p, RECDES * recp, BTID_INT * btid_int,
					 char **rv_undo_data_ptr, char **rv_redo_data_ptr)
{
  int old_mvcc_flags;
  int old_object_size = OR_OID_SIZE;
  int new_object_size = BTREE_OBJECT_FIXED_SIZE (btid_int);
  MVCCID delid, insid;
  char *ptr = NULL;

  bool undo_logging = rv_undo_data_ptr != NULL && *rv_undo_data_ptr != NULL;
  bool redo_logging = rv_redo_data_ptr != NULL && *rv_redo_data_ptr != NULL;

  /* Assert expected arguments. */
  assert (recp != NULL);
  assert (btid_int != NULL);

  if (BTREE_IS_UNIQUE (btid_int->unique_pk))
    {
      if (btree_leaf_is_flaged (recp, BTREE_LEAF_RECORD_CLASS_OID))
	{
	  old_object_size += OR_OID_SIZE;
	}
    }

  old_mvcc_flags = btree_record_object_get_mvcc_flags (recp->data);
  if (old_mvcc_flags & BTREE_OID_HAS_MVCC_INSID)
    {
      OR_GET_MVCCID (recp->data + old_object_size, &insid);
      old_object_size += OR_MVCCID_SIZE;
    }
  else
    {
      insid = MVCCID_ALL_VISIBLE;
    }

  if (old_mvcc_flags & BTREE_OID_HAS_MVCC_DELID)
    {
      OR_GET_MVCCID (recp->data + old_object_size, &delid);
      old_object_size += OR_MVCCID_SIZE;
    }
  else
    {
      delid = MVCCID_NULL;
    }

  if (old_object_size == new_object_size)
    {
      /* All information is already here */

      /* Log undo setting flag. */
      if (undo_logging)
	{
	  *rv_undo_data_ptr =
	    log_rv_pack_undo_record_changes (*rv_undo_data_ptr, OR_OID_SLOTID, OR_SHORT_SIZE, OR_SHORT_SIZE,
					     recp->data + OR_OID_SLOTID);
	}

      /* Set overflow OID's flag. */
      btree_leaf_set_flag (recp, BTREE_LEAF_RECORD_OVERFLOW_OIDS);

#if !defined (NDEBUG)
      (void) btree_check_valid_record (thread_p, btid_int, recp, BTREE_LEAF_NODE, NULL);
#endif

      /* Log redo setting flag. */
      if (redo_logging)
	{
	  /* Leaf record flags are kept in SLOTID field of first OID. */
	  *rv_redo_data_ptr =
	    log_rv_pack_redo_record_changes (*rv_redo_data_ptr, OR_OID_SLOTID, OR_SHORT_SIZE, OR_SHORT_SIZE,
					     recp->data + OR_OID_SLOTID);
	}
      return;
    }

  /* Log undo changes */
  if (undo_logging)
    {
      *rv_undo_data_ptr =
	log_rv_pack_undo_record_changes (*rv_undo_data_ptr, 0, old_object_size, new_object_size, recp->data);
    }

  /* Set overflow OID's flag. */
  btree_leaf_set_flag (recp, BTREE_LEAF_RECORD_OVERFLOW_OIDS);

  /* Must free space to add extra info */
  RECORD_MOVE_DATA (recp, new_object_size, old_object_size);

  /* Set pointer after object OID. */
  ptr = recp->data + OR_OID_SIZE;

  if (BTREE_IS_UNIQUE (btid_int->unique_pk))
    {
      /* Class OID must exist. */
      if (!btree_leaf_is_flaged (recp, BTREE_LEAF_RECORD_CLASS_OID))
	{
	  /* Add top class OID */
	  OR_PUT_OID (recp->data + OR_OID_SIZE, &btid_int->topclass_oid);
	  btree_leaf_set_flag (recp, BTREE_LEAF_RECORD_CLASS_OID);
	}
      else
	{
	  /* Already here. */
	}
      ptr += OR_OID_SIZE;
    }

  /* Add both insert MVCCID and delete MVCCID */
  OR_PUT_MVCCID (ptr, &insid);
  ptr += OR_MVCCID_SIZE;
  OR_PUT_MVCCID (ptr, &delid);
  ptr += OR_MVCCID_SIZE;

  /* Set MVCC flags where OID is packed. */
  btree_record_object_set_mvcc_flags (recp->data, BTREE_OID_HAS_MVCC_INSID_AND_DELID);

#if !defined (NDEBUG)
  (void) btree_check_valid_record (thread_p, btid_int, recp, BTREE_LEAF_NODE, NULL);
#endif

  /* Redo logging. */
  if (redo_logging)
    {
      /* Object OID could not change. Log only changes after its OID. */
      *rv_redo_data_ptr =
	log_rv_pack_redo_record_changes (*rv_redo_data_ptr, 0, old_object_size, new_object_size, recp->data);
    }
}

/*
 * btree_leaf_get_nth_oid_ptr () - Advance to the nth object in b-tree key record data and return pointer.
 *
 * return		: Pointer to nth object in record data.
 * btid (in)		: B-tree data.
 * recp (in)		: Record data.
 * node_type (in)	: Node type (leaf or overflow).
 * oid_list_offset (in) : Offset to list of objects (for leaf it must skip the packed key).
 * n (in)		: Required object index.
 *
 * TODO: This function is no longer used due to changes in b-tree range scan.
 *	 However it may prove useful in the future, so better don't remove it.
 */
static char *
btree_leaf_get_nth_oid_ptr (BTID_INT * btid, RECDES * recp, BTREE_NODE_TYPE node_type, int oid_list_offset, int n)
{
  OR_BUF buf;
  int fixed_size;
  int oids_size;
  int vpid_size;
  int mvcc_info_size;
  short mvcc_flags;
  bool is_fixed_size;

  assert (node_type == BTREE_LEAF_NODE || node_type == BTREE_OVERFLOW_NODE);

  if (n == 0)
    {
      /* First object is always first in record data */
      return recp->data;
    }

  vpid_size = (btree_leaf_is_flaged (recp, BTREE_LEAF_RECORD_OVERFLOW_OIDS)
	       ? DB_ALIGN (DISK_VPID_SIZE, INT_ALIGNMENT) : 0);

  if (BTREE_IS_UNIQUE (btid->unique_pk))
    {
      oids_size = 2 * OR_OID_SIZE;
    }
  else
    {
      oids_size = OR_OID_SIZE;
    }

  is_fixed_size = (node_type == BTREE_OVERFLOW_NODE || BTREE_IS_UNIQUE (btid->unique_pk));
  if (is_fixed_size)
    {
      /* Each object has fixed size */
      fixed_size = BTREE_OBJECT_FIXED_SIZE (btid);

      if (node_type == BTREE_OVERFLOW_NODE)
	{
	  assert (oid_list_offset == 0);
	  assert (n * fixed_size + vpid_size < recp->length);
	  return recp->data + n * fixed_size;
	}
      else			/* node_type == BTREE_LEAF_NODE */
	{
	  assert ((oid_list_offset + (n - 1) * fixed_size + vpid_size) < recp->length);
	  return recp->data + oid_list_offset + (n - 1) * fixed_size;
	}
    }
  /* Not fixed size. */
  assert (node_type == BTREE_LEAF_NODE);
  /* Count objects after key (without first). */
  n = n - 1;
  BTREE_RECORD_OR_BUF_INIT (buf, recp);

  while (n > 0)
    {
      /* Skip object */
      mvcc_flags = btree_record_object_get_mvcc_flags (buf.ptr);
      mvcc_info_size = BTREE_GET_MVCC_INFO_SIZE_FROM_FLAGS (mvcc_flags);

      if (or_advance (&buf, oids_size + mvcc_info_size) != NO_ERROR)
	{
	  assert_release (false);
	  return NULL;
	}

      n--;
    }

  /* buf.ptr points to nth object */
  assert (buf.ptr < buf.endptr);

  return buf.ptr;
}

/*
 * btree_record_get_last_object () - Get last object in record.
 *
 * return		       : Error code.
 * thread_p (in)	       : Thread entry.
 * btid_int (in)	       : B-tree info.
 * recp (in)		       : B-tree leaf/overflow record.
 * node_type (in)	       : Leaf/overflow node type.
 * offset_after_key (in)       : For leaf record, offset to where packed key is ended.
 * oidp (out)		       : Output last object OID.
 * class_oid (out)	       : Output last object class OID.
 * mvcc_info (out)	       : Output last object MVCC info.
 * offset_to_last_object (out) : Output offset in record to last object.
 */
static int
btree_record_get_last_object (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * recp, BTREE_NODE_TYPE node_type,
			      int offset_after_key, OID * oidp, OID * class_oid, BTREE_MVCC_INFO * mvcc_info,
			      int *offset_to_last_object)
{
  char *offset = NULL;		/* Pointer in record data. */
  OR_BUF buf;			/* Buffer used to parse record. */
  int error_code = NO_ERROR;	/* Error code. */

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (recp != NULL);
  assert (node_type == BTREE_LEAF_NODE || node_type == BTREE_OVERFLOW_NODE);
  assert (oidp != NULL);
  assert (class_oid != NULL);
  assert (mvcc_info != NULL);
  assert (offset_to_last_object != NULL);

  /* Create a buffer from b-tree record. */
  BTREE_RECORD_OR_BUF_INIT (buf, recp);

  /* Is last object fixed size? True if: 1. Overflow record. 2. Unique leaf record has more than object. */
  if (node_type == BTREE_OVERFLOW_NODE
      || (BTREE_IS_UNIQUE (btid_int->unique_pk) && offset_after_key != CAST_BUFLEN (buf.endptr - buf.buffer)))
    {
      /* Overflow nodes have fixed size objects. Also leaf records of unique indexes have fixed size object after
       * packed key. Just compute offset to last object and get object from there. */
      /* Set offset to end of record (without leaf link to first overflow). */
      offset = buf.endptr;
      /* Go back on fixed object size. */
      offset -= BTREE_OBJECT_FIXED_SIZE (btid_int);

      /* Save offset to last object offset. */
      *offset_to_last_object = CAST_BUFLEN (offset - recp->data);

      /* Unpack last object. */
      offset = btree_unpack_object (offset, btid_int, node_type, recp, offset_after_key, oidp, class_oid, mvcc_info);
      assert (offset == buf.endptr);
      return NO_ERROR;
    }
  /* Leaf node. */
  assert (node_type == BTREE_LEAF_NODE);

  if (CAST_BUFLEN (buf.endptr - buf.buffer) == offset_after_key)
    {
      /* Only one object! */
      /* Get offset to object. */
      *offset_to_last_object = 0;

      (void) btree_unpack_object (recp->data, btid_int, node_type, recp, offset_after_key, oidp, class_oid, mvcc_info);
      return NO_ERROR;
    }
  /* Leaf node and more than one object. */
  /* Unique should have been already handled. */
  assert (!BTREE_IS_UNIQUE (btid_int->unique_pk));

  /* Objects have variable size, depending on the stored MVCC info. We have to process existing objects until reaching
   * the end of record. */

  /* Start looking for last object after key. */
  or_seek (&buf, offset_after_key);

  /* Advance until record is consumed. */
  while (buf.ptr < buf.endptr)
    {
      offset = buf.ptr;
      error_code = btree_or_get_object (&buf, btid_int, node_type, offset_after_key, oidp, class_oid, mvcc_info);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  assert_release (false);
	  return error_code;
	}
    }
  /* Safe guard: record was consumed. */
  assert (buf.ptr == buf.endptr);

  /* Output offset to last object. */
  *offset_to_last_object = CAST_BUFLEN (offset - recp->data);
  return NO_ERROR;
}

/*
 * btree_record_remove_last_object () - Remove last object from b-tree record.
 *
 * return		      : Void.
 * thread_p (in)	      : Thread entry.
 * btid (in)		      : B-tree info.
 * recp (in)		      : B-tree record.
 * node_type (in)	      : Leaf or overflow node type.
 * offset_to_last_object (in) : Offset to last object (must be known).
 * rv_undo_data_ptr (out)     : If not null, output the packed undo logging for this change.
 * rv_redo_data_ptr (out)     : If not null, output the packed redo logging for this change.
 */
static void
btree_record_remove_last_object (THREAD_ENTRY * thread_p, BTID_INT * btid, RECDES * recp, BTREE_NODE_TYPE node_type,
				 int offset_to_last_object, char **rv_undo_data_ptr, char **rv_redo_data_ptr)
{
  char *first_ovf_vpid_src;
  char *first_ovf_vpid_dest;
  int object_size;
  bool has_overflow_oids = false;

  /* Assert expected arguments. */
  assert (btid != NULL);
  assert (recp != NULL);
  assert (offset_to_last_object > 0);
  assert (recp->length > offset_to_last_object);

  has_overflow_oids = node_type == BTREE_LEAF_NODE && btree_leaf_is_flaged (recp, BTREE_LEAF_RECORD_OVERFLOW_OIDS);
  object_size = recp->length - offset_to_last_object - (has_overflow_oids ? DISK_VPID_ALIGNED_SIZE : 0);

  /* Undo logging. */
  if (rv_undo_data_ptr != NULL && *rv_undo_data_ptr != NULL)
    {
      *rv_undo_data_ptr =
	log_rv_pack_undo_record_changes (*rv_undo_data_ptr, offset_to_last_object, object_size, 0,
					 recp->data + offset_to_last_object);
    }

  if (has_overflow_oids)
    {
      /* Remove last object and save first overflow VPID. */
      first_ovf_vpid_src = recp->data + recp->length - DISK_VPID_ALIGNED_SIZE;
      first_ovf_vpid_dest = recp->data + offset_to_last_object;
      assert ((first_ovf_vpid_src - first_ovf_vpid_dest) >= DISK_VPID_ALIGNED_SIZE);
      VPID_COPY ((VPID *) first_ovf_vpid_dest, (VPID *) first_ovf_vpid_src);
      recp->length = offset_to_last_object + DISK_VPID_ALIGNED_SIZE;
    }
  else
    {
      /* Just cut off the last object. */
      recp->length = offset_to_last_object;
    }

#if !defined (NDEBUG)
  (void) btree_check_valid_record (thread_p, btid, recp, node_type, NULL);
#endif /* !NDEBUG */

  /* Redo logging. */
  if (rv_redo_data_ptr != NULL && *rv_redo_data_ptr != NULL)
    {
      /* Pack redo recovery of change: remove old_size bytes from offset_to_last_object. */
      *rv_redo_data_ptr = log_rv_pack_redo_record_changes (*rv_redo_data_ptr, offset_to_last_object, object_size, 0,
							   NULL /* just * remove */ );
    }
}

/*
 * btree_leaf_get_flag () -
 *   return: flag of leaf record
 *   recp(in):
 */
static short
btree_leaf_get_flag (RECDES * recp)
{
  short slot_id;

  slot_id = OR_GET_SHORT (recp->data + OR_OID_SLOTID);

  return slot_id & BTREE_LEAF_RECORD_MASK;
}

/*
 * btree_record_object_get_mvcc_flags () - get MVCC flag for key oid
 *   return: MVCC flag for key oid
 *   data(in): pointer to OID into key buffer
 */
STATIC_INLINE short
btree_record_object_get_mvcc_flags (char *data)
{
  short vol_id;

  assert (data != NULL);
  vol_id = OR_GET_SHORT (data + OR_OID_VOLID);

  return vol_id & BTREE_OID_MVCC_FLAGS_MASK;
}

/*
 * btree_leaf_is_flaged () -
 *   return:
 *   recp(in):
 *   record_flag(in):
 */
static bool
btree_leaf_is_flaged (RECDES * recp, short record_flag)
{
  assert ((short) (record_flag & ~BTREE_LEAF_RECORD_MASK) == 0);

  return ((OR_GET_SHORT (recp->data + OR_OID_SLOTID) & record_flag) == record_flag);
}

/*
 * btree_record_object_is_flagged () - Check whether object found at rec_data has the MVCC flag.
 *
 * return	  : True if flag is set, false otherwise.
 * rec_data (in)  : Pointer to an object in b-tree record.
 * mvcc_flag (in) : MVCC flag.
 */
STATIC_INLINE bool
btree_record_object_is_flagged (char *rec_data, short mvcc_flag)
{
  assert ((short) (mvcc_flag & ~BTREE_OID_MVCC_FLAGS_MASK) == 0);

  return ((OR_GET_SHORT (rec_data + OR_OID_VOLID) & mvcc_flag) == mvcc_flag);
}

/*
 * btree_leaf_set_flag () -
 *   return:
 *   recp(in/out):
 *   record_flag(in):
 */
static void
btree_leaf_set_flag (RECDES * recp, short record_flag)
{
  short slot_id;

  assert ((short) (record_flag & ~BTREE_LEAF_RECORD_MASK) == 0);

  slot_id = OR_GET_SHORT (recp->data + OR_OID_SLOTID);

  OR_PUT_SHORT (recp->data + OR_OID_SLOTID, slot_id | record_flag);
}

/*
 * btree_record_object_set_mvcc_flags () - Set MVCC flags to an object in a b-tree record.
 *
 * return	   : Void.
 * rec_data (in)   : Pointer to an object in a b-tree record.
 * mvcc_flags (in) : MVCC flags.
 */
static void
btree_record_object_set_mvcc_flags (char *rec_data, short mvcc_flags)
{
  short vol_id;

  assert ((short) (mvcc_flags & ~BTREE_OID_MVCC_FLAGS_MASK) == 0);

  vol_id = OR_GET_SHORT (rec_data + OR_OID_VOLID);

  OR_PUT_SHORT (rec_data + OR_OID_VOLID, vol_id | mvcc_flags);
}

/*
 * btree_leaf_clear_flag () - clear leaf key oid flag
 *   return:  nothing
 *   recp(in/out):
 *   record_flag(in):
 */
static void
btree_leaf_clear_flag (RECDES * recp, short record_flag)
{
  short slot_id;

  assert ((short) (record_flag & ~BTREE_LEAF_RECORD_MASK) == 0);

  slot_id = OR_GET_SHORT (recp->data + OR_OID_SLOTID);

  OR_PUT_SHORT (recp->data + OR_OID_SLOTID, slot_id & ~record_flag);
}

/*
 * btree_record_object_clear_mvcc_flags () - Clear MVCC flags from an object in a b-tree record.
 *
 * return	   : Void.
 * rec_data (in)   : Pointer to an object in a b-tree record.
 * mvcc_flags (in) : MVCC flags to clear.
 */
static void
btree_record_object_clear_mvcc_flags (char *rec_data, short mvcc_flags)
{
  short vol_id;

  assert ((short) (mvcc_flags & ~BTREE_OID_MVCC_FLAGS_MASK) == 0);

  vol_id = OR_GET_SHORT (rec_data + OR_OID_VOLID);

  OR_PUT_SHORT (rec_data + OR_OID_VOLID, vol_id & ~mvcc_flags);
}

/*
 * btree_write_fixed_portion_of_non_leaf_record () -
 *   return:
 *   rec(in):
 *   non_leaf_rec(in):
 *
 * Note: Writes the fixed portion (preamble) of a non leaf record.
 * rec must be long enough to hold the header info.
 */
static void
btree_write_fixed_portion_of_non_leaf_record (RECDES * rec, NON_LEAF_REC * non_leaf_rec)
{
  char *ptr = rec->data;

  assert (!VPID_ISNULL (&(non_leaf_rec->pnt)));

  OR_PUT_INT (ptr, non_leaf_rec->pnt.pageid);
  ptr += OR_INT_SIZE;

  OR_PUT_SHORT (ptr, non_leaf_rec->pnt.volid);
  ptr += OR_SHORT_SIZE;

  OR_PUT_SHORT (ptr, non_leaf_rec->key_len);
}

/*
 * btree_read_fixed_portion_of_non_leaf_record () -
 *   return:
 *   rec(in):
 *   non_leaf_rec(in):
 *
 * Note: Reads the fixed portion (preamble) of a non leaf record.
 */
static void
btree_read_fixed_portion_of_non_leaf_record (RECDES * rec, NON_LEAF_REC * non_leaf_rec)
{
  char *ptr = rec->data;

  non_leaf_rec->pnt.pageid = OR_GET_INT (ptr);
  ptr += OR_INT_SIZE;

  non_leaf_rec->pnt.volid = OR_GET_SHORT (ptr);
  ptr += OR_SHORT_SIZE;

  assert (!VPID_ISNULL (&(non_leaf_rec->pnt)));

  non_leaf_rec->key_len = OR_GET_SHORT (ptr);
}

/*
 * btree_write_fixed_portion_of_non_leaf_record_to_orbuf () -
 *   return:
 *   buf(in):
 *   nlf_rec(in):
 *
 * Note: Writes the fixed portion (preamble) of a non leaf record using
 * the OR_BUF stuff.
 */
static void
btree_write_fixed_portion_of_non_leaf_record_to_orbuf (OR_BUF * buf, NON_LEAF_REC * non_leaf_rec)
{
  assert (!VPID_ISNULL (&(non_leaf_rec->pnt)));

  or_put_int (buf, non_leaf_rec->pnt.pageid);
  or_put_short (buf, non_leaf_rec->pnt.volid);
  or_put_short (buf, non_leaf_rec->key_len);
}

/*
 * btree_read_fixed_portion_of_non_leaf_record_from_orbuf () -
 *   return: NO_ERROR
 *   buf(in):
 *   non_leaf_rec(in):
 *
 * Note: Reads the fixed portion (preamble) of a non leaf record using the OR_BUF stuff.
 */
static int
btree_read_fixed_portion_of_non_leaf_record_from_orbuf (OR_BUF * buf, NON_LEAF_REC * non_leaf_rec)
{
  int rc = NO_ERROR;

  non_leaf_rec->pnt.pageid = or_get_int (buf, &rc);

  if (rc == NO_ERROR)
    {
      non_leaf_rec->pnt.volid = or_get_short (buf, &rc);
    }

  assert (!VPID_ISNULL (&(non_leaf_rec->pnt)));

  if (rc == NO_ERROR)
    {
      non_leaf_rec->key_len = or_get_short (buf, &rc);
    }

  return rc;
}

/*
 * btree_append_oid () -
 *   return:
 *   rec(in):
 *   oid(in):
 *
 * Note: Appends an OID onto the record.  rec is assumed to have room
 * for the new OID and rec.length points to the end of the record
 * where the new OID will go and is word aligned.
 */
static void
btree_append_oid (RECDES * rec, OID * oid)
{
  char *ptr;

  ptr = rec->data + rec->length;
  OR_PUT_OID (ptr, oid);
  rec->length += OR_OID_SIZE;
}

/*
 * btree_add_mvccid () - Add insert/delete MVCCID in b-tree record.
 *
 * return		  : Void.
 * rec (in)		  : B-tree record.
 * oid_offset (in)	  : Offset to object (where MVCC flag is set).
 * mvccid_offset (in)     : Add MVCCID at this offset
 * mvccid (in)            : MVCCID value
 * flag (in)              : MVCCID flag for has insert or delete
 * rv_undo_data_ptr (out) : Outputs undo recovery data for changing the record.
 * rv_redo_data_ptr (out) : Outputs redo recovery data for changing the record.
 */
STATIC_INLINE void
btree_add_mvccid (RECDES * rec, int oid_offset, int mvccid_offset, MVCCID mvccid, short flag,
		  char **rv_undo_data_ptr, char **rv_redo_data_ptr)
{
  int dest_offset;
  char *mvccid_dest_ptr = NULL;
  char *oid_ptr = NULL;

  assert (rec != NULL && oid_offset >= 0 && mvccid_offset > 0 && oid_offset < mvccid_offset);
  assert (!btree_record_object_is_flagged (rec->data + oid_offset, flag));
  assert (rec->length + OR_MVCCID_SIZE < rec->area_size);

  dest_offset = mvccid_offset + OR_MVCCID_SIZE;

  if (rv_undo_data_ptr != NULL && *rv_undo_data_ptr != NULL)
    {
      /* Undo logging: changed flag (is kept in object volume ID). */
      *rv_undo_data_ptr =
	log_rv_pack_undo_record_changes (*rv_undo_data_ptr, oid_offset + OR_OID_VOLID, OR_SHORT_SIZE, OR_SHORT_SIZE,
					 rec->data + oid_offset + OR_OID_VOLID);
      /* Undo logging: added MVCCID. */
      *rv_undo_data_ptr = log_rv_pack_undo_record_changes (*rv_undo_data_ptr, mvccid_offset, 0, OR_MVCCID_SIZE, NULL);
    }

  RECORD_MOVE_DATA (rec, dest_offset, mvccid_offset);

  /* Set MVCC flag. */
  oid_ptr = rec->data + oid_offset;
  btree_record_object_set_mvcc_flags (oid_ptr, flag);

  /* Set MVCCID. */
  mvccid_dest_ptr = rec->data + mvccid_offset;
  OR_PUT_MVCCID (mvccid_dest_ptr, &mvccid);

  if (rv_redo_data_ptr != NULL && *rv_redo_data_ptr != NULL)
    {
      /* Redo logging: changed flag (is kept in object volume ID). */
      *rv_redo_data_ptr =
	log_rv_pack_redo_record_changes (*rv_redo_data_ptr, oid_offset + OR_OID_VOLID, OR_SHORT_SIZE, OR_SHORT_SIZE,
					 rec->data + oid_offset + OR_OID_VOLID);
      /* Redo logging: added MVCCID. */
      *rv_redo_data_ptr =
	log_rv_pack_redo_record_changes (*rv_redo_data_ptr, mvccid_offset, 0, OR_MVCCID_SIZE, mvccid_dest_ptr);
    }
}

/*
 * btree_set_mvccid () - Set MVCCID instead of existing one. This one works for insid and delid.
 *
 * return		  : Error code.
 * rec (in)		  : Record data.
 * mvccid_offset (in)     : Offset of old MVCCID.
 * p_mvccid (in)	  : New MVCCID.
 * rv_undo_data_ptr (in)  : Outputs undo recovery data for changing the record.
 * rv_redo_data_ptr (in)  : Outputs redo recovery data for changing the record.
 */
STATIC_INLINE void
btree_set_mvccid (RECDES * rec, int mvccid_offset, MVCCID * p_mvccid, char **rv_undo_data_ptr, char **rv_redo_data_ptr)
{
  char *mvccid_ptr = NULL;

  assert (rec != NULL && mvccid_offset > 0 && p_mvccid != NULL);

  mvccid_ptr = rec->data + mvccid_offset;

  if (rv_undo_data_ptr != NULL && *rv_undo_data_ptr != NULL)
    {
      /* Redo logging: replace MVCCID. */
      *rv_undo_data_ptr =
	log_rv_pack_undo_record_changes (*rv_undo_data_ptr, mvccid_offset, OR_MVCCID_SIZE, OR_MVCCID_SIZE, mvccid_ptr);
    }

  OR_PUT_MVCCID (mvccid_ptr, p_mvccid);

  if (rv_redo_data_ptr != NULL && *rv_redo_data_ptr != NULL)
    {
      /* Redo logging: replace MVCCID. */
      *rv_redo_data_ptr =
	log_rv_pack_redo_record_changes (*rv_redo_data_ptr, mvccid_offset, OR_MVCCID_SIZE, OR_MVCCID_SIZE, mvccid_ptr);
    }
}

//
// btree_remove_mvccid () - remove insert or delete MVCCID from record and generate incremental logging
//
// record (in/out)           : b-tree record
// oid_offset (in)           : offset to object OID
// mvccid_offset (in)        : offset to MVCCID being removed
// flag (in)                 : has insert or has delete flag
// rv_undo_data_ptr (in/out) : if not null, output undo logging
// rv_redo_data_ptr (in/out) : if not null, output redo logging
//
static inline void
btree_remove_mvccid (RECDES * record, int oid_offset, int mvccid_offset, short flag, char **rv_undo_data_ptr,
		     char **rv_redo_data_ptr)
{
  char *oid_ptr = record->data + oid_offset;
  char *mvccid_ptr = record->data + mvccid_offset;

  if (rv_undo_data_ptr != NULL && *rv_undo_data_ptr != NULL)
    {
      /* Undo logging: remove MVCCID. */
      *rv_undo_data_ptr =
	log_rv_pack_undo_record_changes (*rv_undo_data_ptr, mvccid_offset, OR_MVCCID_SIZE, 0, mvccid_ptr);

      /* Undo logging: clear flag. */
      *rv_undo_data_ptr =
	log_rv_pack_undo_record_changes (*rv_undo_data_ptr, oid_offset + OR_OID_VOLID, OR_SHORT_SIZE,
					 OR_SHORT_SIZE, oid_ptr + OR_OID_VOLID);
    }

  /* Remove. */
  RECORD_MOVE_DATA (record, mvccid_offset, mvccid_offset + OR_MVCCID_SIZE);
  btree_record_object_clear_mvcc_flags (oid_ptr, flag);

  if (rv_redo_data_ptr != NULL && *rv_redo_data_ptr != NULL)
    {
      /* Redo logging: remove MVCCID. */
      *rv_redo_data_ptr = log_rv_pack_redo_record_changes (*rv_redo_data_ptr, mvccid_offset, OR_MVCCID_SIZE, 0, NULL);

      /* Redo logging: clear flag. */
      *rv_redo_data_ptr =
	log_rv_pack_redo_record_changes (*rv_redo_data_ptr, oid_offset + OR_OID_VOLID, OR_SHORT_SIZE,
					 OR_SHORT_SIZE, oid_ptr + OR_OID_VOLID);
    }
}

/*
 * btree_record_append_object () - Append an object and all its info to record.
 *
 * return		  : Void.
 * thread_p (in)	  : Thread entry.
 * btid_int (in)	  : B-tree info.
 * record (in)		  : Leaf/overflow record.
 * node_type (in)	  : Note type.
 * object_info (in)	  : Object & info to append.
 * rv_undo_data_ptr (out) : If not NULL, outputs redo log recovery data for the change.
 * rv_redo_data_ptr (out) : If not NULL, outputs redo log recovery data for the change.
 */
static void
btree_record_append_object (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * record, BTREE_NODE_TYPE node_type,
			    BTREE_OBJECT_INFO * object_info, char **rv_undo_data_ptr, char **rv_redo_data_ptr)
{
  char *append_at = NULL;
  VPID ovf_vpid = VPID_INITIALIZER;
  int offset_to_object = 0;
  int new_data_size = 0;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (record != NULL);
  assert (object_info != NULL);

  /* Set append pointer at the end of record. */
  append_at = record->data + record->length;

  /* Make sure to keep the link to overflow pages at the end. */
  if (node_type == BTREE_LEAF_NODE && record->length > 0
      && btree_leaf_is_flaged (record, BTREE_LEAF_RECORD_OVERFLOW_OIDS))
    {
      /* Set append pointer before the overflow link. */
      append_at -= DISK_VPID_ALIGNED_SIZE;
      /* Save overflow link. */
      OR_GET_VPID (append_at, &ovf_vpid);
      assert (!VPID_ISNULL (&ovf_vpid));
    }
  offset_to_object = CAST_BUFLEN (append_at - record->data);

  /* Pack object. */
  append_at = btree_pack_object (append_at, btid_int, node_type, record, object_info);
  new_data_size = CAST_BUFLEN (append_at - record->data) - offset_to_object;

  if (!VPID_ISNULL (&ovf_vpid))
    {
      /* Pack VPID again. */
      OR_PUT_VPID_ALIGNED (append_at, &ovf_vpid);
      append_at += DISK_VPID_ALIGNED_SIZE;
    }

  /* Update record length. */
  record->length = CAST_BUFLEN (append_at - record->data);

#if !defined (NDEBUG)
  (void) btree_check_valid_record (thread_p, btid_int, record, node_type, NULL);
#endif

  /* Redo logging. */
  if (rv_undo_data_ptr != NULL && *rv_undo_data_ptr != NULL)
    {
      assert (*rv_undo_data_ptr != NULL);
      *rv_undo_data_ptr = log_rv_pack_undo_record_changes (*rv_undo_data_ptr, offset_to_object, 0, new_data_size, NULL);
    }

  /* Redo logging. */
  if (rv_redo_data_ptr != NULL && *rv_redo_data_ptr != NULL)
    {
      assert (*rv_redo_data_ptr != NULL);
      *rv_redo_data_ptr = log_rv_pack_redo_record_changes (*rv_redo_data_ptr, offset_to_object, 0,	/* just insert * data */
							   new_data_size, record->data + offset_to_object);
    }
}

/*
 * btree_insert_object_ordered_by_oid () - Insert in record by keeping objects ordered by OID's.
 *
 * return		  : Error code.
 * thread_p (in)          : Thread entry
 * record (in)		  : B-tree (overflow) record.
 * btid_int (in)	  : B-tree info.
 * object_info (in)	  : Object & info being inserted.
 * rv_undo_data_ptr (in)  : If not null, outputs undo recovery data for the changes made to record.
 * rv_redo_data_ptr (in)  : If not null, outputs redo recovery data for the changes made to record.
 * offset_to_objptr (out) : Output offset to inserted object.
 */
static void
btree_insert_object_ordered_by_oid (THREAD_ENTRY * thread_p, RECDES * record, BTID_INT * btid_int,
				    BTREE_OBJECT_INFO * object_info, char **rv_undo_data_ptr, char **rv_redo_data_ptr,
				    int *offset_to_objptr)
{
  OID *oid = NULL;
  char *oid_ptr = NULL;
  int min, mid, max, num;
  OID mid_oid;
  int size = BTREE_OBJECT_FIXED_SIZE (btid_int);
  int offset_to_object = 0;

  /* Assert expected arguments. */
  assert (record != NULL);
  assert (btid_int != NULL);
  assert (object_info != NULL);
  assert (BTREE_MVCC_INFO_HAS_INSID (&object_info->mvcc_info) && BTREE_MVCC_INFO_HAS_DELID (&object_info->mvcc_info));

  assert (record->length % size == 0);
  num = CEIL_PTVDIV (record->length, size);
  assert (num >= 0);

  /* Binary search for the right position to keep the order */
  min = 0;
  max = num - 1;
  mid = 0;
  oid = &object_info->oid;

  while (min <= max)
    {
      mid = (min + max) / 2;
      oid_ptr = record->data + (size * mid);

      /* Get MID object OID. */
      BTREE_GET_OID (oid_ptr, &mid_oid);

      /* Is same OID? */
      if (OID_EQ (oid, &mid_oid))
	{
	  /* With MVCC, this case is possible if some conditions are met: 1. OID is reusable. 2. Vacuum cleaned heap
	   * entry but didn't clean b-tree entry. 3. A new record is inserted in the same slot. 4. The key for old
	   * record and new record is the same. Just add the OID here. */
	  break;
	}
      else if (OID_GT (oid, &mid_oid))
	{
	  min = mid + 1;
	  mid++;
	}
      else
	{
	  max = mid - 1;
	}
    }

  offset_to_object = size * mid;
  oid_ptr = record->data + offset_to_object;

  if (rv_undo_data_ptr != NULL && *rv_undo_data_ptr != NULL)
    {
      *rv_undo_data_ptr = log_rv_pack_undo_record_changes (*rv_undo_data_ptr, offset_to_object, 0, size, oid_ptr);
    }

  /* oid_ptr points to the address where the new object should be saved */
  /* Make room for a new OID */
  RECORD_MOVE_DATA (record, offset_to_object + size, offset_to_object);

  (void) btree_pack_object (oid_ptr, btid_int, BTREE_OVERFLOW_NODE, record, object_info);

#if !defined (NDEBUG)
  (void) btree_check_valid_record (thread_p, btid_int, record, BTREE_OVERFLOW_NODE, NULL);
#endif

  /* Log redo changes. */
  if (rv_redo_data_ptr != NULL && *rv_redo_data_ptr != NULL)
    {
      *rv_redo_data_ptr = log_rv_pack_redo_record_changes (*rv_redo_data_ptr, offset_to_object, 0, size, oid_ptr);
    }

  if (offset_to_objptr != NULL)
    {
      *offset_to_objptr = offset_to_object;
    }
}

/*
 * btree_start_overflow_page () - Create a new overflow page when OID cannot
 *				  be inserted elsewhere. New page is always
 *				  inserted "after" leaf (and before other
 *				  existing overflow pages).
 *
 * return		    : Error code.
 * thread_p (in)	    : Thread entry.
 * btid_int (in)	    : B-tree info.
 * object_info (in)	    : New object info.
 * first_overflow_vpid (in) : VPID of current first overflow page.
 * near_vpid (in)	    : Hint to allocate new page.
 * new_vpid (out)	    : Output VPID of newly allocated page.
 * new_page_ptr (out)	    : New page.
 */
static int
btree_start_overflow_page (THREAD_ENTRY * thread_p, BTID_INT * btid_int, BTREE_OBJECT_INFO * object_info,
			   VPID * first_overflow_vpid, VPID * near_vpid, VPID * new_vpid, PAGE_PTR * new_page_ptr)
{
  RECDES rec;
  char rec_buf[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  BTREE_OVERFLOW_HEADER ovf_header_info;
  LOG_DATA_ADDR addr;
  int error_code = NO_ERROR;

  /* Redo recovery. */
  char rv_redo_data_buffer[BTREE_RV_BUFFER_SIZE + MAX_ALIGNMENT];
  char *rv_redo_data = PTR_ALIGN (rv_redo_data_buffer, MAX_ALIGNMENT);
  char *rv_redo_data_ptr = NULL;
  int rv_redo_data_length = 0;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (object_info != NULL);
  assert (first_overflow_vpid != NULL);
  assert (new_vpid != NULL);
  assert (new_page_ptr != NULL);
  assert (BTREE_MVCC_INFO_HAS_INSID (&object_info->mvcc_info) && BTREE_MVCC_INFO_HAS_DELID (&object_info->mvcc_info));

  /* Get a new overflow page */
  *new_page_ptr = btree_get_new_page (thread_p, btid_int, new_vpid, near_vpid);
  if (*new_page_ptr == NULL)
    {
      ASSERT_ERROR_AND_SET (error_code);
      return error_code;
    }

  VPID_COPY (&ovf_header_info.next_vpid, first_overflow_vpid);

  error_code = btree_init_overflow_header (thread_p, *new_page_ptr, &ovf_header_info);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      return error_code;
    }

  /* Insert the value in the new overflow page */
  /* Prepare record */
  rec.type = REC_HOME;
  rec.area_size = DB_PAGESIZE;
  rec.data = PTR_ALIGN (rec_buf, BTREE_MAX_ALIGN);
  rec.length = 0;
  btree_record_append_object (thread_p, btid_int, &rec, BTREE_OVERFLOW_NODE, object_info, NULL, NULL);

#if !defined (NDEBUG)
  (void) btree_check_valid_record (thread_p, btid_int, &rec, BTREE_OVERFLOW_NODE, NULL);
#endif /* !NDEBUG */

  /* Insert in page. */
  if (spage_insert_at (thread_p, *new_page_ptr, 1, &rec) != SP_SUCCESS)
    {
      assert_release (false);
      return ER_FAILED;
    }

  /* Initialized log data address */
  addr.offset = 0;
  addr.pgptr = *new_page_ptr;
  addr.vfid = &btid_int->sys_btid->vfid;

  /* Redo log. */
  rv_redo_data_ptr = rv_redo_data;
  LOG_RV_RECORD_SET_MODIFY_MODE (&addr, LOG_RV_RECORD_INSERT);
  BTREE_RV_SET_OVERFLOW_NODE (&addr);
#if !defined (NDEBUG)
  BTREE_RV_REDO_SET_DEBUG_INFO (&addr, rv_redo_data_ptr, btid_int, BTREE_RV_DEBUG_ID_START_OVF);
#endif /* !NDEBUG */
  /* Save first overflow link. */
  OR_PUT_VPID_ALIGNED (rv_redo_data_ptr, first_overflow_vpid);
  rv_redo_data_ptr += DISK_VPID_ALIGNED_SIZE;
  /* Save overflow record data. */
  memcpy (rv_redo_data_ptr, rec.data, rec.length);
  rv_redo_data_ptr += rec.length;

  BTREE_RV_GET_DATA_LENGTH (rv_redo_data_ptr, rv_redo_data, rv_redo_data_length);
  log_append_redo_data (thread_p, RVBT_RECORD_MODIFY_NO_UNDO, &addr, rv_redo_data_length, rv_redo_data);

  pgbuf_set_dirty (thread_p, *new_page_ptr, DONT_FREE);

  return NO_ERROR;
}

/*
 * btree_get_disk_size_of_key () -
 *   return:
 *   key(in):
 */
int
btree_get_disk_size_of_key (DB_VALUE * key)
{
  if (key == NULL || DB_IS_NULL (key))
    {
      assert (key != NULL && !DB_IS_NULL (key));
      return 0;
    }

  return pr_index_writeval_disk_size (key);
}

/*
 * btree_write_record () -
 *   return: NO_ERROR
 *   btid(in):
 *   node_rec(in):
 *   key(in):
 *   node_type(in):
 *   key_type(in):
 *   key_len(in):
 *   during_loading(in):
 *   class_oid(in):
 *   oid(in):
 *   p_mvcc_rec_header(in): MVCC record header
 *   rec(out):
 *
 * Note: This routine forms a btree record for both leaf and non leaf pages.
 *
 * node_rec is a NON_LEAF_REC * if we are writing a non leaf page,
 * otherwise it is a LEAF_REC *. ovfl_key indicates whether the key will
 * be written to the page or stored by the overflow manager. If we are
 * writing a non leaf record, oid should be NULL and will be ignored in
 * any case.
 */
int
btree_write_record (THREAD_ENTRY * thread_p, BTID_INT * btid, void *node_rec, DB_VALUE * key, BTREE_NODE_TYPE node_type,
		    int key_type, int key_len, bool during_loading, OID * class_oid, OID * oid,
		    BTREE_MVCC_INFO * mvcc_info, RECDES * rec)
{
  VPID key_vpid;
  OR_BUF buf;
  int error_code = NO_ERROR;

  assert (node_type == BTREE_LEAF_NODE || node_type == BTREE_NON_LEAF_NODE);
  assert (key_type == BTREE_NORMAL_KEY || key_type == BTREE_OVERFLOW_KEY);
  assert (rec != NULL);

  or_init (&buf, rec->data, rec->area_size);

  if (node_type == BTREE_LEAF_NODE)
    {
      /* first instance oid */
      error_code = or_put_oid (&buf, oid);
      if (error_code != NO_ERROR)
	{
	  assert_release (false);
	  return error_code;
	}
      if (BTREE_IS_UNIQUE (btid->unique_pk) && !OID_EQ (&btid->topclass_oid, class_oid))
	{
	  /* write the subclass OID */
	  error_code = or_put_oid (&buf, class_oid);
	  if (error_code != NO_ERROR)
	    {
	      assert_release (false);
	      return error_code;
	    }
	  btree_leaf_set_flag (rec, BTREE_LEAF_RECORD_CLASS_OID);
	}

      if (mvcc_info != NULL)
	{
	  if (BTREE_MVCC_INFO_HAS_INSID (mvcc_info))
	    {
	      error_code = or_put_mvccid (&buf, mvcc_info->insert_mvccid);
	      if (error_code != NO_ERROR)
		{
		  assert_release (false);
		  return error_code;
		}
	    }
	  if (BTREE_MVCC_INFO_HAS_DELID (mvcc_info))
	    {
	      error_code = or_put_mvccid (&buf, mvcc_info->delete_mvccid);
	      if (error_code != NO_ERROR)
		{
		  assert_release (false);
		  return error_code;
		}
	    }
	  btree_record_object_set_mvcc_flags (rec->data, mvcc_info->flags);
	}
    }
  else
    {
      NON_LEAF_REC *non_leaf_rec = (NON_LEAF_REC *) node_rec;

      btree_write_fixed_portion_of_non_leaf_record_to_orbuf (&buf, non_leaf_rec);
    }

  /* write the key */
  if (key_type == BTREE_NORMAL_KEY)
    {				/* key fits in page */
      PR_TYPE *pr_type;

      if (node_type == BTREE_LEAF_NODE)
	{
	  pr_type = btid->key_type->type;
	}
      else
	{
	  pr_type = btid->nonleaf_key_type->type;
	}

      error_code = pr_type->index_writeval (&buf, key);
      if (error_code != NO_ERROR)
	{
	  assert_release (false);
	  return error_code;
	}
    }
  else
    {
      /* overflow key */
      if (node_type == BTREE_LEAF_NODE)
	{
	  btree_leaf_set_flag (rec, BTREE_LEAF_RECORD_OVERFLOW_KEY);
	}

      error_code = btree_store_overflow_key (thread_p, btid, key, key_len, node_type, &key_vpid);
      if (error_code != NO_ERROR)
	{
	  return error_code;
	}

      /* write the overflow VPID as the key */
      error_code = or_put_int (&buf, key_vpid.pageid);
      if (error_code != NO_ERROR)
	{
	  assert_release (false);
	  return error_code;
	}
      error_code = or_put_short (&buf, key_vpid.volid);
      if (error_code != NO_ERROR)
	{
	  assert_release (false);
	  return error_code;
	}
    }

  error_code = or_put_align32 (&buf);
  if (error_code != NO_ERROR)
    {
      assert_release (false);
      return error_code;
    }

  rec->length = CAST_BUFLEN (buf.ptr - buf.buffer);
  rec->type = REC_HOME;

  /* Success. */
  return NO_ERROR;
}

/*
 * btree_read_record () -
 *   return:
 *   btid(in):
 *   pgptr(in):
 *   rec(in):
 *   key(in):
 *   rec_header(in):
 *   node_type(in):
 *   clear_key(in):
 *   offset(in):
 *   copy_key(in):
 *
 * Note: This routine reads a btree record for both leaf and non leaf pages.
 *
 * copy_key indicates whether strings should be malloced and copied
 * or just returned via pointer.  offset will point to the oid(s) following
 * the key for leaf pages.  clear_key will indicate whether the key needs
 * to be cleared via pr_clear_value by the caller.  If this record is
 * a leaf record, rec_header will be filled in with the LEAF_REC,
 * otherwise, rec_header will be filled in with the NON_LEAF_REC for this
 * record.
 *
 * If you don't want to actually read the key (possibly incurring a
 * malloc for the string), you can send a NULL pointer for the key.
 * index_readval() will do the right thing and simply skip the key in this case.
 */
int
btree_read_record (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR pgptr, RECDES * rec, DB_VALUE * key,
		   void *rec_header, BTREE_NODE_TYPE node_type, bool * clear_key, int *offset, int copy_key,
		   BTREE_SCAN * bts)
{
  int n_prefix = COMMON_PREFIX_UNKNOWN;
  int error;

  assert (pgptr != NULL);
  assert (rec != NULL);
  assert (rec->type == REC_HOME);
  assert (bts == NULL || bts->common_prefix == -1
	  || bts->common_prefix == btree_node_common_prefix (thread_p, btid, pgptr));

  if (bts != NULL)
    {
      n_prefix = bts->common_prefix;
    }

  error =
    btree_read_record_without_decompression (thread_p, btid, rec, key, rec_header, node_type, clear_key, offset,
					     copy_key);
  if (error != NO_ERROR)
    {
      return error;
    }

  if (key != NULL && node_type == BTREE_LEAF_NODE && !btree_leaf_is_flaged (rec, BTREE_LEAF_RECORD_OVERFLOW_KEY)
      && !btree_leaf_is_flaged (rec, BTREE_LEAF_RECORD_FENCE))
    {
      if (n_prefix == COMMON_PREFIX_UNKNOWN)
	{
	  /* recalculate n_prefix */
	  n_prefix = btree_node_common_prefix (thread_p, btid, pgptr);
	}

      assert (n_prefix >= 0);

      if (n_prefix > 0)
	{
	  RECDES peek_rec;
	  DB_VALUE lf_key, result;
	  bool lf_clear_key;
	  LEAF_REC leaf_pnt;
	  int dummy_offset;

	  btree_init_temp_key_value (&lf_clear_key, &lf_key);
	  (void) spage_get_record (thread_p, pgptr, 1, &peek_rec, PEEK);
	  error = btree_read_record_without_decompression (thread_p, btid, &peek_rec, &lf_key, &leaf_pnt,
							   BTREE_LEAF_NODE, &lf_clear_key, &dummy_offset,
							   PEEK_KEY_VALUE);
	  if (error != NO_ERROR)
	    {
	      btree_clear_key_value (clear_key, key);
	      return error;
	    }

	  assert (btree_leaf_is_flaged (&peek_rec, BTREE_LEAF_RECORD_FENCE));
	  assert (DB_VALUE_TYPE (&lf_key) == DB_TYPE_MIDXKEY);

	  pr_midxkey_add_prefix (&result, &lf_key, key, n_prefix);

	  btree_clear_key_value (clear_key, key);
	  btree_clear_key_value (&lf_clear_key, &lf_key);

	  *key = result;
	  *clear_key = true;
	}
      else if (n_prefix < 0)
	{
	  return n_prefix;
	}
    }

  return NO_ERROR;
}

/*
 * btree_read_record_without_decompression () -
 *   return:
 *   btid(in):
 *   rec(in):
 *   key(in):
 *   rec_header(in):
 *   node_type(in):
 *   clear_key(in):
 *   offset(in):
 *   copy_key(in):
 *
 */
static int
btree_read_record_without_decompression (THREAD_ENTRY * thread_p, BTID_INT * btid, RECDES * rec, DB_VALUE * key,
					 void *rec_header, BTREE_NODE_TYPE node_type, bool * clear_key, int *offset,
					 int copy_key)
{
  OR_BUF buf;
  VPID overflow_vpid;
  char *copy_key_buf;
  int copy_key_buf_len;
  int rc = NO_ERROR;
  int key_type = BTREE_NORMAL_KEY;
  LEAF_REC *leaf_rec = NULL;
  NON_LEAF_REC *non_leaf_rec = NULL;

  assert (rec != NULL);
  assert (rec->type == REC_HOME);

  if (key != NULL)
    {
      btree_clear_key_value (clear_key, key);
    }

  *clear_key = false;

#if !defined(NDEBUG)
  if (!rec || !rec->data)
    {
      btree_log_if_enabled ("btree_read_record_without_decompression: null node header pointer. Operation Ignored.");
      return rc;
    }
#endif

  assert (rec_header != NULL);

  or_init (&buf, rec->data, rec->length);

  /*
   * Find the beginning position of the key within the record and read
   * the key length.
   */
  if (node_type == BTREE_LEAF_NODE)
    {
      leaf_rec = (LEAF_REC *) rec_header;
      leaf_rec->key_len = -1;

      rc = or_advance (&buf, OR_OID_SIZE);	/* skip instance oid */
      if (rc != NO_ERROR)
	{
	  return rc;
	}

      if (BTREE_IS_UNIQUE (btid->unique_pk))
	{
	  if (btree_leaf_is_flaged (rec, BTREE_LEAF_RECORD_CLASS_OID))
	    {
	      rc = or_advance (&buf, OR_OID_SIZE);	/* skip class oid */
	      if (rc != NO_ERROR)
		{
		  return rc;
		}
	    }
	}

      if (btree_record_object_is_flagged (rec->data, BTREE_OID_HAS_MVCC_INSID))
	{
	  rc = or_advance (&buf, OR_MVCCID_SIZE);	/* skip insert mvccid */
	  if (rc != NO_ERROR)
	    {
	      return rc;
	    }
	}

      if (btree_record_object_is_flagged (rec->data, BTREE_OID_HAS_MVCC_DELID))
	{
	  rc = or_advance (&buf, OR_MVCCID_SIZE);	/* skip delete mvccid */
	  if (rc != NO_ERROR)
	    {
	      return rc;
	    }
	}

      if (btree_leaf_is_flaged (rec, BTREE_LEAF_RECORD_OVERFLOW_KEY))
	{
	  key_type = BTREE_OVERFLOW_KEY;
	}

      if (btree_leaf_is_flaged (rec, BTREE_LEAF_RECORD_OVERFLOW_OIDS))
	{
	  btree_leaf_get_vpid_for_overflow_oids (rec, &leaf_rec->ovfl);
	}
      else
	{
	  VPID_SET_NULL (&leaf_rec->ovfl);
	}

      assert (leaf_rec->key_len == -1);
    }
  else
    {
      non_leaf_rec = (NON_LEAF_REC *) rec_header;
      non_leaf_rec->key_len = -1;

      rc = btree_read_fixed_portion_of_non_leaf_record_from_orbuf (&buf, non_leaf_rec);
      if (rc != NO_ERROR)
	{
	  return rc;
	}

      if (non_leaf_rec->key_len < 0)
	{
	  key_type = BTREE_OVERFLOW_KEY;
	}
    }

  if (key_type == BTREE_NORMAL_KEY)
    {				/* key is within page */
      TP_DOMAIN *key_domain;
      PR_TYPE *pr_type;
      char *old_ptr;

      if (node_type == BTREE_LEAF_NODE)
	{
	  key_domain = btid->key_type;
	}
      else
	{
	  key_domain = btid->nonleaf_key_type;
	}
      pr_type = key_domain->type;

      copy_key_buf = NULL;
      copy_key_buf_len = 0;

      /*
       * When we read the key, must copy in two cases:
       *   1) we are told to via the copy_key flag, or 2) it is a set.
       */
      if (key != NULL && copy_key == COPY_KEY_VALUE)
	{
	  *clear_key = true;
	}
      else
	{
	  *clear_key = false;
	}

      if (*clear_key)
	{			/* need to copy the key */
	  if (btid->copy_buf != NULL)
	    {			/* check for copy_buf */
	      if (pr_type->id == DB_TYPE_MIDXKEY || QSTR_IS_ANY_CHAR_OR_BIT (pr_type->id))
		{		/* check for the key type */
		  /* read key_val image into the copy_buf */
		  copy_key_buf = btid->copy_buf;
		  copy_key_buf_len = btid->copy_buf_len;
		}
	    }
	}

      old_ptr = buf.ptr;
      rc = pr_type->index_readval (&buf, key, key_domain, -1, *clear_key, copy_key_buf, copy_key_buf_len);
      if (rc != NO_ERROR)
	{
	  return rc;
	}
      assert (CAST_BUFLEN (buf.ptr - old_ptr) > 0);
      if (key != NULL)
	{
	  assert (!DB_IS_NULL (key));
	}

      if (node_type == BTREE_LEAF_NODE)
	{
	  leaf_rec->key_len = CAST_BUFLEN (buf.ptr - old_ptr);
	}
      else
	{
	  non_leaf_rec->key_len = CAST_BUFLEN (buf.ptr - old_ptr);
	}
    }
  else
    {
      /* follow the chain of overflow key page pointers and fetch key */
      overflow_vpid.pageid = or_get_int (&buf, &rc);
      if (rc == NO_ERROR)
	{
	  overflow_vpid.volid = or_get_short (&buf, &rc);
	  if (rc != NO_ERROR)
	    {
	      assert (false);

	      if (key != NULL)
		{
		  db_make_null (key);
		}

	      return rc;
	    }
	}
      else
	{
	  return rc;
	}

      if (key != NULL)
	{
	  rc = btree_load_overflow_key (thread_p, btid, &overflow_vpid, key, node_type);
	  if (rc != NO_ERROR)
	    {
	      db_make_null (key);
	      return rc;
	    }

	  assert (!DB_IS_NULL (key));

	  /* we always clear overflow keys */
	  *clear_key = true;
	}
      else
	{
	  /* we aren't copying the key so they don't have to clear it */
	  *clear_key = false;
	}
    }

  if (key != NULL && key->need_clear)
    {
      *clear_key = true;
    }

  buf.ptr = PTR_ALIGN (buf.ptr, OR_INT_SIZE);

  *offset = CAST_BUFLEN (buf.ptr - buf.buffer);

  return rc;
}

/*
 * btree_dump_root_header () -
 *   return:
 *   rec(in):
 */
static void
btree_dump_root_header (THREAD_ENTRY * thread_p, FILE * fp, PAGE_PTR page_ptr)
{
  OR_BUF buf;
  BTREE_ROOT_HEADER *root_header = NULL;
  TP_DOMAIN *key_type;

  root_header = btree_get_root_header (thread_p, page_ptr);
  if (root_header == NULL)
    {
      fprintf (fp, "btree_dump_root_header: get root header failure\n");

      return;
    }

  or_init (&buf, root_header->packed_key_domain, -1);
  key_type = or_get_domain (&buf, NULL, NULL);

  fprintf (fp, "==============    R O O T    P A G E   ================\n\n");
  fprintf (fp, " Key_Type: %s\n", pr_type_name (TP_DOMAIN_TYPE (key_type)));
  fprintf (fp, " Num OIDs: %d, Num NULLs: %d, Num keys: %d\n", root_header->num_oids, root_header->num_nulls,
	   root_header->num_keys);
  fprintf (fp, " Topclass_oid: (%d %d %d)\n", root_header->topclass_oid.volid, root_header->topclass_oid.pageid,
	   root_header->topclass_oid.slotid);
  fprintf (fp, " Unique: ");
  if (BTREE_IS_UNIQUE (root_header->unique_pk))
    {
      fprintf (fp, "1");
      if (BTREE_IS_PRIMARY_KEY (root_header->unique_pk))
	{
	  fprintf (fp, " (Primary Key)");
	}
    }
  else
    {
      assert (!BTREE_IS_PRIMARY_KEY (root_header->unique_pk));
      fprintf (fp, "0");
    }
  fprintf (fp, "\n");
  fprintf (fp, " OVFID: %d|%d\n", root_header->ovfid.fileid, root_header->ovfid.volid);
  fprintf (fp, " Btree Revision Level: %d\n", root_header->rev_level);
  fprintf (fp, " Reserved: %d\n", root_header->reverse_reserved);	/* unused */
  fprintf (fp, "\n");
}

/*
 * btree_dump_key () -
 *   return:
 *   key(in):
 */
void
btree_dump_key (FILE * fp, const DB_VALUE * key)
{
  fprintf (fp, " ");
  db_fprint_value (fp, key);
  fprintf (fp, " ");
}

/*
 * btree_dump_leaf_record () -
 *   return: nothing
 *   btid(in): B+tree index identifier
 *   rec(in): Pointer to a record in a leaf page of the tree
 *   n(in): Indentation left margin (number of preceding blanks)
 *
 * Note: Dumps the content of a leaf record, namely key and the set of values for the key.
 */
static void
btree_dump_leaf_record (THREAD_ENTRY * thread_p, FILE * fp, BTID_INT * btid, RECDES * rec, int depth)
{
  OR_BUF buf;
  LEAF_REC leaf_record = { {NULL_PAGEID, NULL_VOLID}, 0 };
  int i, k, oid_cnt;
  OID class_oid;
  OID oid;
  int key_len, offset;
  VPID overflow_vpid;
  DB_VALUE key;
  bool clear_key;
  int oid_size;
  MVCCID mvccid;
  int error;
  BTREE_MVCC_INFO mvcc_info;

  btree_init_temp_key_value (&clear_key, &key);

  if (BTREE_IS_UNIQUE (btid->unique_pk))
    {
      oid_size = (2 * OR_OID_SIZE);
    }
  else
    {
      oid_size = OR_OID_SIZE;
    }

  /* output the leaf record structure content */
  btree_print_space (fp, depth * 4 + 1);

  error =
    btree_read_record_without_decompression (thread_p, btid, rec, &key, &leaf_record, BTREE_LEAF_NODE, &clear_key,
					     &offset, PEEK_KEY_VALUE);
  if (error != NO_ERROR)
    {
      return;
    }
  key_len = btree_get_disk_size_of_key (&key);

  fprintf (fp, "Key_Len: %d Ovfl_Page: {%d , %d} ", key_len, leaf_record.ovfl.volid, leaf_record.ovfl.pageid);

  fprintf (fp, "Key: ");
  btree_dump_key (fp, &key);

  btree_clear_key_value (&clear_key, &key);

  overflow_vpid = leaf_record.ovfl;

  /* output the values */
  fprintf (fp, "  Values: ");

  oid_cnt = btree_record_get_num_oids (thread_p, btid, rec, offset, BTREE_LEAF_NODE);
  fprintf (fp, "Oid_Cnt: %d ", oid_cnt);

  /* output first oid */
  (void) btree_leaf_get_first_object (btid, rec, &oid, &class_oid, &mvcc_info);
  if (BTREE_IS_UNIQUE (btid->unique_pk))
    {
      fprintf (fp, " (%d %d %d : %d, %d, %d) ", class_oid.volid, class_oid.pageid, class_oid.slotid, oid.volid,
	       oid.pageid, oid.slotid);
    }
  else
    {
      fprintf (fp, " (%d, %d, %d) ", oid.volid, oid.pageid, oid.slotid);
    }

  /* output MVCCIDs of first OID */
  if (mvcc_info.flags != 0)
    {
      fprintf (fp, " (");
      if (mvcc_info.flags & BTREE_OID_HAS_MVCC_INSID)
	{
	  /* Get and print insert MVCCID */
	  OR_GET_MVCCID (rec->data + oid_size, &mvccid);
	  fprintf (fp, "insid=%llu", (long long) mvccid);

	  if (mvcc_info.flags & BTREE_OID_HAS_MVCC_DELID)
	    {
	      /* Get and print delete MVCCID */
	      OR_GET_MVCCID (rec->data + oid_size + OR_MVCCID_SIZE, &mvccid);
	      fprintf (fp, ", delid=%llu", (long long) mvccid);
	    }
	}
      else
	{
	  /* Safe guard */
	  assert (mvcc_info.flags & BTREE_OID_HAS_MVCC_DELID);

	  /* Get and print delete MVCCID */
	  OR_GET_MVCCID (rec->data + oid_size, &mvccid);
	  fprintf (fp, "delid=%llu", (long long) mvccid);
	}

      fprintf (fp, ")  ");
    }

  /* output remainder OIDs */
  or_init (&buf, rec->data + offset, rec->length - offset);
  if (BTREE_IS_UNIQUE (btid->unique_pk))
    {
      for (k = 1; k < oid_cnt; k++)
	{
	  /* values stored within the record */
	  if (k % 2 == 0)
	    {
	      fprintf (fp, "\n");
	    }

	  /* Get OID */
	  or_get_oid (&buf, &oid);
	  BTREE_OID_CLEAR_MVCC_FLAGS (&oid);

	  /* Get class OID */
	  or_get_oid (&buf, &class_oid);

	  /* Print OID and class OID */
	  fprintf (fp, " (%d %d %d : %d, %d, %d) ", class_oid.volid, class_oid.pageid, class_oid.slotid, oid.volid,
		   oid.pageid, oid.slotid);

	  /* Since objects are fixed size, they contain both insert and delete MVCCID's. */
	  fprintf (fp, " (");

	  /* Get and print insert MVCCID */
	  (void) or_get_mvccid (&buf, &mvccid);
	  fprintf (fp, "insid=%llu", (long long) mvccid);

	  /* Get and print delete MVCCID */
	  (void) or_get_mvccid (&buf, &mvccid);
	  fprintf (fp, ", delid=%llu", (long long) mvccid);

	  fprintf (fp, ")  ");
	}
    }
  else
    {
      for (k = 1; k < oid_cnt; k++)
	{
	  /* values stored within the record */
	  if (k % 4 == 0)
	    {
	      fprintf (fp, "\n");
	    }

	  /* Get MVCC flags */
	  mvcc_info.flags = btree_record_object_get_mvcc_flags (buf.ptr);

	  or_get_oid (&buf, &oid);
	  BTREE_OID_CLEAR_MVCC_FLAGS (&oid);

	  fprintf (fp, " (%d, %d, %d) ", oid.volid, oid.pageid, oid.slotid);

	  if (mvcc_info.flags != 0)
	    {
	      fprintf (fp, " (");
	      if (mvcc_info.flags & BTREE_OID_HAS_MVCC_INSID)
		{
		  /* Get and print insert MVCCID */
		  (void) or_get_mvccid (&buf, &mvccid);
		  fprintf (fp, "insid=%llu", (long long) mvccid);

		  if (mvcc_info.flags & BTREE_OID_HAS_MVCC_DELID)
		    {
		      /* Get and print delete MVCCID */
		      (void) or_get_mvccid (&buf, &mvccid);
		      fprintf (fp, ", delid=%llu", (long long) mvccid);
		    }
		}
	      else
		{
		  /* Safe guard */
		  assert (mvcc_info.flags & BTREE_OID_HAS_MVCC_DELID);

		  /* Get and print delete MVCCID */
		  (void) or_get_mvccid (&buf, &mvccid);
		  fprintf (fp, "delid=%llu", (long long) mvccid);
		}
	      fprintf (fp, ")  ");
	    }
	}
    }

  if (!VPID_ISNULL (&overflow_vpid))
    {
      /* record has an overflow page continuation */
      RECDES overflow_rec;
      PAGE_PTR overflow_page_ptr = NULL;
      char overflow_rec_buf[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];

      overflow_rec.area_size = DB_PAGESIZE;
      overflow_rec.data = PTR_ALIGN (overflow_rec_buf, BTREE_MAX_ALIGN);

      fprintf (fp, "\n\n=======    O V E R F L O W   P A G E S     =========\n");
      fflush (fp);

      /* get all the overflow pages and output their value content */
      while (!VPID_ISNULL (&overflow_vpid))
	{
	  fprintf (fp, "\n ------ Overflow Page {%d , %d} \n", overflow_vpid.volid, overflow_vpid.pageid);
	  overflow_page_ptr =
	    pgbuf_fix (thread_p, &overflow_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
	  if (overflow_page_ptr == NULL)
	    {
	      ASSERT_ERROR ();
	      return;
	    }

	  btree_get_next_overflow_vpid (thread_p, overflow_page_ptr, &overflow_vpid);

	  (void) spage_get_record (thread_p, overflow_page_ptr, 1, &overflow_rec, COPY);

	  oid_cnt = btree_record_get_num_oids (thread_p, btid, &overflow_rec, 0, BTREE_OVERFLOW_NODE);
	  or_init (&buf, overflow_rec.data, overflow_rec.length);
	  fprintf (fp, "Oid_Cnt: %d ", oid_cnt);

	  for (i = 0; i < oid_cnt; i++)
	    {
	      if (i % 4 == 0)
		{
		  fprintf (stdout, "\n");
		}

	      or_get_oid (&buf, &oid);
	      BTREE_OID_CLEAR_MVCC_FLAGS (&oid);

	      fprintf (fp, " (%d, %d, %d) ", oid.volid, oid.pageid, oid.slotid);

	      if (BTREE_IS_UNIQUE (btid->unique_pk))
		{
		  or_get_oid (&buf, &class_oid);
		  fprintf (fp, " (%d, %d, %d) ", class_oid.volid, class_oid.pageid, class_oid.slotid);
		}

	      fprintf (fp, " (");
	      (void) or_get_mvccid (&buf, &mvccid);
	      fprintf (fp, "insid=%llu", (long long) mvccid);
	      (void) or_get_mvccid (&buf, &mvccid);
	      fprintf (fp, ", delid=%llu", (long long) mvccid);
	      fprintf (fp, ")  ");
	    }

	  pgbuf_unfix_and_init (thread_p, overflow_page_ptr);
	}
    }

  fprintf (fp, "\n");
  fflush (fp);
}

/*
 * btree_dump_non_leaf_record () -
 *   return: void
 *   btid(in):
 *   rec(in): Pointer to a record in a non_leaf page
 *   n(in): Indentation left margin (number of preceding blanks)
 *   print_key(in):
 *
 * Note: Dumps the content of a nonleaf record, namely key and child page identifier.
 */
static void
btree_dump_non_leaf_record (THREAD_ENTRY * thread_p, FILE * fp, BTID_INT * btid, RECDES * rec, int depth, int print_key)
{
  NON_LEAF_REC non_leaf_record;
  int key_len, offset;
  DB_VALUE key;
  bool clear_key;
  int error;

  VPID_SET_NULL (&(non_leaf_record.pnt));

  btree_init_temp_key_value (&clear_key, &key);

  /* output the non_leaf record structure content */
  error =
    btree_read_record_without_decompression (thread_p, btid, rec, &key, &non_leaf_record, BTREE_NON_LEAF_NODE,
					     &clear_key, &offset, PEEK_KEY_VALUE);
  if (error != NO_ERROR)
    {
      return;
    }

  btree_print_space (fp, depth * 4);
  fprintf (fp, "Child_Page: {%d , %d} ", non_leaf_record.pnt.volid, non_leaf_record.pnt.pageid);

  if (print_key)
    {
      key_len = btree_get_disk_size_of_key (&key);
      fprintf (fp, "Key_Len: %d  Key: ", key_len);
      btree_dump_key (fp, &key);
    }
  else
    {
      fprintf (fp, "No Key");
    }

  btree_clear_key_value (&clear_key, &key);

  fprintf (fp, "\n");
  fflush (fp);
}

/*
 * btree_get_new_page () - GET a NEW PAGE for the B+tree index
 *   return: The pointer to a newly allocated page for the given B+tree or NULL.
 *           The parameter vpid is set to the page identifier.
 *   btid(in): B+tree index identifier
 *   vpid(out): Set to the page identifier for the newly allocated page
 *   near_vpid(in): A page identifier that may be used in a nearby page allocation. (It may be ignored.)
 *
 * Note: Allocates a new page for the B+tree
 */
static PAGE_PTR
btree_get_new_page (THREAD_ENTRY * thread_p, BTID_INT * btid, VPID * vpid, VPID * near_vpid)
{
  PAGE_PTR page_ptr = NULL;

  if (file_alloc (thread_p, &btid->sys_btid->vfid, btree_initialize_new_page, NULL, vpid, &page_ptr) != NO_ERROR)
    {
      ASSERT_ERROR ();
      return NULL;
    }
  if (page_ptr == NULL)
    {
      assert_release (false);
      return NULL;
    }
  pgbuf_check_page_ptype (thread_p, page_ptr, PAGE_BTREE);

  return page_ptr;
}

/*
 * btree_initialize_new_page () - initialize a new b-tree page
 *
 * return        : NO_ERROR
 * thread_p (in) : thread entry
 * page (in)     : new b-tree page
 * args (in)     : true or nil for undoredo logging; false for redo
 */
int
btree_initialize_new_page (THREAD_ENTRY * thread_p, PAGE_PTR page, void *args)
{
  pgbuf_set_page_ptype (thread_p, page, PAGE_BTREE);

  spage_initialize (thread_p, page, UNANCHORED_KEEP_SEQUENCE, BTREE_MAX_ALIGN, DONT_SAFEGUARD_RVSPACE);
  log_append_undoredo_data2 (thread_p, RVBT_GET_NEWPAGE, NULL, page, -1, 0, 0, NULL, NULL);
  pgbuf_set_dirty (thread_p, page, DONT_FREE);

  return NO_ERROR;
}

/*
 * btree_search_nonleaf_page () -
 *   return: NO_ERROR
 *   btid(in):
 *   page_ptr(in): Pointer to the non_leaf page to be searched
 *   key(in): Key to find
 *   slot_id(out): Set to the record number that contains the key
 *   child_vpid(out): Set to the child page identifier to be followed, or NULL_PAGEID
 *
 * Note: Binary search the page to locate the record that contains the child page pointer to be followed to locate
 *       the key, and return the page identifier for this child page.
 */
static int
btree_search_nonleaf_page (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR page_ptr, DB_VALUE * key, INT16 * slot_id,
			   VPID * child_vpid, page_key_boundary * page_bounds)
{
  int key_cnt, offset;
  int c;
  bool clear_key;
  /* the start position of non-equal-value column */
  int start_col, left_start_col, right_start_col;
  INT16 left, right;
  INT16 middle = 0;
  DB_VALUE temp_key;
  RECDES rec;
  NON_LEAF_REC non_leaf_rec;

  /* initialize child page identifier */
  VPID_SET_NULL (child_vpid);

  btree_init_temp_key_value (&clear_key, &temp_key);

#if !defined(NDEBUG)
  if (!page_ptr || !key || DB_IS_NULL (key))
    {
      btree_log_if_enabled ("btree_search_nonleaf_page: null page/key pointer. Operation Ignored.");
      return ER_FAILED;
    }
#endif

  key_cnt = btree_node_number_of_keys (thread_p, page_ptr);
  assert (key_cnt > 0);

  if (key_cnt <= 0)
    {				/* node record underflow */
      btree_log_if_enabled ("btree_search_nonleaf_page: node key count underflow: %d", key_cnt);
      return ER_FAILED;
    }

  if (key_cnt == 1)
    {
      /*
       * node has dummy neg-inf keys, but a child page pointer
       * So, follow this pointer
       */
      if (spage_get_record (thread_p, page_ptr, 1, &rec, PEEK) != S_SUCCESS)
	{
	  return ER_FAILED;
	}

      btree_read_fixed_portion_of_non_leaf_record (&rec, &non_leaf_rec);

      *slot_id = 1;
      *child_vpid = non_leaf_rec.pnt;

      return NO_ERROR;
    }

  /* binary search the node to find the child page pointer to be followed */
  c = 0;

  /* for non-compressed midxkey; separator is not compressed */
  left_start_col = right_start_col = 0;

  left = 2;			/* Ignore dummy key (neg-inf or 1st key) */
  right = key_cnt;

  while (left <= right)
    {
      btree_clear_key_value (&clear_key, &temp_key);
      middle = CEIL_PTVDIV ((left + right), 2);	/* get the middle record */

      assert (middle > 0);
      if (spage_get_record (thread_p, page_ptr, middle, &rec, PEEK) != S_SUCCESS)
	{
	  return ER_FAILED;
	}

      if (btree_read_record_without_decompression (thread_p, btid, &rec, &temp_key, &non_leaf_rec, BTREE_NON_LEAF_NODE,
						   &clear_key, &offset, PEEK_KEY_VALUE) != NO_ERROR)
	{
	  return ER_FAILED;
	}

      if (DB_VALUE_DOMAIN_TYPE (key) == DB_TYPE_MIDXKEY)
	{
	  start_col = MIN (left_start_col, right_start_col);
	}

      c = btree_compare_key (key, &temp_key, btid->key_type, 1, 1, &start_col);

      if (c == DB_UNK)
	{
	  btree_clear_key_value (&clear_key, &temp_key);
	  return ER_FAILED;
	}

      if (c == 0)
	{
	  /* child page to be followed has been found */
	  *slot_id = middle;
	  *child_vpid = non_leaf_rec.pnt;

	  if (page_bounds != NULL)
	    {
	      if (page_bounds->update_boundary_eq (thread_p, btid, page_ptr, temp_key, clear_key, middle) != NO_ERROR)
		{
		  return ER_FAILED;
		}
	    }

	  btree_clear_key_value (&clear_key, &temp_key);
	  return NO_ERROR;
	}
      else if (c < 0)
	{
	  right = middle - 1;
	  right_start_col = start_col;
	}
      else
	{
	  left = middle + 1;
	  left_start_col = start_col;
	}
    }

  if (c < 0)
    {
      /* child page is the one pointed by the record left to the middle */
      assert (middle - 1 > 0);
      if (spage_get_record (thread_p, page_ptr, middle - 1, &rec, PEEK) != S_SUCCESS)
	{
	  btree_clear_key_value (&clear_key, &temp_key);
	  return ER_FAILED;
	}

      btree_read_fixed_portion_of_non_leaf_record (&rec, &non_leaf_rec);

      *slot_id = middle - 1;
      *child_vpid = non_leaf_rec.pnt;

      if (page_bounds != NULL)
	{
	  if (page_bounds->update_boundary_lt (thread_p, btid, page_ptr, rec, temp_key, clear_key) != NO_ERROR)
	    {
	      return ER_FAILED;
	    }
	}

    }
  else
    {
      /* child page is the one pointed by the middle record */
      *slot_id = middle;
      *child_vpid = non_leaf_rec.pnt;

      if (page_bounds != NULL)
	{
	  if (page_bounds->update_boundary_gt_or_eq (thread_p, btid, page_ptr, temp_key, clear_key, middle, key_cnt) !=
	      NO_ERROR)
	    {
	      return ER_FAILED;
	    }
	}
    }

  btree_clear_key_value (&clear_key, &temp_key);

  return NO_ERROR;
}

/*
 * btree_leaf_is_key_between_min_max () - Output if key is between first and last key in page. Function is useful
 *					  to decide to resume with leaf page after it was unfixed.
 *
 * return	    : Error code.
 * thread_p (in)    : Thread entry.
 * btid_int (in)    : B-tree info.
 * leaf (in)	    : Leaf page.
 * key (in)	    : Searched key.
 * search_key (out) : Output result of search.
 */
static int
btree_leaf_is_key_between_min_max (THREAD_ENTRY * thread_p, BTID_INT * btid_int, PAGE_PTR leaf, DB_VALUE * key,
				   BTREE_SEARCH_KEY_HELPER * search_key)
{
  DB_VALUE border_key;
  RECDES border_record;
  BTREE_NODE_HEADER *node_header = NULL;
  LEAF_REC dummy_leaf_rec;
  int dummy_offset;
  bool clear_key = false;
  int error_code = NO_ERROR;
  DB_VALUE_COMPARE_RESULT c = DB_UNK;
  int key_count = 0;

  /* Assert expected arguments */
  assert (btid_int != NULL);
  assert (leaf != NULL);
  assert (key != NULL && !DB_IS_NULL (key));

  if (DB_VALUE_DOMAIN_TYPE (key) != DB_TYPE_MIDXKEY)
    {
      /* We don't need to do the early check. Output search key result BTREE_KEY_BETWEEN to force a normal search. */
      search_key->result = BTREE_KEY_BETWEEN;
      return NO_ERROR;
    }

  search_key->result = BTREE_KEY_NOTFOUND;
  node_header = btree_get_node_header (thread_p, leaf);
  if (node_header == NULL)
    {
      assert (false);
      return ER_FAILED;
    }
  key_count = btree_node_number_of_keys (thread_p, leaf);
  if (key_count < 1)
    {
      /* Too few keys to decide. */
      return NO_ERROR;
    }

  /*
   * Compare with first key in page.
   */
  /* Read record and get key. */
  btree_init_temp_key_value (&clear_key, &border_key);

  if (spage_get_record (thread_p, leaf, 1, &border_record, PEEK) != S_SUCCESS)
    {
      assert_release (false);
      return ER_FAILED;
    }
  error_code =
    btree_read_record (thread_p, btid_int, leaf, &border_record, &border_key, &dummy_leaf_rec, BTREE_LEAF_NODE,
		       &clear_key, &dummy_offset, PEEK_KEY_VALUE, NULL);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      return error_code;
    }

  /* Compare with first key. */
  c = btree_compare_key (key, &border_key, btid_int->key_type, 1, 1, NULL);
  btree_clear_key_value (&clear_key, &border_key);
  if (c == DB_EQ)
    {
      if (btree_leaf_is_flaged (&border_record, BTREE_LEAF_RECORD_FENCE))
	{
	  /* Let btree_search_leaf_page find the key, if it exists. */
	  search_key->result = BTREE_KEY_BETWEEN;
	  /* Unknown slot */
	  search_key->slotid = -1;
	}
      else
	{
	  /* Key found. */
	  search_key->result = BTREE_KEY_FOUND;
	  search_key->slotid = 1;
	}
      return NO_ERROR;
    }
  else if (c != DB_GT)
    {
      /* Not bigger than first key. */
      search_key->result = (c == DB_LT) ? BTREE_KEY_SMALLER : BTREE_KEY_NOTFOUND;
      /* Unknown slot */
      search_key->slotid = -1;
      return NO_ERROR;
    }
  else if (key_count == 1)
    {
      search_key->result = BTREE_KEY_BIGGER;
      search_key->slotid = key_count + 1;
      return NO_ERROR;
    }

  /*
   * Compare with last key in page.
   */
  /* Read record and get key. */
  if (spage_get_record (thread_p, leaf, key_count, &border_record, PEEK) != S_SUCCESS)
    {
      assert_release (false);
      return ER_FAILED;
    }
  error_code =
    btree_read_record (thread_p, btid_int, leaf, &border_record, &border_key, &dummy_leaf_rec, BTREE_LEAF_NODE,
		       &clear_key, &dummy_offset, PEEK_KEY_VALUE, NULL);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      return error_code;
    }
  /* Compare with last key. */
  c = btree_compare_key (key, &border_key, btid_int->key_type, 1, 1, NULL);
  btree_clear_key_value (&clear_key, &border_key);
  if (c == DB_EQ)
    {
      if (btree_leaf_is_flaged (&border_record, BTREE_LEAF_RECORD_FENCE))
	{
	  search_key->result = BTREE_KEY_BIGGER;
	  search_key->slotid = key_count + 1;
	}
      else
	{
	  search_key->result = BTREE_KEY_FOUND;
	  search_key->slotid = key_count;
	}
      return NO_ERROR;
    }
  else if (c != DB_LT)
    {
      /* Not smaller than last key. */
      search_key->result = (c == DB_GT) ? BTREE_KEY_BIGGER : BTREE_KEY_NOTFOUND;
      search_key->slotid = key_count + 1;
      return NO_ERROR;
    }

  /* Key is between first and last key in leaf page. */
  search_key->result = BTREE_KEY_BETWEEN;
  /* Unknown slot */
  search_key->slotid = -1;
  return NO_ERROR;
}

/*
 * btree_search_leaf_page () - Search key in page and return result.
 *   return	      : Error code.
 *   btid (in)	      : B-tree info.
 *   page_ptr (in)    : Leaf node page pointer.
 *   key (in)	      : Search key.
 *   search_key (out) : Output result:
 *			- BTREE_KEY_FOUND and slotid of key.
 *			- BTREE_KEY_NOTFOUND (unknown compare result).
 *			- BTREE_KEY_SMALLER (smaller than any key in page, slotid = 0).
 *			- BTREE_KEY_BIGGER (bigger than any key in page, slotid = key_cnt + 1).
 *			- BTREE_KEY_BETWEEN (key is not found, but it would belong to this page if it existed.
 *			    slotid of next bigger key, where the searched key should be inserted).
 *
 * Note: Binary search the page to find the location of the key.
 *
 * NOTE: If this function is called after advancing through the index from
 *	 root and if page has upper fence key, under no circumstance can key
 *	 argument be equal to it. The advance algorithm should have pointed to next leaf node.
 *	 However this case is possible when accessing leaf node directly
 *	 (e.g. after unfixing-refixing leaf node). In this case, the key
 *	 is not considered equal to fence key, but rather bigger than all
 *	 keys in page. The caller should know to go to next page.
 */
static int
btree_search_leaf_page (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR page_ptr, DB_VALUE * key,
			BTREE_SEARCH_KEY_HELPER * search_key)
{
  int key_cnt = 0, offset = 0;
  int c = 0, n_prefix = 0;
  bool clear_key = false;
  /* the start position of non-equal-value column */
  int start_col = 0, left_start_col = 0, right_start_col = 0;
  INT16 left = 0, right = 0, middle = 0;
  DB_VALUE temp_key;
  RECDES rec;
  bool is_record_read = false;
  LEAF_REC leaf_pnt;
  int error = NO_ERROR;

  /* Assert expected arguments. */
  assert (btid != NULL);
  assert (key != NULL && !DB_IS_NULL (key));
  assert (page_ptr != NULL);
  assert (search_key != NULL);

  btree_init_temp_key_value (&clear_key, &temp_key);

  /* Initialize search results. */
  search_key->result = BTREE_KEY_NOTFOUND;
  search_key->slotid = NULL_SLOTID;
  search_key->has_fence_key = btree_search_key_helper::NO_FENCE_KEY;

  key_cnt = btree_node_number_of_keys (thread_p, page_ptr);
  if (key_cnt < 0)
    {
      assert (false);
      er_log_debug (ARG_FILE_LINE, "btree_search_leaf_page: node key count underflow: %d.", key_cnt);
      return ER_FAILED;
    }

  /* for compressed midxkey */
  n_prefix = btree_node_common_prefix (thread_p, btid, page_ptr);
  if (n_prefix < 0)
    {
      /* Error case? */
      return n_prefix;
    }
  left_start_col = right_start_col = n_prefix;

#if !defined (NDEBUG)
  if (key_cnt > 0 && DB_VALUE_DOMAIN_TYPE (key) == DB_TYPE_MIDXKEY && n_prefix > 0)
    {
      /* We need to make sure the key is between the values of fence keys. Otherwise, the optimized midxkey compare
       * that skips columns may be broken. */
      BTREE_SEARCH_KEY_HELPER debug_search_key;
      BTREE_NODE_HEADER *node_header = btree_get_node_header (thread_p, page_ptr);
      error = btree_leaf_is_key_between_min_max (thread_p, btid, page_ptr, key, &debug_search_key);
      if (error != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return error;
	}

      assert (debug_search_key.result == BTREE_KEY_FOUND || debug_search_key.result == BTREE_KEY_BETWEEN
	      || (debug_search_key.result == BTREE_KEY_SMALLER && VPID_ISNULL (&node_header->prev_vpid))
	      || (debug_search_key.result == BTREE_KEY_BIGGER && VPID_ISNULL (&node_header->next_vpid)));
    }
#endif /* !NDEBUG */

  /*
   * binary search the node to find if the key exists and in which record it
   * exists, or if it doesn't exist , the in which record it should have been
   * located to preserve the order of keys
   */

  /* Initialize binary search range to first and last key in page. */
  left = 1;
  right = key_cnt;

  /* Loop while binary search range has at least one key. */
  while (left <= right)
    {
      /* Get current range middle record */
      middle = CEIL_PTVDIV ((left + right), 2);
      /* Safe guard. */
      assert (middle > 0);

      /* Get current middle key. */
      if (spage_get_record (thread_p, page_ptr, middle, &rec, PEEK) != S_SUCCESS)
	{
	  /* Unexpected error. */
	  er_log_debug (ARG_FILE_LINE, "btree_search_leaf_page: sp_getrec fails for middle record.");
	  assert (false);
	  return ER_FAILED;
	}

      error =
	btree_read_record_without_decompression (thread_p, btid, &rec, &temp_key, &leaf_pnt, BTREE_LEAF_NODE,
						 &clear_key, &offset, PEEK_KEY_VALUE);
      if (error != NO_ERROR)
	{
	  /* Error! */
	  ASSERT_ERROR ();
	  return error;
	}

      is_record_read = true;

      if (DB_VALUE_DOMAIN_TYPE (key) == DB_TYPE_MIDXKEY)
	{
	  start_col = MIN (left_start_col, right_start_col);
	}

      /* Compare searched key with current middle key. */
      c = btree_compare_key (key, &temp_key, btid->key_type, 1, 1, &start_col);

      /* Clear current middle key. */
      btree_clear_key_value (&clear_key, &temp_key);
      if (c == DB_UNK)
	{
	  /* Unknown compare result? */
	  search_key->result = BTREE_KEY_NOTFOUND;
	  search_key->slotid = NULL_SLOTID;

	  /* Is this an error case? */
	  ASSERT_ERROR_AND_SET (error);
	  return error;
	}

      if (c == DB_EQ)
	{
	  /* Current middle key is equal to searched key. */
	  if (btree_leaf_is_flaged (&rec, BTREE_LEAF_RECORD_FENCE))
	    {
	      search_key->has_fence_key = btree_search_key_helper::HAS_FENCE_KEY;
	      /* Fence key! */
	      assert (middle == 1 || middle == key_cnt);
	      if (middle == 1)
		{
		  /* Set c = DB_GT and fall through to compare with next key. */
		  c = DB_GT;
		}
	      else if (middle == key_cnt)
		{
		  /* Key is bigger than all in page?? I have to understand these fence keys better. */
		  search_key->result = BTREE_KEY_BIGGER;
		  search_key->slotid = key_cnt;
		  return NO_ERROR;
		}
	    }
	  else
	    {
	      /* Key exists in page in current middle slot. */
	      search_key->result = BTREE_KEY_FOUND;
	      search_key->slotid = middle;
	      return NO_ERROR;
	    }
	}
      /* Key not found yet. Keep searching. */
      if (c < 0)
	{
	  /* Continue search between left and current middle. */
	  right = middle - 1;
	  right_start_col = start_col;
	}
      else
	{
	  /* Continue search between current middle and right. */
	  left = middle + 1;
	  left_start_col = start_col;
	}
    }

  if (c < 0)
    {
      if (is_record_read && btree_leaf_is_flaged (&rec, BTREE_LEAF_RECORD_FENCE))
	{
	  search_key->has_fence_key = btree_search_key_helper::HAS_FENCE_KEY;
	}

      /* Key doesn't exist and is smaller than current middle key. */
      if (middle == 1)
	{
	  /* Key is smaller than all records in page. */
	  search_key->result = BTREE_KEY_SMALLER;
	}
      else
	{
	  /* Key doesn't exist but should belong to this page. */
	  search_key->result = BTREE_KEY_BETWEEN;
	}
      search_key->slotid = middle;

      return NO_ERROR;
    }
  else
    {
      if (is_record_read && btree_leaf_is_flaged (&rec, BTREE_LEAF_RECORD_FENCE))
	{
	  search_key->has_fence_key = btree_search_key_helper::HAS_FENCE_KEY;
	}

      /* Key doesn't exist and is bigger than current middle key. */
      if (middle == key_cnt)
	{
	  search_key->result = BTREE_KEY_BIGGER;
	}
      else
	{
	  search_key->result = BTREE_KEY_BETWEEN;
	}
      search_key->slotid = middle + 1;

      return NO_ERROR;
    }

  /* Impossible to reach. */
  assert (false);
  return ER_FAILED;
}

/*
 * xbtree_add_index () - ADD (create) a new B+tree INDEX
 *   return: BTID * (btid on success and NULL on failure)
 *   btid(out): Set to the created B+tree index identifier (Note: btid->vfid.volid should be set by the caller)
 *   key_type(in): Key type of the index to be created.
 *   class_oid(in): OID of the class for which the index is created
 *   attr_id(in): Identifier of the attribute of the class for which the index is created.
 *   unique_pk(in):
 *   num_oids(in):
 *   num_nulls(in):
 *   num_keys(in):
 *
 * Note: Creates the B+tree index. A file identifier (index identifier)
 * is defined on the given volume. This identifier is used by
 * insertion, deletion and search routines, for the created
 * index. The routine allocates the root page of the tree and
 * initializes the root header information.
 */
BTID *
xbtree_add_index (THREAD_ENTRY * thread_p, BTID * btid, TP_DOMAIN * key_type, OID * class_oid, int attr_id,
		  int unique_pk, int num_oids, int num_nulls, int num_keys)
{
  BTREE_ROOT_HEADER root_header_info, *root_header = NULL;
  VPID root_vpid;
  PAGE_PTR page_ptr = NULL;

  root_header = &root_header_info;

  if (class_oid == NULL || OID_ISNULL (class_oid))
    {
      return NULL;
    }

  log_sysop_start (thread_p);

  /* create a file descriptor, allocate and initialize the root page */
  if (btree_create_file (thread_p, class_oid, attr_id, btid) != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto error;
    }
  btree_get_root_vpid_from_btid (thread_p, btid, &root_vpid);

  page_ptr = pgbuf_fix (thread_p, &root_vpid, OLD_PAGE, PGBUF_LATCH_WRITE, PGBUF_UNCONDITIONAL_LATCH);
  if (page_ptr == NULL)
    {
      ASSERT_ERROR ();
      goto error;
    }
  pgbuf_check_page_ptype (thread_p, page_ptr, PAGE_BTREE);

  /* form the root header information */
  root_header->node.split_info.pivot = 0.0f;
  root_header->node.split_info.index = 0;
  VPID_SET_NULL (&(root_header->node.prev_vpid));
  VPID_SET_NULL (&(root_header->node.next_vpid));
  root_header->node.node_level = 1;
  root_header->node.max_key_len = 0;

  if (unique_pk)
    {
      root_header->num_oids = num_oids;
      root_header->num_nulls = num_nulls;
      root_header->num_keys = num_keys;
      root_header->unique_pk = unique_pk;

      assert (BTREE_IS_UNIQUE (root_header->unique_pk));
      assert (BTREE_IS_PRIMARY_KEY (root_header->unique_pk) || !BTREE_IS_PRIMARY_KEY (root_header->unique_pk));
    }
  else
    {
      root_header->num_oids = -1;
      root_header->num_nulls = -1;
      root_header->num_keys = -1;
      root_header->unique_pk = 0;
    }

  COPY_OID (&(root_header->topclass_oid), class_oid);

  VFID_SET_NULL (&(root_header->ovfid));
  root_header->rev_level = BTREE_CURRENT_REV_LEVEL;

  root_header->reverse_reserved = 0;	/* unused */

#if defined (SERVER_MODE)
  root_header->creator_mvccid = logtb_get_current_mvccid (thread_p);
#else	/* !SERVER_MODE */		   /* SA_MODE */
  root_header->creator_mvccid = MVCCID_NULL;
#endif /* SA_MODE */

  if (btree_init_root_header (thread_p, &btid->vfid, page_ptr, root_header, key_type) != NO_ERROR)
    {
      goto error;
    }

  pgbuf_set_dirty (thread_p, page_ptr, FREE);
  page_ptr = NULL;

  log_sysop_attach_to_outer (thread_p);
  vacuum_log_add_dropped_file (thread_p, &btid->vfid, NULL, VACUUM_LOG_ADD_DROPPED_FILE_UNDO);
  if (unique_pk)
    {
      /* drop statistics if aborted */
      log_append_undo_data2 (thread_p, RVBT_REMOVE_UNIQUE_STATS, NULL, NULL, NULL_OFFSET, sizeof (BTID), btid);
    }

  return btid;

error:
  if (page_ptr)
    {
      pgbuf_unfix_and_init (thread_p, page_ptr);
    }

  VFID_SET_NULL (&btid->vfid);
  btid->root_pageid = NULL_PAGEID;

  log_sysop_abort (thread_p);

  return NULL;
}

/*
 * xbtree_delete_index () -
 *   return: NO_ERROR
 *   btid(in): B+tree index identifier
 *
 * Note: Removes the B+tree index. All pages associated with the index are removed. After the routine is called,
 *       the index identifier is not valid any more.
 */
int
xbtree_delete_index (THREAD_ENTRY * thread_p, BTID * btid)
{
  PAGE_PTR P = NULL;
  VPID P_vpid;
  BTREE_ROOT_HEADER *root_header = NULL;
  VFID ovfid;
  int unique_pk;
  int ret = NO_ERROR;

  P_vpid.volid = btid->vfid.volid;	/* read the root page */
  P_vpid.pageid = btid->root_pageid;
  P = pgbuf_fix (thread_p, &P_vpid, OLD_PAGE, PGBUF_LATCH_WRITE, PGBUF_UNCONDITIONAL_LATCH);
  if (P == NULL)
    {
      ASSERT_ERROR_AND_SET (ret);
      return ret;
    }

  (void) pgbuf_check_page_ptype (thread_p, P, PAGE_BTREE);

  /* read the header record */
  root_header = btree_get_root_header (thread_p, P);
  if (root_header == NULL)
    {
      pgbuf_unfix_and_init (thread_p, P);
      return (((ret = er_errid ()) == NO_ERROR) ? ER_FAILED : ret);
    }
  ovfid = root_header->ovfid;
  unique_pk = root_header->unique_pk;
  pgbuf_unfix_and_init (thread_p, P);

  vacuum_log_add_dropped_file (thread_p, &btid->vfid, NULL, VACUUM_LOG_ADD_DROPPED_FILE_POSTPONE);
  if (unique_pk)
    {
      LOG_DATA_ADDR addr = { NULL, NULL, NULL_OFFSET };
      log_append_postpone (thread_p, RVBT_REMOVE_UNIQUE_STATS, &addr, sizeof (*btid), btid);
    }
  if (!VFID_ISNULL (&ovfid))
    {
      file_postpone_destroy (thread_p, &ovfid);
    }
  file_postpone_destroy (thread_p, &btid->vfid);


  btid->root_pageid = NULL_PAGEID;

  return NO_ERROR;
}

/*
 * btree_generate_prefix_domain () -
 *   return:
 *   btid(in):
 *
 * Note: This routine returns a varying domain of the same precision for fixed domains which are one of the string
 *       types. For all other domains, it returns the same domain.
 */
TP_DOMAIN *
btree_generate_prefix_domain (BTID_INT * btid)
{
  TP_DOMAIN *domain = btid->key_type;
  TP_DOMAIN *var_domain;
  DB_TYPE dbtype;
  DB_TYPE vartype;

  dbtype = TP_DOMAIN_TYPE (domain);

  /* varying domains did not come into use until btree revision level 1 */
  if (dbtype == DB_TYPE_CHAR || dbtype == DB_TYPE_NCHAR || dbtype == DB_TYPE_BIT)
    {
      switch (dbtype)
	{
	case DB_TYPE_CHAR:
	  vartype = DB_TYPE_VARCHAR;
	  break;
	case DB_TYPE_NCHAR:
	  vartype = DB_TYPE_VARNCHAR;
	  break;
	case DB_TYPE_BIT:
	  vartype = DB_TYPE_VARBIT;
	  break;
	default:
	  return NULL;
	}

      var_domain =
	tp_domain_resolve (vartype, domain->class_mop, domain->precision, domain->scale, domain->setdomain,
			   domain->collation_id);
    }
  else
    {
      var_domain = domain;
    }

  return var_domain;
}

/*
 * btree_glean_root_header_info () -
 *   return:
 *   root_header(in):
 *   btid(in):
 *
 * Note: This captures the interesting header info into the BTID_INT structure.
 */
int
btree_glean_root_header_info (THREAD_ENTRY * thread_p, BTREE_ROOT_HEADER * root_header, BTID_INT * btid)
{
  int rc;
  OR_BUF buf;

  rc = NO_ERROR;

  btid->unique_pk = root_header->unique_pk;

  or_init (&buf, root_header->packed_key_domain, -1);
  btid->key_type = or_get_domain (&buf, NULL, NULL);

  COPY_OID (&btid->topclass_oid, &root_header->topclass_oid);

  btid->ovfid = root_header->ovfid;	/* structure copy */

  /* check for the last element domain of partial-key is desc; for btree_range_search, part_key_desc is re-set at
   * btree_prepare_bts */
  btid->part_key_desc = 0;

  /* init index key copy_buf info */
  btid->copy_buf = NULL;
  btid->copy_buf_len = 0;

  /* this must be discovered after the Btree key_type */
  btid->nonleaf_key_type = btree_generate_prefix_domain (btid);

  btid->rev_level = root_header->rev_level;

  return rc;
}

/*
 * xbtree_find_multi_uniques () - search a list of unique indexes for specified values
 * return : search return code
 * thread_p (in)  : handler thread
 * class_oid (in) : class oid
 * pruning_type (in) : pruning type
 * btids (in)	  : indexes to search
 * values (in)	  : values to search for
 * count (in)	  : number of indexes
 * op_type (in)	  : operation for which this search is performed
 * oids (in/out)  : found OIDs
 * oids_count (in): number of OIDs found
 *
 * Note: This function assumes that the indexes it searches are unique
 *  indexes. If the operation is S_UPDATE, this function stops at the first
 *  oid it finds in order to comply with the behavior of ON DUPLICATE KEY
 *  UPDATE statement.
 */
BTREE_SEARCH
xbtree_find_multi_uniques (THREAD_ENTRY * thread_p, OID * class_oid, int pruning_type, BTID * btids, DB_VALUE * values,
			   int count, SCAN_OPERATION_TYPE op_type, OID ** oids, int *oids_count)
{
  BTREE_SEARCH result = BTREE_KEY_FOUND;
  OID *found_oids = NULL;
  int i, idx, error = NO_ERROR;
  bool is_at_least_one = false;
  BTID pruned_btid;
  OID pruned_class_oid;
  HFID pruned_hfid;
  PRUNING_CONTEXT context;
  bool is_global_index = false;

  partition_init_pruning_context (&context);

  found_oids = (OID *) db_private_alloc (thread_p, count * sizeof (OID));
  if (found_oids == NULL)
    {
      return BTREE_ERROR_OCCURRED;
    }

  if (pruning_type != DB_NOT_PARTITIONED_CLASS)
    {
      error = partition_load_pruning_context (thread_p, class_oid, pruning_type, &context);
      if (error != NO_ERROR)
	{
	  result = BTREE_ERROR_OCCURRED;
	  goto error_return;
	}
    }

  idx = 0;
  for (i = 0; i < count; i++)
    {
      is_global_index = false;
      BTID_COPY (&pruned_btid, &btids[i]);
      COPY_OID (&pruned_class_oid, class_oid);

      if (pruning_type)
	{
	  /* At this point, there's no way of knowing if btids[i] refers a global unique index or a local one. Perform
	   * pruning and use the partition BTID, even if it is the same one as the BTID we received */
	  error = partition_prune_unique_btid (&context, &values[i], &pruned_class_oid, &pruned_hfid, &pruned_btid);
	  if (error != NO_ERROR)
	    {
	      result = BTREE_ERROR_OCCURRED;
	      goto error_return;
	    }
	}

      result =
	xbtree_find_unique (thread_p, &pruned_btid, op_type, &values[i], &pruned_class_oid, &found_oids[idx],
			    is_global_index);

      if (result == BTREE_KEY_FOUND)
	{
	  if (pruning_type == DB_PARTITION_CLASS)
	    {
	      if (!OID_EQ (&pruned_class_oid, class_oid))
		{
		  /* Found a constraint violation on a different partition: throw invalid partition */
		  er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_INVALID_DATA_FOR_PARTITION, 0);
		  error = ER_INVALID_DATA_FOR_PARTITION;
		  result = BTREE_ERROR_OCCURRED;
		  goto error_return;
		}
	    }
	  is_at_least_one = true;
	  idx++;
	  if (op_type == S_UPDATE)
	    {
	      break;
	    }
	}
      else if (result == BTREE_ERROR_OCCURRED)
	{
	  goto error_return;
	}
      else
	{
	  /* result == BTREE_KEY_NOTFOUND */
	  ;			/* just go to the next one */
	}
    }

  if (is_at_least_one)
    {
      *oids_count = idx;
      *oids = found_oids;
      result = BTREE_KEY_FOUND;
    }
  else
    {
      result = BTREE_KEY_NOTFOUND;
      db_private_free_and_init (thread_p, found_oids);
      *oids = NULL;
      *oids_count = 0;
    }
  partition_clear_pruning_context (&context);
  return result;

error_return:
  if (found_oids != NULL)
    {
      db_private_free_and_init (thread_p, found_oids);
    }
  *oids_count = 0;
  *oids = NULL;
  partition_clear_pruning_context (&context);
  return BTREE_ERROR_OCCURRED;
}

/*
 * btree_find_foreign_key () - Find and lock any existing object in foreign key. Used to check that delete/update on
 *			       primary key is allowed.
 *
 * return	   : Error code.
 * thread_p (in)   : Thread entry.
 * btid (in)	   : B-tree ID.
 * key (in)	   : Key value.
 * class_oid (in)  : Class OID.
 * found_oid (out) : Outputs OID of found object. If no object is found outputs NULL.
 */
int
btree_find_foreign_key (THREAD_ENTRY * thread_p, BTID * btid, DB_VALUE * key, OID * class_oid, OID * found_oid)
{
  BTREE_SCAN btree_scan;
  int error_code = NO_ERROR;
  key_val_range kv_range;
  BTREE_FIND_FK_OBJECT find_fk_object = BTREE_FIND_FK_OBJECT_INITIALIZER;

  assert (btid != NULL);
  assert (key != NULL);
  assert (class_oid != NULL);
  assert (found_oid != NULL);

  /* Find if key has any objects. */

  /* Define range of scan. */
  pr_share_value (key, &kv_range.key1);
  pr_share_value (key, &kv_range.key2);
  kv_range.range = GE_LE;
  kv_range.num_index_term = 0;

  /* Initialize not found. */
  OID_SET_NULL (&find_fk_object.found_oid);

#if defined (SERVER_MODE)
  /* Use S_LOCK to block found object. */
  find_fk_object.lock_mode = S_LOCK;
#endif /* SERVER_MODE */
  /* Prepare scan. */
  BTREE_INIT_SCAN (&btree_scan);
  error_code =
    btree_prepare_bts (thread_p, &btree_scan, btid, NULL, &kv_range, NULL, NULL, NULL, NULL, false, &find_fk_object);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      return error_code;
    }
  /* Execute scan. */
  error_code = btree_range_scan (thread_p, &btree_scan, btree_range_scan_find_fk_any_object);
  assert (error_code == NO_ERROR || er_errid () != NO_ERROR);

  /* Output found object. */
  COPY_OID (found_oid, &find_fk_object.found_oid);

#if defined (SERVER_MODE)
  if (error_code != NO_ERROR || OID_ISNULL (&find_fk_object.found_oid))
    {
      /* Release lock on object if any. */
      if (!OID_ISNULL (&find_fk_object.locked_object))
	{
	  lock_unlock_object_donot_move_to_non2pl (thread_p, &find_fk_object.locked_object,
						   &btree_scan.btid_int.topclass_oid, S_LOCK);
	}
    }
#endif /* SERVER_MODE */
  return error_code;
}

/*
 * btree_scan_clear_key () -
 *   return:
 *   btree_scan(in):
 */
void
btree_scan_clear_key (BTREE_SCAN * btree_scan)
{
  btree_clear_key_value (&btree_scan->clear_cur_key, &btree_scan->cur_key);
}

/*
 * btree_is_unique_type () -
 *   return: Whether the given BTREE_TYPE corresponds to a unique index B+tree
 *   type(in):
 */
bool
btree_is_unique_type (BTREE_TYPE type)
{
  if (type == BTREE_UNIQUE || type == BTREE_REVERSE_UNIQUE || type == BTREE_PRIMARY_KEY)
    {
      return true;
    }
  return false;
}

/*
 * xbtree_class_test_unique () -
 *   return: int
 *   buf(in):
 *   buf_size(in):
 *
 * Note: Return NO_ERROR if the btrees given are unique. Return ER_BTREE_UNIQUE_FAILED if one of unique tests failed.
 * This is used for interpreter and xasl batch checking of uniqueness.
 */
int
xbtree_class_test_unique (THREAD_ENTRY * thread_p, char *buf, int buf_size)
{
  int status = NO_ERROR;
  char *bufp, *buf_endptr;
  BTID btid;

  bufp = buf;
  buf_endptr = (buf + buf_size);

  while ((bufp < buf_endptr) && (status == NO_ERROR))
    {
      /* unpack the BTID */
      bufp = or_unpack_btid (bufp, &btid);

      /* check if the btree is unique */
      if ((status == NO_ERROR) && (xbtree_test_unique (thread_p, &btid) != 1))
	{
	  BTREE_SET_UNIQUE_VIOLATION_ERROR (thread_p, NULL, NULL, NULL, &btid, NULL);
	  status = ER_BTREE_UNIQUE_FAILED;
	}
    }

  return status;
}

/*
 * xbtree_test_unique () -
 *   return: int
 *   btid(in): B+tree index identifier
 *
 * Note: Return 1 (true) if the index is unique, return 0 if the index is not unique, return -1 if the btree isn't
 * keeping track of unique statistics (a regular, plain jane btree).
 */
static int
xbtree_test_unique (THREAD_ENTRY * thread_p, BTID * btid)
{
  INT32 num_oids, num_nulls, num_keys;

  if (logtb_get_global_unique_stats (thread_p, btid, &num_oids, &num_nulls, &num_keys) != NO_ERROR)
    {
      return 0;
    }

  if (num_nulls == -1)
    {
      return -1;
    }
  else if ((num_nulls + num_keys) != num_oids)
    {
      assert (false);
      return 0;
    }
  else
    {
      return 1;
    }
}

/*
 * xbtree_get_unique_pk () -
 *   return:
 *   btid(in):
 */
int
xbtree_get_unique_pk (THREAD_ENTRY * thread_p, BTID * btid)
{
  VPID root_vpid;
  PAGE_PTR root = NULL;
  BTREE_ROOT_HEADER *root_header = NULL;
  int unique_pk;

  root_vpid.pageid = btid->root_pageid;
  root_vpid.volid = btid->vfid.volid;

  root = pgbuf_fix (thread_p, &root_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
  if (root == NULL)
    {
      return 0;
    }

  (void) pgbuf_check_page_ptype (thread_p, root, PAGE_BTREE);

  root_header = btree_get_root_header (thread_p, root);
  if (root_header == NULL)
    {
      return 0;
    }

  unique_pk = root_header->unique_pk;

  pgbuf_unfix_and_init (thread_p, root);

  return unique_pk;
}

/*
 * btree_get_unique_statistics_for_count () - gets unique statistics
 *   return:
 *   btid(in): B+tree index identifier
 *   oid_cnt(in/out): no. of oids
 *   null_cnt(in/out): no. of nulls
 *   key_cnt(in/out): no. of keys
 *
 * Note: In MVCC the statistics are taken from memory structures. In non-mvcc from B-tree header
 */
int
btree_get_unique_statistics_for_count (THREAD_ENTRY * thread_p, BTID * btid, int *oid_cnt, int *null_cnt, int *key_cnt)
{
  LOG_TRAN_BTID_UNIQUE_STATS *unique_stats = NULL;

  unique_stats = logtb_tran_find_btid_stats (thread_p, btid, true);
  if (unique_stats == NULL)
    {
      return ER_FAILED;
    }
  *oid_cnt = unique_stats->tran_stats.num_oids + unique_stats->global_stats.num_oids;
  *key_cnt = unique_stats->tran_stats.num_keys + unique_stats->global_stats.num_keys;
  *null_cnt = unique_stats->tran_stats.num_nulls + unique_stats->global_stats.num_nulls;

  return NO_ERROR;
}

/*
 * btree_get_unique_statistics () -
 *   returns: NO_ERROR
 *   btid(in):
 *   oid_cnt(in):
 *   null_cnt(in):
 *   key_cnt(in):
 *
 * Note: Reads the unique btree statistics from the root header.  If
 * the btree is not a unique btree, all the stats will be -1.
 */
int
btree_get_unique_statistics (THREAD_ENTRY * thread_p, BTID * btid, int *oid_cnt, int *null_cnt, int *key_cnt)
{
  VPID root_vpid;
  PAGE_PTR root = NULL;
  BTREE_ROOT_HEADER *root_header = NULL;
  int ret;

  root_vpid.pageid = btid->root_pageid;
  root_vpid.volid = btid->vfid.volid;

  root = pgbuf_fix (thread_p, &root_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
  if (root == NULL)
    {
      return (((ret = er_errid ()) == NO_ERROR) ? ER_FAILED : ret);
    }

  (void) pgbuf_check_page_ptype (thread_p, root, PAGE_BTREE);

  root_header = btree_get_root_header (thread_p, root);
  if (root_header == NULL)
    {
      return (((ret = er_errid ()) == NO_ERROR) ? ER_FAILED : ret);
    }

  assert ((root_header->unique_pk & (BTREE_CONSTRAINT_UNIQUE | BTREE_CONSTRAINT_PRIMARY_KEY)) != 0);

  *oid_cnt = root_header->num_oids;
  *null_cnt = root_header->num_nulls;
  *key_cnt = root_header->num_keys;

  pgbuf_unfix_and_init (thread_p, root);

  return NO_ERROR;
}

#if defined(ENABLE_UNUSED_FUNCTION)
/*
 * btree_get_subtree_stats () -
 *   return: NO_ERROR
 *   btid(in):
 *   pg_ptr(in):
 *   env(in):
 */
static int
btree_get_subtree_stats (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR page_ptr, BTREE_STATS_ENV * stats_env)
{
  int key_cnt;
  int i, j;
  NON_LEAF_REC non_leaf_rec;
  VPID page_vpid;
  PAGE_PTR page = NULL;
  RECDES rec;
  DB_DOMAIN *key_type;
  int ret = NO_ERROR;
  BTREE_NODE_HEADER *header = NULL;

  key_type = btid->key_type;
  key_cnt = btree_node_number_of_keys (thread_p, page_ptr);

  header = btree_get_node_header (thread_p, page_ptr);
  if (header == NULL)
    {
      er_log_debug (ARG_FILE_LINE, "btree_get_subtree_stats: get node header failure: %d", key_cnt);
      goto exit_on_error;
    }

  if (header->node_level > 1)	/* BTREE_NON_LEAF_NODE */
    {
      if (key_cnt < 0)
	{
	  er_log_debug (ARG_FILE_LINE, "btree_get_subtree_stats: node key count underflow: %d", key_cnt);
	  goto exit_on_error;
	}

      /*
       * traverse all the subtrees of this non_leaf page and accumulate
       * the statistical data in the environment structure
       */
      for (i = 1; i <= key_cnt + 1; i++)
	{
	  if (spage_get_record (thread_p, page_ptr, i, &rec, PEEK) != S_SUCCESS)
	    {
	      goto exit_on_error;
	    }

	  btree_read_fixed_portion_of_non_leaf_record (&rec, &non_leaf_rec);
	  page_vpid = non_leaf_rec.pnt;

	  page = pgbuf_fix (thread_p, &page_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
	  if (page == NULL)
	    {
	      goto exit_on_error;
	    }

	  (void) pgbuf_check_page_ptype (thread_p, page, PAGE_BTREE);

	  ret = btree_get_subtree_stats (thread_p, btid, page, stats_env);
	  if (ret != NO_ERROR)
	    {
	      goto exit_on_error;
	    }

	  pgbuf_unfix_and_init (thread_p, page);
	}

      stats_env->stat_info->height++;
    }
  else
    {
      DB_VALUE key, elem;
      LEAF_REC leaf_rec;
      bool clear_key;
      int offset;
      int k;
      DB_MIDXKEY *midxkey;
      int prev_j_index, prev_k_index;
      char *prev_j_ptr, *prev_k_ptr;

      stats_env->stat_info->leafs++;
      stats_env->stat_info->keys += key_cnt;
      stats_env->stat_info->height = 1;	/* init */

      btree_init_temp_key_value (&clear_key, &key);

      if (stats_env->pkeys)
	{
	  if (TP_DOMAIN_TYPE (key_type) != DB_TYPE_MIDXKEY)
	    {
	      /* single column index */
	      stats_env->stat_info->pkeys[0] += key_cnt;
	    }
	  else
	    {
	      for (i = 1; i <= key_cnt; i++)
		{
		  if (spage_get_record (thread_p, page_ptr, i, &rec, PEEK) != S_SUCCESS)
		    {
		      goto exit_on_error;
		    }

		  /* read key-value */
		  btree_read_record (thread_p, page_ptr, btid, &rec, &key, &leaf_rec, BTREE_LEAF_NODE, &clear_key,
				     &offset, PEEK_KEY_VALUE, NULL);

		  /* extract the sequence of the key-value */
		  midxkey = db_get_midxkey (&key);
		  if (midxkey == NULL)
		    {
		      goto exit_on_error;
		    }

		  prev_j_index = 0;
		  prev_j_ptr = NULL;

		  assert (stats_env->stat_info->pkeys_size <= BTREE_STATS_PKEYS_NUM);
		  for (j = 0; j < stats_env->stat_info->pkeys_size; j++)
		    {
		      /* extract the element of the midxkey */
		      ret = pr_midxkey_get_element_nocopy (midxkey, j, &elem, &prev_j_index, &prev_j_ptr);
		      if (ret != NO_ERROR)
			{
			  goto exit_on_error;
			}

		      if (tp_value_compare (&(stats_env->pkeys[j]), &elem, 0, 1) != DB_EQ)
			{
			  /* found different value */
			  stats_env->stat_info->pkeys[j] += 1;
			  pr_clear_value (&(stats_env->pkeys[j]));	/* clear saved */
			  pr_clone_value (&elem, &(stats_env->pkeys[j]));	/* save */

			  /* propagate to the following partial key-values */
			  prev_k_index = prev_j_index;
			  prev_k_ptr = prev_j_ptr;

			  assert (stats_env->stat_info->pkeys_size <= BTREE_STATS_PKEYS_NUM);
			  for (k = j + 1; k < stats_env->stat_info->pkeys_size; k++)
			    {
			      ret = pr_midxkey_get_element_nocopy (midxkey, k, &elem, &prev_k_index, &prev_k_ptr);
			      if (ret != NO_ERROR)
				{
				  goto exit_on_error;
				}

			      stats_env->stat_info->pkeys[k]++;
			      pr_clear_value (&(stats_env->pkeys[k]));
			      pr_clone_value (&elem, &(stats_env->pkeys[k]));	/* save */
			    }

			  /* go to the next key */
			  break;
			}
		    }

		  btree_clear_key_value (&clear_key, &key);
		}
	    }
	}
    }

  stats_env->stat_info->pages++;

  return ret;

exit_on_error:

  if (page)
    {
      pgbuf_unfix_and_init (thread_p, page);
    }

  return (ret == NO_ERROR && (ret = er_errid ()) == NO_ERROR) ? ER_FAILED : ret;
}
#endif

/*
 * btree_get_stats_midxkey () -
 *   return: NO_ERROR
 *   thread_p(in);
 *   env(in/out): Structure to store and return the statistical information
 *   midxkey(in);
 */
static int
btree_get_stats_midxkey (THREAD_ENTRY * thread_p, BTREE_STATS_ENV * env, DB_MIDXKEY * midxkey)
{
  int i, k;
  int prev_i_index, prev_k_index;
  char *prev_i_ptr, *prev_k_ptr;
  DB_VALUE elem;
  int ret = NO_ERROR;

  if (midxkey == NULL)
    {
      assert_release (false);
      goto exit_on_error;
    }

  prev_i_index = 0;
  prev_i_ptr = NULL;
  for (i = 0; i < env->pkeys_val_num; i++)
    {
      /* extract the element of the key */
      ret = pr_midxkey_get_element_nocopy (midxkey, i, &elem, &prev_i_index, &prev_i_ptr);
      if (ret != NO_ERROR)
	{
	  assert_release (false);
	  goto exit_on_error;
	}

      if (tp_value_compare (&(env->pkeys_val[i]), &elem, 0, 1) != DB_EQ)
	{
	  /* found different value */
	  env->stat_info->pkeys[i]++;
	  pr_clear_value (&(env->pkeys_val[i]));	/* clear saved */
	  pr_clone_value (&elem, &(env->pkeys_val[i]));	/* save */

	  if (elem.need_clear == true)
	    {
	      pr_clear_value (&elem);
	    }

	  /* propagate to the following partial key-values */
	  prev_k_index = prev_i_index;
	  prev_k_ptr = prev_i_ptr;
	  for (k = i + 1; k < env->pkeys_val_num; k++)
	    {
	      ret = pr_midxkey_get_element_nocopy (midxkey, k, &elem, &prev_k_index, &prev_k_ptr);
	      if (ret != NO_ERROR)
		{
		  assert_release (false);
		  goto exit_on_error;
		}

	      env->stat_info->pkeys[k]++;
	      pr_clear_value (&(env->pkeys_val[k]));	/* clear saved */
	      pr_clone_value (&elem, &(env->pkeys_val[k]));	/* save */

	      if (elem.need_clear == true)
		{
		  pr_clear_value (&elem);
		}
	    }

	  break;
	}
      else if (elem.need_clear == true)
	{
	  pr_clear_value (&elem);
	}
    }

  return ret;

exit_on_error:

  return (ret == NO_ERROR && (ret = er_errid ()) == NO_ERROR) ? ER_FAILED : ret;
}

/*
 * btree_get_stats_key () -
 *   return: NO_ERROR
 *   thread_p(in);
 *   env(in/out): Structure to store and return the statistical information
 */
static int
btree_get_stats_key (THREAD_ENTRY * thread_p, BTREE_STATS_ENV * env, MVCC_SNAPSHOT * mvcc_snapshot)
{
  BTREE_SCAN *BTS;
  RECDES rec;
  DB_VALUE key_value;
  LEAF_REC leaf_pnt;
  bool clear_key = false;
  int offset;
  int ret = NO_ERROR;

  assert (env != NULL);

  btree_init_temp_key_value (&clear_key, &key_value);

  if (mvcc_snapshot != NULL)
    {
      int max_visible_oids = 1;
      int num_visible_oids = 0;

      BTS = &(env->btree_scan);

      if (BTS->C_page == NULL)
	{
	  goto exit_on_error;
	}

      assert (BTS->slot_id > 0);
      if (spage_get_record (thread_p, BTS->C_page, BTS->slot_id, &rec, PEEK) != S_SUCCESS)
	{
	  goto exit_on_error;
	}

      /* filter out fence_key */
      if (btree_leaf_is_flaged (&rec, BTREE_LEAF_RECORD_FENCE))
	{
	  goto count_keys;
	}

      /* read key-value */
      assert (clear_key == false);

      if (btree_read_record (thread_p, &BTS->btid_int, BTS->C_page, &rec, &key_value, (void *) &leaf_pnt,
			     BTREE_LEAF_NODE, &clear_key, &offset, PEEK_KEY_VALUE, NULL) != NO_ERROR)
	{
	  goto exit_on_error;
	}

      /* Is there any visible objects? */
      max_visible_oids = 1;
      ret =
	btree_get_num_visible_from_leaf_and_ovf (thread_p, &BTS->btid_int, &rec, offset, &leaf_pnt, &max_visible_oids,
						 mvcc_snapshot, &num_visible_oids);
      if (ret != NO_ERROR)
	{
	  /* Error. */
	  goto exit_on_error;
	}
      else if (num_visible_oids == 0)
	{
	  /* No visible object. */
	  goto end;
	}
    }

count_keys:
  env->stat_info->keys++;

  if (env->pkeys_val_num <= 0)
    {
      ;				/* do not request pkeys info; go ahead */
    }
  else if (env->pkeys_val_num == 1)
    {
      /* single column index */
      env->stat_info->pkeys[0]++;
    }
  else
    {
      /* multi column index */

      if (mvcc_snapshot != NULL)
	{
	  /* filter out fence_key */
	  if (btree_leaf_is_flaged (&rec, BTREE_LEAF_RECORD_FENCE))
	    {
	      assert (ret == NO_ERROR);

	      env->stat_info->keys--;
	      assert (env->stat_info->keys >= 0);

	      goto end;
	    }

	  /* key_value already computed */
	  assert (!DB_IS_NULL (&key_value));

	  /* get pkeys info */
	  ret = btree_get_stats_midxkey (thread_p, env, db_get_midxkey (&key_value));
	  if (ret != NO_ERROR)
	    {
	      goto exit_on_error;
	    }

	  goto end;
	}

      BTS = &(env->btree_scan);

      if (BTS->C_page == NULL)
	{
	  goto exit_on_error;
	}

      assert (BTS->slot_id > 0);
      if (spage_get_record (thread_p, BTS->C_page, BTS->slot_id, &rec, PEEK) != S_SUCCESS)
	{
	  goto exit_on_error;
	}

      /* filter out fence_key */
      if (btree_leaf_is_flaged (&rec, BTREE_LEAF_RECORD_FENCE))
	{
	  assert (ret == NO_ERROR);

	  env->stat_info->keys--;
	  assert (env->stat_info->keys >= 0);

	  goto end;
	}

      /* read key-value */

      assert (clear_key == false);

      if (btree_read_record (thread_p, &BTS->btid_int, BTS->C_page, &rec, &key_value, (void *) &leaf_pnt,
			     BTREE_LEAF_NODE, &clear_key, &offset, PEEK_KEY_VALUE, NULL) != NO_ERROR)
	{
	  goto exit_on_error;
	}

      /* get pkeys info */
      ret = btree_get_stats_midxkey (thread_p, env, db_get_midxkey (&key_value));
      if (ret != NO_ERROR)
	{
	  goto exit_on_error;
	}
    }

end:

  if (clear_key)
    {
      pr_clear_value (&key_value);
      clear_key = false;
    }

  return ret;

exit_on_error:

  ret = (ret == NO_ERROR && (ret = er_errid ()) == NO_ERROR) ? ER_FAILED : ret;

  goto end;
}

/*
 * btree_get_stats_with_AR_sampling () - Do Acceptance/Rejection Sampling
 *   return: NO_ERROR
 *   env(in/out): Structure to store and return the statistical information
 */
static int
btree_get_stats_with_AR_sampling (THREAD_ENTRY * thread_p, BTREE_STATS_ENV * env)
{
  BTREE_SCAN *BTS;
  int n, i;
  bool found;
  int key_cnt;
  int exp_ratio;
  int ret = NO_ERROR;
#if !defined(NDEBUG)
  BTREE_NODE_HEADER *header = NULL;
#endif

  assert (env != NULL);
  assert (env->stat_info != NULL);

  BTS = &(env->btree_scan);
  BTS->use_desc_index = 0;	/* init */

  for (n = 0; n < STATS_SAMPLING_THRESHOLD; n++)
    {
      if (env->stat_info->leafs >= STATS_SAMPLING_LEAFS_MAX)
	{
	  break;		/* found all samples */
	}

      BTS->C_page =
	btree_find_AR_sampling_leaf (thread_p, BTS->btid_int.sys_btid, &BTS->C_vpid, env->stat_info, &found);
      if (BTS->C_page == NULL)
	{
	  goto exit_on_error;
	}

      /* found sampling leaf page */
      if (found)
	{
	  key_cnt = btree_node_number_of_keys (thread_p, BTS->C_page);
	  assert_release (key_cnt >= 0);

#if !defined(NDEBUG)
	  header = btree_get_node_header (thread_p, BTS->C_page);

	  assert (header != NULL);
	  assert (header->node_level == 1);	/* BTREE_LEAF_NODE */
#endif

	  if (key_cnt > 0)
	    {
	      env->stat_info->leafs++;

	      BTS->slot_id = 1;
	      BTS->oid_pos = 0;

	      assert_release (BTS->slot_id <= key_cnt);

	      for (i = 0; i < key_cnt; i++)
		{
		  ret = btree_get_stats_key (thread_p, env, NULL);
		  if (ret != NO_ERROR)
		    {
		      goto exit_on_error;
		    }

		  /* get the next index record */
		  ret = btree_find_next_index_record (thread_p, BTS);
		  if (ret != NO_ERROR)
		    {
		      goto exit_on_error;
		    }
		}
	    }
	}

      if (BTS->P_page != NULL)
	{
	  pgbuf_unfix_and_init (thread_p, BTS->P_page);
	}

      if (BTS->C_page != NULL)
	{
	  pgbuf_unfix_and_init (thread_p, BTS->C_page);
	}

      if (BTS->O_page != NULL)
	{
	  pgbuf_unfix_and_init (thread_p, BTS->O_page);
	}
    }				/* for (n = 0; ... ) */

  /* apply distributed expension */
  if (env->stat_info->leafs > 0)
    {
      exp_ratio = env->stat_info->pages / env->stat_info->leafs;

      env->stat_info->leafs *= exp_ratio;
      if (env->stat_info->leafs < 0)
	{
	  env->stat_info->leafs = INT_MAX;
	}

      env->stat_info->keys *= exp_ratio;
      if (env->stat_info->keys < 0)
	{
	  env->stat_info->keys = INT_MAX;
	}

      for (i = 0; i < env->pkeys_val_num; i++)
	{
	  env->stat_info->pkeys[i] *= exp_ratio;
	  if (env->stat_info->pkeys[i] < 0)
	    {			/* multiply-overflow defence */
	      env->stat_info->pkeys[i] = INT_MAX;
	    }
	}
    }

end:

  if (BTS->P_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, BTS->P_page);
    }

  if (BTS->C_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, BTS->C_page);
    }

  if (BTS->O_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, BTS->O_page);
    }

  return ret;

exit_on_error:

  ret = (ret == NO_ERROR && (ret = er_errid ()) == NO_ERROR) ? ER_FAILED : ret;

  goto end;
}

/*
 * btree_get_stats_with_fullscan () - Do Full Scan
 *   return: NO_ERROR
 *   env(in/out): Structure to store and return the statistical information
 */
static int
btree_get_stats_with_fullscan (THREAD_ENTRY * thread_p, BTREE_STATS_ENV * env)
{
  BTREE_SCAN *BTS;
  VPID C_vpid;			/* vpid of current leaf page */
  int ret = NO_ERROR;
  MVCC_SNAPSHOT *mvcc_snapshot = NULL;

  assert (env != NULL);
  assert (env->stat_info != NULL);

  mvcc_snapshot = logtb_get_mvcc_snapshot (thread_p);
  if (mvcc_snapshot == NULL)
    {
      ASSERT_ERROR_AND_SET (ret);
      goto exit_on_error;
    }

  BTS = &(env->btree_scan);
  BTS->use_desc_index = 0;	/* get the left-most leaf page */

  ret = btree_find_lower_bound_leaf (thread_p, BTS, env->stat_info);
  if (ret != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto exit_on_error;
    }

  VPID_SET_NULL (&C_vpid);	/* init */

  while (!BTREE_END_OF_SCAN (BTS))
    {
      /* move on another leaf page */
      if (!VPID_EQ (&(BTS->C_vpid), &C_vpid))
	{
	  VPID_COPY (&C_vpid, &(BTS->C_vpid));	/* keep current leaf vpid */

	  env->stat_info->leafs++;
	}

      ret = btree_get_stats_key (thread_p, env, mvcc_snapshot);
      if (ret != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto exit_on_error;
	}

      /* get the next index record */
      ret = btree_find_next_index_record (thread_p, BTS);
      if (ret != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto exit_on_error;
	}
    }

end:

  if (BTS->P_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, BTS->P_page);
    }

  if (BTS->C_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, BTS->C_page);
    }

  if (BTS->O_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, BTS->O_page);
    }

  return ret;

exit_on_error:

  assert_release (ret != NO_ERROR);

  goto end;
}

/*
 * btree_get_root_vpid_from_btid () -
 *   return: pageid or NULL_PAGEID
 *   btid(in): B+tree index identifier
 *   first_vpid(out):
 *
 * Note: get the page identifier of the first allocated page of the given file.
 */
void
btree_get_root_vpid_from_btid (THREAD_ENTRY * thread_p, BTID * btid, VPID * root_vpid)
{
  assert (btid != NULL);
  assert (root_vpid != NULL);
  assert (!VFID_ISNULL (&btid->vfid));
  root_vpid->volid = btid->vfid.volid;
  root_vpid->pageid = btid->root_pageid;
}

/*
 * btree_get_btid_from_file () - get btid for file (caller must make sure this is indeed a b-tree file
 *
 * return         : error code
 * thread_p (in)  : thread entry
 * vfid (in)      : file identifier
 * btid_out (out) : b-tree identifier
 */
int
btree_get_btid_from_file (THREAD_ENTRY * thread_p, const VFID * vfid, BTID * btid_out)
{
  VPID vpid_sticky;

  int error_code = NO_ERROR;

  error_code = file_get_sticky_first_page (thread_p, vfid, &vpid_sticky);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      return error_code;
    }
  assert (!VPID_ISNULL (&vpid_sticky));
  assert (vfid->volid == vpid_sticky.volid);
  btid_out->vfid = *vfid;
  btid_out->root_pageid = vpid_sticky.pageid;
  return NO_ERROR;
}

/*
 * btree_get_stats () - Get Statistical Information about the B+tree index
 *   return: NO_ERROR
 *   stat_info_p(in/out): Structure to store and return the statistical information
 *   with_fullscan(in): true iff WITH FULLSCAN
 *
 * Note: Computes and returns statistical information about B+tree which consist of the number of leaf pages,
 * total number of pages, number of keys and the height of the tree.
 */
int
btree_get_stats (THREAD_ENTRY * thread_p, BTREE_STATS * stat_info_p, bool with_fullscan)
{
  int npages;
  BTREE_STATS_ENV stat_env, *env;
  VPID root_vpid;
  PAGE_PTR root_page_ptr = NULL;
  DB_TYPE dom_type;
  BTREE_ROOT_HEADER *root_header = NULL;
  int i;
  int ret = NO_ERROR;

  assert_release (stat_info_p != NULL);
  assert_release (!BTID_IS_NULL (&stat_info_p->btid));

  ret = file_get_num_user_pages (thread_p, &(stat_info_p->btid.vfid), &npages);
  if (ret != NO_ERROR)
    {
      ASSERT_ERROR ();
      return ret;
    }
  assert_release (npages >= 1);

  /* For the optimization of the sampling, if the btree file has currently the same pages as we gathered statistics, we
   * guess the btree file has not been modified; So, we take current stats as it is */
  if (!with_fullscan)
    {
      /* check if the stats has been gathered */
      if (stat_info_p->keys > 0)
	{
	  /* guess the stats has not been modified */
	  if (npages == stat_info_p->pages)
	    {
	      return NO_ERROR;
	    }
	}
    }

  /* set environment variable */
  env = &stat_env;
  BTREE_INIT_SCAN (&(env->btree_scan));
  env->btree_scan.btid_int.sys_btid = &(stat_info_p->btid);
  env->stat_info = stat_info_p;
  env->pkeys_val_num = stat_info_p->pkeys_size;

  assert (env->pkeys_val_num <= BTREE_STATS_PKEYS_NUM);
  for (i = 0; i < env->pkeys_val_num; i++)
    {
      db_make_null (&(env->pkeys_val[i]));
    }

  root_vpid.pageid = env->stat_info->btid.root_pageid;	/* read root page */
  root_vpid.volid = env->stat_info->btid.vfid.volid;

  root_page_ptr = pgbuf_fix (thread_p, &root_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
  if (root_page_ptr == NULL)
    {
      goto exit_on_error;
    }

  (void) pgbuf_check_page_ptype (thread_p, root_page_ptr, PAGE_BTREE);

  root_header = btree_get_root_header (thread_p, root_page_ptr);
  if (root_header == NULL)
    {
      goto exit_on_error;
    }

  ret = btree_glean_root_header_info (thread_p, root_header, &(env->btree_scan.btid_int));
  if (ret != NO_ERROR)
    {
      pgbuf_unfix_and_init (thread_p, root_page_ptr);
      goto exit_on_error;
    }

  pgbuf_unfix_and_init (thread_p, root_page_ptr);

  dom_type = TP_DOMAIN_TYPE (env->btree_scan.btid_int.key_type);
  if (env->pkeys_val_num <= 0)
    {
      /* do not request pkeys info; go ahead */
      if (!tp_valid_indextype (dom_type) && dom_type != DB_TYPE_MIDXKEY)
	{
	  assert_release (false);
	  goto exit_on_error;
	}
    }
  else if (env->pkeys_val_num == 1)
    {
      /* single column index */
      if (!tp_valid_indextype (dom_type))
	{
	  assert_release (false);
	  goto exit_on_error;
	}
    }
  else
    {
      /* multi column index */
      if (dom_type != DB_TYPE_MIDXKEY)
	{
	  assert_release (false);
	  goto exit_on_error;
	}
    }

  /* initialize environment stat_info structure */
  env->stat_info->pages = npages;
  env->stat_info->leafs = 0;
  env->stat_info->height = 0;
  env->stat_info->keys = 0;

  for (i = 0; i < env->pkeys_val_num; i++)
    {
      env->stat_info->pkeys[i] = 0;	/* clear old stats */
    }

  if (with_fullscan || npages <= STATS_SAMPLING_THRESHOLD)
    {
      /* do fullscan at small table */
      ret = btree_get_stats_with_fullscan (thread_p, env);
    }
  else
    {
      ret = btree_get_stats_with_AR_sampling (thread_p, env);
    }

  if (ret != NO_ERROR)
    {
      goto exit_on_error;
    }

  /* check for emptiness */
  for (i = 0; i < env->pkeys_val_num; i++)
    {
      assert_release (env->stat_info->keys >= env->stat_info->pkeys[i]);

      if (env->stat_info->keys <= 0)
	{
	  /* is empty */
	  assert_release (env->stat_info->pkeys[i] == 0);
	  env->stat_info->pkeys[i] = 0;
	}
      else
	{
	  env->stat_info->pkeys[i] = MAX (env->stat_info->pkeys[i], 1);
	}
    }

  if (npages < env->stat_info->height)
    {
      // this is a corner case. if b-tree had only one page when npages was read, but its root was split immediately
      // after, we'd have this awkward situation.
      //
      // but we may read npages again, and this time it should be better (we rely also on the fact that one root is
      // split, it is never merged back to one page again).
      //
      ret = file_get_num_user_pages (thread_p, &(stat_info_p->btid.vfid), &npages);
      if (ret != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return ret;
	}
      assert_release (npages >= 1);
      assert_release (npages >= env->stat_info->height);
    }

  /* check for leaf pages */
  env->stat_info->leafs = MAX (1, env->stat_info->leafs);
  env->stat_info->leafs = MIN (env->stat_info->leafs, npages - (env->stat_info->height - 1));

  assert_release (env->stat_info->pages >= 1);
  assert_release (env->stat_info->leafs >= 1);
  assert_release (env->stat_info->height >= 1);
  assert_release (env->stat_info->keys >= 0);

end:

  if (root_page_ptr)
    {
      pgbuf_unfix_and_init (thread_p, root_page_ptr);
    }

  /* clear partial key-values */
  for (i = 0; i < env->pkeys_val_num; i++)
    {
      pr_clear_value (&(env->pkeys_val[i]));
    }

  perfmon_inc_stat (thread_p, PSTAT_BT_NUM_GET_STATS);

  return ret;

exit_on_error:

  ret = (ret == NO_ERROR && (ret = er_errid ()) == NO_ERROR) ? ER_FAILED : ret;

  goto end;
}

/*
 * xbtree_get_key_type () - Obtains index key type.
 *
 * return	  : Error code.
 * thread_p (in)  : Thread entry
 * btid (in)	  : B-tree identifier.
 * key_type (out) : Index key type.
 */
int
xbtree_get_key_type (THREAD_ENTRY * thread_p, BTID btid, TP_DOMAIN ** key_type)
{
  VPID root_vpid;
  PAGE_PTR root_page;
  BTREE_ROOT_HEADER *root_header = NULL;
  OR_BUF buf;

  root_vpid.pageid = btid.root_pageid;
  root_vpid.volid = btid.vfid.volid;

  assert (key_type != NULL);
  *key_type = NULL;

  root_page = pgbuf_fix (thread_p, &root_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
  if (root_page == NULL)
    {
      return ER_FAILED;
    }

  root_header = btree_get_root_header (thread_p, root_page);
  or_init (&buf, root_header->packed_key_domain, -1);
  *key_type = or_get_domain (&buf, NULL, NULL);

  pgbuf_unfix (thread_p, root_page);

  if (*key_type == NULL)
    {
      return ER_FAILED;
    }

  return NO_ERROR;
}

/*
 * btree_check_page_key () - Check (verify) page
 *   return: either: DISK_INVALID, DISK_VALID, DISK_ERROR
 *   btid(in):
 *   page_ptr(in): Page pointer
 *   page_vpid(in): Page identifier
 *
 * Note: Verifies the correctness of the specified page of the B+tree.
 * Tests include checking the order of the keys in the page,
 * checking the key count and maximum key length values stored page header.
 */
static DISK_ISVALID
btree_check_page_key (THREAD_ENTRY * thread_p, const OID * class_oid_p, BTID_INT * btid, const char *btname,
		      PAGE_PTR page_ptr, VPID * page_vpid)
{
  int key_cnt, offset;
  RECDES peek_rec1, peek_rec2;
  DB_VALUE key1, key2;
  BTREE_NODE_HEADER *header = NULL;
  BTREE_NODE_TYPE node_type;
  int k, overflow_key1 = 0, overflow_key2 = 0;
  bool clear_key1, clear_key2;
  LEAF_REC leaf_pnt;
  NON_LEAF_REC nleaf_pnt;
  DISK_ISVALID valid = DISK_ERROR;
  int c;
  char err_buf[LINE_MAX];

  /* initialize */
  leaf_pnt.key_len = 0;
  VPID_SET_NULL (&leaf_pnt.ovfl);
  nleaf_pnt.key_len = 0;
  VPID_SET_NULL (&nleaf_pnt.pnt);

  btree_init_temp_key_value (&clear_key1, &key1);
  btree_init_temp_key_value (&clear_key2, &key2);

  key_cnt = btree_node_number_of_keys (thread_p, page_ptr);

  header = btree_get_node_header (thread_p, page_ptr);
  if (header == NULL)
    {
      snprintf (err_buf, LINE_MAX, "btree_check_page_key: get node header failure: %d\n", key_cnt);
      er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_EMERGENCY_ERROR, 1, err_buf);
      valid = DISK_INVALID;
      goto error;
    }

  node_type = (header->node_level > 1) ? BTREE_NON_LEAF_NODE : BTREE_LEAF_NODE;

  if ((node_type == BTREE_NON_LEAF_NODE && key_cnt <= 0) || (node_type == BTREE_LEAF_NODE && key_cnt < 0))
    {
      snprintf (err_buf, LINE_MAX, "btree_check_page_key: node key count underflow: %d\n", key_cnt);
      er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_EMERGENCY_ERROR, 1, err_buf);
      valid = DISK_INVALID;
      goto error;
    }

  if (key_cnt == 0)
    {
      return DISK_VALID;
    }

  if (key_cnt == 1)
    {
      /* there is only one key, so no order check */
      if (spage_get_record (thread_p, page_ptr, 1, &peek_rec1, PEEK) != S_SUCCESS)
	{
	  valid = DISK_ERROR;
	  goto error;
	}

      return DISK_VALID;
    }

  for (k = 1; k < key_cnt; k++)
    {
      if (spage_get_record (thread_p, page_ptr, k, &peek_rec1, PEEK) != S_SUCCESS)
	{
	  valid = DISK_ERROR;
	  goto error;
	}

      if (btree_leaf_is_flaged (&peek_rec1, BTREE_LEAF_RECORD_FENCE))
	{
	  continue;
	}

      /* read the current record key */
      if (node_type == BTREE_LEAF_NODE)
	{
	  if (btree_read_record (thread_p, btid, page_ptr, &peek_rec1, &key1, (void *) &leaf_pnt, BTREE_LEAF_NODE,
				 &clear_key1, &offset, PEEK_KEY_VALUE, NULL) != NO_ERROR)
	    {
	      valid = DISK_ERROR;
	      goto error;
	    }
	  overflow_key1 = (leaf_pnt.key_len < 0);
	}
      else
	{
	  if (btree_read_record (thread_p, btid, page_ptr, &peek_rec1, &key1, (void *) &nleaf_pnt,
				 BTREE_NON_LEAF_NODE, &clear_key1, &offset, PEEK_KEY_VALUE, NULL) != NO_ERROR)
	    {
	      valid = DISK_ERROR;
	      goto error;
	    }
	  overflow_key1 = (nleaf_pnt.key_len < 0);
	}

      if ((!overflow_key1 && (btree_get_disk_size_of_key (&key1) > header->max_key_len))
	  || (overflow_key1 && (DISK_VPID_SIZE > header->max_key_len)))
	{
	  btree_dump_page (thread_p, stdout, class_oid_p, btid, btname, page_ptr, page_vpid, 2, 2);

	  snprintf (err_buf, LINE_MAX,
		    "btree_check_page_key: --- max key length test failed for page "
		    "{%d , %d}. Check key_rec = %d\n", page_vpid->volid, page_vpid->pageid, k);
	  er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_EMERGENCY_ERROR, 1, err_buf);
	  valid = DISK_INVALID;
	  goto error;
	}

      if (spage_get_record (thread_p, page_ptr, k + 1, &peek_rec2, PEEK) != S_SUCCESS)
	{
	  valid = DISK_ERROR;
	  goto error;
	}

      if (btree_leaf_is_flaged (&peek_rec2, BTREE_LEAF_RECORD_FENCE))
	{
	  btree_clear_key_value (&clear_key1, &key1);
	  continue;
	}

      /* read the next record key */
      if (node_type == BTREE_LEAF_NODE)
	{
	  if (btree_read_record (thread_p, btid, page_ptr, &peek_rec2, &key2, (void *) &leaf_pnt, BTREE_LEAF_NODE,
				 &clear_key2, &offset, PEEK_KEY_VALUE, NULL) != NO_ERROR)
	    {
	      valid = DISK_ERROR;
	      goto error;
	    }
	  overflow_key2 = (leaf_pnt.key_len < 0);
	}
      else
	{
	  if (btree_read_record (thread_p, btid, page_ptr, &peek_rec2, &key2, (void *) &nleaf_pnt,
				 BTREE_NON_LEAF_NODE, &clear_key2, &offset, PEEK_KEY_VALUE, NULL) != NO_ERROR)
	    {
	      valid = DISK_ERROR;
	      goto error;
	    }
	  overflow_key2 = (nleaf_pnt.key_len < 0);
	}

      if ((!overflow_key2 && (btree_get_disk_size_of_key (&key2) > header->max_key_len))
	  || (overflow_key2 && (DISK_VPID_SIZE > header->max_key_len)))
	{
	  btree_dump_page (thread_p, stdout, class_oid_p, btid, btname, page_ptr, page_vpid, 2, 2);

	  snprintf (err_buf, LINE_MAX,
		    "btree_check_page_key: --- max key length test failed for page "
		    "{%d , %d}. Check key_rec = %d\n", page_vpid->volid, page_vpid->pageid, k + 1);
	  er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_EMERGENCY_ERROR, 1, err_buf);
	  valid = DISK_INVALID;
	  goto error;
	}

      if (k == 1 && node_type == BTREE_NON_LEAF_NODE)
	{
	  c = DB_LT;		/* TODO - may compare with neg-inf sep */
	}
      else
	{
	  /* compare the keys for the order */
	  c = btree_compare_key (&key1, &key2, btid->key_type, 1, 1, NULL);
	}

      if (c != DB_LT)
	{
	  btree_dump_page (thread_p, stdout, class_oid_p, btid, btname, page_ptr, page_vpid, 2, 2);

	  snprintf (err_buf, LINE_MAX,
		    "btree_check_page_key:--- key order test failed for page"
		    " {%d , %d}. Check key_recs = %d and %d\n", page_vpid->volid, page_vpid->pageid, k, k + 1);
	  er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_EMERGENCY_ERROR, 1, err_buf);
	  valid = DISK_INVALID;
	  goto error;
	}

      btree_clear_key_value (&clear_key1, &key1);
      btree_clear_key_value (&clear_key2, &key2);
    }

  /* page check passed */
  return DISK_VALID;

error:

  btree_clear_key_value (&clear_key1, &key1);
  btree_clear_key_value (&clear_key2, &key2);

  return valid;
}

/*
 * btree_verify_subtree () - Check (verify) a page and its subtrees
 *   return: either: DISK_INVALID, DISK_VALID, DISK_ERROR
 *   btid(in): B+tree index identifier
 *   pg_ptr(in): Page pointer for the subtree root page
 *   pg_vpid(in): Page identifier for the subtree root page
 *   INFO(in):
 *
 * Note: Verifies the correctness of the content of the given page together with its subtree
 */
static DISK_ISVALID
btree_verify_subtree (THREAD_ENTRY * thread_p, const OID * class_oid_p, BTID_INT * btid, const char *btname,
		      PAGE_PTR pg_ptr, VPID * pg_vpid, BTREE_NODE_INFO * INFO)
{
  int key_cnt;
  NON_LEAF_REC nleaf_ptr;
  VPID page_vpid;
  PAGE_PTR page = NULL;
  RECDES rec;
  DB_VALUE curr_key;
  int offset;
  bool clear_key = false;
  int i;
  DISK_ISVALID valid = DISK_ERROR;
  BTREE_NODE_INFO INFO2;
  BTREE_NODE_HEADER *header = NULL;
  BTREE_NODE_TYPE node_type;
  char err_buf[LINE_MAX];

  db_make_null (&INFO2.max_key);
  btree_init_temp_key_value (&clear_key, &curr_key);

  /* test the page for the order of the keys within the page and get the biggest key of this page */
  valid = btree_check_page_key (thread_p, class_oid_p, btid, btname, pg_ptr, pg_vpid);
  if (valid != DISK_VALID)
    {
      goto error;
    }

  key_cnt = btree_node_number_of_keys (thread_p, pg_ptr);

  header = btree_get_node_header (thread_p, pg_ptr);
  if (header == NULL)
    {
      valid = DISK_INVALID;
      goto error;
    }

  node_type = (header->node_level > 1) ? BTREE_NON_LEAF_NODE : BTREE_LEAF_NODE;

  if ((node_type == BTREE_NON_LEAF_NODE && key_cnt <= 0) || (node_type == BTREE_LEAF_NODE && key_cnt < 0))
    {
      btree_dump_page (thread_p, stdout, class_oid_p, btid, btname, pg_ptr, pg_vpid, 2, 2);
      snprintf (err_buf, LINE_MAX, "btree_verify_subtree: node key count underflow: %d\n", key_cnt);
      er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_EMERGENCY_ERROR, 1, err_buf);
      valid = DISK_INVALID;
      goto error;
    }

  /* initialize INFO structure */
  INFO->max_key_len = header->max_key_len;
  INFO->height = 0;
  INFO->tot_key_cnt = 0;
  INFO->page_cnt = 0;
  INFO->leafpg_cnt = 0;
  INFO->nleafpg_cnt = 0;
  db_make_null (&INFO->max_key);

  if (node_type == BTREE_NON_LEAF_NODE)
    {				/* a non-leaf page */
      if (key_cnt < 0)
	{
	  btree_dump_page (thread_p, stdout, class_oid_p, btid, btname, pg_ptr, pg_vpid, 2, 2);

	  snprintf (err_buf, LINE_MAX, "btree_verify_subtree: node key count underflow: %d\n", key_cnt);
	  er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_EMERGENCY_ERROR, 1, err_buf);
	  valid = DISK_INVALID;
	  goto error;
	}

      INFO2.key_area_len = 0;
      db_make_null (&INFO2.max_key);

      /* traverse all the subtrees of this non_leaf page and accumulate the statistical data in the INFO structure */
      for (i = 1; i <= key_cnt; i++)
	{
	  if (spage_get_record (thread_p, pg_ptr, i, &rec, PEEK) != S_SUCCESS)
	    {
	      valid = DISK_ERROR;
	      goto error;
	    }

	  if (btree_read_record (thread_p, btid, pg_ptr, &rec, &curr_key, &nleaf_ptr, BTREE_NON_LEAF_NODE,
				 &clear_key, &offset, PEEK_KEY_VALUE, NULL) != NO_ERROR)
	    {
	      valid = DISK_ERROR;
	      goto error;
	    }

	  page_vpid = nleaf_ptr.pnt;

	  page = pgbuf_fix (thread_p, &page_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
	  if (page == NULL)
	    {
	      valid = DISK_ERROR;
	      goto error;
	    }

	  (void) pgbuf_check_page_ptype (thread_p, page, PAGE_BTREE);

	  valid = btree_verify_subtree (thread_p, class_oid_p, btid, btname, page, &page_vpid, &INFO2);
	  if (valid != DISK_VALID)
	    {
	      goto error;
	    }

	  /* accumulate results */
	  INFO->height = INFO2.height + 1;
	  INFO->tot_key_cnt += INFO2.tot_key_cnt;
	  INFO->page_cnt += INFO2.page_cnt;
	  INFO->leafpg_cnt += INFO2.leafpg_cnt;
	  INFO->nleafpg_cnt += INFO2.nleafpg_cnt;

	  pgbuf_unfix_and_init (thread_p, page);
	  btree_clear_key_value (&clear_key, &curr_key);
	}
      INFO->page_cnt += 1;
      INFO->nleafpg_cnt += 1;
    }
  else
    {				/* a leaf page */
      /* form the INFO structure from the header information */
      INFO->height = 1;
      INFO->tot_key_cnt = key_cnt;
      INFO->page_cnt = 1;
      INFO->leafpg_cnt = 1;
      INFO->nleafpg_cnt = 0;
    }

  return DISK_VALID;

error:
  btree_clear_key_value (&clear_key, &curr_key);

  if (page)
    {
      pgbuf_unfix_and_init (thread_p, page);
    }

  return valid;
}

/*
 * btree_verify_tree () - Check (verify) tree
 *   return: either: DISK_INVALID, DISK_VALID, DISK_ERROR
 *   btid_int(in): B+tree index identifier
 *
 * Note: Verifies the correctness of the B+tree index. During tree traversal, several tests are conducted,
 * such as checking the order of keys on a page or among pages that are in a father-child relationship.
 */
DISK_ISVALID
btree_verify_tree (THREAD_ENTRY * thread_p, const OID * class_oid_p, BTID_INT * btid_int, const char *btname)
{
  VPID p_vpid;
  PAGE_PTR root = NULL;
  BTREE_NODE_INFO INFO;
  DISK_ISVALID valid = DISK_ERROR;

  p_vpid.pageid = btid_int->sys_btid->root_pageid;	/* read root page */
  p_vpid.volid = btid_int->sys_btid->vfid.volid;
  root = pgbuf_fix (thread_p, &p_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
  if (root == NULL)
    {
      valid = DISK_ERROR;
      goto error;
    }

  (void) pgbuf_check_page_ptype (thread_p, root, PAGE_BTREE);

  /* traverse the tree and store the statistical data in the INFO structure */
  valid = btree_verify_subtree (thread_p, class_oid_p, btid_int, btname, root, &p_vpid, &INFO);
  if (valid != DISK_VALID)
    {
      goto error;
    }

  pgbuf_unfix_and_init (thread_p, root);

  return DISK_VALID;

error:

  if (root)
    {
      pgbuf_unfix_and_init (thread_p, root);
    }

  return valid;
}

/*
 *       		 db_check consistency routines
 */

/*
 * btree_check_pages () -
 *   return: DISK_VALID, DISK_VALID or DISK_ERROR
 *   btid(in): B+tree index identifier
 *   pg_ptr(in): Page pointer
 *   pg_vpid(in): Page identifier
 *
 * Note: Verify that given page and all its subpages are valid.
 */
static DISK_ISVALID
btree_check_pages (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR pg_ptr, VPID * pg_vpid)
{
  VPID page_vpid;		/* Child page identifier */
  PAGE_PTR page = NULL;		/* Child page pointer */
  RECDES rec;			/* Record descriptor for page node records */
  DISK_ISVALID vld = DISK_ERROR;	/* Validity return code from subtree */
  int key_cnt;			/* Number of keys in the page */
  int i;			/* Loop counter */
  NON_LEAF_REC nleaf;
  BTREE_NODE_HEADER *header = NULL;
  BTREE_NODE_TYPE node_type;

  /* Verify the given page */
  vld = file_check_vpid (thread_p, &btid->sys_btid->vfid, pg_vpid);
  if (vld != DISK_VALID)
    {
      goto error;
    }

#ifdef SPAGE_DEBUG
  if (spage_check (thread_p, pg_ptr) != NO_ERROR)
    {
      vld = DISK_ERROR;
      goto error;
    }
#endif /* SPAGE_DEBUG */

  /* Verify subtree child pages */

  key_cnt = btree_node_number_of_keys (thread_p, pg_ptr);

  header = btree_get_node_header (thread_p, pg_ptr);
  if (header == NULL)
    {
      vld = DISK_ERROR;
      goto error;
    }

  node_type = (header->node_level > 1) ? BTREE_NON_LEAF_NODE : BTREE_LEAF_NODE;

  if (node_type == BTREE_NON_LEAF_NODE)
    {				/* non-leaf page */
      for (i = 1; i <= key_cnt; i++)
	{
	  if (spage_get_record (thread_p, pg_ptr, i, &rec, PEEK) != S_SUCCESS)
	    {
	      vld = DISK_ERROR;
	      goto error;
	    }
	  btree_read_fixed_portion_of_non_leaf_record (&rec, &nleaf);
	  page_vpid = nleaf.pnt;

	  page = pgbuf_fix (thread_p, &page_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
	  if (page == NULL)
	    {
	      vld = DISK_ERROR;
	      goto error;
	    }

	  (void) pgbuf_check_page_ptype (thread_p, page, PAGE_BTREE);

	  vld = btree_check_pages (thread_p, btid, page, &page_vpid);
	  if (vld != DISK_VALID)
	    {
	      goto error;
	    }
	  pgbuf_unfix_and_init (thread_p, page);
	}
    }

  return DISK_VALID;

error:

  if (page)
    {
      pgbuf_unfix_and_init (thread_p, page);
    }
  return vld;

}

/*
 * btree_check_tree () -
 *   return: DISK_VALID, DISK_INVALID or DISK_ERROR
 *   btid(in): B+tree index identifier
 *
 * Note: Verify that all the pages of the specified index are valid.
 */
DISK_ISVALID
btree_check_tree (THREAD_ENTRY * thread_p, const OID * class_oid_p, BTID * btid, const char *btname)
{
  DISK_ISVALID valid = DISK_ERROR;
  VPID r_vpid;			/* root page identifier */
  PAGE_PTR r_pgptr = NULL;	/* root page pointer */
  BTID_INT btid_int;
  BTREE_ROOT_HEADER *root_header = NULL;

  /* Fetch the root page */
  r_vpid.pageid = btid->root_pageid;
  r_vpid.volid = btid->vfid.volid;
  r_pgptr = pgbuf_fix (thread_p, &r_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
  if (r_pgptr == NULL)
    {
      valid = DISK_ERROR;
      goto error;
    }

  (void) pgbuf_check_page_ptype (thread_p, r_pgptr, PAGE_BTREE);

  root_header = btree_get_root_header (thread_p, r_pgptr);
  if (root_header == NULL)
    {
      valid = DISK_ERROR;
      goto error;
    }

  btid_int.sys_btid = btid;
  if (btree_glean_root_header_info (thread_p, root_header, &btid_int) != NO_ERROR)
    {
      valid = DISK_ERROR;
      goto error;
    }

  valid = btree_check_pages (thread_p, &btid_int, r_pgptr, &r_vpid);
  if (valid != DISK_VALID)
    {
      goto error;
    }

  pgbuf_unfix_and_init (thread_p, r_pgptr);

  /* Now check for the logical correctness of the tree */
  return btree_verify_tree (thread_p, class_oid_p, &btid_int, btname);

error:

  if (r_pgptr)
    {
      pgbuf_unfix_and_init (thread_p, r_pgptr);
    }
  return valid;
}

/*
 * btree_check_by_btid () -
 *   btid(in): B+tree index identifier
 *   return: either: DISK_INVALID, DISK_VALID, DISK_ERROR
 *
 * Note: Verify that all pages of a btree indices are valid.
 */
DISK_ISVALID
btree_check_by_btid (THREAD_ENTRY * thread_p, BTID * btid)
{
  DISK_ISVALID valid = DISK_ERROR;
  char *btname;
  FILE_DESCRIPTORS fdes;

  assert (!VFID_ISNULL (&btid->vfid));

  if (file_descriptor_get (thread_p, &btid->vfid, &fdes) != NO_ERROR)
    {
      ASSERT_ERROR ();
      return DISK_ERROR;
    }

  if (btree_get_btid_from_file (thread_p, &btid->vfid, btid) != NO_ERROR)
    {
      ASSERT_ERROR ();
      return DISK_ERROR;
    }

  /* get the index name of the index key */
  if (heap_get_indexinfo_of_btid (thread_p, &fdes.btree.class_oid, btid, NULL, NULL, NULL, NULL, &btname, NULL) !=
      NO_ERROR)
    {
      if (er_errid () == NO_ERROR)
	{
	  /* this is sometimes expected. I found a case when index was just loaded, but class object was not updated
	   * yet. heap_get_indexinfo_of_btid is ambiguously handled, it does not set errors, but returns error code.
	   * this crashes in ASSERT_ERROR safe-guards.
	   *
	   * this is, for now, a quick fix to avoid the safe-guard. I hope it won't hide other issues.
	   */
	  btree_log_if_enabled ("btree_check_by_btid on (%d, %d|%d) failed, because index info could not be "
				"fetched. it is possible that index is still loading... \n", BTID_AS_ARGS (btid));
	  valid = DISK_VALID;
	}
      goto exit_on_end;
    }

  valid = btree_check_tree (thread_p, &fdes.btree.class_oid, btid, btname);
  if (valid == DISK_ERROR)
    {
      ASSERT_ERROR ();
    }
  else if (valid == DISK_INVALID)
    {
      assert (false);
    }

exit_on_end:
  if (btname)
    {
      free_and_init (btname);
    }
  assert (valid != DISK_INVALID);

  return valid;
}

int
btree_get_pkey_btid (THREAD_ENTRY * thread_p, OID * cls_oid, BTID * pkey_btid)
{
  OR_CLASSREP *cls_repr = NULL;
  OR_INDEX *curr_idx;
  int cache_idx = -1;
  int i;
  int error = NO_ERROR;

  assert (pkey_btid != NULL);

  BTID_SET_NULL (pkey_btid);

  cls_repr = heap_classrepr_get (thread_p, cls_oid, NULL, NULL_REPRID, &cache_idx);
  if (cls_repr == NULL)
    {
      ASSERT_ERROR_AND_SET (error);

      er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, error, 0);
      return error;
    }

  for (i = 0, curr_idx = cls_repr->indexes; i < cls_repr->n_indexes; i++, curr_idx++)
    {
      if (curr_idx == NULL)
	{
	  error = ER_UNEXPECTED;
	  er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, error, 1, "Bad index information in class representation.");
	  break;
	}

      if (curr_idx->type == BTREE_PRIMARY_KEY)
	{
	  BTID_COPY (pkey_btid, &curr_idx->btid);
	  break;
	}
    }

  if (cls_repr != NULL)
    {
      heap_classrepr_free_and_init (cls_repr, &cache_idx);
    }

  return error;
}

/*
 * btree_check_by_class_oid () -
 *   cls_oid(in):
 *   return: either: DISK_INVALID, DISK_VALID, DISK_ERROR
 *
 */
DISK_ISVALID
btree_check_by_class_oid (THREAD_ENTRY * thread_p, OID * cls_oid, BTID * idx_btid)
{
  OR_CLASSREP *cls_repr = NULL;
  OR_INDEX *curr;
  BTID btid;
  int i;
  int cache_idx = -1;
  DISK_ISVALID rv = DISK_VALID;

  if (lock_object (thread_p, cls_oid, oid_Root_class_oid, IS_LOCK, LK_UNCOND_LOCK) != LK_GRANTED)
    {
      return DISK_ERROR;
    }

  cls_repr = heap_classrepr_get (thread_p, cls_oid, NULL, NULL_REPRID, &cache_idx);
  if (cls_repr == NULL)
    {
      lock_unlock_object (thread_p, cls_oid, oid_Root_class_oid, IS_LOCK, true);

      ASSERT_ERROR ();
      er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, er_errid (), 0);
      return DISK_ERROR;
    }

  for (i = 0, curr = cls_repr->indexes; i < cls_repr->n_indexes; i++, curr++)
    {
      if (curr == NULL)
	{
	  er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_UNEXPECTED, 1, "Bad index information in class representation.");
	  rv = DISK_ERROR;
	  break;
	}

      if (idx_btid != NULL && !BTID_IS_EQUAL (&curr->btid, idx_btid))
	{
	  continue;
	}

      BTID_COPY (&btid, &curr->btid);
      if (btree_check_by_btid (thread_p, &btid) != DISK_VALID)
	{
	  rv = DISK_ERROR;
	  break;
	}
    }

  lock_unlock_object (thread_p, cls_oid, oid_Root_class_oid, IS_LOCK, true);

  if (cls_repr)
    {
      heap_classrepr_free_and_init (cls_repr, &cache_idx);
    }

  return rv;
}

/*
 * btree_repair_prev_link_by_btid () -
 *   btid(in) :
 *   repair(in) :
 *   index_name(in) :
 *   return:
 */
static DISK_ISVALID
btree_repair_prev_link_by_btid (THREAD_ENTRY * thread_p, BTID * btid, bool repair, char *index_name)
{
  PAGE_PTR current_pgptr, next_pgptr, root_pgptr;
  VPID current_vpid, next_vpid;
  DISK_ISVALID valid = DISK_VALID;
  PGBUF_LATCH_MODE request_mode;
  int retry_count = 0;
  int retry_max = 20;
  char output[LINE_MAX];
  BTREE_NODE_HEADER *header = NULL;
  BTREE_NODE_TYPE node_type;

  VPID_SET_NULL (&next_vpid);

  snprintf (output, LINE_MAX, "%s - %s... ", repair ? "repair index" : "check index", index_name);
  xcallback_console_print (thread_p, output);

  current_pgptr = NULL;
  next_pgptr = NULL;
  root_pgptr = NULL;

  request_mode = repair ? PGBUF_LATCH_WRITE : PGBUF_LATCH_READ;

  /* root page */
  VPID_SET (&current_vpid, btid->vfid.volid, btid->root_pageid);
  root_pgptr = pgbuf_fix (thread_p, &current_vpid, OLD_PAGE, request_mode, PGBUF_UNCONDITIONAL_LATCH);
  if (root_pgptr == NULL)
    {
      valid = DISK_ERROR;
      goto exit_repair;
    }

  (void) pgbuf_check_page_ptype (thread_p, root_pgptr, PAGE_BTREE);

retry_repair:
  if (retry_count >= retry_max)
    {
      valid = DISK_ERROR;
      goto exit_repair;
    }

#if defined(SERVER_MODE)
  if (retry_count > 0)
    {
      thread_sleep (10);
    }
#endif

  if (current_pgptr)
    {
      pgbuf_unfix_and_init (thread_p, current_pgptr);
    }
  if (next_pgptr)
    {
      pgbuf_unfix_and_init (thread_p, next_pgptr);
    }

  while (!VPID_ISNULL (&current_vpid))
    {
      current_pgptr = pgbuf_fix (thread_p, &current_vpid, OLD_PAGE, request_mode, PGBUF_CONDITIONAL_LATCH);
      if (current_pgptr == NULL)
	{
	  retry_count++;
	  goto retry_repair;
	}

      (void) pgbuf_check_page_ptype (thread_p, current_pgptr, PAGE_BTREE);

      header = btree_get_node_header (thread_p, current_pgptr);
      if (header == NULL)
	{
	  valid = DISK_ERROR;
	  goto exit_repair;
	}

      node_type = (header->node_level > 1) ? BTREE_NON_LEAF_NODE : BTREE_LEAF_NODE;

      if (node_type == BTREE_LEAF_NODE)
	{
	  next_vpid = header->next_vpid;
	  break;
	}
      else
	{
	  RECDES rec;
	  NON_LEAF_REC non_leaf_rec;

	  if (spage_get_record (thread_p, current_pgptr, 1, &rec, PEEK) != S_SUCCESS)
	    {
	      valid = DISK_ERROR;
	      goto exit_repair;
	    }
	  btree_read_fixed_portion_of_non_leaf_record (&rec, &non_leaf_rec);
	  current_vpid = non_leaf_rec.pnt;
	  pgbuf_unfix_and_init (thread_p, current_pgptr);
	}
    }

  assert (node_type == BTREE_LEAF_NODE);
  assert (header != NULL);

  while (!VPID_ISNULL (&next_vpid))
    {
      next_pgptr = pgbuf_fix (thread_p, &next_vpid, OLD_PAGE, request_mode, PGBUF_CONDITIONAL_LATCH);
      if (next_pgptr == NULL)
	{
	  retry_count++;
	  goto retry_repair;
	}

      (void) pgbuf_check_page_ptype (thread_p, next_pgptr, PAGE_BTREE);

      header = btree_get_node_header (thread_p, next_pgptr);
      if (header == NULL)
	{
	  valid = DISK_ERROR;
	  goto exit_repair;
	}

      if (!VPID_EQ (&header->prev_vpid, &current_vpid))
	{
	  er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_BTREE_CORRUPT_PREV_LINK, 3, index_name, next_vpid.volid,
		  next_vpid.pageid);

	  if (repair)
	    {
	      BTID_INT bint;

	      log_sysop_start (thread_p);
	      bint.sys_btid = btid;
	      if (btree_set_vpid_previous_vpid (thread_p, &bint, next_pgptr, &current_vpid) != NO_ERROR)
		{
		  valid = DISK_ERROR;
		  log_sysop_abort (thread_p);
		  goto exit_repair;
		}
	      valid = DISK_INVALID;
	      log_sysop_commit (thread_p);
	      er_set (ER_NOTIFICATION_SEVERITY, ARG_FILE_LINE, ER_BTREE_REPAIR_PREV_LINK, 3, index_name,
		      next_vpid.volid, next_vpid.pageid);
	    }
	  else
	    {
	      valid = DISK_INVALID;
	      goto exit_repair;
	    }
	}
      pgbuf_unfix_and_init (thread_p, current_pgptr);

      /* move to next page */
      current_vpid = next_vpid;
      next_vpid = header->next_vpid;
      current_pgptr = next_pgptr;
      next_pgptr = NULL;
    }

exit_repair:
  if (root_pgptr)
    {
      pgbuf_unfix (thread_p, root_pgptr);
    }
  if (current_pgptr)
    {
      pgbuf_unfix (thread_p, current_pgptr);
    }
  if (next_pgptr)
    {
      pgbuf_unfix (thread_p, next_pgptr);
    }

  if (valid == DISK_ERROR)
    {
      xcallback_console_print (thread_p, (char *) "error\n");
    }
  else if (valid == DISK_VALID)
    {
      xcallback_console_print (thread_p, (char *) "pass\n");
    }
  else
    {
      if (repair)
	{
	  xcallback_console_print (thread_p, (char *) "repaired\n");
	}
      else
	{
	  xcallback_console_print (thread_p, (char *) "repair needed\n");
	}
    }

  return valid;
}

/*
 * btree_repair_prev_link_by_class_oid () -
 *   oid(in) :
 *   repair(in) :
 *   return:
 */
static DISK_ISVALID
btree_repair_prev_link_by_class_oid (THREAD_ENTRY * thread_p, OID * oid, BTID * index_btid, bool repair)
{
  OR_CLASSREP *cls_repr = NULL;
  OR_INDEX *curr;
  int i;
  int cache_idx = -1;
  DISK_ISVALID valid = DISK_VALID;
  char *index_name;

  if (lock_object (thread_p, oid, oid_Root_class_oid, IS_LOCK, LK_UNCOND_LOCK) != LK_GRANTED)
    {
      return DISK_ERROR;
    }

  cls_repr = heap_classrepr_get (thread_p, oid, NULL, NULL_REPRID, &cache_idx);

  if (cls_repr == NULL)
    {
      lock_unlock_object (thread_p, oid, oid_Root_class_oid, IS_LOCK, true);
      return DISK_ERROR;
    }

  for (i = 0, curr = cls_repr->indexes; i < cls_repr->n_indexes && curr && valid == DISK_VALID; i++, curr++)
    {
      if (index_btid != NULL && !BTID_IS_EQUAL (&curr->btid, index_btid))
	{
	  continue;
	}

      heap_get_indexinfo_of_btid (thread_p, oid, &curr->btid, NULL, NULL, NULL, NULL, &index_name, NULL);
      valid = btree_repair_prev_link_by_btid (thread_p, &curr->btid, repair, index_name);
      if (index_name)
	{
	  free_and_init (index_name);
	}
    }

  lock_unlock_object (thread_p, oid, oid_Root_class_oid, IS_LOCK, true);
  if (cls_repr)
    {
      heap_classrepr_free_and_init (cls_repr, &cache_idx);
    }

  return valid;
}

/*
 * btree_repair_prev_link () -
 *   oid(in) :
 *   index_btid(in) :
 *   repair(in) :
 *   return:
 */
DISK_ISVALID
btree_repair_prev_link (THREAD_ENTRY * thread_p, OID * oid, BTID * index_btid, bool repair)
{
  BTID btid;
  DISK_ISVALID valid;
  char *index_name = NULL;
  OID class_oid = OID_INITIALIZER;

  if (oid != NULL && !OID_ISNULL (oid))
    {
      return btree_repair_prev_link_by_class_oid (thread_p, oid, index_btid, repair);
    }

  valid = DISK_VALID;

  /* Go to each file, check only the btree files */
  VFID_SET_NULL (&btid.vfid);
  while (true)
    {
      if (file_tracker_interruptable_iterate (thread_p, FILE_BTREE, &btid.vfid, &class_oid) != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  valid = valid == DISK_VALID ? DISK_ERROR : valid;
	  break;
	}
      if (VFID_ISNULL (&btid.vfid))
	{
	  /* no more b-trees */
	  break;
	}

      if (btree_get_btid_from_file (thread_p, &btid.vfid, &btid) != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  valid = valid == DISK_VALID ? DISK_ERROR : valid;
	  break;
	}

      /* get the index name of the index key */
      if (heap_get_indexinfo_of_btid (thread_p, &class_oid, &btid, NULL, NULL, NULL, NULL, &index_name, NULL)
	  != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  valid = valid == DISK_VALID ? DISK_ERROR : valid;
	  break;
	}

      valid = btree_repair_prev_link_by_btid (thread_p, &btid, repair, index_name);
      if (valid == DISK_ERROR)
	{
	  ASSERT_ERROR ();
	  break;
	}
    }
  if (!OID_ISNULL (&class_oid))
    {
      lock_unlock_object (thread_p, &class_oid, oid_Root_class_oid, SCH_S_LOCK, true);
    }

  return valid;
}

/*
 * btree_check_all () -
 *   return: either: DISK_INVALID, DISK_VALID, DISK_ERROR
 *
 * Note: Verify that all pages of all btree indices are valid.
 */
DISK_ISVALID
btree_check_all (THREAD_ENTRY * thread_p)
{
  DISK_ISVALID valid, allvalid;	/* Validation return code */
  BTID btid;

  OID class_oid = OID_INITIALIZER;

  int error_code = NO_ERROR;

  allvalid = DISK_VALID;
  /* Go to each file, check only the btree files */
  VFID_SET_NULL (&btid.vfid);
  while (true)
    {
      error_code = file_tracker_interruptable_iterate (thread_p, FILE_BTREE, &btid.vfid, &class_oid);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  allvalid = (allvalid == DISK_VALID) ? DISK_ERROR : allvalid;
	  break;
	}
      if (VFID_ISNULL (&btid.vfid))
	{
	  /* no more b-tree files */
	  break;
	}
      assert (!OID_ISNULL (&class_oid));

      /* Check BTree file */
      valid = btree_check_by_btid (thread_p, &btid);
      if (valid == DISK_ERROR)
	{
	  ASSERT_ERROR ();
	  allvalid = (allvalid == DISK_VALID) ? DISK_ERROR : allvalid;
	  break;
	}
      if (valid == DISK_INVALID)
	{
	  assert_release (false);
	  allvalid = valid;
	}
    }

  if (!OID_ISNULL (&class_oid))
    {
      lock_unlock_object (thread_p, &class_oid, oid_Root_class_oid, SCH_S_LOCK, true);
    }
  return allvalid;
}

/*
 * btree_keyoid_checkscan_start () -
 *   return: NO_ERROR
 *   btid(in): B+tree index identifier
 *   btscan(out): Set to key-oid check scan structure.
 *
 * Note: Start a <key-oid> check scan on the index.
 */
int
btree_keyoid_checkscan_start (THREAD_ENTRY * thread_p, BTID * btid, BTREE_CHECKSCAN * btscan)
{
  assert (btid != NULL);

  /* initialize scan structure */
  btscan->btid = *btid;
  BTREE_INIT_SCAN (&btscan->btree_scan);

  /* Initialize OID list. */
  btscan->oid_list.oidp = (OID *) os_malloc (ISCAN_OID_BUFFER_CAPACITY);
  if (btscan->oid_list.oidp == NULL)
    {
      er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_OUT_OF_VIRTUAL_MEMORY, 1, ISCAN_OID_BUFFER_CAPACITY);
      return ER_OUT_OF_VIRTUAL_MEMORY;
    }
  btscan->oid_list.oid_cnt = 0;
  btscan->oid_list.capacity = ISCAN_OID_BUFFER_CAPACITY / OR_OID_SIZE;
  btscan->oid_list.max_oid_cnt = btscan->oid_list.capacity;
  btscan->oid_list.next_list = NULL;

  return NO_ERROR;
}

/*
 * btree_keyoid_checkscan_check () -
 *   return: either: DISK_INVALID, DISK_VALID, DISK_ERROR
 *   btscan(in): B+tree key-oid check scan structure.
 *   cls_oid(in):
 *   key(in): Key pointer
 *   oid(in): Object identifier for the key
 *
 * Note: Check if the given key-oid pair exists in the index.
 */
DISK_ISVALID
btree_keyoid_checkscan_check (THREAD_ENTRY * thread_p, BTREE_CHECKSCAN * btscan, OID * cls_oid, DB_VALUE * key,
			      OID * oid)
{
  int k;			/* Loop iteration variable */
  INDX_SCAN_ID isid;
  DISK_ISVALID status;
  key_val_range kv_range;
  MVCC_SNAPSHOT *mvcc_snapshot = NULL;

  mvcc_snapshot = logtb_get_mvcc_snapshot (thread_p);
  if (mvcc_snapshot == NULL)
    {
      ASSERT_ERROR ();
      return DISK_INVALID;
    }

  /* initialize scan structure */
  BTREE_INIT_SCAN (&btscan->btree_scan);

  scan_init_index_scan (&isid, &btscan->oid_list, mvcc_snapshot);

  assert (!pr_is_set_type (DB_VALUE_DOMAIN_TYPE (key)));

  pr_share_value (key, &kv_range.key1);
  pr_share_value (key, &kv_range.key2);
  kv_range.range = GE_LE;
  kv_range.num_index_term = 0;

  do
    {
      /* search index */
      btscan->oid_list.oid_cnt =
	btree_keyval_search (thread_p, &btscan->btid, S_SELECT, &btscan->btree_scan, &kv_range, cls_oid, NULL,
			     &isid, false);
      assert (btscan->oid_list.oid_cnt <= btscan->oid_list.capacity);

      if (DB_VALUE_DOMAIN_TYPE (key) == DB_TYPE_MIDXKEY && key->data.midxkey.domain == NULL)
	{
	  /* set the appropriate domain, as it might be needed for printing if the given key-oid pair does not exist in
	   * the index. */
	  key->data.midxkey.domain = btscan->btree_scan.btid_int.key_type;
	}

      if (btscan->oid_list.oid_cnt < 0)
	{
	  status = DISK_ERROR;
	  goto end;
	}

      /* search current set of OIDs to see if given <key-oid> pair exists */
      for (k = 0; k < btscan->oid_list.oid_cnt; k++)
	{
	  if (OID_EQ (&btscan->oid_list.oidp[k], oid))
	    {			/* <key-oid> pair found */
	      status = DISK_VALID;
	      goto end;
	    }
	}
    }
  while (!BTREE_END_OF_SCAN (&btscan->btree_scan));

  /* indicate <key_oid> pair is not found */
  status = DISK_INVALID;

end:

  btree_scan_clear_key (&btscan->btree_scan);

  /* do not use copy_buf for key-val scan, only use for key-range scan */

  return status;
}

/*
 * btree_keyoid_checkscan_end () -
 *   return:
 *   btscan(in): B+tree key-oid check scan structure.
 *
 * Note: End the <key-oid> check scan on the index.
 */
void
btree_keyoid_checkscan_end (THREAD_ENTRY * thread_p, BTREE_CHECKSCAN * btscan)
{
  /* Deallocate allocated areas */
  if (btscan->oid_list.oidp)
    {
      os_free_and_init (btscan->oid_list.oidp);
      btscan->oid_list.capacity = 0;
      btscan->oid_list.max_oid_cnt = 0;
    }
}

/*
 *       		     b+tree space routines
 */

/*
 * btree_get_subtree_capacity () -
 *   return: NO_ERROR
 *   btid(in):
 *   pg_ptr(in):
 *   cpc(in):
 */
static int
btree_get_subtree_capacity (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR pg_ptr, BTREE_CAPACITY * cpc)
{
  RECDES rec;			/* Page record descriptor */
  int free_space;		/* Total free space of the Page */
  int key_cnt;			/* Page key count */
  NON_LEAF_REC nleaf_ptr;	/* NonLeaf Record pointer */
  VPID page_vpid;		/* Child page identifier */
  PAGE_PTR page = NULL;		/* Child page pointer */
  int i;			/* Loop counter */
  int offset;			/* Offset to the beginning of OID list */
  int oid_cnt;			/* Number of OIDs */
  VPID ovfl_vpid;		/* Overflow page identifier */
  RECDES orec;			/* Overflow record descriptor */
  LEAF_REC leaf_pnt;

  bool clear_key = false;
  PAGE_PTR ovfp = NULL;
  DB_VALUE key1;
  int ret = NO_ERROR;
  BTREE_NODE_HEADER *header = NULL;
  BTREE_NODE_TYPE node_type;

  /* initialize */
  leaf_pnt.key_len = 0;
  VPID_SET_NULL (&leaf_pnt.ovfl);

  btree_init_temp_key_value (&clear_key, &key1);

  /* initialize capacity structure */
  cpc->dis_key_cnt = 0;
  cpc->tot_val_cnt = 0;
  cpc->avg_val_per_key = 0;
  cpc->leaf_pg_cnt = 0;
  cpc->nleaf_pg_cnt = 0;
  cpc->tot_pg_cnt = 0;
  cpc->height = 0;
  cpc->sum_rec_len = 0;
  cpc->sum_key_len = 0;
  cpc->avg_key_len = 0;
  cpc->avg_rec_len = 0;
  cpc->tot_free_space = 0;
  cpc->tot_space = 0;
  cpc->tot_used_space = 0;
  cpc->avg_pg_key_cnt = 0;
  cpc->avg_pg_free_sp = 0;

  free_space = spage_get_free_space (thread_p, pg_ptr);

  key_cnt = btree_node_number_of_keys (thread_p, pg_ptr);

  header = btree_get_node_header (thread_p, pg_ptr);
  if (header == NULL)
    {
      goto exit_on_error;
    }

  node_type = (header->node_level > 1) ? BTREE_NON_LEAF_NODE : BTREE_LEAF_NODE;

  if (node_type == BTREE_NON_LEAF_NODE)
    {				/* a non-leaf page */
      BTREE_CAPACITY cpc2;

      /* traverse all the subtrees of this non_leaf page and accumulate the statistical data in the cpc structure */
      for (i = 1; i <= key_cnt; i++)
	{
	  if (spage_get_record (thread_p, pg_ptr, i, &rec, PEEK) != S_SUCCESS)
	    {
	      goto exit_on_error;
	    }
	  btree_read_fixed_portion_of_non_leaf_record (&rec, &nleaf_ptr);
	  page_vpid = nleaf_ptr.pnt;
	  page = pgbuf_fix (thread_p, &page_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
	  if (page == NULL)
	    {
	      goto exit_on_error;
	    }

	  (void) pgbuf_check_page_ptype (thread_p, page, PAGE_BTREE);

	  ret = btree_get_subtree_capacity (thread_p, btid, page, &cpc2);
	  if (ret != NO_ERROR)
	    {
	      goto exit_on_error;
	    }

	  /* form the cpc structure for a non-leaf node page */
	  cpc->dis_key_cnt += cpc2.dis_key_cnt;
	  cpc->tot_val_cnt += cpc2.tot_val_cnt;
	  cpc->leaf_pg_cnt += cpc2.leaf_pg_cnt;
	  cpc->nleaf_pg_cnt += cpc2.nleaf_pg_cnt;
	  cpc->tot_pg_cnt += cpc2.tot_pg_cnt;
	  cpc->height = cpc2.height + 1;
	  cpc->sum_rec_len += cpc2.sum_rec_len;
	  cpc->sum_key_len += cpc2.sum_key_len;
	  cpc->tot_free_space += cpc2.tot_free_space;
	  cpc->tot_space += cpc2.tot_space;
	  cpc->tot_used_space += cpc2.tot_used_space;
	  pgbuf_unfix_and_init (thread_p, page);
	}			/* for */
      cpc->avg_val_per_key = ((cpc->dis_key_cnt > 0) ? (cpc->tot_val_cnt / cpc->dis_key_cnt) : 0);
      cpc->nleaf_pg_cnt += 1;
      cpc->tot_pg_cnt += 1;
      cpc->tot_free_space += free_space;
      cpc->tot_space += DB_PAGESIZE;
      cpc->tot_used_space += (DB_PAGESIZE - free_space);
      cpc->avg_key_len = ((cpc->dis_key_cnt > 0) ? ((int) (cpc->sum_key_len / cpc->dis_key_cnt)) : 0);
      cpc->avg_rec_len = ((cpc->dis_key_cnt > 0) ? ((int) (cpc->sum_rec_len / cpc->dis_key_cnt)) : 0);
      cpc->avg_pg_key_cnt = ((cpc->leaf_pg_cnt > 0) ? ((int) (cpc->dis_key_cnt / cpc->leaf_pg_cnt)) : 0);
      cpc->avg_pg_free_sp = ((cpc->tot_pg_cnt > 0) ? (cpc->tot_free_space / cpc->tot_pg_cnt) : 0);
    }
  else
    {				/* a leaf page */

      /* form the cpc structure for a leaf node page */
      cpc->dis_key_cnt = key_cnt;
      cpc->leaf_pg_cnt = 1;
      cpc->nleaf_pg_cnt = 0;
      cpc->tot_pg_cnt = 1;
      cpc->height = 1;
      for (i = 1; i <= cpc->dis_key_cnt; i++)
	{
	  if (spage_get_record (thread_p, pg_ptr, i, &rec, PEEK) != S_SUCCESS)
	    {
	      goto exit_on_error;
	    }
	  cpc->sum_rec_len += rec.length;

	  /* read the current record key */
	  if (btree_read_record (thread_p, btid, pg_ptr, &rec, &key1, &leaf_pnt, BTREE_LEAF_NODE, &clear_key, &offset,
				 PEEK_KEY_VALUE, NULL) != NO_ERROR)
	    {
	      goto exit_on_error;
	    }
	  cpc->sum_key_len += btree_get_disk_size_of_key (&key1);
	  btree_clear_key_value (&clear_key, &key1);

	  /* find the value (OID) count for the record */
	  oid_cnt = btree_record_get_num_oids (thread_p, btid, &rec, offset, BTREE_LEAF_NODE);

	  ovfl_vpid = leaf_pnt.ovfl;
	  if (!VPID_ISNULL (&ovfl_vpid))
	    {			/* overflow pages exist */
	      do
		{
		  ovfp = pgbuf_fix (thread_p, &ovfl_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
		  if (ovfp == NULL)
		    {
		      goto exit_on_error;
		    }

		  (void) pgbuf_check_page_ptype (thread_p, ovfp, PAGE_BTREE);

		  btree_get_next_overflow_vpid (thread_p, ovfp, &ovfl_vpid);

		  if (spage_get_record (thread_p, ovfp, 1, &orec, PEEK) != S_SUCCESS)
		    {
		      goto exit_on_error;
		    }

		  oid_cnt += btree_record_get_num_oids (thread_p, btid, &orec, 0, BTREE_OVERFLOW_NODE);
		  pgbuf_unfix_and_init (thread_p, ovfp);
		}
	      while (!VPID_ISNULL (&ovfl_vpid));
	    }			/* if */
	  cpc->tot_val_cnt += oid_cnt;

	}			/* for */
      cpc->avg_val_per_key = ((cpc->dis_key_cnt > 0) ? (cpc->tot_val_cnt / cpc->dis_key_cnt) : 0);
      cpc->avg_key_len = ((cpc->dis_key_cnt > 0) ? ((int) (cpc->sum_key_len / cpc->dis_key_cnt)) : 0);
      cpc->avg_rec_len = ((cpc->dis_key_cnt > 0) ? ((int) (cpc->sum_rec_len / cpc->dis_key_cnt)) : 0);
      cpc->tot_free_space = (float) free_space;
      cpc->tot_space = DB_PAGESIZE;
      cpc->tot_used_space = (cpc->tot_space - cpc->tot_free_space);
      cpc->avg_pg_key_cnt = ((cpc->leaf_pg_cnt > 0) ? (cpc->dis_key_cnt / cpc->leaf_pg_cnt) : 0);
      cpc->avg_pg_free_sp = ((cpc->tot_pg_cnt > 0) ? (cpc->tot_free_space / cpc->tot_pg_cnt) : 0);

    }				/* if-else */

  return ret;

exit_on_error:

  if (page)
    {
      pgbuf_unfix_and_init (thread_p, page);
    }
  if (ovfp)
    {
      pgbuf_unfix_and_init (thread_p, ovfp);
    }

  btree_clear_key_value (&clear_key, &key1);

  return (ret == NO_ERROR && (ret = er_errid ()) == NO_ERROR) ? ER_FAILED : ret;
}

/*
 * btree_index_capacity () -
 *   return: NO_ERROR
 *   btid(in): B+tree index identifier
 *   cpc(out): Set to contain index capacity information
 *
 * Note: Form and return index capacity/space related information
 */
int
btree_index_capacity (THREAD_ENTRY * thread_p, BTID * btid, BTREE_CAPACITY * cpc)
{
  VPID root_vpid;		/* root page identifier */
  PAGE_PTR root = NULL;		/* root page pointer */
  BTID_INT btid_int;
  BTREE_ROOT_HEADER *root_header = NULL;
  int ret = NO_ERROR;

  /* read root page */
  root_vpid.pageid = btid->root_pageid;
  root_vpid.volid = btid->vfid.volid;
  root = pgbuf_fix (thread_p, &root_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
  if (root == NULL)
    {
      goto exit_on_error;
    }

  (void) pgbuf_check_page_ptype (thread_p, root, PAGE_BTREE);

  root_header = btree_get_root_header (thread_p, root);
  if (root_header == NULL)
    {
      goto exit_on_error;
    }

  btid_int.sys_btid = btid;
  ret = btree_glean_root_header_info (thread_p, root_header, &btid_int);
  if (ret != NO_ERROR)
    {
      goto exit_on_error;
    }

  /* traverse the tree and store the capacity info */
  ret = btree_get_subtree_capacity (thread_p, &btid_int, root, cpc);
  if (ret != NO_ERROR)
    {
      goto exit_on_error;
    }

  pgbuf_unfix_and_init (thread_p, root);

  return ret;

exit_on_error:

  if (root)
    {
      pgbuf_unfix_and_init (thread_p, root);
    }

  return (ret == NO_ERROR && (ret = er_errid ()) == NO_ERROR) ? ER_FAILED : ret;
}

/*
 * btree_dump_capacity () -
 *   return: NO_ERROR
 *   btid(in): B+tree index identifier
 *
 * Note: Dump index capacity/space information.
 */
int
btree_dump_capacity (THREAD_ENTRY * thread_p, FILE * fp, BTID * btid)
{
  BTREE_CAPACITY cpc;
  int ret = NO_ERROR;
  char *index_name = NULL;
  char *class_name = NULL;
  FILE_DESCRIPTORS fdes;

  assert (fp != NULL && btid != NULL);

  /* get index capacity information */
  ret = btree_index_capacity (thread_p, btid, &cpc);
  if (ret != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto exit;
    }

  ret = file_descriptor_get (thread_p, &btid->vfid, &fdes);
  if (ret != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto exit;
    }

  if (heap_get_class_name (thread_p, &fdes.btree.class_oid, &class_name) != NO_ERROR)
    {
      ASSERT_ERROR_AND_SET (ret);
      goto exit;
    }

  /* get index name */
  ret = heap_get_indexinfo_of_btid (thread_p, &fdes.btree.class_oid, btid, NULL, NULL, NULL, NULL, &index_name, NULL);
  if (ret != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto exit;
    }

  fprintf (fp, "\n-------------------------------------------------------------\n");
  fprintf (fp, "BTID: {{%d, %d}, %d}, %s ON %s, CAPACITY INFORMATION:\n", btid->vfid.volid, btid->vfid.fileid,
	   btid->root_pageid, (index_name == NULL) ? "*UNKOWN_INDEX*" : index_name,
	   (class_name == NULL) ? "*UNKNOWN_CLASS*" : class_name);

  /* dump the capacity information */
  fprintf (fp, "\nDistinct Key Count: %d\n", cpc.dis_key_cnt);
  fprintf (fp, "Total Value Count: %d\n", cpc.tot_val_cnt);
  fprintf (fp, "Average Value Count Per Key: %d\n", cpc.avg_val_per_key);
  fprintf (fp, "Total Page Count: %d\n", cpc.tot_pg_cnt);
  fprintf (fp, "Leaf Page Count: %d\n", cpc.leaf_pg_cnt);
  fprintf (fp, "NonLeaf Page Count: %d\n", cpc.nleaf_pg_cnt);
  fprintf (fp, "Height: %d\n", cpc.height);
  fprintf (fp, "Average Key Length: %d\n", cpc.avg_key_len);
  fprintf (fp, "Average Record Length: %d\n", cpc.avg_rec_len);
  fprintf (fp, "Total Index Space: %.0f bytes\n", cpc.tot_space);
  fprintf (fp, "Used Index Space: %.0f bytes\n", cpc.tot_used_space);
  fprintf (fp, "Free Index Space: %.0f bytes\n", cpc.tot_free_space);
  fprintf (fp, "Average Page Free Space: %.0f bytes\n", cpc.avg_pg_free_sp);
  fprintf (fp, "Average Page Key Count: %d\n", cpc.avg_pg_key_cnt);
  fprintf (fp, "-------------------------------------------------------------\n");

exit:

  if (class_name != NULL)
    {
      free_and_init (class_name);
    }

  if (index_name != NULL)
    {
      free_and_init (index_name);
    }

  return ret;
}

/*
 * b+tree dump routines
 */

/*
 * btree_print_space () -
 *   return:
 *   n(in):
 */
static void
btree_print_space (FILE * fp, int n)
{

  while (n--)			/* print n space character */
    {
      fprintf (fp, " ");
    }

}

/*
 * btree_dump_page () -
 *   return: nothing
 *   btid(in): B+tree index identifier
 *   page_ptr(in): Page pointer
 *   pg_vpid(in): Page identifier
 *   n(in): Identation left margin (number of preceding blanks)
 *   level(in):
 *
 * Note: Dumps the content of the given page of the tree.
 */
static void
btree_dump_page (THREAD_ENTRY * thread_p, FILE * fp, const OID * class_oid_p, BTID_INT * btid, const char *btname,
		 PAGE_PTR page_ptr, VPID * pg_vpid, int depth, int level)
{
  int key_cnt;
  int i;
  RECDES rec;
  BTREE_NODE_HEADER *header = NULL;
  BTREE_NODE_TYPE node_type;
  VPID vpid;

  if (pg_vpid == NULL)
    {
      pgbuf_get_vpid (page_ptr, &vpid);
      pg_vpid = &vpid;
    }

  key_cnt = btree_node_number_of_keys (thread_p, page_ptr);

  /* get the header record */
  header = btree_get_node_header (thread_p, page_ptr);
  if (header == NULL)
    {
      btree_print_space (fp, depth * 4);
      fprintf (fp, "btree_dump_page: get node header failure: %d\n", key_cnt);
      return;
    }

  node_type = (header->node_level > 1) ? BTREE_NON_LEAF_NODE : BTREE_LEAF_NODE;

  btree_print_space (fp, depth * 4);
  fprintf (fp,
	   "[%s PAGE {%d, %d}, level: %d, depth: %d, keys: %d, Prev: {%d, %d}, Next: {%d, %d}, Max key len: %d]\n",
	   node_type_to_string (node_type), pg_vpid->volid, pg_vpid->pageid, header->node_level, depth, key_cnt,
	   header->prev_vpid.volid, header->prev_vpid.pageid, header->next_vpid.volid, header->next_vpid.pageid,
	   header->max_key_len);

  if (class_oid_p && !OID_ISNULL (class_oid_p))
    {
      char *class_name_p = NULL;
      if (heap_get_class_name (thread_p, class_oid_p, &class_name_p) != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return;
	}

      btree_print_space (fp, depth * 4);
      fprintf (fp, "INDEX %s ON CLASS %s (CLASS_OID:%2d|%4d|%2d) \n\n", (btname) ? btname : "*UNKNOWN-INDEX*",
	       (class_name_p) ? class_name_p : "*UNKNOWN-CLASS*", class_oid_p->volid, class_oid_p->pageid,
	       class_oid_p->slotid);
      if (class_name_p)
	{
	  free_and_init (class_name_p);
	}
    }

  fflush (fp);

  if (key_cnt < 0)
    {
      btree_print_space (fp, depth * 4);
      fprintf (fp, "btree_dump_page: node key count underflow: %d\n", key_cnt);
      return;
    }

  if (level > 1)
    {
      /* output the content of each record */
      for (i = 1; i <= key_cnt; i++)
	{
	  (void) spage_get_record (thread_p, page_ptr, i, &rec, PEEK);
	  if (node_type == BTREE_LEAF_NODE)
	    {
	      if (btree_leaf_is_flaged (&rec, BTREE_LEAF_RECORD_FENCE))
		{
		  fprintf (fp, "(F)");
		}
	      else
		{
		  fprintf (fp, "   ");
		}

	      btree_dump_leaf_record (thread_p, fp, btid, &rec, depth);
	    }
	  else
	    {
	      btree_dump_non_leaf_record (thread_p, fp, btid, &rec, depth, 1);
	    }
	  /* fprintf (fp, "\n"); */
	}
    }

  fprintf (fp, "\n");
}

/*
 * btree_dump_page_with_subtree () -
 *   return: nothing
 *   btid(in): B+tree index identifier
 *   pg_ptr(in): Page pointer
 *   pg_vpid(in): Page identifier
 *   n(in): Identation left margin (number of preceding blanks)
 *   level(in):
 *
 * Note: Dumps the content of the given page together with its subtrees
 */
static void
btree_dump_page_with_subtree (THREAD_ENTRY * thread_p, FILE * fp, BTID_INT * btid, PAGE_PTR pg_ptr, VPID * pg_vpid,
			      int depth, int level)
{
  int key_cnt;
  int i;
  NON_LEAF_REC nleaf_ptr;
  VPID page_vpid;
  PAGE_PTR page = NULL;
  RECDES rec;
  BTREE_NODE_HEADER *header = NULL;
  BTREE_NODE_TYPE node_type;

  key_cnt = btree_node_number_of_keys (thread_p, pg_ptr);

  btree_dump_page (thread_p, fp, NULL, btid, NULL, pg_ptr, pg_vpid, depth, level);	/* dump current page */

  /* get the header record */
  header = btree_get_node_header (thread_p, pg_ptr);
  if (header == NULL)
    {
      fprintf (fp, "btree_dump_page_with_subtree: get node header failure: %d.\n", key_cnt);
      return;
    }

  node_type = (header->node_level > 1) ? BTREE_NON_LEAF_NODE : BTREE_LEAF_NODE;

  if (node_type == BTREE_NON_LEAF_NODE)
    {				/* page is non_leaf */
#if !defined(NDEBUG)
      if (key_cnt < 0)
	{
	  fprintf (fp, "btree_dump_page_with_subtree: node key count underflow: %d.\n", key_cnt);
	  return;
	}
#endif

      /* for each child page pointer in this non_leaf page, dump the corresponding subtree */
      for (i = 1; i <= key_cnt; i++)
	{
	  (void) spage_get_record (thread_p, pg_ptr, i, &rec, PEEK);
	  btree_read_fixed_portion_of_non_leaf_record (&rec, &nleaf_ptr);
	  page_vpid = nleaf_ptr.pnt;
	  page = pgbuf_fix (thread_p, &page_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
	  if (page == NULL)
	    {
	      return;
	    }
	  btree_dump_page_with_subtree (thread_p, fp, btid, page, &page_vpid, depth + 1, level);
	  pgbuf_unfix_and_init (thread_p, page);
	}
    }

  return;
}

/*
 * btree_dump () -
 *   return: nothing
 *   btid(in): B+tree index identifier
 *   level(in):
 *
 * Note: Dumps the content of the each page in the B+tree by
 * traversing the tree in an "inorder" manner. The header
 * information, as well as the content of each record in a page
 * are dumped. The header information for a non_leaf page
 * contains the key count and maximum key length information.
 * Maximum key length refers to the longest key in the page and
 * in its subtrees. The header information for a leaf page
 * contains also the next_page information, which is the page
 * identifier of the next sibling page, and the overflow page
 * count information. root header information contains
 * statistical data for the whole tree. These consist of total
 * key count of the tree, total page count, leaf page count,
 * non_leaf page count, total overflow page count and the height
 * of the tree. Total key count refers only to those keys that
 * are stored in the leaf pages of the tree. The index key type
 * is also stored in the root header.
 *
 * NOTE: never used
 */
void
btree_dump (THREAD_ENTRY * thread_p, FILE * fp, BTID * btid, int level)
{
  VPID p_vpid;
  PAGE_PTR root = NULL;
  BTID_INT btid_int;
  BTREE_ROOT_HEADER *root_header = NULL;

  p_vpid.pageid = btid->root_pageid;	/* read root page */
  p_vpid.volid = btid->vfid.volid;
  root = pgbuf_fix (thread_p, &p_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
  if (root == NULL)
    {
      return;
    }

  root_header = btree_get_root_header (thread_p, root);
  if (root_header == NULL)
    {
      goto end;			/* do nothing */
    }

  btid_int.sys_btid = btid;
  if (btree_glean_root_header_info (thread_p, root_header, &btid_int) != NO_ERROR)
    {
      goto end;			/* do nothing */
    }

  fprintf (fp, "\n------------ The B+Tree Index Dump Start ---------------------\n\n\n");
  btree_dump_root_header (thread_p, fp, root);	/* output root header information */

  if (level != 0)
    {
      btree_dump_page_with_subtree (thread_p, fp, &btid_int, root, &p_vpid, 0, level);
    }

  fprintf (fp, "\n------------ The B+Tree Index Dump End ---------------------\n\n\n");

end:
  pgbuf_unfix_and_init (thread_p, root);

  return;
}


/*
 * btree_read_key_type () -
 *   return:
 *   btid(in):
 */
TP_DOMAIN *
btree_read_key_type (THREAD_ENTRY * thread_p, BTID * btid)
{
  VPID p_vpid;
  PAGE_PTR root = NULL;
  TP_DOMAIN *key_type = NULL;
  BTREE_ROOT_HEADER *root_header = NULL;

  p_vpid.pageid = btid->root_pageid;	/* read root page */
  p_vpid.volid = btid->vfid.volid;
  root = pgbuf_fix (thread_p, &p_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
  if (root == NULL)
    {
      return NULL;
    }

  (void) pgbuf_check_page_ptype (thread_p, root, PAGE_BTREE);

  root_header = btree_get_root_header (thread_p, root);
  if (root_header == NULL)
    {
      pgbuf_unfix_and_init (thread_p, root);
      return NULL;
    }

  (void) or_unpack_domain (root_header->packed_key_domain, &key_type, 0);

  pgbuf_unfix_and_init (thread_p, root);

  return key_type;
}

/*
 * btree_delete_key_from_leaf () - Delete a b-tree key completely.
 *
 * return		     : Error code.
 * thread_p (in)	     : Thread entry.
 * btid (in)		     : B-tree info.
 * leaf_pg (in)		     : Leaf page.
 * leafrec_pnt (in)	     : Leaf record info.
 * delete_helper (in)	     : B-tree delete helper.
 * search_key (in)	     : Search key result.
 */
static int
btree_delete_key_from_leaf (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR leaf_pg, LEAF_REC * leafrec_pnt,
			    BTREE_DELETE_HELPER * delete_helper, BTREE_SEARCH_KEY_HELPER * search_key)
{
  int ret = NO_ERROR;		/* Error code. */
  int key_cnt;			/* Node key count. */
  BTREE_NODE_HEADER *header = NULL;	/* Node header. */
  LOG_LSA prev_lsa;
  char leaf_record_buffer[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  RECDES leaf_record = RECDES_INITIALIZER;

  assert (delete_helper->is_system_op_started == false);
  assert (delete_helper->purpose != BTREE_OP_INSERT_MVCC_DELID
	  && delete_helper->purpose != BTREE_OP_DELETE_UNDO_INSERT_UNQ_MULTIUPD);

  /* Is this an overflow key? Should we delete it too? */
  /* If this is undo of inserted object, overflow key deletion will be handled automatically. Don't delete here. */
  if (leafrec_pnt->key_len < 0)
    {
      assert (delete_helper->purpose != BTREE_OP_DELETE_VACUUM_OBJECT || VACUUM_IS_THREAD_VACUUM_WORKER (thread_p));
      log_sysop_start (thread_p);
      delete_helper->is_system_op_started = true;

      /* Delete overflow key. */
      ret = btree_delete_overflow_key (thread_p, btid, leaf_pg, search_key->slotid, BTREE_LEAF_NODE);
      if (ret != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto exit_on_error;
	}
      /* Overflow key deleted. */
    }

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  header = btree_get_node_header (thread_p, leaf_pg);
  if (header == NULL)
    {
      assert_release (false);
      ret = ER_FAILED;
      goto exit_on_error;
    }

  if (delete_helper->is_system_op_started)
    {
      /* Before deleting the slot, we will need the record data for undo logging. */
      leaf_record.area_size = DB_PAGESIZE;
      leaf_record.data = PTR_ALIGN (leaf_record_buffer, BTREE_MAX_ALIGN);
      if (spage_get_record (thread_p, leaf_pg, search_key->slotid, &leaf_record, COPY) != S_SUCCESS)
	{
	  assert_release (false);
	  ret = ER_FAILED;
	  goto exit_on_error;
	}
    }

  /* now delete the btree slot */
  assert (search_key->slotid > 0);
  if (spage_delete (thread_p, leaf_pg, search_key->slotid) != search_key->slotid)
    {
      ASSERT_ERROR_AND_SET (ret);
      goto exit_on_error;
    }

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  /* key deleted, update node header */
  key_cnt = btree_node_number_of_keys (thread_p, leaf_pg);
  if (key_cnt == 0)
    {
      header->max_key_len = 0;
    }

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  /* We need to log previous lsa. */
  LSA_COPY (&prev_lsa, pgbuf_get_lsa (leaf_pg));

  /* Save redo logging. */
  /* Flag recovery that key is being removed completely. */
  LOG_RV_RECORD_SET_MODIFY_MODE (&delete_helper->leaf_addr, LOG_RV_RECORD_DELETE);
  /* Since this is completely removed, no debugging info is required. */
  assert (!BTREE_RV_HAS_DEBUG_INFO (delete_helper->leaf_addr.offset));

  /* Add logging. */
  btree_rv_log_delete_object (thread_p, *delete_helper, delete_helper->leaf_addr, leaf_record.length, 0,
			      leaf_record.data, NULL);

  btree_delete_log (delete_helper, BTREE_DELETE_MODIFY_MSG ("removed key"),
		    BTREE_DELETE_MODIFY_ARGS (thread_p, delete_helper, leaf_pg, &prev_lsa, true, search_key->slotid, 0,
					      btid->sys_btid));

  if (delete_helper->is_system_op_started)
    {
      btree_delete_sysop_end (thread_p, delete_helper);
    }

#if !defined(NDEBUG)
  (void) btree_verify_node (thread_p, btid, leaf_pg);
#endif

  return ret;

exit_on_error:

  if (delete_helper->is_system_op_started)
    {
      log_sysop_abort (thread_p);
      delete_helper->is_system_op_started = false;
    }

  assert_release (ret != NO_ERROR);
  return ret;
}

/*
 * btree_replace_first_oid_with_ovfl_oid () - Replace the object in leaf page with an object from the first overflow page.
 *
 * return		    : Error code.
 * thread_p (in)	    : Thread entry.
 * btid (in)		    : B-tree info.
 * key (in)		    : Key value.
 * delete_helper (in)	    : B-tree delete helper.
 * leaf_page (in)	    : Leaf page.
 * search_key (in)	    : Search key result.
 * leaf_rec (in)	    : Key leaf record.
 * ovfl_vpid (in)	    : VPID of first overflow page.
 */
static int
btree_replace_first_oid_with_ovfl_oid (THREAD_ENTRY * thread_p, BTID_INT * btid, DB_VALUE * key,
				       BTREE_DELETE_HELPER * delete_helper, PAGE_PTR leaf_page,
				       BTREE_SEARCH_KEY_HELPER * search_key, RECDES * leaf_rec, VPID * ovfl_vpid)
{
  int ret = NO_ERROR;		/* Error code. */
  BTREE_OBJECT_INFO last_ovf_object;
  PAGE_PTR ovfl_page = NULL;	/* First overflow page. */
  RECDES ovfl_copy_rec;		/* Overflow record. */
  /* Buffer to store overflow record data. */
  char ovfl_copy_rec_buf[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  int offset_to_ovfl_object = 0;	/* Offset to last object. */
  bool is_sytem_op_started = false;
  bool save_system_op_started = false;

  LOG_LSA prev_lsa;

  /* Recovery data. */
  char rv_undo_data_buffer[BTREE_RV_BUFFER_SIZE + BTREE_MAX_ALIGN];
  char *rv_undo_data = PTR_ALIGN (rv_undo_data_buffer, BTREE_MAX_ALIGN);
  char *rv_undo_data_ptr = NULL;
  int rv_undo_data_length = 0;
  int rv_redo_data_length = 0;

#if !defined (NDEBUG)
  OID save_oid;
#endif /* !NDEBUG */

  /* Assert expected arguments. */
  assert (btid != NULL);
  assert (leaf_page != NULL);
  assert (search_key != NULL && search_key->result == BTREE_KEY_FOUND && search_key->slotid > 0);
  assert (delete_helper != NULL);
  assert (leaf_rec != NULL);
  assert (ovfl_vpid != NULL);
  assert (btree_is_delete_object_purpose (delete_helper->purpose));
  assert (delete_helper->rv_redo_data != NULL);
  assert (delete_helper->leaf_addr.offset != 0 && delete_helper->leaf_addr.pgptr == leaf_page);

  /* Since we cannot leave the leaf record without any objects, we will need to replace it with an overflow object.
   * Logging physical delete, because it has logical undo, cannot work well under system operation. For this reason,
   * the operation will be split into two sub-operations: 1. Swap first object in leaf record with last object in first
   * overflow page. This is done under a system operation that is committed at the end. 2. Remove relocated object from
   * overflow record. */

  /* Get overflow record. */
  ovfl_copy_rec.area_size = DB_PAGESIZE;
  ovfl_copy_rec.data = PTR_ALIGN (ovfl_copy_rec_buf, BTREE_MAX_ALIGN);
  ovfl_page = pgbuf_fix (thread_p, ovfl_vpid, OLD_PAGE, PGBUF_LATCH_WRITE, PGBUF_UNCONDITIONAL_LATCH);
  if (ovfl_page == NULL)
    {
      ASSERT_ERROR_AND_SET (ret);
      goto exit_on_error;
    }

#if !defined (NDEBUG)
  (void) pgbuf_check_page_ptype (thread_p, ovfl_page, PAGE_BTREE);
#endif /* !NDEBUG */

  if (spage_get_record (thread_p, ovfl_page, 1, &ovfl_copy_rec, COPY) != S_SUCCESS)
    {
      assert_release (false);
      ret = ER_FAILED;
      goto exit_on_error;
    }

#if !defined (NDEBUG)
  (void) btree_check_valid_record (thread_p, btid, &ovfl_copy_rec, BTREE_OVERFLOW_NODE, NULL);
#endif /* NDEBUG */
  /* Get last object. */
  ret = btree_record_get_last_object (thread_p, btid, &ovfl_copy_rec, BTREE_OVERFLOW_NODE, 0, &last_ovf_object.oid,
				      &last_ovf_object.class_oid, &last_ovf_object.mvcc_info, &offset_to_ovfl_object);
  if (ret != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto exit_on_error;
    }
  /* Last object obtained. */

  /* Swap operation must use system op. */
  save_system_op_started = delete_helper->is_system_op_started;
  log_sysop_start (thread_p);
  is_sytem_op_started = true;
  delete_helper->is_system_op_started = true;

  /* So let's swap last object with leaf record. */

  /* Get first object complete information. */
#if !defined (NDEBUG)
  COPY_OID (&save_oid, &delete_helper->object_info.oid);
#endif /* !NDEBUG */
  ret =
    btree_leaf_get_first_object (btid, leaf_rec, &delete_helper->object_info.oid, &delete_helper->object_info.class_oid,
				 &delete_helper->object_info.mvcc_info);
  assert (OID_EQ (&save_oid, &delete_helper->object_info.oid));

  /* Replace first object with overflow object. */
  delete_helper->rv_redo_data_ptr = delete_helper->rv_redo_data;
  rv_undo_data_ptr = rv_undo_data;
#if !defined (NDEBUG)
  BTREE_RV_UNDOREDO_SET_DEBUG_INFO (&delete_helper->leaf_addr, delete_helper->rv_redo_data_ptr, rv_undo_data_ptr, btid,
				    BTREE_RV_DEBUG_ID_SWAP_LEAF);
#endif /* !NDEBUG */
  LOG_RV_RECORD_SET_MODIFY_MODE (&delete_helper->leaf_addr, LOG_RV_RECORD_UPDATE_PARTIAL);
  btree_leaf_change_first_object (thread_p, leaf_rec, btid, &last_ovf_object.oid, &last_ovf_object.class_oid,
				  &last_ovf_object.mvcc_info, NULL, &rv_undo_data_ptr,
				  &delete_helper->rv_redo_data_ptr);
  if (spage_update (thread_p, leaf_page, search_key->slotid, leaf_rec) != SP_SUCCESS)
    {
      assert_release (false);
      ret = ER_FAILED;
      goto exit_on_error;
    }

  LSA_COPY (&prev_lsa, pgbuf_get_lsa (leaf_page));
  BTREE_RV_GET_DATA_LENGTH (delete_helper->rv_redo_data_ptr, delete_helper->rv_redo_data, rv_redo_data_length);
  BTREE_RV_GET_DATA_LENGTH (rv_undo_data_ptr, rv_undo_data, rv_undo_data_length);
  log_append_undoredo_data (thread_p, RVBT_RECORD_MODIFY_UNDOREDO, &delete_helper->leaf_addr, rv_undo_data_length,
			    rv_redo_data_length, rv_undo_data, delete_helper->rv_redo_data);
  pgbuf_set_dirty (thread_p, leaf_page, DONT_FREE);

  btree_delete_log (delete_helper, BTREE_DELETE_MODIFY_MSG ("remove first object by replacing with an overflow object")
		    "\t" BTREE_OBJINFO_MSG ("overflow object"),
		    BTREE_DELETE_MODIFY_ARGS (thread_p, delete_helper, leaf_page, &prev_lsa, true, search_key->slotid,
					      leaf_rec->length, btid->sys_btid),
		    BTREE_OBJINFO_AS_ARGS (&last_ovf_object));

  /* Replace object in overflow with object we want to delete. */
  ret =
    btree_overflow_record_replace_object (thread_p, btid, delete_helper, ovfl_page, &ovfl_copy_rec,
					  &offset_to_ovfl_object, &delete_helper->object_info);
  if (ret != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto exit_on_error;
    }

  /* Swap execute successfully. Commit it. */
  /* Commit swap. */
  /* todo: with new system op we can get rid of this swapping hack and use logical undo */
  log_sysop_commit (thread_p);
  is_sytem_op_started = false;
  delete_helper->is_system_op_started = save_system_op_started;

  /* Now remove relocated object from overflow page. */
  /* Reset logging for btree_overflow_remove_object. */
  delete_helper->leaf_addr.offset = search_key->slotid;
  delete_helper->rv_redo_data_ptr = delete_helper->rv_redo_data;
  ret =
    btree_overflow_remove_object (thread_p, key, btid, delete_helper, &ovfl_page, leaf_page, leaf_page, leaf_rec,
				  search_key, offset_to_ovfl_object);
  if (ret != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto exit_on_error;
    }

  if (ovfl_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, ovfl_page);
    }

  return NO_ERROR;

exit_on_error:

  if (delete_helper->purpose == BTREE_OP_DELETE_UNDO_INSERT
      || delete_helper->purpose == BTREE_OP_DELETE_UNDO_INSERT_UNQ_MULTIUPD)
    {
      assert_release (false);
    }
  if (is_sytem_op_started)
    {
      log_sysop_abort (thread_p);
    }
  delete_helper->is_system_op_started = save_system_op_started;
  if (ovfl_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, ovfl_page);
    }

  assert_release (ret != NO_ERROR);
  return ret;
}

/*
 * btree_modify_leaf_ovfl_vpid () - Modify the link to first overflow page in leaf record.
 *
 * return		    : Error code.
 * thread_p (in)	    : Thread entry.
 * btid_int (in)	    : B-tree info.
 * delete_helper (in)	    : B-tree delete helper.
 * leaf_page (in)	    : Leaf page.
 * leaf_record (in)	    : Leaf record.
 * search_key (in)	    : Search key result.
 * next_ovfl_vpid (in)	    : New link to first overflow page.
 */
static int
btree_modify_leaf_ovfl_vpid (THREAD_ENTRY * thread_p, BTID_INT * btid_int, BTREE_DELETE_HELPER * delete_helper,
			     PAGE_PTR leaf_page, RECDES * leaf_record, BTREE_SEARCH_KEY_HELPER * search_key,
			     VPID * next_ovfl_vpid)
{
  char rv_undo_data_buffer[BTREE_RV_BUFFER_SIZE + BTREE_MAX_ALIGN];
  char *rv_undo_data = PTR_ALIGN (rv_undo_data_buffer, BTREE_MAX_ALIGN);
  char *rv_undo_data_ptr = NULL;
  int rv_undo_data_length = 0;
  int rv_redo_data_length = 0;

  LOG_LSA prev_lsa;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (delete_helper != NULL);
  assert (leaf_page != NULL);
  assert (search_key != NULL && search_key->result == BTREE_KEY_FOUND && search_key->slotid > 0);
  assert (leaf_record != NULL);
  assert (next_ovfl_vpid != NULL);
  assert (delete_helper->rv_redo_data != NULL && delete_helper->rv_redo_data_ptr != NULL);
  assert (delete_helper->is_system_op_started);

  /* We need undoredo logging. */
  rv_undo_data_ptr = rv_undo_data;

#if !defined (NDEBUG)
  /* For debugging recovery. */
  BTREE_RV_UNDOREDO_SET_DEBUG_INFO (&delete_helper->leaf_addr, delete_helper->rv_redo_data_ptr, rv_undo_data_ptr,
				    btid_int, BTREE_RV_DEBUG_ID_OVF_LINK);
#endif /* !NDEBUG */
  LOG_RV_RECORD_SET_MODIFY_MODE (&delete_helper->leaf_addr, LOG_RV_RECORD_UPDATE_PARTIAL);

  btree_leaf_record_change_overflow_link (thread_p, btid_int, leaf_record, next_ovfl_vpid, &rv_undo_data_ptr,
					  &delete_helper->rv_redo_data_ptr);

  if (spage_update (thread_p, leaf_page, search_key->slotid, leaf_record) != SP_SUCCESS)
    {
      /* Unexpected. */
      assert_release (false);
      return ER_FAILED;
    }

  /* We need to log previous lsa. */
  LSA_COPY (&prev_lsa, pgbuf_get_lsa (leaf_page));

  /* Add logging. */
  BTREE_RV_GET_DATA_LENGTH (delete_helper->rv_redo_data_ptr, delete_helper->rv_redo_data, rv_redo_data_length);
  BTREE_RV_GET_DATA_LENGTH (rv_undo_data_ptr, rv_undo_data, rv_undo_data_length);
  log_append_undoredo_data (thread_p, RVBT_RECORD_MODIFY_UNDOREDO, &delete_helper->leaf_addr, rv_undo_data_length,
			    rv_redo_data_length, rv_undo_data, delete_helper->rv_redo_data);

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  pgbuf_set_dirty (thread_p, leaf_page, DONT_FREE);

  btree_delete_log (delete_helper, BTREE_DELETE_MODIFY_MSG ("remove object and first overflow page (unknown vpid).")
		    "\t" "new link vpid = %d|%d",
		    BTREE_DELETE_MODIFY_ARGS (thread_p, delete_helper, leaf_page, &prev_lsa, true, search_key->slotid,
					      leaf_record->length, btid_int->sys_btid), VPID_AS_ARGS (next_ovfl_vpid));

  /* Success. */
  return NO_ERROR;
}

/*
 * btree_modify_overflow_link () - Modify next overflow link in overflow page
 *				   header.
 *
 * return		    : Error code.
 * thread_p (in)	    : Thread entry.
 * btid_int (in)	    : B-tree info.
 * delete_helper (in)	    : B-tree delete helper.
 * ovfl_page (in)	    : Overflow page.
 * next_ovfl_vpid (in)	    : New link to next overflow.
 */
static int
btree_modify_overflow_link (THREAD_ENTRY * thread_p, BTID_INT * btid_int, BTREE_DELETE_HELPER * delete_helper,
			    PAGE_PTR ovfl_page, VPID * next_ovfl_vpid)
{
  LOG_DATA_ADDR ovf_addr;
  BTREE_OVERFLOW_HEADER ovf_header_info;
  RECDES overflow_header_record;

  LOG_LSA prev_lsa;

  char rv_undo_data_buffer[BTREE_RV_BUFFER_SIZE + BTREE_MAX_ALIGN];
  char *rv_undo_data = PTR_ALIGN (rv_undo_data_buffer, BTREE_MAX_ALIGN);
  int rv_undo_data_length = 0;
  int rv_redo_data_length;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (delete_helper != NULL);
  assert (ovfl_page != NULL);
  assert (next_ovfl_vpid != NULL);
  assert (delete_helper->rv_redo_data != NULL && delete_helper->rv_redo_data_ptr != NULL);
  assert (delete_helper->is_system_op_started);

  /* Create record with new overflow header info and update page. */

  /* We need undoredo logging. */
  overflow_header_record.area_size = sizeof (BTREE_OVERFLOW_HEADER);
  overflow_header_record.data = rv_undo_data;
  if (spage_get_record (thread_p, ovfl_page, HEADER, &overflow_header_record, COPY) != S_SUCCESS)
    {
      assert_release (false);
      return ER_FAILED;
    }
  rv_undo_data_length = sizeof (BTREE_OVERFLOW_HEADER);

  /* Update overflow header info. */
  VPID_COPY (&ovf_header_info.next_vpid, next_ovfl_vpid);

  /* Create record with new overflow header info and update page. */
  overflow_header_record.data = (char *) &ovf_header_info;
  overflow_header_record.length = sizeof (BTREE_OVERFLOW_HEADER);

  if (spage_update (thread_p, ovfl_page, HEADER, &overflow_header_record) != SP_SUCCESS)
    {
      /* Unexpected. */
      assert_release (false);
      return ER_FAILED;
    }

  /* We need to log previous lsa. */
  LSA_COPY (&prev_lsa, pgbuf_get_lsa (ovfl_page));

  /* Log the change. */
  ovf_addr.offset = HEADER;
  ovf_addr.pgptr = ovfl_page;
  ovf_addr.vfid = &btid_int->sys_btid->vfid;

  /* Redo logging. */
  BTREE_RV_SET_OVERFLOW_NODE (&ovf_addr);
  /* Update entire record. */
  LOG_RV_RECORD_SET_MODIFY_MODE (&ovf_addr, LOG_RV_RECORD_UPDATE_ALL);
  /* Pack record data. */
  memcpy (delete_helper->rv_redo_data_ptr, overflow_header_record.data, overflow_header_record.length);
  delete_helper->rv_redo_data_ptr += overflow_header_record.length;

  /* Add logging. */
  BTREE_RV_GET_DATA_LENGTH (delete_helper->rv_redo_data_ptr, delete_helper->rv_redo_data, rv_redo_data_length);
  log_append_undoredo_data (thread_p, RVBT_RECORD_MODIFY_UNDOREDO, &ovf_addr, rv_undo_data_length,
			    rv_redo_data_length, rv_undo_data, delete_helper->rv_redo_data);

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  pgbuf_set_dirty (thread_p, ovfl_page, DONT_FREE);

  btree_delete_log (delete_helper, BTREE_DELETE_MODIFY_MSG ("remove object and non-first overflow page (unknown vpid)")
		    "\t" "new link vpid = %d|%d",
		    BTREE_DELETE_MODIFY_ARGS (thread_p, delete_helper, ovfl_page, &prev_lsa, false, HEADER,
					      overflow_header_record.length, btid_int->sys_btid),
		    VPID_AS_ARGS (next_ovfl_vpid));

  return NO_ERROR;
}

/*
 * btree_delete_meta_record - delete record for merge
 *
 *   return: (error code)
 *   thread_p(in):
 *   btid(in): B+tree index identifier
 *   page_ptr(in):
 *   slot_id(in):
 *   node_type:
 *
 */
static int
btree_delete_meta_record (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR page_ptr, int slot_id)
{
  int ret = NO_ERROR;
  RECDES rec;
  int dummy_offset;
  bool dummy_clear_key;
  NON_LEAF_REC nleaf_pnt = { {NULL_PAGEID, NULL_VOLID}, 0 };
  LEAF_REC leaf_pnt = { {NULL_PAGEID, NULL_VOLID}, 0 };
  char *recset_data;
  int recset_data_length;
  PGLENGTH log_addr_offset;
  char recset_data_buf[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  BTREE_NODE_HEADER *header = NULL;
  BTREE_NODE_TYPE node_type;

  /* init */
  recset_data = PTR_ALIGN (recset_data_buf, BTREE_MAX_ALIGN);

  assert (slot_id > 0);
  if (spage_get_record (thread_p, page_ptr, slot_id, &rec, PEEK) != S_SUCCESS)
    {
      goto exit_on_error;
    }

  header = btree_get_node_header (thread_p, page_ptr);
  if (header == NULL)
    {
      goto exit_on_error;
    }

  node_type = (header->node_level > 1) ? BTREE_NON_LEAF_NODE : BTREE_LEAF_NODE;

  assert (node_type == BTREE_NON_LEAF_NODE);

  if (node_type == BTREE_NON_LEAF_NODE)
    {
      btree_read_fixed_portion_of_non_leaf_record (&rec, &nleaf_pnt);

      /* prepare undo log record */
      btree_rv_write_log_record (recset_data, &recset_data_length, &rec, BTREE_NON_LEAF_NODE);

      if (nleaf_pnt.key_len < 0)
	{			/* overflow key */
	  /* get the overflow manager to delete the key */
	  ret = btree_delete_overflow_key (thread_p, btid, page_ptr, slot_id, BTREE_NON_LEAF_NODE);
	  if (ret != NO_ERROR)
	    {
	      goto exit_on_error;
	    }
	}
    }
  else
    {
      ret =
	btree_read_record (thread_p, btid, page_ptr, &rec, NULL, &leaf_pnt, BTREE_LEAF_NODE, &dummy_clear_key,
			   &dummy_offset, PEEK_KEY_VALUE, NULL);
      if (ret != NO_ERROR)
	{
	  goto exit_on_error;
	}

      /* prepare undo log record */
      btree_rv_write_log_record (recset_data, &recset_data_length, &rec, BTREE_LEAF_NODE);

      if (leaf_pnt.key_len < 0)
	{			/* overflow key */
	  /* get the overflow manager to delete the key */
	  ret = btree_delete_overflow_key (thread_p, btid, page_ptr, slot_id, BTREE_LEAF_NODE);
	  if (ret != NO_ERROR)
	    {
	      goto exit_on_error;
	    }
	}
    }

  assert (slot_id > 0);
  if (spage_delete (thread_p, page_ptr, slot_id) != slot_id)
    {
      goto exit_on_error;
    }

  /* log the deleted slot_id for undo/redo purposes */
  log_addr_offset = slot_id;
  log_append_undoredo_data2 (thread_p, RVBT_NDRECORD_DEL, &btid->sys_btid->vfid, page_ptr, log_addr_offset,
			     recset_data_length, sizeof (log_addr_offset), recset_data, &log_addr_offset);

  return ret;

exit_on_error:

  return (ret == NO_ERROR && (ret = er_errid ()) == NO_ERROR) ? ER_FAILED : ret;
}

/*
 * btree_write_default_split_info() -
 *   return:
 *   info(in/out):
 */
static void
btree_write_default_split_info (BTREE_NODE_SPLIT_INFO * info)
{
  assert (info != NULL);

  info->pivot = BTREE_SPLIT_DEFAULT_PIVOT;
  info->index = 1;
}

/*
 * btree_merge_root () -
 *   return: NO_ERROR
 *   btid(in): B+tree index identifier
 *   P(in): Page pointer for the root to be merged
 *   Q(in): Page pointer for the root child page to be merged
 *   R(in): Page pointer for the root child page to be merged
 *   P_vpid(in): Page identifier for page P
 *   Q_vpid(in): Page identifier for page Q
 *   R_vpid(in): Page identifier for page R
 *
 * Note: When the root page has only two children (non_leaf)
 * that can be merged together, then they are merged through
 * this specific root merge operation. The main distinction of
 * this routine from the regular merge operation is that in this
 * the content of the two child pages are moved to the root, in
 * order not to change the originial root page. The root can also
 * be a specific non-leaf page, that is, it may have only one key
 * and one child page pointer. In this case, R_id, the page
 * identifier for the page R is NULL_PAGEID. In both cases, the
 * height of the tree is reduced by one, after the merge
 * operation. The two (one) child pages are not deallocated by
 * this routine. Deallocation of these pages are left to the
 * calling routine.
 *
 * Note:  Page Q and Page R contents are not changed by this routine,
 * since these pages will be deallocated by the calling routine.
 */
static int
btree_merge_root (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR P, PAGE_PTR Q, PAGE_PTR R)
{
  int left_cnt, right_cnt;
  RECDES peek_rec;
  int i, j;
  char *recset_data;		/* for recovery purposes */
  int recset_length;		/* for recovery purposes */
  RECSET_HEADER recset_header;	/* for recovery purposes */
  int ret = NO_ERROR;
  char recset_data_buf[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  LOG_DATA_ADDR addr;
  BTREE_ROOT_HEADER *root_header = NULL;
  int Q_end, R_start;
#if !defined(NDEBUG)
  int p_level, q_level, r_level;
#endif
  BTREE_NODE_HEADER *q_header = NULL, *r_header = NULL;

#if !defined(NDEBUG)
  if (prm_get_integer_value (PRM_ID_ER_BTREE_DEBUG) & BTREE_DEBUG_DUMP_SIMPLE)
    {
      VPID *P_vpid = pgbuf_get_vpid_ptr (P);
      VPID *Q_vpid = pgbuf_get_vpid_ptr (Q);
      VPID *R_vpid = pgbuf_get_vpid_ptr (R);

      printf ("btree_merge_root: P{%d, %d}, Q{%d, %d}, R{%d, %d}\n", P_vpid->volid, P_vpid->pageid, Q_vpid->volid,
	      Q_vpid->pageid, R_vpid->volid, R_vpid->pageid);
    }

  p_level = btree_get_node_level (thread_p, P);
  assert (p_level > 2);

  q_level = btree_get_node_level (thread_p, Q);
  assert (q_level > 1);

  r_level = btree_get_node_level (thread_p, R);
  assert (r_level > 1);

  assert (q_level == r_level);
  assert (p_level == q_level + 1);
  assert (p_level == r_level + 1);

  btree_verify_node (thread_p, btid, P);
  btree_verify_node (thread_p, btid, Q);
  btree_verify_node (thread_p, btid, R);
#endif

  /* initializations */
  recset_data = NULL;

  /* log the P record contents for undo purposes, if a crash happens the records of root page P will be inserted back.
   * There is no need for undo logs for pages Q and R, since they are not changed by this routine, because they will be
   * deallocated after a successful merge operation. There is also no need for redo logs for pages Q and R, since these
   * pages will be deallocated by the caller routine. */

  /* for recovery purposes */
  recset_data = PTR_ALIGN (recset_data_buf, BTREE_MAX_ALIGN);
  assert (recset_data != NULL);

  /* remove fence key for merge */
  left_cnt = btree_node_number_of_keys (thread_p, Q);
  right_cnt = btree_node_number_of_keys (thread_p, R);

  Q_end = left_cnt;
  if (left_cnt > 0)
    {
      /* read the last record to check upper fence_key */
      if (spage_get_record (thread_p, Q, left_cnt, &peek_rec, PEEK) != S_SUCCESS)
	{
	  goto exit_on_error;
	}

      /* delete left page upper fence_key before merge */
      if (btree_leaf_is_flaged (&peek_rec, BTREE_LEAF_RECORD_FENCE))
	{
	  assert_release (left_cnt >= 1);
	  assert (!btree_leaf_is_flaged (&peek_rec, BTREE_LEAF_RECORD_OVERFLOW_KEY));
	  Q_end--;
	}
    }

  left_cnt = Q_end;

  R_start = 1;
  if (right_cnt > 0)
    {
      /* read the first record to check lower fence_key */
      if (spage_get_record (thread_p, R, 1, &peek_rec, PEEK) != S_SUCCESS)
	{
	  goto exit_on_error;
	}

      /* delete right page lower fence_key before merge */
      if (btree_leaf_is_flaged (&peek_rec, BTREE_LEAF_RECORD_FENCE))
	{
	  assert_release (right_cnt >= 1);
	  assert (!btree_leaf_is_flaged (&peek_rec, BTREE_LEAF_RECORD_OVERFLOW_KEY));
	  R_start++;
	}
    }

  right_cnt = right_cnt - (R_start + 1);

  /* delete all records in P (should be just 2) */

  /* delete second record */
  ret = btree_delete_meta_record (thread_p, btid, P, 2);
  if (ret != NO_ERROR)
    {
      goto exit_on_error;
    }

  /* delete first record */
  ret = btree_delete_meta_record (thread_p, btid, P, 1);
  if (ret != NO_ERROR)
    {
      goto exit_on_error;
    }

  /* Log the page Q records for undo/redo purposes on page P. */
  recset_header.rec_cnt = left_cnt;
  recset_header.first_slotid = 1;
  ret = btree_rv_util_save_page_records (thread_p, Q, 1, Q_end, 1, recset_data, &recset_length);
  if (ret != NO_ERROR)
    {
      goto exit_on_error;
    }

  /* move content of the left page to the root page */
  for (i = 1; i <= Q_end; i++)
    {
      if (spage_get_record (thread_p, Q, i, &peek_rec, PEEK) != S_SUCCESS
	  || spage_insert_at (thread_p, P, i, &peek_rec) != SP_SUCCESS)
	{
	  if (i > 1)
	    {
	      recset_header.rec_cnt = i - 1;
	      recset_header.first_slotid = 1;
	      log_append_undo_data2 (thread_p, RVBT_INS_PGRECORDS, &btid->sys_btid->vfid, P, -1, sizeof (RECSET_HEADER),
				     &recset_header);
	    }
	  goto exit_on_error;
	}
    }				/* for */

  log_append_undoredo_data2 (thread_p, RVBT_INS_PGRECORDS, &btid->sys_btid->vfid, P, -1, sizeof (RECSET_HEADER),
			     recset_length, &recset_header, recset_data);

  /* Mark page as deallocated by setting its level to -1. This should cover cases when leaf page is re-fixed and used
   * before its deallocation. See BTREE_IS_PAGE_VALID_LEAF. */
  addr.vfid = NULL;
  addr.pgptr = Q;
  addr.offset = 0;
  q_header = btree_get_node_header (thread_p, Q);
  assert (q_header != NULL);
  log_append_undo_data (thread_p, RVBT_MARK_DEALLOC_PAGE, &addr, sizeof (q_header->node_level), &q_header->node_level);
  q_header->node_level = -1;
  pgbuf_set_dirty (thread_p, Q, DONT_FREE);

  /* Log the page R records for undo purposes on page P. */
  right_cnt = btree_node_number_of_keys (thread_p, R);

  recset_header.rec_cnt = right_cnt;
  recset_header.first_slotid = left_cnt + 1;

  ret = btree_rv_util_save_page_records (thread_p, R, R_start, right_cnt, left_cnt + 1, recset_data, &recset_length);
  if (ret != NO_ERROR)
    {
      goto exit_on_error;
    }

  /* move content of the right page to the root page */
  assert (R_start > 0);
  for (i = R_start, j = 1; j <= right_cnt; i++, j++)
    {
      assert (left_cnt + j > 0);
      if (spage_get_record (thread_p, R, i, &peek_rec, PEEK) != S_SUCCESS
	  || spage_insert_at (thread_p, P, left_cnt + j, &peek_rec) != SP_SUCCESS)
	{
	  if (j > 1)
	    {
	      recset_header.rec_cnt = j - 1;
	      recset_header.first_slotid = left_cnt + 1;
	      log_append_undo_data2 (thread_p, RVBT_INS_PGRECORDS, &btid->sys_btid->vfid, P, -1, sizeof (RECSET_HEADER),
				     &recset_header);
	    }
	  goto exit_on_error;
	}
    }				/* for */

  log_append_undoredo_data2 (thread_p, RVBT_INS_PGRECORDS, &btid->sys_btid->vfid, P, -1, sizeof (RECSET_HEADER),
			     recset_length, &recset_header, recset_data);

  /* Mark page as deallocated by setting its level to -1. This should cover cases when leaf page is re-fixed and used
   * before its deallocation. See BTREE_IS_PAGE_VALID_LEAF. */
  addr.vfid = NULL;
  addr.pgptr = R;
  addr.offset = 0;
  r_header = btree_get_node_header (thread_p, R);
  assert (r_header != NULL);
  log_append_undo_data (thread_p, RVBT_MARK_DEALLOC_PAGE, &addr, sizeof (r_header->node_level), &r_header->node_level);
  r_header->node_level = -1;
  pgbuf_set_dirty (thread_p, R, DONT_FREE);

  /* update root page */
  root_header = btree_get_root_header (thread_p, P);
  if (root_header == NULL)
    {
      goto exit_on_error;
    }

  btree_node_header_undo_log (thread_p, &btid->sys_btid->vfid, P);

  VPID_SET_NULL (&root_header->node.prev_vpid);
  VPID_SET_NULL (&root_header->node.next_vpid);
  btree_write_default_split_info (&(root_header->node.split_info));
  root_header->node.node_level--;
  assert_release (root_header->node.node_level > 1);

  btree_node_header_redo_log (thread_p, &btid->sys_btid->vfid, P);

#if !defined(NDEBUG)
  {
    BTREE_NODE_HEADER *qheader = NULL, *rheader = NULL;

    qheader = btree_get_node_header (thread_p, Q);
    assert (qheader != NULL);

    rheader = btree_get_node_header (thread_p, R);
    assert (rheader != NULL);

    assert (root_header->node.max_key_len == MAX (qheader->max_key_len, rheader->max_key_len));
  }
#endif

  pgbuf_set_dirty (thread_p, P, DONT_FREE);

  perfmon_inc_stat (thread_p, PSTAT_BT_NUM_MERGES);

#if !defined(NDEBUG)
  btree_verify_node (thread_p, btid, P);
#endif

  return ret;

exit_on_error:

  return (ret == NO_ERROR && (ret = er_errid ()) == NO_ERROR) ? ER_FAILED : ret;
}

/*
 * btree_merge_node () -
 *   return: NO_ERROR
 *   btid(in): The B+tree index identifier
 *   P(in): Page pointer for the parent page of page Q
 *   Q(in): Page pointer for the child page of P that will be merged
 *   R(in): Page pointer for the left or right sibling of page Q
 *   next_page(in):
 *   P_vpid(in): Page identifier for page P
 *   Q_vpid(in): Page identifier for page Q
 *   R_vpid(in): Page identifier for page R
 *   p_slot_id(in): The slot of parent page P which points page to be merged (right page)
 *   child_vpid(in): Child page identifier to be followed, Q or R.
 *
 * Note: Page Q is merged with page R which may be its left or right sibling. Depending on the efficiency of
 * the merge operation the merge operation may take place on Page Q or on page R to reduce the size of the data
 * that will moved. After the merge operation either page Q or page R becomes ready for deallocation.
 * Deallocation is left to the calling routine.
 *
 * Note: The page which will be deallocated by the caller after a successful merge operation is not changed
 * by this routine.
 */
static int
btree_merge_node (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR P, PAGE_PTR left_pg, PAGE_PTR right_pg,
		  INT16 p_slot_id, VPID * child_vpid, BTREE_MERGE_STATUS status)
{
  int left_cnt, right_cnt;
  int i, ret = NO_ERROR;
  VPID *left_vpid = pgbuf_get_vpid_ptr (left_pg);

  /* record decoding */
  RECDES peek_rec;
  NON_LEAF_REC nleaf_pnt;
  LEAF_REC leaf_pnt;
  int offset;

  /* recovery */
  LOG_DATA_ADDR addr;
  char *recset_data;		/* for recovery purposes */
  int recset_length;		/* for recovery purposes */
  char recset_data_buf[IO_MAX_PAGE_SIZE + MAX_ALIGNMENT];

  /* merge & recompress buff */
  int left_prefix, right_prefix;
  int left_used, right_used, total_size;
  RECDES rec[MAX_LEAF_REC_NUM];
  int rec_idx;
  char merge_buf[(IO_MAX_PAGE_SIZE * 4) + MAX_ALIGNMENT];
  char *merge_buf_ptr = merge_buf;
  int merge_buf_size = sizeof (merge_buf);
  int merge_idx = 0;

  PGSLOTID sp_id;

  PAGE_PTR next_page_after_merged = NULL;

  BTREE_NODE_HEADER *left_header = NULL;
  BTREE_NODE_HEADER *right_header = NULL;

  /* Remember first and last slot id's for non-fence records in both left and right nodes. */
  int left_first_non_fence_slotid = NULL_SLOTID;
  int left_last_non_fence_slotid = NULL_SLOTID;
  int right_first_non_fence_slotid = NULL_SLOTID;
  int right_last_non_fence_slotid = NULL_SLOTID;

  DB_VALUE left_fence_key;
  DB_VALUE right_fence_key;
  bool left_fence_key_clear = false;
  bool right_fence_key_clear = false;

  bool merged_has_lower_fence = false;
  bool merged_has_upper_fence = false;
  RECDES merged_upper_fence_record;
  char merged_upper_fence_record_buffer[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  int merged_prefix = 0;

#if !defined(NDEBUG)
  if (prm_get_integer_value (PRM_ID_ER_BTREE_DEBUG) & BTREE_DEBUG_DUMP_SIMPLE)
    {
      VPID *P_vpid = pgbuf_get_vpid_ptr (P);
      VPID *right_vpid = pgbuf_get_vpid_ptr (right_pg);

      printf ("btree_merge_node: P{%d, %d}, Q{%d, %d}, R{%d, %d}\n", P_vpid->volid, P_vpid->pageid, left_vpid->volid,
	      left_vpid->pageid, right_vpid->volid, right_vpid->pageid);
    }
#endif

#if !defined(NDEBUG)
  btree_verify_node (thread_p, btid, P);
  btree_verify_node (thread_p, btid, left_pg);
#endif

  /***********************************************************
   ***  Merging two b-tree nodes (leaf or non-leaf).
   ***  All records from right page must be moved to the left page.
   ***  Next link in merged page and previous link in next page must be
   ***  updated.
   ***  If leaf nodes are merged and if they have fences, records may need
   ***  to be decompressed and compressed again.
   ***********************************************************/

  /***********************************************************
   ***  STEP 0: initializations, save undo image of left
   *** 		calculate uncompress size & memory alloc
   ***********************************************************/
  /* initializations */
  VPID_SET_NULL (child_vpid);
  recset_data = PTR_ALIGN (recset_data_buf, MAX_ALIGNMENT);

  left_cnt = btree_node_number_of_keys (thread_p, left_pg);
  right_cnt = btree_node_number_of_keys (thread_p, right_pg);

  left_header = btree_get_node_header (thread_p, left_pg);
  right_header = btree_get_node_header (thread_p, right_pg);
  assert (left_header != NULL && right_header != NULL);

  btree_init_temp_key_value (&left_fence_key_clear, &left_fence_key);
  btree_init_temp_key_value (&right_fence_key_clear, &right_fence_key);

  left_used = btree_node_size_uncompressed (thread_p, btid, left_pg);
  if (left_used < 0)
    {
      ASSERT_ERROR ();
      return left_used;
    }
  left_prefix = btree_node_common_prefix (thread_p, btid, left_pg);
  if (left_prefix < 0)
    {
      ASSERT_ERROR ();
      return left_prefix;
    }

  right_used = btree_node_size_uncompressed (thread_p, btid, right_pg);
  if (right_used < 0)
    {
      ASSERT_ERROR ();
      return right_used;
    }
  right_prefix = btree_node_common_prefix (thread_p, btid, right_pg);
  if (right_prefix < 0)
    {
      ASSERT_ERROR ();
      return right_prefix;
    }

  total_size = left_used + right_used + MAX_MERGE_ALIGN_WASTE;
  if (total_size > (int) sizeof (merge_buf))
    {
      merge_buf_size = total_size;
      merge_buf_ptr = (char *) db_private_alloc (thread_p, merge_buf_size);
    }

  /***********************************************************
   ***  STEP 1: check current fences and new fences
   ***********************************************************/
  /* Handle left page fences. NOTE: If left page has only one record and that is fence, it is considered upper fence. */
  /* Left lower fence. */
  if (left_cnt >= 2 && btree_is_fence_key (left_pg, 1))
    {
      assert (left_header->node_level == 1);
      assert (!VPID_ISNULL (&left_header->prev_vpid));

      /* Non-fence records start from index 2. */
      left_first_non_fence_slotid = 2;

      /* This is used as lower fence for merged page. */
      merged_has_lower_fence = true;

      /* Lower fence will just be kept in left page. */
      /* Read lower fence value. */
      if (spage_get_record (thread_p, left_pg, 1, &peek_rec, PEEK) != S_SUCCESS)
	{
	  assert_release (false);
	  ret = ER_FAILED;
	  goto exit_on_error;
	}
      ret =
	btree_read_record_without_decompression (thread_p, btid, &peek_rec, &left_fence_key, &leaf_pnt, BTREE_LEAF_NODE,
						 &left_fence_key_clear, &offset, PEEK_KEY_VALUE);
      if (ret != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto exit_on_error;
	}
    }
  else
    {
      /* No left lower fence. */
      left_first_non_fence_slotid = 1;
    }

  /* Left upper fence - it must be discarded */
  left_last_non_fence_slotid = (left_cnt >= 1 && btree_is_fence_key (left_pg, left_cnt)) ? (left_cnt - 1) : left_cnt;

  /* Handle right page fences. NOTE: If right page has only one record and that is fence, it is considered lower fence. */
  /* Right lower fence - it must be discarded */
  right_first_non_fence_slotid = (right_cnt >= 1 && btree_is_fence_key (right_pg, 1)) ? 2 : 1;

  /* Right upper fence. */
  if (right_cnt >= 2 && btree_is_fence_key (right_pg, right_cnt))
    {
      assert (right_header->node_level == 1);
      assert (!VPID_ISNULL (&right_header->next_vpid));

      /* Non-fence records stop before this. */
      right_last_non_fence_slotid = right_cnt - 1;

      /* This will be upper fence for merged page too. */
      merged_has_upper_fence = true;

      /* Copy fence record from right page (to be later moved to left page). */
      merged_upper_fence_record.area_size = DB_PAGESIZE;
      merged_upper_fence_record.data = PTR_ALIGN (merged_upper_fence_record_buffer, BTREE_MAX_ALIGN);
      if (spage_get_record (thread_p, right_pg, right_cnt, &merged_upper_fence_record, COPY) != S_SUCCESS)
	{
	  assert_release (false);
	  ret = ER_FAILED;
	  goto exit_on_error;
	}
      ret =
	btree_read_record_without_decompression (thread_p, btid, &merged_upper_fence_record, &right_fence_key,
						 &leaf_pnt, BTREE_LEAF_NODE, &right_fence_key_clear, &offset,
						 PEEK_KEY_VALUE);
      if (ret != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto exit_on_error;
	}
    }
  else
    {
      right_last_non_fence_slotid = right_cnt;
    }

  /* Merged page prefix. */
  /* Prefix after merge cannot be better than left or right page prefix. */
  if (TP_DOMAIN_TYPE (btid->key_type) == DB_TYPE_MIDXKEY && merged_has_lower_fence && merged_has_upper_fence)
    {
      /* Get common prefix of left_fence_key and right_fence_key. */
      assert (!DB_IS_NULL (&left_fence_key));
      assert (!DB_IS_NULL (&right_fence_key));
      merged_prefix = pr_midxkey_common_prefix (&left_fence_key, &right_fence_key);
    }

  /***********************************************************
   ***  STEP 2: copy (or keep) left.
   ***  Copy if common prefix has changed (to compress records
   ***  again).
   ***  Keep records as they are if common prefix didn't change.
   ***********************************************************/
  rec_idx = -1;
  merge_idx = 0;

/* NEXT_MERGE_RECORD - advance in rec array and prepare new record descriptor
 */
#define NEXT_MERGE_RECORD() \
  do \
    { \
      /* If not first record, add last record length to merge_idx. */ \
      merge_idx += (rec_idx >= 0) ? rec[rec_idx].length : 0; \
      /* Increment record index. */ \
      rec_idx++; \
      /* Set aligned record data pointer. */ \
      rec[rec_idx].data = \
	PTR_ALIGN (&merge_buf_ptr[merge_idx], BTREE_MAX_ALIGN); \
      /* Update merge_idx. */ \
      merge_idx = CAST_BUFLEN (rec[rec_idx].data - merge_buf_ptr); \
      /* Set area size. */ \
      rec[rec_idx].area_size = merge_buf_size - merge_idx; \
      rec[rec_idx].type = REC_HOME; \
    } \
  while (false)

  if (merged_prefix != left_prefix)
    {
      /* Left page records must be recompressed. */
      /* Copy current records in rec array, update them considering new fences and we will later add them back in page. */
      for (i = left_first_non_fence_slotid; i <= left_last_non_fence_slotid; i++)
	{
	  NEXT_MERGE_RECORD ();

	  assert (!btree_is_fence_key (left_pg, i));
	  if (spage_get_record (thread_p, left_pg, i, &rec[rec_idx], COPY) != S_SUCCESS)
	    {
	      assert_release (false);
	      ret = ER_FAILED;
	      goto exit_on_error;
	    }
	  ret = btree_recompress_record (thread_p, btid, &rec[rec_idx], &left_fence_key, left_prefix, merged_prefix);
	  if (ret != NO_ERROR)
	    {
	      ASSERT_ERROR ();
	      goto exit_on_error;
	    }
	}
    }

  /* Left fence key no longer required. */
  btree_clear_key_value (&left_fence_key_clear, &left_fence_key);

  /***********************************************************
   ***  STEP 3: copy right page.
   ***********************************************************/
  for (i = right_first_non_fence_slotid; i <= right_last_non_fence_slotid; i++)
    {
      NEXT_MERGE_RECORD ();

      assert (!btree_is_fence_key (right_pg, i));
      if (spage_get_record (thread_p, right_pg, i, &rec[rec_idx], COPY) != S_SUCCESS)
	{
	  assert_release (false);
	  ret = ER_FAILED;
	  goto exit_on_error;
	}
      ret = btree_recompress_record (thread_p, btid, &rec[rec_idx], &right_fence_key, right_prefix, merged_prefix);
      if (ret != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto exit_on_error;
	}
    }

  /* Right fence key no longer required. */
  btree_clear_key_value (&right_fence_key_clear, &right_fence_key);

  /* Increment rec_idx one last time. */
  rec_idx++;

/* NEXT_MERGE_RECORD definition no longer required. */
#undef NEXT_MERGE_RECORD


  /***********************************************************
   ***  STEP 4: Save left page (undo logging) before changing it.
   ***********************************************************/
  /* add undo logging for left_pg */
  log_append_undo_data2 (thread_p, RVBT_COPYPAGE, &btid->sys_btid->vfid, left_pg, -1, DB_PAGESIZE, left_pg);

  /***********************************************************
   ***  STEP 5: remove records from left page.
   ***********************************************************/
  /* Remove upper fence (if there is one). */
  if (left_cnt > left_last_non_fence_slotid)
    {
      assert (left_cnt == left_last_non_fence_slotid + 1);
      assert (btree_is_fence_key (left_pg, left_cnt));
      if (spage_delete (thread_p, left_pg, left_cnt) != left_cnt)
	{
	  assert_release (false);
	  ret = ER_FAILED;
	  goto exit_on_error;
	}
    }
  /* Remove non-fence records. */
  if (merged_prefix != left_prefix)
    {
      /* All records from left have changed. Remove existing records. Keep lower fence key. */
      for (i = left_last_non_fence_slotid; i >= left_first_non_fence_slotid; i--)
	{
	  assert (i > 0);
	  assert (!btree_is_fence_key (left_pg, i));
	  if (spage_delete (thread_p, left_pg, i) != i)
	    {
	      assert_release (false);
	      ret = ER_FAILED;
	      goto exit_on_error;
	    }
	}
    }
  else
    {
      /* Records need no changes. They have not been saved in rec array. They are kept as they are. */
    }

  /***********************************************************
   ***  STEP 6: append rec array.
   ***********************************************************/
  for (i = 0; i < rec_idx; i++)
    {
      if (spage_insert (thread_p, left_pg, &rec[i], &sp_id) != SP_SUCCESS)
	{
	  assert_release (false);
	  ret = ER_FAILED;
	  goto exit_on_error;
	}

      assert (sp_id > 0);
    }

  /***********************************************************
   ***  STEP 7: append upper fence.
   ***********************************************************/
  if (merged_has_upper_fence)
    {
      if (spage_insert (thread_p, left_pg, &merged_upper_fence_record, &sp_id) != SP_SUCCESS)
	{
	  assert_release (false);
	  ret = ER_FAILED;
	  goto exit_on_error;
	}
    }

  /***********************************************************
   ***  STEP 8: update child link of page P
   ***********************************************************/
  /* get and log the old node record to be deleted for undo purposes */
  assert (p_slot_id > 0);
  if (spage_get_record (thread_p, P, p_slot_id, &peek_rec, PEEK) != S_SUCCESS)
    {
      assert_release (false);
      ret = ER_FAILED;
      goto exit_on_error;
    }

  btree_read_fixed_portion_of_non_leaf_record (&peek_rec, &nleaf_pnt);

  if (nleaf_pnt.key_len < 0)
    {				/* overflow key */
      /* get the overflow manager to delete the key */
      ret = btree_delete_overflow_key (thread_p, btid, P, p_slot_id, BTREE_NON_LEAF_NODE);
      if (ret != NO_ERROR)
	{
	  assert_release (false);
	  goto exit_on_error;
	}
    }

  btree_rv_write_log_record (recset_data, &recset_length, &peek_rec, BTREE_NON_LEAF_NODE);
  log_append_undoredo_data2 (thread_p, RVBT_NDRECORD_DEL, &btid->sys_btid->vfid, P, p_slot_id, recset_length,
			     sizeof (p_slot_id), recset_data, &p_slot_id);
  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  assert (p_slot_id > 0);
  if (spage_delete (thread_p, P, p_slot_id) != p_slot_id)
    {
      assert_release (false);
      ret = ER_FAILED;
      goto exit_on_error;
    }

  pgbuf_set_dirty (thread_p, P, DONT_FREE);

  *child_vpid = *left_vpid;

  /***********************************************************
   ***  STEP 9: update left page header info
   ***          write redo log for left
   ***********************************************************/
  VPID_COPY (&left_header->next_vpid, &right_header->next_vpid);
  left_header->max_key_len = MAX (left_header->max_key_len, right_header->max_key_len);
  btree_write_default_split_info (&(left_header->split_info));

  /***********************************************************
   ***  STEP 10: log (redo) changes of left page.
   ***********************************************************/
  /* add redo logging for left_pg */
  log_append_redo_data2 (thread_p, RVBT_COPYPAGE, &btid->sys_btid->vfid, left_pg, -1, DB_PAGESIZE, left_pg);
  pgbuf_set_dirty (thread_p, left_pg, DONT_FREE);

  /***********************************************************
   ***  STEP 11: Mark page as deallocated by setting its level to -1.
   ***           This should cover cases when leaf page is re-fixed and used
   ***           before its deallocation.
   ***           See BTREE_IS_PAGE_VALID_LEAF.
   ***********************************************************/
  addr.vfid = NULL;
  addr.pgptr = right_pg;
  addr.offset = 0;
  assert (right_header != NULL);
  log_append_undo_data (thread_p, RVBT_MARK_DEALLOC_PAGE, &addr, sizeof (right_header->node_level),
			&right_header->node_level);
  right_header->node_level = -1;
  pgbuf_set_dirty (thread_p, right_pg, DONT_FREE);

  perfmon_inc_stat (thread_p, PSTAT_BT_NUM_MERGES);

#if !defined(NDEBUG)
  btree_verify_node (thread_p, btid, P);
  btree_verify_node (thread_p, btid, left_pg);
#endif

  /***********************************************************
   ***  STEP 12: update link for next leaf node after the
   ***		 merged nodes to point to the left page.
   ***********************************************************/
  next_page_after_merged = btree_get_next_page (thread_p, left_pg);
  if (next_page_after_merged != NULL)
    {
      /* Update previous link. */
#if !defined (NDEBUG)
      (void) pgbuf_check_page_ptype (thread_p, next_page_after_merged, PAGE_BTREE);
#endif /* !NDEBUG */
      ret = btree_set_vpid_previous_vpid (thread_p, btid, next_page_after_merged, left_vpid);
      pgbuf_unfix_and_init (thread_p, next_page_after_merged);
      if (ret != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto exit_on_error;
	}
    }

  if (merge_buf_ptr != merge_buf)
    {
      db_private_free_and_init (thread_p, merge_buf_ptr);
    }

  /* Success. */
  return NO_ERROR;

exit_on_error:

  assert_release (ret != NO_ERROR);

  if (merge_buf_ptr != merge_buf)
    {
      db_private_free_and_init (thread_p, merge_buf_ptr);
    }

  btree_clear_key_value (&left_fence_key_clear, &left_fence_key);
  btree_clear_key_value (&right_fence_key_clear, &right_fence_key);

  return ret;
}

/*
 * btree_node_size_uncompressed -
 *
 *   return:
 *   thread_p(in):
 *   btid(in):
 *   page_ptr(in):
 *
 */
static int
btree_node_size_uncompressed (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR page_ptr)
{
  int used_size, key_cnt = 0, prefix, prefix_len, offset;
  RECDES rec;
  DB_VALUE key;
  bool clear_key = false;
  DB_MIDXKEY *midx_key = NULL;
  LEAF_REC leaf_pnt;
  int error;

  btree_init_temp_key_value (&clear_key, &key);

  used_size = DB_PAGESIZE - spage_get_free_space (thread_p, page_ptr);

  prefix = btree_node_common_prefix (thread_p, btid, page_ptr);
  if (prefix > 0)
    {
#if !defined(NDEBUG)
      BTREE_NODE_HEADER *header = NULL;

      header = btree_get_node_header (thread_p, page_ptr);

      assert (header != NULL);
      assert (header->node_level == 1);	/* BTREE_LEAF_NODE */
#endif

      error = spage_get_record (thread_p, page_ptr, 1, &rec, PEEK);
      if (error != S_SUCCESS)
	{
	  assert (false);
	  return error;
	}

      error =
	btree_read_record_without_decompression (thread_p, btid, &rec, &key, &leaf_pnt, BTREE_LEAF_NODE, &clear_key,
						 &offset, PEEK_KEY_VALUE);
      if (error != NO_ERROR)
	{
	  return error;
	}

      assert (!btree_leaf_is_flaged (&rec, BTREE_LEAF_RECORD_OVERFLOW_KEY));
      assert (btree_leaf_is_flaged (&rec, BTREE_LEAF_RECORD_FENCE));
      assert (DB_VALUE_TYPE (&key) == DB_TYPE_MIDXKEY);

      midx_key = db_get_midxkey (&key);

      btree_clear_key_value (&clear_key, &key);

      prefix_len = pr_midxkey_get_element_offset (midx_key, prefix);

      /* at here, we can not calculate aligned size of uncompressed rec. alignment is already included in
       * CAN_MERGE_WHEN_EMPTY */
      key_cnt = btree_node_number_of_keys (thread_p, page_ptr);
      used_size += (key_cnt - 2) * prefix_len;
    }
  else if (prefix < 0)
    {
      return prefix;
    }

  return used_size;
}

/*
 * btree_node_mergeable -
 *
 *   return:
 *   thread_p(in):
 *   btid(in):
 *   L_page(in):
 *   R_page(in):
 *
 */
static BTREE_MERGE_STATUS
btree_node_mergeable (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR L_page, PAGE_PTR R_page)
{
  BTREE_NODE_HEADER *l_header = NULL, *r_header = NULL;
  BTREE_NODE_TYPE l_node_type, r_node_type;
  int L_used, R_used, L_cnt, R_cnt;
  int L_non_fence_cnt = 0, R_non_fence_cnt = 0;

  /* case 1 : one of page is empty. a page is considered empty if it has no keys or only fence keys. merge will be
   * forced. */

  L_cnt = btree_node_number_of_keys (thread_p, L_page);
  R_cnt = btree_node_number_of_keys (thread_p, R_page);

  if (L_cnt == 0)
    {
      /* Left page is completely empty. */
      return BTREE_MERGE_FORCE;
    }
  L_non_fence_cnt = L_cnt;
  if (btree_is_fence_key (L_page, 1))
    {
      L_non_fence_cnt--;
    }
  if (L_cnt > 1 && btree_is_fence_key (L_page, L_cnt))
    {
      L_non_fence_cnt--;
    }
  if (L_non_fence_cnt == 0)
    {
      /* Left page has only fence keys. If uncompressed right page fits a page, we should merge pages. */
      R_used = btree_node_size_uncompressed (thread_p, btid, R_page);
      if (R_used + FORCE_MERGE_WHEN_EMPTY < DB_PAGESIZE)
	{
	  return BTREE_MERGE_FORCE;
	}
      else if (R_used + CAN_MERGE_WHEN_EMPTY < DB_PAGESIZE)
	{
	  return BTREE_MERGE_TRY;
	}
      /* Uncompressed right page is too big. */
      return BTREE_MERGE_NO;
    }

  if (R_cnt == 0)
    {
      /* Right page is completely empty. */
      return BTREE_MERGE_FORCE;
    }
  R_non_fence_cnt = R_cnt;
  if (btree_is_fence_key (R_page, 1))
    {
      R_non_fence_cnt--;
    }
  if (R_cnt > 1 && btree_is_fence_key (R_page, R_cnt))
    {
      R_non_fence_cnt--;
    }
  if (R_non_fence_cnt == 0)
    {
      /* Right page has only fence keys. If uncompressed left page fits a page, we should merge pages. */
      L_used = btree_node_size_uncompressed (thread_p, btid, L_page);
      if (L_used + FORCE_MERGE_WHEN_EMPTY < DB_PAGESIZE)
	{
	  return BTREE_MERGE_FORCE;
	}
      else if (L_used + CAN_MERGE_WHEN_EMPTY < DB_PAGESIZE)
	{
	  return BTREE_MERGE_TRY;
	}
      /* Uncompressed right page is too big. */
      return BTREE_MERGE_NO;
    }

  /* case 2: each page has only one key. merge will be forced. */

  if (L_non_fence_cnt == 1 && R_non_fence_cnt == 1)
    {
      return BTREE_MERGE_FORCE;
    }

  /* case 3 : size */

  l_header = btree_get_node_header (thread_p, L_page);
  if (l_header == NULL)
    {
      assert_release (false);
      return BTREE_MERGE_NO;
    }

  r_header = btree_get_node_header (thread_p, R_page);
  if (r_header == NULL)
    {
      assert_release (false);
      return BTREE_MERGE_NO;
    }

  l_node_type = (l_header->node_level > 1) ? BTREE_NON_LEAF_NODE : BTREE_LEAF_NODE;
  r_node_type = (r_header->node_level > 1) ? BTREE_NON_LEAF_NODE : BTREE_LEAF_NODE;

  assert (l_node_type == r_node_type);

  L_used = DB_PAGESIZE - spage_get_free_space (thread_p, L_page);
  R_used = DB_PAGESIZE - spage_get_free_space (thread_p, R_page);
  if (L_used + R_used + CAN_MERGE_WHEN_EMPTY < DB_PAGESIZE)
    {
      /* check uncompressed size */
      if (l_node_type == BTREE_LEAF_NODE)
	{
	  /* recalculate uncompressed left size */
	  L_used = btree_node_size_uncompressed (thread_p, btid, L_page);
	  if (L_used < 0)
	    {
	      return BTREE_MERGE_NO;
	    }

	  if (L_used + R_used + CAN_MERGE_WHEN_EMPTY >= DB_PAGESIZE)
	    {
	      return BTREE_MERGE_NO;
	    }

	  /* recalculate uncompressed right size */
	  R_used = btree_node_size_uncompressed (thread_p, btid, R_page);

	  if (L_used + R_used + CAN_MERGE_WHEN_EMPTY >= DB_PAGESIZE)
	    {
	      /* can recalculate used size after recompress with new fence key (can return true in some cases) but
	       * split and merge will be done more frequently (trade off of space and SMO) */
	      return BTREE_MERGE_NO;
	    }
	}

      if (L_used + R_used + FORCE_MERGE_WHEN_EMPTY < DB_PAGESIZE)
	{
	  /* Merge must be executed. */
	  return BTREE_MERGE_FORCE;
	}

      /* Merge can be executed. If promotions fail, it will be skipped. */
      return BTREE_MERGE_TRY;
    }

  return BTREE_MERGE_NO;
}

/*
 * btree_key_append_object_as_new_overflow () - Insert object into a new overflow page.
 *
 * return		     : Error code.
 * thread_p (in)	     : Thread entry.
 * btid_int (in)	     : B-tree info.
 * leaf_page (in)	     : Leaf page.
 * object_info (in)	     : Object & info.
 * insert_helper (in)	     : B-tree insert helper.
 * search_key (in)	     : Search key result.
 * leaf_rec (in)	     : Leaf record.
 * first_ovfl_vpid (in)	     : VPID of first overflow.
 */
static int
btree_key_append_object_as_new_overflow (THREAD_ENTRY * thread_p, BTID_INT * btid_int, PAGE_PTR leaf_page,
					 BTREE_OBJECT_INFO * object_info, BTREE_INSERT_HELPER * insert_helper,
					 BTREE_SEARCH_KEY_HELPER * search_key, RECDES * leaf_rec,
					 VPID * first_ovfl_vpid)
{
  int ret = NO_ERROR;
  VPID ovfl_vpid;
  PAGE_PTR ovfl_page = NULL;
  char rv_undo_data_buffer[BTREE_RV_BUFFER_SIZE + BTREE_MAX_ALIGN];
  char *rv_undo_data = PTR_ALIGN (rv_undo_data_buffer, BTREE_MAX_ALIGN);
  char *rv_undo_data_ptr = NULL;
  int rv_undo_data_length = 0;
  int rv_redo_data_length = 0;
  bool save_sysop_started = false;

  LOG_LSA prev_lsa;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (leaf_page != NULL);
  assert (object_info != NULL);
  assert (insert_helper != NULL);
  assert (search_key != NULL);
  assert (leaf_rec != NULL);
  assert (first_ovfl_vpid != NULL);
  assert (insert_helper->rv_redo_data != NULL && insert_helper->rv_redo_data_ptr != NULL);
  assert (btree_is_insert_object_purpose (insert_helper->purpose));

  save_sysop_started = insert_helper->is_system_op_started;
  if (!insert_helper->is_system_op_started)
    {
      log_sysop_start (thread_p);
      insert_helper->is_system_op_started = true;
    }
  assert (log_check_system_op_is_started (thread_p));
  rv_undo_data_ptr = rv_undo_data;

  /* Create overflow page. */
  /* Note that this page may be leaked if server crashes before changing the link in leaf page. */
  ret =
    btree_start_overflow_page (thread_p, btid_int, object_info, first_ovfl_vpid, pgbuf_get_vpid_ptr (leaf_page),
			       &ovfl_vpid, &ovfl_page);
  if (ret != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto error;
    }

#if !defined (NDEBUG)
  BTREE_RV_UNDOREDO_SET_DEBUG_INFO (&insert_helper->leaf_addr, insert_helper->rv_redo_data_ptr, rv_undo_data_ptr,
				    btid_int, BTREE_RV_DEBUG_ID_INS_NEW_OVF);
#endif /* !NDEBUG */
  LOG_RV_RECORD_SET_MODIFY_MODE (&insert_helper->leaf_addr, LOG_RV_RECORD_UPDATE_PARTIAL);

  /* Update link in leaf record. */
  btree_leaf_record_change_overflow_link (thread_p, btid_int, leaf_rec, &ovfl_vpid, &rv_undo_data_ptr,
					  &insert_helper->rv_redo_data_ptr);

  /* Update record in page. */
  if (spage_update (thread_p, leaf_page, search_key->slotid, leaf_rec) != SP_SUCCESS)
    {
      assert_release (false);
      ret = ER_FAILED;
      goto error;
    }

  LSA_COPY (&prev_lsa, pgbuf_get_lsa (leaf_page));

  /* Logging changes on leaf. */
  BTREE_RV_GET_DATA_LENGTH (insert_helper->rv_redo_data_ptr, insert_helper->rv_redo_data, rv_redo_data_length);
  assert (rv_undo_data_ptr != NULL);
  /* Undo redo the operation. */
  /* Undo is physical in this case. */
  BTREE_RV_GET_DATA_LENGTH (rv_undo_data_ptr, rv_undo_data, rv_undo_data_length);
  log_append_undoredo_data (thread_p, RVBT_RECORD_MODIFY_UNDOREDO, &insert_helper->leaf_addr, rv_undo_data_length,
			    rv_redo_data_length, rv_undo_data, insert_helper->rv_redo_data);

  if (!save_sysop_started)
    {
      /* End system operation. */
      btree_insert_sysop_end (thread_p, insert_helper);
    }

  btree_insert_log (insert_helper,
		    BTREE_INSERT_MODIFY_MSG ("create new overflow") "\t" PGBUF_PAGE_STATE_MSG ("new overflow page"),
		    BTREE_INSERT_MODIFY_ARGS (thread_p, insert_helper, insert_helper->leaf_addr.pgptr, &prev_lsa, true,
					      search_key->slotid, leaf_rec->length, btid_int->sys_btid),
		    PGBUF_PAGE_STATE_ARGS (ovfl_page));

  /* Mark pages dirty and free overflow page. */
  pgbuf_set_dirty (thread_p, ovfl_page, FREE);
  pgbuf_set_dirty (thread_p, leaf_page, DONT_FREE);

  return NO_ERROR;

error:
  if (!save_sysop_started && insert_helper->is_system_op_started)
    {
      /* This might be a problem since compensate was not successfully executed. */
      assert (insert_helper->purpose != BTREE_OP_INSERT_UNDO_PHYSICAL_DELETE);
      log_sysop_abort (thread_p);
      insert_helper->is_system_op_started = false;
    }
  if (ovfl_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, ovfl_page);
    }
  return ret;
}

/*
 * btree_key_append_object_to_overflow () - Insert object in an existing overflow page. The page must be
 *					    checked for free space before calling this function.
 *
 * return		    : Error code.
 * thread_p (in)	    : Thread entry.
 * btid_int (in)	    : B-tree info.
 * ovfl_page (in)	    : Overflow page.
 * object_info (in)	    : Object & info to insert.
 * insert_helper (in)	    : B-tree insert helper.
 */
static int
btree_key_append_object_to_overflow (THREAD_ENTRY * thread_p, BTID_INT * btid_int, PAGE_PTR ovfl_page,
				     BTREE_OBJECT_INFO * object_info, BTREE_INSERT_HELPER * insert_helper)
{
  RECDES ovfl_rec;
  char ovfl_rec_buf[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  LOG_DATA_ADDR addr;

  LOG_LSA prev_lsa;

  /* Recovery. */
  char rv_undo_data_buffer[BTREE_RV_BUFFER_SIZE + BTREE_MAX_ALIGN];
  char *rv_undo_data = PTR_ALIGN (rv_undo_data_buffer, BTREE_MAX_ALIGN);
  char *rv_undo_data_ptr = NULL;
  int rv_undo_data_length = 0;
  char rv_redo_data_buffer[BTREE_RV_BUFFER_SIZE + BTREE_MAX_ALIGN];
  char *rv_redo_data = PTR_ALIGN (rv_redo_data_buffer, BTREE_MAX_ALIGN);
  char *rv_redo_data_ptr = rv_redo_data;
  int rv_redo_data_length;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (ovfl_page != NULL);
  assert (object_info != NULL);
  assert (insert_helper != NULL);
  assert (btree_is_insert_object_purpose (insert_helper->purpose));

  /* Prepare record. */
  ovfl_rec.type = REC_HOME;
  ovfl_rec.area_size = DB_PAGESIZE;
  ovfl_rec.data = PTR_ALIGN (ovfl_rec_buf, BTREE_MAX_ALIGN);

  /* Get record. */
  if (spage_get_record (thread_p, ovfl_page, 1, &ovfl_rec, COPY) != S_SUCCESS)
    {
      assert_release (false);
      return ER_FAILED;
    }

  /* Prepare logging. */
  addr.offset = 1;
  addr.pgptr = ovfl_page;
  addr.vfid = &btid_int->sys_btid->vfid;

  if (insert_helper->is_system_op_started)
    {
      /* Physical undo is necessary. */
      rv_undo_data_ptr = rv_undo_data;
    }

#if !defined (NDEBUG)
  /* For debugging recovery. */
  BTREE_RV_UNDOREDO_SET_DEBUG_INFO (&addr, rv_redo_data_ptr, rv_undo_data_ptr, btid_int, BTREE_RV_DEBUG_ID_INS_OLD_OVF);
#endif /* NDEBUG */
  BTREE_RV_SET_OVERFLOW_NODE (&addr);
  LOG_RV_RECORD_SET_MODIFY_MODE (&addr, LOG_RV_RECORD_UPDATE_PARTIAL);

  /* Object must have fixed size. */
  BTREE_MVCC_INFO_SET_FIXED_SIZE (&object_info->mvcc_info);
  btree_insert_object_ordered_by_oid (thread_p, &ovfl_rec, btid_int, object_info, &rv_undo_data_ptr, &rv_redo_data_ptr,
				      NULL);

  if (spage_update (thread_p, ovfl_page, 1, &ovfl_rec) != SP_SUCCESS)
    {
      assert_release (false);
      return ER_FAILED;
    }

  /* We need to log previous lsa. */
  LSA_COPY (&prev_lsa, pgbuf_get_lsa (ovfl_page));

  BTREE_RV_GET_DATA_LENGTH (rv_redo_data_ptr, rv_redo_data, rv_redo_data_length);
  if (rv_undo_data_ptr != NULL)
    {
      BTREE_RV_GET_DATA_LENGTH (rv_undo_data_ptr, rv_undo_data, rv_undo_data_length);
    }
  btree_rv_log_insert_object (thread_p, *insert_helper, addr, rv_undo_data_length, rv_redo_data_length, rv_undo_data,
			      rv_redo_data);

  btree_insert_log (insert_helper, BTREE_INSERT_MODIFY_MSG ("append object at the end of record"),
		    BTREE_INSERT_MODIFY_ARGS (thread_p, insert_helper, ovfl_page, &prev_lsa, false, 1, ovfl_rec.length,
					      btid_int->sys_btid));

  pgbuf_set_dirty (thread_p, ovfl_page, DONT_FREE);

  return NO_ERROR;
}

/*
 *
 */
static int
btree_rv_write_log_record_for_key_insert (char *log_rec, int *log_length, INT16 key_len, RECDES * recp)
{
  *(INT16 *) ((char *) log_rec + LOFFS1) = key_len;
  *(INT16 *) ((char *) log_rec + LOFFS2) = BTREE_LEAF_NODE;
  *(INT16 *) ((char *) log_rec + LOFFS3) = recp->type;
  memcpy ((char *) log_rec + LOFFS4, recp->data, recp->length);

  *log_length = recp->length + LOFFS4;

  return NO_ERROR;
}

static int
btree_rv_write_log_record (char *log_rec, int *log_length, RECDES * recp, BTREE_NODE_TYPE node_type)
{
  assert (node_type == BTREE_LEAF_NODE || node_type == BTREE_NON_LEAF_NODE);

  *(INT16 *) ((char *) log_rec + OFFS1) = node_type;
  *(INT16 *) ((char *) log_rec + OFFS2) = recp->type;
  memcpy ((char *) log_rec + OFFS3, recp->data, recp->length);

  *log_length = recp->length + OFFS3;

  return NO_ERROR;
}

/*
 * btree_find_free_overflow_oids_page () - Find overflow page that has enough free space to store a new object.
 *
 * return		: Error code.
 * thread_p (in)	: Thread entry.
 * btid (in)		: B-tree info.
 * first_ovfl_vpid (in) : VPID of first overflow page (or VPID NULL if there is no overflow).
 * overflow_page (out)	: Output overflow page with enough free space.
 */
static int
btree_find_free_overflow_oids_page (THREAD_ENTRY * thread_p, BTID_INT * btid, VPID * first_ovfl_vpid,
				    PAGE_PTR * overflow_page)
{
  VPID ovfl_vpid;
  int space_needed = BTREE_OBJECT_FIXED_SIZE (btid);
  int error_code = NO_ERROR;
  PERF_UTIME_TRACKER ovf_fix_time_track;

  /* Assert expected arguments. */
  assert (btid != NULL);
  assert (first_ovfl_vpid != NULL);
  assert (overflow_page != NULL && *overflow_page == NULL);

  ovfl_vpid = *first_ovfl_vpid;

  PERF_UTIME_TRACKER_START (thread_p, &ovf_fix_time_track);

  while (!VPID_ISNULL (&ovfl_vpid))
    {
      *overflow_page = pgbuf_fix (thread_p, &ovfl_vpid, OLD_PAGE, PGBUF_LATCH_WRITE, PGBUF_UNCONDITIONAL_LATCH);
      if (*overflow_page == NULL)
	{
	  ASSERT_ERROR_AND_SET (error_code);
	  return error_code;
	}

#if !defined (NDEBUG)
      (void) pgbuf_check_page_ptype (thread_p, *overflow_page, PAGE_BTREE);
#endif /* !NDEBUG */

      if (spage_max_space_for_new_record (thread_p, *overflow_page) > space_needed)
	{
	  btree_perf_ovf_oids_fix_time (thread_p, &ovf_fix_time_track);
	  return NO_ERROR;
	}

      btree_get_next_overflow_vpid (thread_p, *overflow_page, &ovfl_vpid);

      pgbuf_unfix_and_init (thread_p, *overflow_page);
    }

  btree_perf_ovf_oids_fix_time (thread_p, &ovf_fix_time_track);
  return NO_ERROR;
}

/*
 * btree_find_oid_and_its_page () - Find OID in leaf/overflow pages and output its position.
 *
 * return		  : Error code.
 * thread_p (in)	  : Thread entry.
 * btid_int (in)	  : B-tree info.
 * oid (in)		  : Object OID.
 * leaf_page (in)	  : Fixed leaf page (where object's key is found).
 * purpose (in)		  : Purpose/context for the function call.
 * match_mvccinfo (in)	  : Non-null value to be matched or null if it doesn't matter.
 * leaf_record (in)	  : Key leaf record.
 * leaf_rec_info (in)	  : Key leaf record info.
 * after_key_offset (in)  : Offset in leaf record where packed key is ended.
 * found_page (out)	  : Outputs leaf or overflow page where object is found.
 * prev_page (out)	  : Previous page of the overflow page where object object is found. If object is in leaf it
 *			    will output NULL. If object is in first overflow, it will output leaf page.
 *			    If argument is NULL, previous overflow page is unfixed.
 * offset_to_object (out) : Offset to object in the record of leaf/overflow.
 *
 * TODO: output overflow record
 */
static int
btree_find_oid_and_its_page (THREAD_ENTRY * thread_p, BTID_INT * btid_int, OID * oid, PAGE_PTR leaf_page,
			     BTREE_OP_PURPOSE purpose, BTREE_MVCC_INFO * match_mvccinfo, RECDES * leaf_record,
			     LEAF_REC * leaf_rec_info, int after_key_offset, PAGE_PTR * found_page,
			     PAGE_PTR * prev_page, int *offset_to_object, BTREE_MVCC_INFO * object_mvcc_info)
{
  int error_code = NO_ERROR;
  VPID overflow_vpid;
  PAGE_PTR overflow_page = NULL;
  PAGE_PTR prev_overflow_page = NULL;
  PERF_UTIME_TRACKER ovf_fix_time_track;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (oid != NULL);
  assert (leaf_page != NULL);
  assert (leaf_record != NULL);
  assert (leaf_rec_info != NULL);
  assert (after_key_offset > 0);
  assert (prev_page == NULL || *prev_page == NULL);
  assert (found_page != NULL && *found_page == NULL);
  assert (offset_to_object != NULL);

  /* Find object in leaf. */
  error_code =
    btree_find_oid_from_leaf (thread_p, btid_int, leaf_record, after_key_offset, oid, match_mvccinfo, purpose,
			      offset_to_object, object_mvcc_info);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      return error_code;
    }
  if (*offset_to_object != NOT_FOUND)
    {
      /* Found object. */
      *found_page = leaf_page;
      return NO_ERROR;
    }
  if (VPID_ISNULL (&leaf_rec_info->ovfl))
    {
      /* Not found. */
      return NO_ERROR;
    }
  /* Search through overflow pages. */
  VPID_COPY (&overflow_vpid, &leaf_rec_info->ovfl);
  do
    {
      PERF_UTIME_TRACKER_START (thread_p, &ovf_fix_time_track);
      overflow_page = pgbuf_fix (thread_p, &overflow_vpid, OLD_PAGE, PGBUF_LATCH_WRITE, PGBUF_UNCONDITIONAL_LATCH);
      btree_perf_ovf_oids_fix_time (thread_p, &ovf_fix_time_track);
      if (overflow_page == NULL)
	{
	  ASSERT_ERROR_AND_SET (error_code);
	  goto error;
	}
      error_code =
	btree_find_oid_from_ovfl (thread_p, btid_int, overflow_page, oid, purpose, match_mvccinfo, offset_to_object,
				  object_mvcc_info);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto error;
	}
      if (*offset_to_object != NOT_FOUND)
	{
	  /* Object was found. Stop looking. */
	  break;
	}
      /* Object was not found. Go to next overflow page. */
      if (prev_overflow_page != NULL)
	{
	  pgbuf_unfix_and_init (thread_p, prev_overflow_page);
	}
      prev_overflow_page = overflow_page;
      overflow_page = NULL;

      error_code = btree_get_next_overflow_vpid (thread_p, prev_overflow_page, &overflow_vpid);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto error;
	}
    }
  while (!VPID_ISNULL (&overflow_vpid));

  if (*offset_to_object == NOT_FOUND)
    {
      /* Not found. */
      assert (overflow_page == NULL);
      if (prev_overflow_page != NULL)
	{
	  pgbuf_unfix_and_init (thread_p, prev_overflow_page);
	}
    }
  else
    {
      assert (overflow_page != NULL);
      *found_page = overflow_page;

      if (prev_page != NULL)
	{
	  *prev_page = prev_overflow_page != NULL ? prev_overflow_page : leaf_page;
	}
      else if (prev_overflow_page != NULL)
	{
	  pgbuf_unfix_and_init (thread_p, prev_overflow_page);
	}
    }
  return NO_ERROR;

error:
  assert_release (error_code != NO_ERROR);

  if (overflow_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, overflow_page);
    }
  if (prev_overflow_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, prev_overflow_page);
    }
  return error_code;
}

/*
 * btree_find_oid_does_mvcc_info_match () - Match an object by its MVCC info and the purpose of search.
 *
 * return	       : Error code.
 * thread_p (in)       : Thread entry.
 * mvcc_info (in)      : Object MVCC info.
 * purpose (in)	       : Btree operation purpose.
 * match_mvccinfo (in) : MVCC info to be matched (or NULL if not necessary).
 * is_match (out)      : Outputs true if object MVCC info matches the expectations.
 *
 * NOTE: This function can handle mismatches between information stored in heap and b-tree. Because vacuum system
 *	 doesn't clean the entries for one object in both heap and b-trees, the information found in them can be
 *	 different (e.g. one can have insert MVCCID cleaned while the other doesn't).
 *	 Moreover, if the object OID's are reusable, there can be duplicate OID's in b-tree (one is deleted and must be
 *	 vacuumed and one is newer and can be recently inserted or even recently deleted).
 *	 Based on purpose of the search, we try to match the insert MVCCID or delete MVCCID or just check that object
 *	 doesn't have a valid delete MVCCID.
 */
static int
btree_find_oid_does_mvcc_info_match (THREAD_ENTRY * thread_p, BTREE_MVCC_INFO * mvcc_info, BTREE_OP_PURPOSE purpose,
				     BTREE_MVCC_INFO * match_mvccinfo, bool * is_match)
{
  /* Assert expected arguments. */
  assert (mvcc_info != NULL);
  assert (is_match != NULL);

  *is_match = false;
  switch (purpose)
    {
    case BTREE_OP_DELETE_VACUUM_INSID:
      /* Match insert MVCCID to vacuum. */
      assert (match_mvccinfo != NULL && BTREE_MVCC_INFO_IS_INSID_NOT_ALL_VISIBLE (match_mvccinfo));
      if (BTREE_MVCC_INFO_HAS_INSID (mvcc_info) && mvcc_info->insert_mvccid == match_mvccinfo->insert_mvccid)
	{
	  /* This is the insert MVCCID to be vacuumed. */
	  *is_match = true;
	}
      else
	{
	  /* Not a match. */
	}
      return NO_ERROR;

    case BTREE_OP_DELETE_OBJECT_PHYSICAL_POSTPONED:
    case BTREE_OP_DELETE_VACUUM_OBJECT:
      /* Match delete MVCCID to not remove the wrong object (reused). */
      assert (match_mvccinfo != NULL && BTREE_MVCC_INFO_IS_DELID_VALID (match_mvccinfo));
      if (BTREE_MVCC_INFO_HAS_DELID (mvcc_info) && mvcc_info->delete_mvccid == match_mvccinfo->delete_mvccid)
	{
	  /* This is the object to be vacuumed/deleted. */
	  *is_match = true;
	}
      else
	{
	  /* Not a match. */
	}
      return NO_ERROR;

    case BTREE_OP_DELETE_UNDO_INSERT_DELID:
      /* We want to rollback an MVCC delete. Just removing the delete MVCCID is enough. If delete MVCCID does not
       * match, it means it must be an older object, before being reused, which was not vacuumed yet. */
      assert (match_mvccinfo != NULL && BTREE_MVCC_INFO_IS_DELID_VALID (match_mvccinfo));
      if (BTREE_MVCC_INFO_HAS_DELID (mvcc_info))
	{
	  if (mvcc_info->delete_mvccid == match_mvccinfo->delete_mvccid)
	    {
	      /* Maybe we have to match insert MVCCID too. */
	      if (BTREE_MVCC_INFO_IS_INSID_NOT_ALL_VISIBLE (match_mvccinfo)
		  && BTREE_MVCC_INFO_INSID (mvcc_info) != match_mvccinfo->insert_mvccid)
		{
		  /* Not a match */
		}
	      else
		{
		  /* It's a match. */
		  *is_match = true;
		}
	    }
	  else
	    {
	      /* Not a match. */
	    }
	}
      else
	{
	  /*
	   * No delete MVCCID. In case of multi updates, we may have the same OID twice in buffer, but with different
	   * MVCC info. Thus, the OID may appear first with MVCC insert id only. Then, the same OID appears again with
	   * MVCC delete id. We have to continue the search if the MVCC info does not match.
	   */
	}

      return NO_ERROR;

    case BTREE_OP_DELETE_UNDO_INSERT:
    case BTREE_OP_DELETE_UNDO_INSERT_UNQ_MULTIUPD:
      /* We just inserted this object and want to remove it. Insert MVCCID must match and should not be deleted. */
      if (BTREE_MVCC_INFO_IS_DELID_VALID (mvcc_info))
	{
	  /* This must be an old object, reused, but not yet vacuumed. */
	  /* Not a match. */
	  return NO_ERROR;
	}
      if (match_mvccinfo != NULL && BTREE_MVCC_INFO_IS_INSID_NOT_ALL_VISIBLE (match_mvccinfo))
	{
	  /* We must match insert MVCCID. */
	  if (BTREE_MVCC_INFO_INSID (mvcc_info) == match_mvccinfo->insert_mvccid)
	    {
	      /* This is a match. */
	      *is_match = true;
	      return NO_ERROR;
	    }
	  else
	    {
	      /* Insert MVCCID is different or doesn't exist. We don't expect such case. */
	      assert_release (false);
	      return NO_ERROR;
	    }
	}
      /* We don't have an insert MVCCID to be matched. Object MVCC info should either have no insert MVCCID or it
       * should be all visible. */
      if (BTREE_MVCC_INFO_IS_INSID_NOT_ALL_VISIBLE (mvcc_info))
	{
	  /* We don't expect this case. */
	  assert_release (false);
	  return ER_FAILED;
	}
      else
	{
	  /* This is a match. */
	  *is_match = true;
	  return NO_ERROR;
	}
      /* Unreachable. */
      assert_release (false);
      return ER_FAILED;

    case BTREE_OP_DELETE_OBJECT_PHYSICAL:
    case BTREE_OP_INSERT_MVCC_DELID:
    case BTREE_OP_INSERT_MARK_DELETED:
    default:
      /* We are looking for an object not deleted. It is possible to find same OID, but deleted, if reusable. */
      if (!BTREE_MVCC_INFO_IS_DELID_VALID (mvcc_info))
	{
	  /* This is the object we want to delete. */
	  *is_match = true;
	}
      else
	{
	  /* This must be same OID but before being reused. It should be vacuumed soon. */
	  /* Not a match. */
	}
      return NO_ERROR;
    }
}

/*
 * btree_find_oid_from_leaf () - Find OID in leaf record and output its offset and MVCC info.
 *
 * return		  : Error code.
 * thread_p (in)	  : Thread entry.
 * btid (in)		  : B-tree info.
 * leaf_record (in)	  : Leaf record.
 * after_key_offset (in)  : Offset in record where packed key is ended.
 * oid (in)		  : OID of object to find.
 * match_mvccinfo (in)	  : Non-null value to be matched or null if it doesn't matter.
 * purpose (in)		  : Purpose/context for the call.
 * offset_to_object (out) : Output offset to found object or NOT_FOUND.
 * mvcc_info (out)	  : Output object MVCC info when found.
 */
static int
btree_find_oid_from_leaf (THREAD_ENTRY * thread_p, BTID_INT * btid, RECDES * leaf_record, int after_key_offset,
			  OID * oid, BTREE_MVCC_INFO * match_mvccinfo, BTREE_OP_PURPOSE purpose, int *offset_to_object,
			  BTREE_MVCC_INFO * mvcc_info)
{
  OR_BUF buf;			/* Buffer to read record. */
  OID inst_oid;			/* OID read from record. */
  OID class_oid;		/* Class OID read from record. */
  BTREE_MVCC_INFO local_mvcc_info;	/* Local MVCC info. */
  int error_code = NO_ERROR;	/* Error code. */
  bool is_match = false;	/* Set to true when OID is found and MVCC info matches expectations. */
  bool is_first = true;		/* Used to skip packed key. */

  assert (btid != NULL);
  assert (leaf_record != NULL);
  assert (after_key_offset > 0);
  assert (oid != NULL);
  assert (offset_to_object != NULL);

  if (mvcc_info == NULL)
    {
      /* MVCC info is not for output but is required internally. */
      mvcc_info = &local_mvcc_info;
    }

  BTREE_RECORD_OR_BUF_INIT (buf, leaf_record);
  while (buf.ptr < buf.endptr)
    {
      /* If the object has fixed size, it is forced to have both insert MVCCID and delete MVCCID. This can happen if:
       * 1. The index is unique, and this is not the key's first object. 2. The keys has overflow OID's and this is the
       * first object. In any other cases follow the MVCC flags. */
      *offset_to_object = CAST_BUFLEN (buf.ptr - buf.buffer);

      /* Get object and all its information from record. */
      if (btree_or_get_object (&buf, btid, BTREE_LEAF_NODE, after_key_offset, &inst_oid, &class_oid, mvcc_info) !=
	  NO_ERROR)
	{
	  assert_release (false);
	  error_code = ER_FAILED;
	  goto error;
	}

      /* Is the OID we're searching? */
      if (OID_EQ (&inst_oid, oid))
	{
	  /* OID matches. */
	  /* Is MVCC info according to expectations? */
	  error_code = btree_find_oid_does_mvcc_info_match (thread_p, mvcc_info, purpose, match_mvccinfo, &is_match);
	  if (error_code != NO_ERROR)
	    {
	      ASSERT_ERROR ();
	      goto error;
	    }
	  if (is_match)
	    {
	      /* Object is a match. */
	      return NO_ERROR;
	    }
	  /* Not our object. */
	  /* Continue looking. */
	}
      if (is_first)
	{
	  /* Skip key. */
	  or_seek (&buf, after_key_offset);
	  is_first = false;
	}
    }
  /* Object was not found. */
  *offset_to_object = NOT_FOUND;
  return NO_ERROR;

error:
  assert_release (error_code != NO_ERROR);
  *offset_to_object = NOT_FOUND;
  return error_code;
}

/*
 * btree_find_oid_from_ovfl () - Find object in overflow page.
 *
 * return		  : Error code.
 * thread_p (in)	  : Thread entry.
 * btid_int (in)	  : B-tree info.
 * overflow_page (in)	  : Overflow page.
 * oid (in)		  : OID to find.
 * purpose (in)		  : Purpose of call.
 * match_mvccinfo (in)	  : Non-null value to be matched or null if it doesn't matter.
 * offset_to_object (out) : If object is found, it saves the offset to object. Otherwise, NOT_FOUND is output.
 * mvcc_info (out)	  : Output MVCC info if object is found.
 */
static int
btree_find_oid_from_ovfl (THREAD_ENTRY * thread_p, BTID_INT * btid_int, PAGE_PTR overflow_page, OID * oid,
			  BTREE_OP_PURPOSE purpose, BTREE_MVCC_INFO * match_mvccinfo, int *offset_to_object,
			  BTREE_MVCC_INFO * mvcc_info)
{
  OID inst_oid;			/* OID read from record. */
  int min, mid, max;		/* min, mid, max values used for binary search. */
  int num_oids;			/* Number of objects in record. */
  int size;			/* Object and all its info size */
  int error_code = NO_ERROR;	/* Error code. */
  char *oid_ptr = NULL, *ptr = NULL;	/* Pointer in record data. */
  BTREE_MVCC_INFO local_mvcc_info;	/* Local MVCC info. */
  RECDES ovf_record;		/* Overflow record. */
  bool is_match = false;	/* Set to true if object is found and its MVCC info matches expectations. */

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (overflow_page != NULL);
  assert (oid != NULL);
  assert (offset_to_object != NULL);

  if (mvcc_info == NULL)
    {
      /* MVCC info is not for output but is required internally. */
      mvcc_info = &local_mvcc_info;
    }

  *offset_to_object = NOT_FOUND;
  if (spage_get_record (thread_p, overflow_page, 1, &ovf_record, PEEK) != S_SUCCESS)
    {
      assert_release (false);
      return ER_FAILED;
    }

  /* Try early out: check first oid */
  BTREE_GET_OID (ovf_record.data, &inst_oid);
  assert ((inst_oid.slotid & BTREE_LEAF_RECORD_MASK) == 0);
  assert ((inst_oid.volid & BTREE_OID_MVCC_FLAGS_MASK) == 0);

  if (OID_LT (oid, &inst_oid))
    {
      /* Not in this page. */
      return NO_ERROR;
    }
  else if (OID_EQ (oid, &inst_oid))
    {
      /* OID matched. */
      /* Check MVCC info. */
      ptr = ovf_record.data + OR_OID_SIZE;
      if (BTREE_IS_UNIQUE (btid_int->unique_pk))
	{
	  ptr += OR_OID_SIZE;
	}
      (void) btree_unpack_mvccinfo (ptr, mvcc_info, BTREE_OID_HAS_MVCC_INSID_AND_DELID);
      error_code = btree_find_oid_does_mvcc_info_match (thread_p, mvcc_info, purpose, match_mvccinfo, &is_match);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return error_code;
	}
      if (is_match)
	{
	  /* First object is a match. */
	  *offset_to_object = 0;
	  return NO_ERROR;
	}
    }
  /* First object is not a match. */

  /* Try early out: check last object. */

  /* Find last object. */
  /* Compute size of one object and all its info. */
  size = BTREE_OBJECT_FIXED_SIZE (btid_int);
  /* Get last object. */
  oid_ptr = ovf_record.data + (ovf_record.length - size);
  BTREE_GET_OID (oid_ptr, &inst_oid);
  assert ((inst_oid.slotid & BTREE_LEAF_RECORD_MASK) == 0);
  assert ((inst_oid.volid & BTREE_OID_MVCC_FLAGS_MASK) == 0);

  if (OID_GT (oid, &inst_oid))
    {
      /* Not in this page. */
      return NO_ERROR;
    }
  else if (OID_EQ (oid, &inst_oid))
    {
      /* OID matched. */
      /* Check MVCC info. */
      ptr = oid_ptr + OR_OID_SIZE;
      if (BTREE_IS_UNIQUE (btid_int->unique_pk))
	{
	  ptr += OR_OID_SIZE;
	}
      (void) btree_unpack_mvccinfo (ptr, mvcc_info, BTREE_OID_HAS_MVCC_INSID_AND_DELID);
      error_code = btree_find_oid_does_mvcc_info_match (thread_p, mvcc_info, purpose, match_mvccinfo, &is_match);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return error_code;
	}
      if (is_match)
	{
	  /* Last object is a match. */
	  *offset_to_object = CAST_BUFLEN (oid_ptr - ovf_record.data);
	  return NO_ERROR;
	}
    }
  /* Early outs failed. Do a binary search after OID. */

  num_oids = btree_record_get_num_oids (thread_p, btid_int, &ovf_record, 0, BTREE_OVERFLOW_NODE);

  /* First and last object were already checked. Try others. */
  min = 1;
  max = num_oids - 2;

  /* Search OID. */
  while (min <= max)
    {
      /* Get MID object. */
      mid = (min + max) / 2;
      oid_ptr = ovf_record.data + (size * mid);
      BTREE_GET_OID (oid_ptr, &inst_oid);
      assert ((inst_oid.slotid & BTREE_LEAF_RECORD_MASK) == 0);
      assert ((inst_oid.volid & BTREE_OID_MVCC_FLAGS_MASK) == 0);

      /* Check OID. */
      if (OID_EQ (oid, &inst_oid))
	{
	  char *oid_ptr_lower_bound;
	  char *oid_ptr_upper_bound;

	  /* check a sequence of objects (same OID with different MVCC info) */
	  oid_ptr_lower_bound = oid_ptr - size * (mid - min);
	  oid_ptr_upper_bound = oid_ptr + size * (max - mid);

	  return btree_seq_find_oid_from_ovfl (thread_p, btid_int, oid, &ovf_record, oid_ptr, oid_ptr_lower_bound,
					       oid_ptr_upper_bound, purpose, match_mvccinfo, offset_to_object,
					       mvcc_info);
	}
      else if (OID_GT (oid, &inst_oid))
	{
	  /* Try between mid + 1 and max. */
	  min = mid + 1;
	}
      else
	{
	  /* Try between min and mid - 1. */
	  assert (OID_LT (oid, &inst_oid));
	  max = mid - 1;
	}
    }

  /* Not found. */
  return NO_ERROR;
}

/*
 * btree_seq_find_oid_from_ovfl () - Find object in overflow page.
 *
 * return		  : Error code.
 * thread_p (in)	  : Thread entry.
 * btid_int (in)	  : B-tree info.
 * oid (in)		  : OID to find.
 * ovf_record(in)	  : overflow record
 * initial_oid_ptr (in)   : pointer to OID initially found
 * oid_ptr_lower_bound (in) : pointer lower allowed bound within OID buffer
 * oid_ptr_upper_bound (in) : pointer upper allowed bound within OID buffer
 * purpose (in)		  : Purpose of call.
 * match_mvccinfo (in)	  : Non-null value to be matched or null if it doesn't matter.
 * offset_to_object (out) : If object is found, it saves the offset to object. Otherwise, NOT_FOUND is output.
 * mvcc_info (out)	  : Output MVCC info if object is found.
 */
static int
btree_seq_find_oid_from_ovfl (THREAD_ENTRY * thread_p, BTID_INT * btid_int, OID * oid,
			      RECDES * ovf_record, char *initial_oid_ptr, char *oid_ptr_lower_bound,
			      char *oid_ptr_upper_bound, BTREE_OP_PURPOSE purpose, BTREE_MVCC_INFO * match_mvccinfo,
			      int *offset_to_object, BTREE_MVCC_INFO * mvcc_info)
{
  OID inst_oid;
  char *oid_ptr;
  char *ptr;
  int obj_size = BTREE_OBJECT_FIXED_SIZE (btid_int);
  int error_code;
  bool is_match;

  /* first, check OID and previous ones */
  oid_ptr = initial_oid_ptr;

  while (oid_ptr >= oid_ptr_lower_bound)
    {
      BTREE_GET_OID (oid_ptr, &inst_oid);
      assert ((inst_oid.slotid & BTREE_LEAF_RECORD_MASK) == 0);
      assert ((inst_oid.volid & BTREE_OID_MVCC_FLAGS_MASK) == 0);

      /* Check OID. */
      if (!OID_EQ (oid, &inst_oid))
	{
	  break;
	}

      /* OID matched. */
      /* Check MVCC info. */
      ptr = oid_ptr + OR_OID_SIZE;
      if (BTREE_IS_UNIQUE (btid_int->unique_pk))
	{
	  ptr += OR_OID_SIZE;
	}

      (void) btree_unpack_mvccinfo (ptr, mvcc_info, BTREE_OID_HAS_MVCC_INSID_AND_DELID);
      error_code = btree_find_oid_does_mvcc_info_match (thread_p, mvcc_info, purpose, match_mvccinfo, &is_match);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return error_code;
	}

      if (is_match)
	{
	  /* Object is a match. */
	  *offset_to_object = CAST_BUFLEN (oid_ptr - ovf_record->data);
	  return NO_ERROR;
	}

      oid_ptr -= obj_size;
    }

  /* check next OIDs */
  oid_ptr = initial_oid_ptr + obj_size;

  while (oid_ptr <= oid_ptr_upper_bound)
    {
      BTREE_GET_OID (oid_ptr, &inst_oid);
      assert ((inst_oid.slotid & BTREE_LEAF_RECORD_MASK) == 0);
      assert ((inst_oid.volid & BTREE_OID_MVCC_FLAGS_MASK) == 0);

      /* Check OID. */
      if (!OID_EQ (oid, &inst_oid))
	{
	  break;
	}

      /* OID matched. */
      /* Check MVCC info. */
      ptr = oid_ptr + OR_OID_SIZE;
      if (BTREE_IS_UNIQUE (btid_int->unique_pk))
	{
	  ptr += OR_OID_SIZE;
	}

      (void) btree_unpack_mvccinfo (ptr, mvcc_info, BTREE_OID_HAS_MVCC_INSID_AND_DELID);
      error_code = btree_find_oid_does_mvcc_info_match (thread_p, mvcc_info, purpose, match_mvccinfo, &is_match);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return error_code;
	}

      if (is_match)
	{
	  /* Object is a match. */
	  *offset_to_object = CAST_BUFLEN (oid_ptr - ovf_record->data);
	  return NO_ERROR;
	}

      oid_ptr += obj_size;
    }

  return NO_ERROR;
}

/*
 * btree_get_prefix_separator () -
 *   return: db_value containing the prefix key. This must be cleared when it is done being used.
 *   key1(in): first key
 *   key2(in): second key
 *   prefix_key(in):
 *
 * Note: This function finds the prefix (the separator) of two strings.
 * Currently this is only done for one of the six string types,
 * but with multi-column indexes and uniques coming, we may want to do prefix keys for sequences as well.
 *
 * The purpose of this routine is to find a prefix that is greater than or equal to the first key but strictly less
 * than the second key.  This routine assumes that the second key is strictly greater than the first key.
 *
 * If this function could not generate common prefix key
 * (ex: key domain == integer)
 * copy key2 to prefix_key (because Index separator use key2 in general case)
 */
/* TODO: change key generation
 * (db_string_unique_prefix, pr_midxkey_unique_prefix)
 */
int
btree_get_prefix_separator (const DB_VALUE * key1, const DB_VALUE * key2, DB_VALUE * prefix_key, TP_DOMAIN * key_domain)
{
  int c;
  int err = NO_ERROR;

  assert (DB_IS_NULL (key1) || (DB_VALUE_DOMAIN_TYPE (key1) == DB_VALUE_DOMAIN_TYPE (key2)));
  assert (!DB_IS_NULL (key2));
  assert_release (key_domain != NULL);

#if !defined(NDEBUG)
  c = btree_compare_key ((DB_VALUE *) key1, (DB_VALUE *) key2, key_domain, 1, 1, NULL);
  assert (c == DB_LT);
#endif

  if (DB_VALUE_DOMAIN_TYPE (key1) == DB_TYPE_MIDXKEY)
    {
      assert_release (TP_DOMAIN_TYPE (key_domain) == DB_TYPE_MIDXKEY);

      err = pr_midxkey_unique_prefix (key1, key2, prefix_key);
    }
  else if (pr_is_string_type (DB_VALUE_DOMAIN_TYPE (key1)))
    {
      assert_release (TP_DOMAIN_TYPE (key_domain) != DB_TYPE_MIDXKEY);

      err = db_string_unique_prefix (key1, key2, prefix_key, key_domain);
    }
  else
    {
      /* In this case, key2 is used as separator in B+tree so, copy key2 to prefix_key */
      err = pr_clone_value (key2, prefix_key);
    }

  if (err != NO_ERROR)
    {
      assert_release (false);
      return ER_FAILED;
    }

  c = btree_compare_key ((DB_VALUE *) key1, prefix_key, key_domain, 1, 1, NULL);

  if (c != DB_LT)
    {
      assert_release (false);
      return ER_FAILED;
    }

  c = btree_compare_key (prefix_key, (DB_VALUE *) key2, key_domain, 1, 1, NULL);

  if (!(c == DB_LT || c == DB_EQ))
    {
      assert_release (false);
      return ER_FAILED;
    }

  return err;
}

/*
 * btree_find_split_point () -
 *   return: the key or key separator (prefix) to be moved to the
 *           parent page, or NULL_KEY. The length of the returned
 *           key, or prefix, is set in mid_keylen. The parameter
 *           mid_slot is set to the record number of the split point record.
 *   btid(in):
 *   page_ptr(in): Pointer to the page
 *   mid_slot(out): Set to contain the record number for the split point slot
 *   key(in): Key to be inserted to the index (or modified).
 *   helper(in): B-tree insert helper.
 *   clear_midkey(in):
 *
 * Note: Finds the split point of the given page by considering the
 * length of the existing records and the length of the key.
 * For a leaf page split operation, if there are n keys in the
 * page, then mid_slot can be set to :
 *
 *              0 : all the records in the page are to be moved to the newly
 *                  allocated page, key is to be inserted into the original
 *                  page. Mid_key is between key and the first record key.
 *
 *              n : all the records will be kept in the original page. Key is
 *                  to be inserted to the newly allocated page. Mid_key is
 *                  between the last record key and the key.
 *      otherwise : slot point is in the range 1 to n-1, inclusive. The page
 *                  is to be split into half.
 *
 * Note: the returned db_value should be cleared and FREED by the caller.
 */
static DB_VALUE *
btree_find_split_point (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR page_ptr, int *mid_slot, DB_VALUE * key,
			BTREE_INSERT_HELPER * helper, bool * clear_midkey)
{
  RECDES rec;
  BTREE_NODE_HEADER *header = NULL;
  BTREE_NODE_TYPE node_type;
  INT16 slot_id = NULL_SLOTID;
  int new_ent_size = 0, new_fence_size = 0;
  int key_cnt = 0, key_len = 0, max_key_len = 0, offset = 0;
  INT16 tot_rec = 0;
  int i = 0, mid_size = 0;
  bool m_clear_key = false, n_clear_key = false;
  DB_VALUE *mid_key = NULL, *next_key = NULL, *prefix_key = NULL, *tmp_key;
  bool is_key_added_to_left = false, found = false;
  NON_LEAF_REC nleaf_pnt;
  LEAF_REC leaf_pnt;
  BTREE_SEARCH_KEY_HELPER search_key;
  int stop_at = 0, start_with = 0;
  int left_fence_size = 0;
  int right_fence_size = 0;
  int left_size = 0;
  int left_max_size = 0;
  int left_min_size = 0;
  int right_max_size = 0;
  int record_size = 0;
  int do_increment = 1;

  key_cnt = btree_node_number_of_keys (thread_p, page_ptr);
  if (key_cnt <= 0)
    {
      er_log_debug (ARG_FILE_LINE, "btree_find_split_point: node key count underflow: %d", key_cnt);
      goto error;
    }

  /* get the page header */
  header = btree_get_node_header (thread_p, page_ptr);
  if (header == NULL)
    {
      er_log_debug (ARG_FILE_LINE, "btree_find_split_point: get node header failure: %d", key_cnt);
      goto error;
    }

  node_type = (header->node_level > 1) ? BTREE_NON_LEAF_NODE : BTREE_LEAF_NODE;

  key_len = btree_get_disk_size_of_key (key);
  key_len = BTREE_GET_KEY_LEN_IN_PAGE (key_len);

  /* find the slot position of the key if it is to be located in the page */
  if (node_type == BTREE_LEAF_NODE)
    {
      if (btree_search_leaf_page (thread_p, btid, page_ptr, key, &search_key) != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto error;
	}
      found = (search_key.result == BTREE_KEY_FOUND);
      slot_id = search_key.slotid;
      if (slot_id == NULL_SLOTID)	/* leaf search failed */
	{
	  assert (false);
	  goto error;
	}
    }
  else
    {
      found = 0;
      slot_id = NULL_SLOTID;
    }

  /* Start splitting records into left and right nodes. The algorithm must consider next rules: 1. The size of split
   * records should be done as close as possible to the size indicated by split_info. Split info is not applied to page
   * header and fences. 2. Left and right nodes should have enough space for new data required by insert, and also for
   * new fences. This applies only to leaf nodes. 3. After split & insert, both nodes must have at least one non-fence
   * record. */

  /* Compute maximum page size considering headers. */
  left_max_size = BTREE_NODE_MAX_SPLIT_SIZE (thread_p, page_ptr);
  right_max_size = left_max_size;

  /* Compute total record size. Filter out fences here. */
  start_with = 1;
  if (btree_is_fence_key (page_ptr, start_with))
    {
      assert (node_type == BTREE_LEAF_NODE);
      left_fence_size = spage_get_space_for_record (thread_p, page_ptr, start_with);

      /* Left fence will be included in left leaf. Subtract its size from the maximum size allowed. */
      left_max_size -= left_fence_size;
      start_with++;
    }

  stop_at = key_cnt;
  if (btree_is_fence_key (page_ptr, stop_at))
    {
      assert (node_type == BTREE_LEAF_NODE);
      right_fence_size = spage_get_space_for_record (thread_p, page_ptr, stop_at);

      /* Right fence will be included in right leaf. Subtract its size from the maximum size allowed. */
      right_max_size -= right_fence_size;
      stop_at--;
    }

  if (node_type == BTREE_LEAF_NODE)
    {
      new_ent_size = btree_get_max_new_data_size (thread_p, btid, page_ptr, node_type, key_len, helper, found);

      /* Until we know where new entity belongs, we must reserve enough space in both left and right leaf. */
      left_max_size -= new_ent_size;
      right_max_size -= new_ent_size;

      /* New fences are added to both leaves: an upper fence for left leaf and lower fence for right leaf. We don't
       * know their size yet, but we can estimate the largest size using node maximum key length. */
      /* TODO: Fences currently optimize only midxkey key types. Save storage by not using fence keys when they are not
       * required. */
      max_key_len = MAX (key_len, header->max_key_len);
      new_fence_size = LEAF_FENCE_MAX_SIZE (max_key_len) + spage_slot_size ();

      /* Adjust maximum size for both leaves. */
      left_max_size -= new_fence_size;
      right_max_size -= new_fence_size;
    }
  else
    {
      /* New key is not added to non-leaf. */
      new_ent_size = 0;

      /* No fences in non-leaf. */
      new_fence_size = 0;
    }

  /* First find out the size of the data on the page, don't count the header record or fences. */
  for (i = start_with, tot_rec = 0; i <= stop_at; i++)
    {
      tot_rec += spage_get_space_for_record (thread_p, page_ptr, i);
    }
  tot_rec += new_ent_size;

  /* Compute mid_size, the desired size of left node according to split info. */
  mid_size = btree_split_find_pivot (tot_rec, &(header->split_info));

  /* Split records and new entity considering mid_size, left_max_size, and right_max_size. Since we work with left
   * node, translate right_max_size into left_min_size by subtracting from total records size. */
  left_min_size = tot_rec - right_max_size;
  /* Safe guard. */
  assert (left_min_size < left_max_size);

  /* Find the last slot ID belonging to left node (and save it in the mid_slot pointer). */
  for (i = start_with, left_size = 0; true; i = i + do_increment)
    {
      do_increment = 1;
      if (node_type == BTREE_LEAF_NODE && i == slot_id && !is_key_added_to_left)
	{
	  /* New entity belongs to left leaf. Ignore it for non-leaf. */
	  is_key_added_to_left = true;

	  /* Adjust leaf sizes now that we know the key belongs to left leaf. */
	  left_max_size += new_ent_size;
	  right_max_size += new_ent_size;
	  left_min_size -= new_ent_size;

	  if (found)
	    {
	      /* Consider current record with new data. */
	      record_size = spage_get_space_for_record (thread_p, page_ptr, i);
	      record_size += new_ent_size;
	    }
	  else
	    {
	      /* Consider new record. */
	      record_size = new_ent_size;
	      /* Do not increment i this iteration. */
	      do_increment = 0;
	    }
	}
      else
	{
	  record_size = spage_get_space_for_record (thread_p, page_ptr, i);
	}
      if (left_size < left_min_size)
	{
	  /* Right node is too large. Keep adding records to left node. */
	  left_size += record_size;
	  continue;
	}
      /* Add new record to left and check its new size. */
      left_size += record_size;
      if (left_size > MIN (left_max_size, mid_size))
	{
	  /* We reached the desired size, or the maximum size allowed for left node. Stop one record before this. */
	  *mid_slot = i - 1;
#if !defined (NDEBUG)
	  /* Update left_size for debug checks. */
	  left_size -= record_size;
#endif /* !NDEBUG */
	  break;
	}
      if (i == stop_at)
	{
	  /* All non-fence records have been processed. Stop. */
	  *mid_slot = i;
	  break;
	}
    }

  /* Adjust mid_slot according to rule #3. */
  if (*mid_slot == (start_with - 1) && (node_type == BTREE_NON_LEAF_NODE || !is_key_added_to_left || found))
    {
      /* There are no records in the left node. Adjust mid_slot. */
      (*mid_slot)++;

#if !defined (NDEBUG)
      /* Update left_size for debug checks. */
      left_size += spage_get_space_for_record (thread_p, page_ptr, *mid_slot);
#endif /* !NDEBUG */
    }
  if (*mid_slot == stop_at && (node_type == BTREE_NON_LEAF_NODE || is_key_added_to_left || found))
    {
      /* There are no records in the right leaf. Adjust mid_slot. */
      (*mid_slot)--;
#if !defined (NDEBUG)
      /* Update left_size for debug checks. */
      left_size -= spage_get_space_for_record (thread_p, page_ptr, *mid_slot);
#endif /* !NDEBUG */
    }

  /* Safe guard: Rule #2. */
  assert (left_size <= left_max_size);
  assert (left_size >= left_min_size);
  assert (tot_rec - left_size <= right_max_size);
  assert (left_size + new_fence_size <= BTREE_NODE_MAX_SPLIT_SIZE (thread_p, page_ptr));
  assert (tot_rec - left_size + new_fence_size <= BTREE_NODE_MAX_SPLIT_SIZE (thread_p, page_ptr));

  /* Safe guard: Rules #3. */
  /* Left node will have at least one non-fence record. */
  assert (*mid_slot >= start_with
	  || (*mid_slot == (start_with - 1) && node_type == BTREE_LEAF_NODE && is_key_added_to_left));
  /* Right node will have at least one non-fence record. */
  assert (*mid_slot < stop_at || (*mid_slot == stop_at && node_type == BTREE_LEAF_NODE && !is_key_added_to_left));

  /* TODO: Optimize memory usage. We don't need to allocated/deallocate all DB_VALUE types and their content in all
   * cases. */
  mid_key = (DB_VALUE *) db_private_alloc (thread_p, sizeof (DB_VALUE));
  if (mid_key == NULL)
    {
      goto error;
    }

  btree_init_temp_key_value (&m_clear_key, mid_key);

  if (*mid_slot == (slot_id - 1) && is_key_added_to_left && !found)
    {
      /* the new key is the split key */
      PR_TYPE *pr_type;

      /* Safe guard. */
      assert (*mid_slot != key_cnt);

      if (node_type == BTREE_LEAF_NODE)
	{
	  pr_type = btid->key_type->type;
	}
      else
	{
	  pr_type = btid->nonleaf_key_type->type;
	}

      m_clear_key = false;

      pr_type->setval (mid_key, key, m_clear_key);
    }
  else
    {
      /* the split key is one of the keys on the page */
      assert (*mid_slot > 0);
      if (spage_get_record (thread_p, page_ptr, *mid_slot, &rec, PEEK) != S_SUCCESS)
	{
	  goto error;
	}

      /* we copy the key here because rec lives on the stack and mid_key is returned from this routine. */
      if (node_type == BTREE_LEAF_NODE)
	{
	  if (btree_read_record (thread_p, btid, page_ptr, &rec, mid_key, (void *) &leaf_pnt, node_type, &m_clear_key,
				 &offset, COPY_KEY_VALUE, NULL) != NO_ERROR)
	    {
	      goto error;
	    }
	}
      else
	{
	  if (btree_read_record (thread_p, btid, page_ptr, &rec, mid_key, (void *) &nleaf_pnt, node_type, &m_clear_key,
				 &offset, COPY_KEY_VALUE, NULL) != NO_ERROR)
	    {
	      goto error;
	    }
	}
    }

  /* The determination of the prefix key is dependent on the next key */
  next_key = (DB_VALUE *) db_private_alloc (thread_p, sizeof (DB_VALUE));
  if (next_key == NULL)
    {
      goto error;
    }

  btree_init_temp_key_value (&n_clear_key, next_key);

  if (*mid_slot == key_cnt && slot_id == (key_cnt + 1))
    {
      assert (node_type == BTREE_LEAF_NODE);

      n_clear_key = true;
      if (pr_clone_value (key, next_key) != NO_ERROR)
	{
	  goto error;
	}
    }
  else
    {
      /* The next key is one of the keys on the page */
      assert ((*mid_slot) + 1 > 0);
      if (spage_get_record (thread_p, page_ptr, (*mid_slot) + 1, &rec, PEEK) != S_SUCCESS)
	{
	  goto error;
	}

      /* we copy the key here because rec lives on the stack and mid_key is returned from this routine. */
      if (node_type == BTREE_LEAF_NODE)
	{
	  if (btree_read_record (thread_p, btid, page_ptr, &rec, next_key, (void *) &leaf_pnt, node_type, &n_clear_key,
				 &offset, COPY_KEY_VALUE, NULL) != NO_ERROR)
	    {
	      goto error;
	    }
	}
      else
	{
	  if (btree_read_record (thread_p, btid, page_ptr, &rec, next_key, (void *) &nleaf_pnt, node_type, &n_clear_key,
				 &offset, COPY_KEY_VALUE, NULL) != NO_ERROR)
	    {
	      goto error;
	    }
	}
    }

  /* now that we have the mid key and the next key, we can determine the prefix key. */
  prefix_key = (DB_VALUE *) db_private_alloc (thread_p, sizeof (DB_VALUE));
  if (prefix_key == NULL)
    {
      goto error;
    }

  /* Check if we can make use of prefix keys.  We can't use them in the upper levels of the trees because the algorithm
   * will fall apart.  We can only use them when splitting a leaf page. */
  if (node_type == BTREE_LEAF_NODE)
    {
      if ((btree_get_disk_size_of_key (mid_key) >= BTREE_MAX_KEYLEN_INPAGE)
	  || (btree_get_disk_size_of_key (next_key) >= BTREE_MAX_KEYLEN_INPAGE))
	{
	  /* if one of key is overflow key prefix key could be longer then max_key_len in page (that means insert could
	   * be failed) so, in this case use next key itself as prefix key */
	  pr_clone_value (next_key, prefix_key);
	}
      else
	{
	  if (btree_get_prefix_separator (mid_key, next_key, prefix_key, btid->key_type) != NO_ERROR)
	    {
	      goto error;
	    }
	}
    }
  else
    {
      /* return the next_key */
      pr_clone_value (next_key, prefix_key);
    }

  *clear_midkey = true;		/* we must always clear prefix keys */

  /* replace the mid_key with the prefix_key */
  tmp_key = mid_key;
  mid_key = prefix_key;
  prefix_key = tmp_key;		/* this makes sure we clear/free the old mid key */
  goto success;

  /* error handling and cleanup. */
error:

  if (mid_key)
    {
      btree_clear_key_value (&m_clear_key, mid_key);
      db_private_free_and_init (thread_p, mid_key);
    }
  mid_key = NULL;

  /* fall through */

success:

  if (next_key)
    {
      btree_clear_key_value (&n_clear_key, next_key);
      db_private_free_and_init (thread_p, next_key);
    }
  if (prefix_key)
    {
      pr_clear_value (prefix_key);
      db_private_free_and_init (thread_p, prefix_key);
    }

  return mid_key;
}

/*
 * btree_split_find_pivot () -
 *   return:
 *   total(in):
 *   split_info(in):
 */
static int
btree_split_find_pivot (int total, BTREE_NODE_SPLIT_INFO * split_info)
{
  int split_point;

  if (split_info->pivot == 0
      || (split_info->pivot > BTREE_SPLIT_LOWER_BOUND && split_info->pivot < BTREE_SPLIT_UPPER_BOUND))
    {
      split_point = CEIL_PTVDIV (total, 2);
    }
  else
    {
      split_point = (int) (total * MAX (MIN (split_info->pivot, BTREE_SPLIT_MAX_PIVOT), BTREE_SPLIT_MIN_PIVOT));
    }

  return split_point;
}

/*
 * btree_split_next_pivot () -
 *   return:
 *   split_info(in):
 *   new_value(in):
 *   max_index(in):
 */
static int
btree_split_next_pivot (BTREE_NODE_SPLIT_INFO * split_info, float new_value, int max_index)
{
  float new_pivot;

  assert (0.0f <= split_info->pivot);
  assert (split_info->pivot <= 1.0f);

  split_info->index = MIN (split_info->index + 1, max_index);

  if (split_info->pivot == 0)
    {
      new_pivot = new_value;
    }
  else
    {
      /* cumulative moving average(running average) */
      new_pivot = split_info->pivot;
      new_pivot = (new_pivot + ((new_value - new_pivot) / split_info->index));
    }

  split_info->pivot = MAX (0.0f, MIN (1.0f, new_pivot));

  return NO_ERROR;
}

static bool
btree_node_is_compressed (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR page_ptr)
{
  int key_cnt;
  RECDES peek_rec;
  BTREE_NODE_HEADER *header = NULL;
  BTREE_NODE_TYPE node_type;

  assert (btid != NULL);

  if (TP_DOMAIN_TYPE (btid->key_type) != DB_TYPE_MIDXKEY)
    {
      return false;
    }

  key_cnt = btree_node_number_of_keys (thread_p, page_ptr);
  if (key_cnt < 2)
    {
      return false;
    }

  header = btree_get_node_header (thread_p, page_ptr);
  if (header == NULL)
    {
      return false;
    }

  node_type = (header->node_level > 1) ? BTREE_NON_LEAF_NODE : BTREE_LEAF_NODE;

  if (node_type == BTREE_NON_LEAF_NODE)
    {
      return false;
    }

  /* check if lower fence key */
  if (spage_get_record (thread_p, page_ptr, 1, &peek_rec, PEEK) != S_SUCCESS)
    {
      assert (false);
    }
  if (btree_leaf_is_flaged (&peek_rec, BTREE_LEAF_RECORD_FENCE) == false)
    {
      return false;
    }

  /* check if upper fence key */
  assert (key_cnt > 0);
  if (spage_get_record (thread_p, page_ptr, key_cnt, &peek_rec, PEEK) != S_SUCCESS)
    {
      assert (false);
    }
  if (btree_leaf_is_flaged (&peek_rec, BTREE_LEAF_RECORD_FENCE) == false)
    {
      return false;
    }

  return true;
}

static int
btree_node_common_prefix (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR page_ptr)
{
  RECDES peek_rec;
  int diff_column;
  int key_cnt;

  DB_VALUE lf_key, uf_key;
  bool lf_clear_key = false, uf_clear_key = false;
  int offset;
  LEAF_REC leaf_pnt;
  int error = NO_ERROR;

  if (btree_node_is_compressed (thread_p, btid, page_ptr) == false)
    {
      return 0;
    }

  btree_init_temp_key_value (&lf_clear_key, &lf_key);
  btree_init_temp_key_value (&uf_clear_key, &uf_key);

  key_cnt = btree_node_number_of_keys (thread_p, page_ptr);
  assert (key_cnt >= 2);

  spage_get_record (thread_p, page_ptr, 1, &peek_rec, PEEK);
  error =
    btree_read_record_without_decompression (thread_p, btid, &peek_rec, &lf_key, &leaf_pnt, BTREE_LEAF_NODE,
					     &lf_clear_key, &offset, PEEK_KEY_VALUE);
  if (error != NO_ERROR)
    {
      goto cleanup;
    }
  assert (!btree_leaf_is_flaged (&peek_rec, BTREE_LEAF_RECORD_OVERFLOW_KEY));
  assert (btree_leaf_is_flaged (&peek_rec, BTREE_LEAF_RECORD_FENCE));
  assert (DB_VALUE_TYPE (&lf_key) == DB_TYPE_MIDXKEY);

  assert (key_cnt > 0);
  spage_get_record (thread_p, page_ptr, key_cnt, &peek_rec, PEEK);
  error =
    btree_read_record_without_decompression (thread_p, btid, &peek_rec, &uf_key, &leaf_pnt, BTREE_LEAF_NODE,
					     &uf_clear_key, &offset, PEEK_KEY_VALUE);
  if (error != NO_ERROR)
    {
      goto cleanup;
    }
  assert (!btree_leaf_is_flaged (&peek_rec, BTREE_LEAF_RECORD_OVERFLOW_KEY));
  assert (btree_leaf_is_flaged (&peek_rec, BTREE_LEAF_RECORD_FENCE));
  assert (DB_VALUE_TYPE (&uf_key) == DB_TYPE_MIDXKEY);

  diff_column = pr_midxkey_common_prefix (&lf_key, &uf_key);

cleanup:
  /* clean up */
  btree_clear_key_value (&lf_clear_key, &lf_key);
  btree_clear_key_value (&uf_clear_key, &uf_key);

  if (error == NO_ERROR)
    {
      return diff_column;
    }
  else
    {
      return error;
    }
}

/*
 * btree_recompress_record () - Re-compress record for new prefix.
 *
 * return	   : Error code.
 * thread_p (in)   : Thread entry.
 * btid_int (in)   : B-tree info.
 * record (in)	   : B-tree leaf record.
 * fence_key (in)  : Lower or upper fence key value.
 * old_prefix (in) : Old prefix.
 * new_prefix (in) : New prefix.
 */
static int
btree_recompress_record (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * record, DB_VALUE * fence_key,
			 int old_prefix, int new_prefix)
{
  int error_code = NO_ERROR;
  LEAF_REC dummy_leaf_record_info;
  int offset_after_key = 0;
  int new_offset_after_key = 0;
  int old_key_len = 0;
  int new_key_len = 0;
  int offset_before_key = 0;
  bool clear_key = false;
  DB_VALUE key;
  DB_VALUE recompress_key;
  OR_BUF write_key_buffer;

  assert (btid_int != NULL);
  assert (record != NULL);

  btree_init_temp_key_value (&clear_key, &key);

  if (old_prefix == new_prefix)
    {
      /* Recompression is not needed. */
      return NO_ERROR;
    }

  /* Fence key must have a value if uncompress is needed. */
  assert (old_prefix == 0 || (fence_key != NULL && !DB_IS_NULL (fence_key)));

  error_code =
    btree_read_record_without_decompression (thread_p, btid_int, record, &key, &dummy_leaf_record_info, BTREE_LEAF_NODE,
					     &clear_key, &offset_after_key, PEEK_KEY_VALUE);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      return error_code;
    }

  /* Save aligned size of old key. */
  old_key_len = btree_get_disk_size_of_key (&key);
  old_key_len = DB_ALIGN (old_key_len, INT_ALIGNMENT);

  /* Uncompress. */
  db_make_null (&recompress_key);
  if (old_prefix > 0)
    {
      pr_midxkey_add_prefix (&recompress_key, fence_key, &key, old_prefix);
    }
  else
    {
      pr_clone_value (&key, &recompress_key);
    }

  /* Compress. */
  if (new_prefix > 0)
    {
      pr_midxkey_remove_prefix (&recompress_key, new_prefix);
    }

  /* Save aligned size of new key. */
  new_key_len = btree_get_disk_size_of_key (&recompress_key);
  new_key_len = DB_ALIGN (new_key_len, INT_ALIGNMENT);

  offset_before_key = offset_after_key - old_key_len;

  /* Move the rest of the record first. */
  new_offset_after_key = offset_after_key + new_key_len - old_key_len;
  RECORD_MOVE_DATA (record, new_offset_after_key, offset_after_key);

  /* Pack new key. */
  or_init (&write_key_buffer, record->data + offset_before_key, new_key_len);
  btid_int->key_type->type->index_writeval (&write_key_buffer, &recompress_key);
  or_align (&write_key_buffer, INT_ALIGNMENT);
  assert (write_key_buffer.ptr == write_key_buffer.endptr);

  btree_clear_key_value (&clear_key, &key);
  pr_clear_value (&recompress_key);

  return NO_ERROR;
}

static int
btree_compress_node (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR page_ptr)
{
  int i, key_cnt, diff_column;
  RECDES peek_rec, rec;
  char rec_buf[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  DB_VALUE key;
  bool clear_key = false;
  int offset, new_offset, key_len, new_key_len;
  LEAF_REC leaf_pnt;
  int error = NO_ERROR;

  rec.area_size = DB_PAGESIZE;
  rec.data = PTR_ALIGN (rec_buf, BTREE_MAX_ALIGN);

  key_cnt = btree_node_number_of_keys (thread_p, page_ptr);

  diff_column = btree_node_common_prefix (thread_p, btid, page_ptr);
  if (diff_column == 0)
    {
      return 0;
    }
  else if (diff_column < 0)
    {
      return diff_column;
    }

  btree_init_temp_key_value (&clear_key, &key);

  /* compress prefix */
  for (i = 2; i < key_cnt; i++)
    {
      (void) spage_get_record (thread_p, page_ptr, i, &peek_rec, PEEK);

      assert (!btree_leaf_is_flaged (&peek_rec, BTREE_LEAF_RECORD_FENCE));

      if (btree_leaf_is_flaged (&peek_rec, BTREE_LEAF_RECORD_OVERFLOW_KEY))
	{
	  /* do not compress overflow key */
	  continue;
	}

      (void) spage_get_record (thread_p, page_ptr, i, &rec, COPY);

      error =
	btree_read_record_without_decompression (thread_p, btid, &rec, &key, &leaf_pnt, BTREE_LEAF_NODE, &clear_key,
						 &offset, PEEK_KEY_VALUE);
      if (error != NO_ERROR)
	{
	  return error;
	}
      assert (clear_key == false);

      key_len = btree_get_disk_size_of_key (&key);
      pr_midxkey_remove_prefix (&key, diff_column);
      new_key_len = btree_get_disk_size_of_key (&key);

      new_key_len = DB_ALIGN (new_key_len, INT_ALIGNMENT);
      key_len = DB_ALIGN (key_len, INT_ALIGNMENT);

      new_offset = offset + new_key_len - key_len;

      if (new_offset != offset)
	{
	  /* move the remaining part of record */
	  memmove (rec.data + new_offset, rec.data + offset, rec.length - offset);
	  rec.length = new_offset + (rec.length - offset);
	}

#if !defined (NDEBUG)
      btree_check_valid_record (thread_p, btid, &rec, BTREE_LEAF_NODE, &key);
#endif

      spage_update (thread_p, page_ptr, i, &rec);
      btree_clear_key_value (&clear_key, &key);
    }

#if !defined(NDEBUG)
  btree_verify_node (thread_p, btid, page_ptr);
#endif

  return error;
}

/*
 * btree_split_node () -
 *   return: NO_ERROR
 *           child_vpid is set to page identifier for the child page to be
 *           followed, Q or R, or the page identifier of a newly allocated
 *           page to insert the key, or NULL_PAGEID. The parameter key is
 *           set to the middle key that will be put into the parent page P.
 *   btid(in): The index identifier
 *   P(in): Page pointer for the parent page of page Q
 *   Q(in): Page pointer for the page to be split
 *   R(in): Page pointer for the newly allocated page
 *   next_page(in):
 *   P_vpid(in): Page identifier for page Q
 *   Q_vpid(in): Page identifier for page Q
 *   R_vpid(in): Page identifier for page R
 *   p_slot_id(in): The slot of parent page P which points to page Q
 *   node_type(in): shows whether page Q is a leaf page, or not
 *   key(in): the key caller is trying to follow
 *   helper(in): B-tree insert helper structure
 *   child_vpid(out): Set to the child page identifier based on key
 *
 * Note: Page Q is split into two pages: Q and R. The second half of
 * of the page Q is move to page R. The middle key of of the
 * split operation is moved to parent page P. Depending on the
 * split point, the whole page Q may be moved to page R, or the
 * whole page content may be kept in page Q. If the key can not
 * fit into one of the pages after the split, a new page is
 * allocated for the key and its page identifier is returned.
 * The headers of all pages are updated, accordingly.
 */
static int
btree_split_node (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR P, PAGE_PTR Q, PAGE_PTR R, VPID * P_vpid,
		  VPID * Q_vpid, VPID * R_vpid, INT16 p_slot_id, BTREE_NODE_TYPE node_type, DB_VALUE * key,
		  BTREE_INSERT_HELPER * helper, VPID * child_vpid)
{
  int key_cnt, leftcnt, rightcnt;
  RECDES peek_rec, rec;
  NON_LEAF_REC nleaf_rec;
  BTREE_NODE_HEADER *pheader = NULL, *qheader = NULL;
  BTREE_NODE_HEADER right_header_info, *rheader = NULL;
  int i, j, c;
  int sep_key_len, key_len;
  bool clear_sep_key;
  DB_VALUE *sep_key;
  int ret = NO_ERROR;
  char rec_buf[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  int key_type;

  bool flag_fence_insert = false;
  OID dummy_oid = { NULL_PAGEID, 0, 0 };
  int leftsize, rightsize;
  VPID right_next_vpid;
  int right_max_key_len;

  /* for recovery purposes */
  char *p_redo_data;
  int p_redo_length;
  char p_redo_data_buf[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];

  PAGE_PTR page_after_right = NULL;

  rheader = &right_header_info;

  /***********************************************************
   ***  STEP 0: initializations
   ***********************************************************/
  p_redo_data = NULL;

  rec.data = NULL;

  /* initialize child page identifier */
  VPID_SET_NULL (child_vpid);
  sep_key = NULL;

  /* Assert expected arguments. */
  assert (P != NULL);
  assert (Q != NULL);
  assert (R != NULL);
  assert (!VPID_ISNULL (P_vpid));
  assert (!VPID_ISNULL (Q_vpid));
  assert (!VPID_ISNULL (R_vpid));
  assert (pgbuf_get_latch_mode (P) == PGBUF_LATCH_WRITE);
  assert (pgbuf_get_latch_mode (Q) == PGBUF_LATCH_WRITE);
  assert (pgbuf_get_latch_mode (R) == PGBUF_LATCH_WRITE);

#if !defined(NDEBUG)
  if (prm_get_integer_value (PRM_ID_ER_BTREE_DEBUG) & BTREE_DEBUG_DUMP_SIMPLE)
    {
      printf ("btree_split_node: P{%d, %d}, Q{%d, %d}, R{%d, %d}\n", P_vpid->volid, P_vpid->pageid, Q_vpid->volid,
	      Q_vpid->pageid, R_vpid->volid, R_vpid->pageid);
    }
#endif

#if !defined(NDEBUG)
  btree_verify_node (thread_p, btid, P);
  btree_verify_node (thread_p, btid, Q);
#endif
  rec.area_size = DB_PAGESIZE;
  rec.data = PTR_ALIGN (rec_buf, BTREE_MAX_ALIGN);

  key_cnt = btree_node_number_of_keys (thread_p, Q);
  if (key_cnt <= 0)
    {
      ASSERT_ERROR_AND_SET (ret);
      goto exit_on_error;
    }

#if !defined(NDEBUG)
  if (prm_get_integer_value (PRM_ID_ER_BTREE_DEBUG) & BTREE_DEBUG_TEST_SPLIT)
    {
      btree_split_test (thread_p, btid, key, Q_vpid, Q, node_type);
    }
#endif

  /********************************************************************
   ***  STEP 1: find split point & sep_key
   ***          make fence key to be inserted
   ***
   ***   find the middle record of the page Q and find the number of
   ***   keys after split in pages Q and R, respectively
   ********************************************************************/
  qheader = btree_get_node_header (thread_p, Q);
  if (qheader == NULL)
    {
      assert_release (false);
      ret = ER_FAILED;
      goto exit_on_error;
    }

  sep_key = btree_find_split_point (thread_p, btid, Q, &leftcnt, key, helper, &clear_sep_key);
  if (sep_key == NULL || DB_IS_NULL (sep_key))
    {
      er_log_debug (ARG_FILE_LINE, "btree_split_node: Null middle key after split. Operation Ignored.\n");
      ASSERT_ERROR_AND_SET (ret);
      goto exit_on_error;
    }
  assert (leftcnt <= key_cnt && leftcnt >= 0);

  /* make fence record */
  if (node_type == BTREE_LEAF_NODE)
    {
      PR_TYPE *pr_type = btid->key_type->type;
      sep_key_len = pr_type->get_index_size_of_value (sep_key);

      if (sep_key_len < BTREE_MAX_KEYLEN_INPAGE && sep_key_len <= qheader->max_key_len)
	{
	  ret =
	    btree_write_record (thread_p, btid, NULL, sep_key, BTREE_LEAF_NODE, BTREE_NORMAL_KEY, sep_key_len, false,
				&btid->topclass_oid, &dummy_oid, NULL, &rec);
	  if (ret != NO_ERROR)
	    {
	      ASSERT_ERROR ();
	      goto exit_on_error;
	    }

	  btree_leaf_set_flag (&rec, BTREE_LEAF_RECORD_FENCE);

	  flag_fence_insert = true;
	}
      else
	{
	  /* do not insert fence key if sep_key is overflow key */
	  flag_fence_insert = false;
	}
    }

  if (prm_get_bool_value (PRM_ID_USE_BTREE_FENCE_KEY) == false)
    {
      flag_fence_insert = false;
    }

  rightcnt = key_cnt - leftcnt;

  /*********************************************************************
   ***  STEP 2: save undo image of Q
   ***		update Q, R header info
   *********************************************************************/
  /* add undo logging for page Q */
  log_append_undo_data2 (thread_p, RVBT_COPYPAGE, &btid->sys_btid->vfid, Q, -1, DB_PAGESIZE, Q);

  /* We may need to update the max_key length if the mid key is larger than the max key length.  This can happen due to
   * disk padding when the prefix key length approaches the fixed key length. */
  sep_key_len = btree_get_disk_size_of_key (sep_key);
  sep_key_len = BTREE_GET_KEY_LEN_IN_PAGE (sep_key_len);
  qheader->max_key_len = MAX (sep_key_len, qheader->max_key_len);

  /* set rheader max_key_len as qheader max_key_len */
  right_max_key_len = qheader->max_key_len;
  right_next_vpid = qheader->next_vpid;

  if (node_type == BTREE_LEAF_NODE)
    {
      qheader->next_vpid = *R_vpid;
    }
  else
    {
      VPID_SET_NULL (&qheader->next_vpid);
    }

  if (leftcnt == 0)
    {
      /* Only key length will exist in page. Set max key length. */
      /* Max key length would have been set when key is inserted. However, we set it here to suppress assert of
       * btree_verify_node. */
      qheader->max_key_len = BTREE_GET_KEY_LEN_IN_PAGE (btree_get_disk_size_of_key (key));
    }

  qheader->split_info.index = 1;

  rheader->node_level = qheader->node_level;
  rheader->max_key_len = right_max_key_len;
  if (key_cnt - leftcnt == 0 && flag_fence_insert == false)
    {
      /* Only key length will exist in page. Set max key length. */
      /* Max key length would have been set when key is inserted. However, we set it here to suppress assert of
       * btree_verify_node. */
      rheader->max_key_len = BTREE_GET_KEY_LEN_IN_PAGE (btree_get_disk_size_of_key (key));
    }

  rheader->next_vpid = right_next_vpid;

  if (node_type == BTREE_LEAF_NODE)
    {
      rheader->prev_vpid = *Q_vpid;
    }
  else
    {
      VPID_SET_NULL (&(rheader->prev_vpid));
    }

  rheader->split_info = qheader->split_info;

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  ret = btree_init_node_header (thread_p, &btid->sys_btid->vfid, R, rheader, false);
  if (ret != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto exit_on_error;
    }

  /*******************************************************************
   ***   STEP 3: move second half of page Q to page R
   ***           insert fence key to Q
   ***           make redo image for Q
   *******************************************************************/
  /* lower fence key for R */
  rightsize = 0;
  j = 1;
  if (flag_fence_insert == true)
    {
      rightsize = j;
      assert (j > 0);
      if (spage_insert_at (thread_p, R, j++, &rec) != SP_SUCCESS)
	{
	  ret = ER_FAILED;
	  goto exit_on_error;
	}
    }

  /* move the second half of page Q to page R */
  for (i = 1; i <= rightcnt; i++, j++)
    {
      assert (leftcnt + 1 > 0);
      if (spage_get_record (thread_p, Q, leftcnt + 1, &peek_rec, PEEK) != S_SUCCESS)
	{
	  assert_release (false);
	  ret = ER_FAILED;
	  goto exit_on_error;
	}

      assert (j > 0);
      if (spage_insert_at (thread_p, R, j, &peek_rec) != SP_SUCCESS)
	{
	  assert_release (false);
	  ret = ER_FAILED;
	  goto exit_on_error;
	}

      rightsize = j;

      assert (leftcnt + 1 > 0);
      if (spage_delete (thread_p, Q, leftcnt + 1) != leftcnt + 1)
	{
	  assert_release (false);
	  ret = ER_FAILED;
	  goto exit_on_error;
	}
    }

  leftsize = leftcnt;
  /* upper fence key for Q */
  if (flag_fence_insert == true)
    {
      assert (leftcnt + 1 > 0);
      if (spage_insert_at (thread_p, Q, leftcnt + 1, &rec) != SP_SUCCESS)
	{
	  assert_release (false);
	  ret = ER_FAILED;
	  goto exit_on_error;
	}
      leftsize++;
    }

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  ret = btree_compress_node (thread_p, btid, Q);
  if (ret != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto exit_on_error;
    }

  /* add redo logging for page Q */
  log_append_redo_data2 (thread_p, RVBT_COPYPAGE, &btid->sys_btid->vfid, Q, -1, DB_PAGESIZE, Q);

  /***************************************************************************
   ***   STEP 4: add redo log for R
   ***    Log the second half of page Q for redo purposes on Page R,
   ***    the records on the second half of page Q will be inserted to page R
   ***************************************************************************/

  ret = btree_compress_node (thread_p, btid, R);
  if (ret != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto exit_on_error;
    }

  log_append_redo_data2 (thread_p, RVBT_COPYPAGE, &btid->sys_btid->vfid, R, -1, DB_PAGESIZE, R);

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  /****************************************************************************
   ***   STEP 5: insert sep_key to P
   ***           add undo/redo log for page P
   ***
   ***    update the parent page P to keep the middle key and to point to
   ***    pages Q and R.  Remember that this mid key will be on a non leaf page
   ***    regardless of whether we are splitting a leaf or non leaf page.
   ****************************************************************************/
  nleaf_rec.pnt = *R_vpid;
  key_len = btree_get_disk_size_of_key (sep_key);
  if (key_len < BTREE_MAX_KEYLEN_INPAGE)
    {
      key_type = BTREE_NORMAL_KEY;
      nleaf_rec.key_len = key_len;
    }
  else
    {
      key_type = BTREE_OVERFLOW_KEY;
      nleaf_rec.key_len = -1;
    }

  ret =
    btree_write_record (thread_p, btid, &nleaf_rec, sep_key, BTREE_NON_LEAF_NODE, key_type, key_len, false, NULL, NULL,
			NULL, &rec);
  if (ret != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto exit_on_error;
    }

  p_slot_id++;

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  /* add undo/redo logging for page P */
  assert (p_slot_id > 0);
  if (spage_insert_at (thread_p, P, p_slot_id, &rec) != SP_SUCCESS)
    {
      assert_release (false);
      ret = ER_FAILED;
      goto exit_on_error;
    }

  p_redo_data = PTR_ALIGN (p_redo_data_buf, BTREE_MAX_ALIGN);

  btree_rv_write_log_record (p_redo_data, &p_redo_length, &rec, BTREE_NON_LEAF_NODE);
  log_append_undoredo_data2 (thread_p, RVBT_NDRECORD_INS, &btid->sys_btid->vfid, P, p_slot_id, sizeof (p_slot_id),
			     p_redo_length, &p_slot_id, p_redo_data);

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  key_cnt = btree_node_number_of_keys (thread_p, P);
  assert_release (key_cnt > 0);

  pheader = btree_get_node_header (thread_p, P);
  if (pheader == NULL)
    {
      assert_release (false);
      ret = ER_FAILED;
      goto exit_on_error;
    }

  assert_release (pheader->split_info.pivot >= 0);

  btree_node_header_undo_log (thread_p, &btid->sys_btid->vfid, P);

  btree_split_next_pivot (&pheader->split_info, (float) p_slot_id / key_cnt, key_cnt);

  /* We may need to update the max_key length if the mid key is larger than the max key length. This can happen due to
   * disk padding when the prefix key length approaches the fixed key length. */
  sep_key_len = btree_get_disk_size_of_key (sep_key);
  sep_key_len = BTREE_GET_KEY_LEN_IN_PAGE (sep_key_len);
  pheader->max_key_len = MAX (sep_key_len, pheader->max_key_len);

  btree_node_header_redo_log (thread_p, &btid->sys_btid->vfid, P);

  /* find the child page to be followed */
  c = btree_compare_key (key, sep_key, btid->key_type, 1, 1, NULL);
  assert (c == DB_LT || c == DB_EQ || c == DB_GT);

  if (c == DB_UNK)
    {
      assert_release (false);
      ret = ER_FAILED;
      goto exit_on_error;
    }
  else if (c < 0)
    {
      /* set child page pointer */
      *child_vpid = *Q_vpid;
    }
  else
    {
      /* set child page pointer */
      *child_vpid = *R_vpid;
    }

  /* TODO : update child_vpid max_key_len */
  if (sep_key)
    {
      btree_clear_key_value (&clear_sep_key, sep_key);
      db_private_free_and_init (thread_p, sep_key);
    }

  pgbuf_set_dirty (thread_p, P, DONT_FREE);
  pgbuf_set_dirty (thread_p, Q, DONT_FREE);
  pgbuf_set_dirty (thread_p, R, DONT_FREE);

  if (rheader->node_level == 1)
    {
      /* Since leaf level can be processed in reversed order, we need to update the prev link of next page after the
       * one that was split. */
      page_after_right = btree_get_next_page (thread_p, R);
      if (page_after_right != NULL)
	{
	  ret = btree_set_vpid_previous_vpid (thread_p, btid, page_after_right, R_vpid);
	  /* We don't expect any errors here. */
	  assert (ret == NO_ERROR);
	  pgbuf_unfix_and_init (thread_p, page_after_right);
	}
    }

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  perfmon_inc_stat (thread_p, PSTAT_BT_NUM_SPLITS);

#if !defined(NDEBUG)
  btree_verify_node (thread_p, btid, P);
  btree_verify_node (thread_p, btid, Q);
  btree_verify_node (thread_p, btid, R);
#endif

  return ret;

exit_on_error:

  if (sep_key)
    {
      btree_clear_key_value (&clear_sep_key, sep_key);
      db_private_free_and_init (thread_p, sep_key);
    }

  assert (ret != NO_ERROR);
  return ret;
}

#if !defined(NDEBUG)
/*
 * btree_set_split_point () -
 *   return: the key or key separator (prefix) to be moved to the
 *           parent page, or NULL_KEY. The length of the returned
 *           key, or prefix, is set in mid_keylen. The parameter
 *           mid_slot is set to the record number of the split point record.
 *   btid(in):
 *   page_ptr(in): Pointer to the page
 *   mid_slot(in): Set to contain the record number for the split point slot
 *   key(in): Key to be inserted to the index
 *   clear_midkey(in):
 *
 */
static DB_VALUE *
btree_set_split_point (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR page_ptr, INT16 mid_slot, DB_VALUE * key,
		       bool * clear_midkey)
{
  RECDES rec;
  BTREE_NODE_HEADER *header = NULL;
  BTREE_NODE_TYPE node_type;
  INT16 slot_id;
  int key_cnt, offset;
  bool m_clear_key, n_clear_key;
  DB_VALUE *mid_key = NULL, *next_key = NULL, *prefix_key = NULL, *tmp_key;
  NON_LEAF_REC nleaf_pnt;
  LEAF_REC leaf_pnt;
  BTREE_SEARCH_KEY_HELPER search_key;

  key_cnt = btree_node_number_of_keys (thread_p, page_ptr);
  if (key_cnt <= 0)
    {
      assert (false);
    }

  /* get the page header */
  header = btree_get_node_header (thread_p, page_ptr);
  if (header == NULL)
    {
      assert (false);
    }

  node_type = (header->node_level > 1) ? BTREE_NON_LEAF_NODE : BTREE_LEAF_NODE;

  /* find the slot position of the key if it is to be located in the page */
  if (node_type == BTREE_LEAF_NODE)
    {
      if (btree_search_leaf_page (thread_p, btid, page_ptr, key, &search_key) != NO_ERROR)
	{
	  assert (false);
	}
      slot_id = search_key.slotid;
      if (slot_id == NULL_SLOTID)	/* leaf search failed */
	{
	  assert (false);
	}
    }
  else
    {
      slot_id = NULL_SLOTID;
    }

  mid_key = (DB_VALUE *) db_private_alloc (thread_p, sizeof (DB_VALUE));
  if (mid_key == NULL)
    {
      assert (false);
    }

  btree_init_temp_key_value (&m_clear_key, mid_key);

  /* the split key is one of the keys on the page */
  assert (mid_slot > 0);
  if (spage_get_record (thread_p, page_ptr, mid_slot, &rec, PEEK) != S_SUCCESS)
    {
      assert (false);
    }

  /* we copy the key here because rec lives on the stack and mid_key is returned from this routine. */
  if (node_type == BTREE_LEAF_NODE)
    {
      if (btree_read_record (thread_p, btid, page_ptr, &rec, mid_key, (void *) &leaf_pnt, node_type, &m_clear_key,
			     &offset, COPY_KEY_VALUE, NULL) != NO_ERROR)
	{
	  assert (false);
	}
    }
  else
    {
      if (btree_read_record (thread_p, btid, page_ptr, &rec, mid_key, (void *) &nleaf_pnt, node_type, &m_clear_key,
			     &offset, COPY_KEY_VALUE, NULL) != NO_ERROR)
	{
	  assert (false);
	}
    }

  /* The determination of the prefix key is dependent on the next key */
  next_key = (DB_VALUE *) db_private_alloc (thread_p, sizeof (DB_VALUE));
  if (next_key == NULL)
    {
      assert (false);
    }

  btree_init_temp_key_value (&n_clear_key, next_key);

  if (mid_slot == key_cnt && slot_id == (key_cnt + 1))
    {
      /* the next key is the new key, we don't have to read it */
      n_clear_key = true;
      if (pr_clone_value (key, next_key) != NO_ERROR)
	{
	  assert (false);
	}
    }
  else
    {
      /* The next key is one of the keys on the page */
      assert (mid_slot + 1 > 0);
      if (spage_get_record (thread_p, page_ptr, mid_slot + 1, &rec, PEEK) != S_SUCCESS)
	{
	  assert (false);
	}

      /* we copy the key here because rec lives on the stack and mid_key is returned from this routine. */
      if (node_type == BTREE_LEAF_NODE)
	{
	  if (btree_read_record (thread_p, btid, page_ptr, &rec, next_key, (void *) &leaf_pnt, node_type, &n_clear_key,
				 &offset, COPY_KEY_VALUE, NULL) != NO_ERROR)
	    {
	      assert (false);
	    }
	}
      else
	{
	  if (btree_read_record (thread_p, btid, page_ptr, &rec, next_key, (void *) &nleaf_pnt, node_type, &n_clear_key,
				 &offset, COPY_KEY_VALUE, NULL) != NO_ERROR)
	    {
	      assert (false);
	    }
	}
    }

  /* now that we have the mid key and the next key, we can determine the prefix key. */

  prefix_key = (DB_VALUE *) db_private_alloc (thread_p, sizeof (DB_VALUE));
  if (prefix_key == NULL)
    {
      assert (false);
    }

  /* Check if we can make use of prefix keys.  We can't use them in the upper levels of the trees because the algorithm
   * will fall apart.  We can only use them when splitting a leaf page. */
  if (node_type == BTREE_LEAF_NODE)
    {
      if (btree_get_prefix_separator (mid_key, next_key, prefix_key, btid->key_type) != NO_ERROR)
	{
	  assert (false);
	}
    }
  else
    {
      /* return the next_key */
      pr_clone_value (next_key, prefix_key);
    }

  *clear_midkey = true;		/* we must always clear prefix keys */

  /* replace the mid_key with the prefix_key */
  tmp_key = mid_key;
  mid_key = prefix_key;
  prefix_key = tmp_key;		/* this makes sure we clear/free the old mid key */

  if (next_key)
    {
      btree_clear_key_value (&n_clear_key, next_key);
      db_private_free_and_init (thread_p, next_key);
    }
  if (prefix_key)
    {
      pr_clear_value (prefix_key);
      db_private_free_and_init (thread_p, prefix_key);
    }

  return mid_key;
}

/*
 * btree_split_test () -
 *
 *   btid(in):
 *   key(in):
 *   S_vpid(in):
 *   S_page(in):
 *   node_type(in):
 */
static void
btree_split_test (THREAD_ENTRY * thread_p, BTID_INT * btid, DB_VALUE * key, VPID * S_vpid, PAGE_PTR S_page,
		  BTREE_NODE_TYPE node_type)
{
  RECDES rec, peek_rec;
  int i, j, key_cnt, lcnt, rcnt, sep_key_len, ret;
  PAGE_PTR L_page, R_page;
  VPID L_vpid, R_vpid;
  BTREE_NODE_HEADER header_info, *header = NULL;
  DB_VALUE *sep_key;
  bool fence_insert = false;
  bool clear_sep_key = true;
  OID dummy_oid = { NULL_PAGEID, 0, 0 };
  char rec_buf[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];

  log_sysop_start (thread_p);

  header = &header_info;

  rec.area_size = DB_PAGESIZE;
  rec.data = PTR_ALIGN (rec_buf, BTREE_MAX_ALIGN);

  key_cnt = btree_node_number_of_keys (thread_p, S_page);
  assert (key_cnt > 0);

  L_page = btree_get_new_page (thread_p, btid, &L_vpid, S_vpid);
  R_page = btree_get_new_page (thread_p, btid, &R_vpid, S_vpid);

  /* dummy header */
  memset (header, 0, sizeof (BTREE_NODE_HEADER));
  btree_init_node_header (thread_p, &btid->sys_btid->vfid, L_page, header, false);
  btree_init_node_header (thread_p, &btid->sys_btid->vfid, R_page, header, false);

  for (lcnt = 1; lcnt < key_cnt; i++)
    {
      fence_insert = false;
      sep_key = btree_set_split_point (thread_p, btid, S_page, lcnt, key, &clear_sep_key);
      assert (sep_key != NULL);

      if (node_type == BTREE_LEAF_NODE)
	{
	  PR_TYPE *pr_type;

	  pr_type = btid->key_type->type;
	  sep_key_len = pr_type->get_index_size_of_value (sep_key);

	  if (sep_key_len < BTREE_MAX_KEYLEN_INPAGE)
	    {
	      ret =
		btree_write_record (thread_p, btid, NULL, sep_key, BTREE_LEAF_NODE, BTREE_NORMAL_KEY, sep_key_len,
				    false, &btid->topclass_oid, &dummy_oid, NULL, &rec);

	      btree_leaf_set_flag (&rec, BTREE_LEAF_RECORD_FENCE);
	      fence_insert = true;
	    }
	}

      rcnt = key_cnt - lcnt;

      /* Right page test */
      j = 1;
      /* lower fence key for Right */
      if (fence_insert == true)
	{
	  assert (j > 0);
	  ret = spage_insert_at (thread_p, R_page, j++, &rec);
	  if (ret != SP_SUCCESS)
	    {
	      assert (false);
	    }
	}

      /* move the second half of page P to page R */
      for (i = 1; i <= rcnt; i++, j++)
	{
	  assert (lcnt + i > 0);
	  ret = spage_get_record (thread_p, S_page, lcnt + i, &peek_rec, PEEK);
	  if (ret != S_SUCCESS)
	    {
	      assert (false);
	    }

	  assert (j > 0);
	  ret = spage_insert_at (thread_p, R_page, j, &peek_rec);
	  if (ret != SP_SUCCESS)
	    {
	      assert (false);
	    }
	}

      /* Left page test */
      for (i = 1; i <= lcnt; i++)
	{
	  ret = spage_get_record (thread_p, S_page, i, &peek_rec, PEEK);
	  if (ret != S_SUCCESS)
	    {
	      assert (false);
	    }

	  ret = spage_insert_at (thread_p, L_page, i, &peek_rec);
	  if (ret != SP_SUCCESS)
	    {
	      assert (false);
	    }
	}

      /* upper fence key for Left */
      if (fence_insert == true)
	{
	  assert (i > 0);
	  ret = spage_insert_at (thread_p, L_page, i, &rec);
	  if (ret != SP_SUCCESS)
	    {
	      assert (false);
	    }
	}

      /* clean up */
      if (fence_insert == true)
	{
	  lcnt++, rcnt++;
	}

      assert (btree_node_number_of_keys (thread_p, L_page) == lcnt);
      assert (btree_node_number_of_keys (thread_p, R_page) == rcnt);

      for (i = 1; i <= lcnt; i++)
	{
	  ret = spage_delete (thread_p, L_page, 1);
	  if (ret != 1)
	    {
	      assert (false);
	    }
	}

      for (i = 1; i <= rcnt; i++)
	{
	  ret = spage_delete (thread_p, R_page, 1);
	  if (ret != 1)
	    {
	      assert (false);
	    }
	}

      assert (btree_node_number_of_keys (thread_p, L_page) == 0);
      assert (btree_node_number_of_keys (thread_p, R_page) == 0);

      btree_clear_key_value (&clear_sep_key, sep_key);
      db_private_free_and_init (thread_p, sep_key);
    }

  pgbuf_unfix_and_init (thread_p, L_page);
  pgbuf_unfix_and_init (thread_p, R_page);

  /* this was just a test, abort all changes */
  log_sysop_abort (thread_p);
}
#endif

/*
 * btree_split_root () -
 *   return: NO_ERROR
 *           child_vpid parameter is set to the child page to be followed
 *           after the split operation, or the page identifier of a newly
 *           allocated page for future key insertion, or NULL_PAGEID.
 *           The parameter key is set to the middle key of the split operation.
 *   btid(in): B+tree index identifier
 *   P(in): Page pointer for the root to be split
 *   Q(in): Page pointer for the newly allocated page
 *   R(in): Page pointer for the newly allocated page
 *   P_vpid(in): Page identifier for root page P
 *   Q_vpid(in): Page identifier for page Q
 *   R_vpid(in): Page identifier for page R
 *   node_type(in): shows whether root is currently a leaf page, or not
 *   key(in): the key caller is trying to follow
 *   helper(in): B-tree insert helper structure
 *   child_vpid(out): Set to the child page identifier based on key.
 *
 * Note: The root page P is split into two pages: Q and R. In order
 * not to change the actual root page, the first half of the page
 * is moved to page Q and the second half is moved to page R.
 * Depending on the split point found, the whole root page may be
 * moved to Q, or R, leaving the other one empty for future  key
 * insertion. If the key cannot fit into either Q or R after the
 * split, a new page is allocated and its page identifier is
 * returned. Two new records are formed within root page to point
 * to pages Q and R. The headers of all pages are updated.
 */
static int
btree_split_root (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR P, PAGE_PTR Q, PAGE_PTR R, VPID * P_vpid,
		  VPID * Q_vpid, VPID * R_vpid, BTREE_NODE_TYPE node_type, DB_VALUE * key, BTREE_INSERT_HELPER * helper,
		  VPID * child_vpid)
{
  int key_cnt, leftcnt, rightcnt;
  RECDES rec, peek_rec;
  NON_LEAF_REC nleaf_rec;
  BTREE_ROOT_HEADER *pheader = NULL;
  BTREE_NODE_HEADER q_header_info, *qheader = NULL;
  BTREE_NODE_HEADER r_header_info, *rheader = NULL;
  int i, j, c;
  int sep_key_len, key_len;
  bool clear_sep_key;
  DB_VALUE *sep_key;
  DB_VALUE *neg_inf_key = NULL;
  char *recset_data;		/* for recovery purposes */
  RECSET_HEADER recset_header;	/* for recovery purposes */
  int recset_length;		/* for recovery purposes */
  int sp_success;
  PGLENGTH log_addr_offset;
  int ret = NO_ERROR;
  char rec_buf[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  char recset_data_buf[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  int key_type;
  BTREE_NODE_SPLIT_INFO split_info;
  int node_level;
  bool flag_fence_insert = false;
  OID dummy_oid = { NULL_PAGEID, 0, 0 };
  int leftsize, rightsize;

  qheader = &q_header_info;
  rheader = &r_header_info;

  /***********************************************************
   ***  STEP 0: initializations
   ***********************************************************/
  recset_data = NULL;
  rec.data = NULL;

  /* initialize child page identifier */
  VPID_SET_NULL (child_vpid);
  sep_key = NULL;

#if !defined(NDEBUG)
  if ((!P || !Q || !R) || VPID_ISNULL (P_vpid) || VPID_ISNULL (Q_vpid) || VPID_ISNULL (R_vpid))
    {
      goto exit_on_error;
    }
#endif

#if !defined(NDEBUG)
  if (prm_get_integer_value (PRM_ID_ER_BTREE_DEBUG) & BTREE_DEBUG_DUMP_SIMPLE)
    {
      printf ("btree_split_root: P{%d, %d}, Q{%d, %d}, R{%d, %d}\n", P_vpid->volid, P_vpid->pageid, Q_vpid->volid,
	      Q_vpid->pageid, R_vpid->volid, R_vpid->pageid);
    }
#endif

#if !defined(NDEBUG)
  btree_verify_node (thread_p, btid, P);
#endif

  /* initializations */
  rec.area_size = DB_PAGESIZE;
  rec.data = PTR_ALIGN (rec_buf, BTREE_MAX_ALIGN);

  /* log the whole root page P for undo purposes. */
  log_append_undo_data2 (thread_p, RVBT_COPYPAGE, &btid->sys_btid->vfid, P, -1, DB_PAGESIZE, P);

  /* get the number of keys in the root page P */
  key_cnt = btree_node_number_of_keys (thread_p, P);
  if (key_cnt <= 0)
    {
      goto exit_on_error;
    }

#if !defined(NDEBUG)
  node_level = btree_get_node_level (thread_p, P);
  assert (node_level >= 1);
#endif

  pheader = btree_get_root_header (thread_p, P);
  if (pheader == NULL)
    {
      goto exit_on_error;
    }

  split_info = pheader->node.split_info;
  split_info.index = 1;

#if !defined(NDEBUG)
  if (prm_get_integer_value (PRM_ID_ER_BTREE_DEBUG) & BTREE_DEBUG_TEST_SPLIT)
    {
      btree_split_test (thread_p, btid, key, P_vpid, P, node_type);
    }
#endif

  /********************************************************************
   ***  STEP 1: find split point & sep_key
   ***          make fence key to be inserted
   ***
   ***   find the middle record of the page Q and find the number of
   ***   keys after split in pages Q and R, respectively
   ********************************************************************/

  sep_key = btree_find_split_point (thread_p, btid, P, &leftcnt, key, helper, &clear_sep_key);
  if (sep_key == NULL || DB_IS_NULL (sep_key))
    {
      er_log_debug (ARG_FILE_LINE, "btree_split_root: Null middle key after split. Operation Ignored.\n");
      goto exit_on_error;
    }
  assert (leftcnt <= key_cnt && leftcnt >= 0);

  /* make fence record */
  if (node_type == BTREE_LEAF_NODE)
    {
      PR_TYPE *pr_type;

      pr_type = btid->key_type->type;

      sep_key_len = pr_type->get_index_size_of_value (sep_key);

      if (sep_key_len < BTREE_MAX_KEYLEN_INPAGE && sep_key_len <= pheader->node.max_key_len)
	{
	  ret =
	    btree_write_record (thread_p, btid, NULL, sep_key, BTREE_LEAF_NODE, BTREE_NORMAL_KEY, sep_key_len, false,
				&btid->topclass_oid, &dummy_oid, NULL, &rec);
	  if (ret != NO_ERROR)
	    {
	      goto exit_on_error;
	    }

	  btree_leaf_set_flag (&rec, BTREE_LEAF_RECORD_FENCE);
	  flag_fence_insert = true;
	}
      else
	{
	  /* do not insert fence key if sep_key is overflow key */
	  flag_fence_insert = false;
	}
    }

  if (prm_get_bool_value (PRM_ID_USE_BTREE_FENCE_KEY) == false)
    {
      flag_fence_insert = false;
    }

  /* neg-inf key is dummy key which is not used in comparison so set it as sep_key */
  neg_inf_key = sep_key;

  rightcnt = key_cnt - leftcnt;

  /*********************************************************************
   ***  STEP 2: update P, Q, R header info
   *********************************************************************/
  /* update page P header */
  pheader->node.node_level++;

  /* We may need to update the max_key length if the sep key is larger than the max key length. This can happen due to
   * disk padding when the prefix key length approaches the fixed key length. */
  sep_key_len = btree_get_disk_size_of_key (sep_key);
  sep_key_len = BTREE_GET_KEY_LEN_IN_PAGE (sep_key_len);
  pheader->node.max_key_len = MAX (sep_key_len, pheader->node.max_key_len);
  btree_write_default_split_info (&(pheader->node.split_info));

  btree_node_header_redo_log (thread_p, &btid->sys_btid->vfid, P);

  /* update page Q header */
  qheader->node_level = pheader->node.node_level - 1;
  qheader->max_key_len = pheader->node.max_key_len;
  if (leftcnt == 0 && flag_fence_insert == false)
    {
      /* Only key length will exist in page. Set max key length. */
      /* Max key length would have been set when key is inserted. However, we set it here to suppress assert of
       * btree_verify_node. */
      qheader->max_key_len = BTREE_GET_KEY_LEN_IN_PAGE (btree_get_disk_size_of_key (key));
    }

  VPID_SET_NULL (&(qheader->prev_vpid));	/* non leaf or first leaf node */

  if (node_type == BTREE_LEAF_NODE)
    {
      qheader->next_vpid = *R_vpid;
    }
  else
    {
      VPID_SET_NULL (&(qheader->next_vpid));
    }

  qheader->split_info = split_info;

  if (btree_init_node_header (thread_p, &btid->sys_btid->vfid, Q, qheader, true) != NO_ERROR)
    {
      goto exit_on_error;
    }

  /* update page R header */
  rheader->node_level = pheader->node.node_level - 1;
  rheader->max_key_len = pheader->node.max_key_len;
  if (key_cnt - leftcnt == 0 && flag_fence_insert == false)
    {
      /* Only key length will exist in page. Set max key length. */
      /* Max key length would have been set when key is inserted. However, we set it here to suppress assert of
       * btree_verify_node. */
      rheader->max_key_len = BTREE_GET_KEY_LEN_IN_PAGE (btree_get_disk_size_of_key (key));
    }

  VPID_SET_NULL (&(rheader->next_vpid));	/* non leaf or last leaf node */

  if (node_type == BTREE_LEAF_NODE)
    {
      rheader->prev_vpid = *Q_vpid;
    }
  else
    {
      VPID_SET_NULL (&(rheader->prev_vpid));
    }

  rheader->split_info = split_info;

  if (btree_init_node_header (thread_p, &btid->sys_btid->vfid, R, rheader, true) != NO_ERROR)
    {
      goto exit_on_error;
    }


  /*******************************************************************
   ***   STEP 3: move second half of page P to page R
   ***           insert fence key to R
   ***           add undo / redo log for R
   *******************************************************************/
  /* move the second half of root page P to page R */
  assert (btree_node_number_of_keys (thread_p, P) == leftcnt + rightcnt);

  j = 1;
  /* lower fence key for page R */
  if (flag_fence_insert == true)
    {
      rightsize = j;
      assert (j > 0);
      if (spage_insert_at (thread_p, R, j++, &rec) != SP_SUCCESS)
	{
	  goto exit_on_error;
	}
    }

  for (i = 1; i <= rightcnt; i++, j++)
    {
      assert (leftcnt + 1 > 0);
      if (spage_get_record (thread_p, P, leftcnt + 1, &peek_rec, PEEK) != S_SUCCESS)
	{
	  goto exit_on_error;
	}

      assert (j > 0);
      sp_success = spage_insert_at (thread_p, R, j, &peek_rec);
      if (sp_success != SP_SUCCESS)
	{
	  goto exit_on_error;
	}
      rightsize = j;

      assert (leftcnt + 1 > 0);
      if (spage_delete (thread_p, P, leftcnt + 1) != leftcnt + 1)
	{
	  goto exit_on_error;
	}
    }

  /* for recovery purposes */
  recset_data = PTR_ALIGN (recset_data_buf, BTREE_MAX_ALIGN);

  /* Log page R records for redo purposes */
  ret = btree_rv_util_save_page_records (thread_p, R, 1, j - 1, 1, recset_data, &recset_length);
  if (ret != NO_ERROR)
    {
      goto exit_on_error;
    }

  log_append_redo_data2 (thread_p, RVBT_INS_PGRECORDS, &btid->sys_btid->vfid, R, -1, recset_length, recset_data);


  /*******************************************************************
   ***   STEP 4: move first half of page P to page Q
   ***           insert fence key to Q
   ***           add undo / redo log for Q
   *******************************************************************/
  /* move the first half of root page P to page Q */

  for (i = 1; i <= leftcnt; i++)
    {
      if (spage_get_record (thread_p, P, 1, &peek_rec, PEEK) != S_SUCCESS)
	{
	  goto exit_on_error;
	}

      sp_success = spage_insert_at (thread_p, Q, i, &peek_rec);
      if (sp_success != SP_SUCCESS)
	{
	  goto exit_on_error;
	}
      leftsize = i;

      if (spage_delete (thread_p, P, 1) != 1)
	{
	  goto exit_on_error;
	}
    }

  /* upper fence key for Q */
  if (flag_fence_insert == true)
    {
      assert (i > 0);
      if (spage_insert_at (thread_p, Q, i, &rec) != SP_SUCCESS)
	{
	  goto exit_on_error;
	}
      leftsize = i;
    }
  else
    {
      i--;
    }

  /* Log page Q records for redo purposes */
  ret = btree_rv_util_save_page_records (thread_p, Q, 1, i, 1, recset_data, &recset_length);
  if (ret != NO_ERROR)
    {
      goto exit_on_error;
    }
  log_append_redo_data2 (thread_p, RVBT_INS_PGRECORDS, &btid->sys_btid->vfid, Q, -1, recset_length, recset_data);

  /****************************************************************************
   ***   STEP 5: insert sep_key to P
   ***           add redo log for page P
   ****************************************************************************/

  /* Log deletion of all page P records (except the header!!) for redo purposes */
  recset_header.rec_cnt = key_cnt;
  recset_header.first_slotid = 1;
  log_append_redo_data2 (thread_p, RVBT_DEL_PGRECORDS, &btid->sys_btid->vfid, P, -1, sizeof (RECSET_HEADER),
			 &recset_header);

  /* update the root page P to keep the middle key and to point to page Q and R.  Remember that this mid key will be on
   * a non leaf page regardless of whether we are splitting a leaf or non leaf page. */
  nleaf_rec.pnt = *Q_vpid;
  key_len = btree_get_disk_size_of_key (neg_inf_key);
  if (key_len < BTREE_MAX_KEYLEN_INPAGE)
    {
      key_type = BTREE_NORMAL_KEY;
      nleaf_rec.key_len = key_len;
    }
  else
    {
      key_type = BTREE_OVERFLOW_KEY;
      nleaf_rec.key_len = -1;
    }

  ret =
    btree_write_record (thread_p, btid, &nleaf_rec, neg_inf_key, BTREE_NON_LEAF_NODE, key_type, key_len, false, NULL,
			NULL, NULL, &rec);
  if (ret != NO_ERROR)
    {
      goto exit_on_error;
    }

  if (spage_insert_at (thread_p, P, 1, &rec) != SP_SUCCESS)
    {
      goto exit_on_error;
    }

  /* log the inserted record for undo/redo purposes, */
  btree_rv_write_log_record (recset_data, &recset_length, &rec, BTREE_NON_LEAF_NODE);

  log_addr_offset = 1;
  log_append_redo_data2 (thread_p, RVBT_NDRECORD_INS, &btid->sys_btid->vfid, P, log_addr_offset, recset_length,
			 recset_data);

  nleaf_rec.pnt = *R_vpid;
  key_len = btree_get_disk_size_of_key (sep_key);
  if (key_len < BTREE_MAX_KEYLEN_INPAGE)
    {
      key_type = BTREE_NORMAL_KEY;
      nleaf_rec.key_len = key_len;
    }
  else
    {
      key_type = BTREE_OVERFLOW_KEY;
      nleaf_rec.key_len = -1;
    }

  ret =
    btree_write_record (thread_p, btid, &nleaf_rec, sep_key, BTREE_NON_LEAF_NODE, key_type, key_len, false, NULL, NULL,
			NULL, &rec);
  if (ret != NO_ERROR)
    {
      goto exit_on_error;
    }

  if (spage_insert_at (thread_p, P, 2, &rec) != SP_SUCCESS)
    {
      goto exit_on_error;
    }

  /* log the inserted record for undo/redo purposes, */
  btree_rv_write_log_record (recset_data, &recset_length, &rec, BTREE_NON_LEAF_NODE);

  log_addr_offset = 2;
  log_append_redo_data2 (thread_p, RVBT_NDRECORD_INS, &btid->sys_btid->vfid, P, log_addr_offset, recset_length,
			 recset_data);

  /* find the child page to be followed */

  c = btree_compare_key (key, sep_key, btid->key_type, 1, 1, NULL);
  assert (c == DB_LT || c == DB_EQ || c == DB_GT);

  if (c == DB_UNK)
    {
      goto exit_on_error;
    }
  else if (c < 0)
    {
      /* set child page identifier */
      *child_vpid = *Q_vpid;

    }
  else
    {
      /* set child page identifier */
      *child_vpid = *R_vpid;
    }

  if (sep_key)
    {
      btree_clear_key_value (&clear_sep_key, sep_key);
      db_private_free_and_init (thread_p, sep_key);
    }

  pgbuf_set_dirty (thread_p, P, DONT_FREE);
  pgbuf_set_dirty (thread_p, Q, DONT_FREE);
  pgbuf_set_dirty (thread_p, R, DONT_FREE);

  perfmon_inc_stat (thread_p, PSTAT_BT_NUM_SPLITS);

#if !defined(NDEBUG)
  btree_verify_node (thread_p, btid, P);
  btree_verify_node (thread_p, btid, Q);
  btree_verify_node (thread_p, btid, R);
#endif

  return ret;

exit_on_error:

  if (sep_key)
    {
      btree_clear_key_value (&clear_sep_key, sep_key);
      db_private_free_and_init (thread_p, sep_key);
    }

  return (ret == NO_ERROR && (ret = er_errid ()) == NO_ERROR) ? ER_FAILED : ret;
}

/*
 * btree_update () -
 *   return: NO_ERROR
 *   btid(in): B+tree index identifier
 *   old_key(in): Old key value
 *   new_key(in): New key value
 *   locked_keys(in): keys already locked by the current transaction when search
 *   cls_oid(in):
 *   oid(in): Object identifier to be updated
 *   op_type(in):
 *   unique_stat_info(in):
 *   unique(in):
 *   p_mvcc_rec_header(in/out): array of MVCC_REC_HEADER of size 2 or NULL
 *
 * Note: Deletes the <old_key, oid> key-value pair from the B+tree
 * index and inserts the <new_key, oid> key-value pair to the
 * B+tree index which results in the update of the specified
 * index entry for the given object identifier.
 */
int
btree_update (THREAD_ENTRY * thread_p, BTID * btid, DB_VALUE * old_key, DB_VALUE * new_key, OID * cls_oid, OID * oid,
	      int op_type, btree_unique_stats * unique_stat_info, int *unique, MVCC_REC_HEADER * p_mvcc_rec_header)
{
  MVCC_REC_HEADER *p_local_rec_header = NULL;
  int ret = NO_ERROR;

  assert (old_key != NULL);
  assert (new_key != NULL);
  assert (unique != NULL);

#if !defined (SERVER_MODE)
  assert_release (p_mvcc_rec_header == NULL);
#endif /* SERVER_MODE */

  if (p_mvcc_rec_header != NULL)
    {
      /* in MVCC, logical deletion means DEL_ID insertion */
      /* Note that it is possible that update "in-place" is done instead of standard MVCC update, in which case the
       * "logical" deletion is no longer required. */
      ret =
	btree_mvcc_delete (thread_p, btid, old_key, cls_oid, oid, op_type, unique_stat_info, unique,
			   &p_mvcc_rec_header[0]);
      if (ret != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto exit_on_error;
	}
    }
  else
    {
      /* In-place update. Remove object physically. */
      ret = btree_physical_delete (thread_p, btid, old_key, oid, cls_oid, unique, op_type, unique_stat_info);
      if (ret != NO_ERROR)
	{
	  /* if the btree we are updating is a btree for unique attributes it is possible that the btree update has
	   * already been performed via the template unique checking. In this case, we will ignore the error from
	   * btree_delete */
	  if (*unique && er_errid () == ER_BTREE_UNKNOWN_KEY)
	    {
	      /* Is this still true? */
	      goto end;
	    }
	  ASSERT_ERROR ();
	  goto exit_on_error;
	}
    }

  if (p_mvcc_rec_header != NULL)
    {
      p_local_rec_header = &p_mvcc_rec_header[1];
    }

  ret = btree_insert (thread_p, btid, new_key, cls_oid, oid, op_type, unique_stat_info, unique, p_local_rec_header);
  if (ret != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto exit_on_error;
    }

end:

  perfmon_inc_stat (thread_p, PSTAT_BT_NUM_UPDATES);

  return ret;

exit_on_error:
  perfmon_inc_stat (thread_p, PSTAT_BT_NUM_UPDATES);

  assert_release (ret != NO_ERROR);
  return ret;
}

/*
 * btree_reflect_global_unique_statistics () - reflects the global statistical information into btree header
 *   return: NO_ERROR
 *   unique_stat_info(in):
 *   only_active_tran(in): if true then reflect statistics only if transaction is active
 *
 * Note: We don't need to log the changes at this point because the changes were
 *	 already logged at commit stage.
 */
int
btree_reflect_global_unique_statistics (THREAD_ENTRY * thread_p, GLOBAL_UNIQUE_STATS * unique_stat_info,
					bool only_active_tran)
{
  VPID root_vpid;
  PAGE_PTR root = NULL;
  BTREE_ROOT_HEADER *root_header = NULL;
  int ret = NO_ERROR;
  LOG_LSA *page_lsa = NULL;

  /* check if unique_stat_info is NULL */
  if (unique_stat_info == NULL)
    {
      assert (false);
      return ER_FAILED;
    }

  /* fix the root page */
  root_vpid.pageid = unique_stat_info->btid.root_pageid;
  root_vpid.volid = unique_stat_info->btid.vfid.volid;
  root = pgbuf_fix (thread_p, &root_vpid, OLD_PAGE, PGBUF_LATCH_WRITE, PGBUF_UNCONDITIONAL_LATCH);
  if (root == NULL)
    {
      ASSERT_ERROR_AND_SET (ret);
      goto exit;
    }

  (void) pgbuf_check_page_ptype (thread_p, root, PAGE_BTREE);

  /* read the root information */
  root_header = btree_get_root_header (thread_p, root);
  if (root_header == NULL)
    {
      assert (false);
      ret = ER_FAILED;
      goto exit;
    }

  if (root_header->num_nulls != -1)
    {
      assert_release (BTREE_IS_UNIQUE (root_header->unique_pk));

      if (!only_active_tran || logtb_is_current_active (thread_p))
	{
	  /* update header information */
	  root_header->num_nulls = unique_stat_info->unique_stats.num_nulls;
	  root_header->num_oids = unique_stat_info->unique_stats.num_oids;
	  root_header->num_keys = unique_stat_info->unique_stats.num_keys;

	  page_lsa = pgbuf_get_lsa (root);
	  /* update the page's LSA to the last global unique statistics change that was made at commit, only if it is
	   * newer than the last change recorded in the page's LSA. */
	  if (LSA_LT (page_lsa, &unique_stat_info->last_log_lsa))
	    {
	      if (pgbuf_set_lsa (thread_p, root, &unique_stat_info->last_log_lsa) == NULL)
		{
		  assert (false);
		  ret = ER_FAILED;
		  goto exit;
		}
	    }

	  /* set the root page as dirty page */
	  pgbuf_set_dirty (thread_p, root, DONT_FREE);

	  if (prm_get_bool_value (PRM_ID_LOG_UNIQUE_STATS) == true)
	    {
	      _er_log_debug (ARG_FILE_LINE,
			     "Reflect unique statistics to index (%d, %d|%d):"
			     "nulls=%d, oids=%d, keys=%d. LSA=%lld|%d.\n", unique_stat_info->btid.root_pageid,
			     unique_stat_info->btid.vfid.volid, unique_stat_info->btid.vfid.fileid,
			     unique_stat_info->unique_stats.num_nulls, unique_stat_info->unique_stats.num_oids,
			     unique_stat_info->unique_stats.num_keys,
			     (long long int) unique_stat_info->last_log_lsa.pageid,
			     (int) unique_stat_info->last_log_lsa.offset);
	    }
	}
    }

exit:

  if (root != NULL)
    {
      pgbuf_unfix_and_init (thread_p, root);
    }

  return ret;
}

/*
 * btree_locate_key () - Locate leaf node in b-tree for the given key.
 *   return: error code.
 *   btid_int (in) : B+tree index info.
 *   key (in) : Key to locate
 *   pg_vpid (out) : Outputs Leaf node page VPID.
 *   slot_id (out) : Outputs slot ID of key if found, or slot ID of key if it was to be inserted.
 *   leaf_page_out(out): Page pointer
 *   found_p (out) : Outputs true if key was found and false otherwise.
 *
 * Note: Search the B+tree index to locate the page and record that contains
 *	 the key, or would contain the key if the key was to be located.
 */
int
btree_locate_key (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key, VPID * pg_vpid, INT16 * slot_id,
		  PAGE_PTR * leaf_page_out, bool * found_p)
{
  PAGE_PTR leaf_page = NULL;	/* Leaf node page pointer. */
  int error = NO_ERROR;

  /* Search key result. */
  BTREE_SEARCH_KEY_HELPER search_key = BTREE_SEARCH_KEY_HELPER_INITIALIZER;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (btid_int->sys_btid != NULL);
  assert (found_p != NULL);
  assert (slot_id != NULL);
  assert (key != NULL && !DB_IS_NULL (key) && !btree_multicol_key_is_null (key));
  assert (!BTREE_INVALID_INDEX_ID (btid_int->sys_btid));

  *found_p = false;
  bool reuse_btid_int = true;

  /* Advance in b-tree following key until leaf node is reached. */
  error = btree_search_key_and_apply_functions (thread_p, btid_int->sys_btid, btid_int, key, NULL, &reuse_btid_int,
						btree_advance_and_find_key, slot_id, NULL, NULL, &search_key,
						&leaf_page);
  if (error != NO_ERROR)
    {
      ASSERT_ERROR ();
      assert (leaf_page == NULL);
      *leaf_page_out = NULL;
      return error;
    }
  assert (leaf_page != NULL);

  /* Output found and slot ID. */
  *found_p = (search_key.result == BTREE_KEY_FOUND);
  *slot_id = search_key.slotid;
  if (pg_vpid != NULL)
    {
      /* Output leaf node page VPID. */
      pgbuf_get_vpid (leaf_page, pg_vpid);
    }
  /* Assign leaf node page pointer. */
  *leaf_page_out = leaf_page;

  return error;
}

/*
 * btree_find_lower_bound_leaf () -
 *   return: NO_ERROR
 *   BTS(in):
 *   stat_info(in):
 *
 * Note: Find the first/last leaf page of the B+tree index.
 */
static int
btree_find_lower_bound_leaf (THREAD_ENTRY * thread_p, BTREE_SCAN * bts, BTREE_STATS * stat_info_p)
{
  int key_cnt;
  int ret = NO_ERROR;
  BTREE_NODE_HEADER *header = NULL;
  BTREE_NODE_TYPE node_type;
  RECDES rec;

  if (bts->use_desc_index)
    {
      assert_release (stat_info_p == NULL);
      bts->C_page = btree_find_rightmost_leaf (thread_p, bts->btid_int.sys_btid, &bts->C_vpid, stat_info_p);
    }
  else
    {
      bts->C_page = btree_find_leftmost_leaf (thread_p, bts->btid_int.sys_btid, &bts->C_vpid, stat_info_p);
    }

  if (bts->C_page == NULL)
    {
      goto exit_on_error;
    }

  /* get header information (key_cnt) */
  key_cnt = btree_node_number_of_keys (thread_p, bts->C_page);

  header = btree_get_node_header (thread_p, bts->C_page);
  if (header == NULL)
    {
      goto exit_on_error;
    }

  node_type = (header->node_level > 1) ? BTREE_NON_LEAF_NODE : BTREE_LEAF_NODE;

  if (node_type != BTREE_LEAF_NODE)
    {
      assert_release (false);
      goto exit_on_error;
    }

  /* set slot id and OID position */
  if (bts->use_desc_index)
    {
      bts->slot_id = key_cnt;
    }
  else
    {
      bts->slot_id = 1;
    }

  if (key_cnt == 0)
    {
      /* tree is empty; need to unfix current leaf page */
      ret = btree_find_next_index_record (thread_p, bts);
      if (ret != NO_ERROR)
	{
	  goto exit_on_error;
	}

      assert_release (BTREE_END_OF_SCAN (bts));
    }
  else
    {
      /* Key may be fence and fences must be filtered out. */
      if (spage_get_record (thread_p, bts->C_page, bts->slot_id, &rec, PEEK) != S_SUCCESS)
	{
	  assert (false);
	  goto exit_on_error;
	}
      assert (rec.length % 4 == 0);

      if (btree_leaf_is_flaged (&rec, BTREE_LEAF_RECORD_FENCE))
	{
	  /* Filter out fence key. */
	  ret = btree_find_next_index_record (thread_p, bts);
	  if (ret != NO_ERROR)
	    {
	      return ret;
	    }
	}
      else
	{
	  bts->oid_pos = 0;
	  assert_release (bts->slot_id <= key_cnt);
	}
    }

  return ret;

exit_on_error:

  return (ret == NO_ERROR && (ret = er_errid ()) == NO_ERROR) ? ER_FAILED : ret;
}

/*
 * btree_find_leftmost_leaf () -
 *   return: page pointer
 *   btid(in):
 *   pg_vpid(in):
 *   stat_info_p(in):
 *
 * Note: Find the page identifier for the first leaf page of the B+tree index.
 */
static PAGE_PTR
btree_find_leftmost_leaf (THREAD_ENTRY * thread_p, BTID * btid, VPID * pg_vpid, BTREE_STATS * stat_info)
{
  return btree_find_boundary_leaf (thread_p, btid, pg_vpid, stat_info, BTREE_BOUNDARY_FIRST);
}

/*
 * btree_find_rightmost_leaf () -
 *   return: page pointer
 *   btid(in):
 *   pg_vpid(in):
 *   stat_info(in):
 *
 * Note: Find the page identifier for the last leaf page of the B+tree index.
 */
static PAGE_PTR
btree_find_rightmost_leaf (THREAD_ENTRY * thread_p, BTID * btid, VPID * pg_vpid, BTREE_STATS * stat_info)
{
  return btree_find_boundary_leaf (thread_p, btid, pg_vpid, stat_info, BTREE_BOUNDARY_LAST);
}

/*
 * btree_find_boundary_leaf () -
 *   return: page pointer
 *   btid(in):
 *   pg_vpid(in):
 *   stat_info(in):
 *
 * Note: Find the page identifier for the first/last leaf page of the B+tree index.
 */
static PAGE_PTR
btree_find_boundary_leaf (THREAD_ENTRY * thread_p, BTID * btid, VPID * pg_vpid, BTREE_STATS * stat_info,
			  BTREE_BOUNDARY where)
{
  PAGE_PTR P_page = NULL, C_page = NULL;
  VPID P_vpid, C_vpid;
  BTREE_ROOT_HEADER *root_header = NULL;
  BTREE_NODE_HEADER *header = NULL;
  BTREE_NODE_TYPE node_type;
  NON_LEAF_REC nleaf;
  RECDES rec;
  int key_cnt = 0, index = 0;
  int root_level = 0, depth = 0;

  VPID_SET_NULL (pg_vpid);

  /* read the root page */
  P_vpid.volid = btid->vfid.volid;
  P_vpid.pageid = btid->root_pageid;
  P_page = pgbuf_fix (thread_p, &P_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
  if (P_page == NULL)
    {
      ASSERT_ERROR ();
      goto error;
    }

  (void) pgbuf_check_page_ptype (thread_p, P_page, PAGE_BTREE);

  root_header = btree_get_root_header (thread_p, P_page);
  if (root_header == NULL)
    {
      goto error;
    }

  root_level = root_header->node.node_level;
  node_type = (root_level > 1) ? BTREE_NON_LEAF_NODE : BTREE_LEAF_NODE;

  while (node_type == BTREE_NON_LEAF_NODE)
    {
      key_cnt = btree_node_number_of_keys (thread_p, P_page);
      if (key_cnt <= 0)
	{			/* node record underflow */
	  er_log_debug (ARG_FILE_LINE, "btree_find_boundary_leaf: node key count underflow: %d.Operation Ignored.",
			key_cnt);
	  goto error;
	}

      assert (where == BTREE_BOUNDARY_FIRST || where == BTREE_BOUNDARY_LAST);
      if (where == BTREE_BOUNDARY_FIRST)
	{
	  index = 1;
	}
      else
	{
	  index = key_cnt;
	}

      depth++;

      /* get the child page to flow */
      assert (index > 0);
      if (spage_get_record (thread_p, P_page, index, &rec, PEEK) != S_SUCCESS)
	{
	  goto error;
	}

      btree_read_fixed_portion_of_non_leaf_record (&rec, &nleaf);
      C_vpid = nleaf.pnt;
      C_page = pgbuf_fix (thread_p, &C_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
      if (C_page == NULL)
	{
	  ASSERT_ERROR ();
	  goto error;
	}

      (void) pgbuf_check_page_ptype (thread_p, C_page, PAGE_BTREE);

      pgbuf_unfix_and_init (thread_p, P_page);

      key_cnt = btree_node_number_of_keys (thread_p, C_page);

      header = btree_get_node_header (thread_p, C_page);
      if (header == NULL)
	{
	  goto error;
	}

      node_type = (header->node_level > 1) ? BTREE_NON_LEAF_NODE : BTREE_LEAF_NODE;

      P_page = C_page;
      C_page = NULL;
      P_vpid = C_vpid;
    }

  if (key_cnt != 0)
    {
      goto end;			/* OK */
    }

again:

  header = btree_get_node_header (thread_p, P_page);
  if (header == NULL)
    {
      goto error;
    }

  /* fix the next leaf page and set slot_id and oid_pos if it exists. */
  assert (where == BTREE_BOUNDARY_FIRST || where == BTREE_BOUNDARY_LAST);
  if (where == BTREE_BOUNDARY_FIRST)
    {
      C_vpid = header->next_vpid;	/* move backward */
    }
  else
    {
      C_vpid = header->prev_vpid;	/* move foward */
    }

  if (!VPID_ISNULL (&C_vpid))
    {
      C_page = pgbuf_fix (thread_p, &C_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
      if (C_page == NULL)
	{
	  ASSERT_ERROR ();
	  goto error;
	}

      (void) pgbuf_check_page_ptype (thread_p, C_page, PAGE_BTREE);

      /* unfix the previous leaf page if it is fixed. */
      if (P_page != NULL)
	{
	  pgbuf_unfix_and_init (thread_p, P_page);
	  /* do not clear bts->P_vpid for UNCONDITIONAL lock request handling */
	}
    }

  /* check if the current leaf page has valid slots */
  if (C_page != NULL)
    {
      key_cnt = btree_node_number_of_keys (thread_p, C_page);

      if (key_cnt <= 0)
	{			/* empty page */
	  P_page = C_page;
	  C_page = NULL;
	  goto again;
	}

      P_vpid = C_vpid;
      P_page = C_page;
    }

  /* NOTE that we do NOT release the page latch on P here */
end:

  *pg_vpid = P_vpid;

  assert_release (root_level == depth + 1);

  if (stat_info)
    {
      stat_info->height = root_level;
    }

  return P_page;

error:

  if (P_page)
    {
      pgbuf_unfix_and_init (thread_p, P_page);
    }
  if (C_page)
    {
      pgbuf_unfix_and_init (thread_p, C_page);
    }

  return NULL;
}

/*
 * btree_find_AR_sampling_leaf () -
 *   return: page pointer
 *   btid(in):
 *   pg_vpid(in):
 *   stat_info_p(in):
 *   found_p(out):
 *
 * Note: Find the page identifier via the Acceptance/Rejection Sampling leaf page of the B+tree index.
 * Note: Random Sampling from Databases (Chapter 3. Random Sampling from B+ Trees)
 */
static PAGE_PTR
btree_find_AR_sampling_leaf (THREAD_ENTRY * thread_p, BTID * btid, VPID * pg_vpid, BTREE_STATS * stat_info_p,
			     bool * found_p)
{
  PAGE_PTR P_page = NULL, C_page = NULL;
  VPID P_vpid, C_vpid;
  int slot_id;
  BTREE_ROOT_HEADER *root_header = NULL;
  BTREE_NODE_HEADER *header = NULL;
  BTREE_NODE_TYPE node_type;
  NON_LEAF_REC nleaf;
  RECDES rec;
  int est_page_size, free_space;
  int key_cnt = 0;
  int root_level = 0, depth = 0;
  double prob = 1.0;		/* Acceptance probability */

  assert (stat_info_p != NULL);
  assert (found_p != NULL);

  *found_p = false;		/* init */

  VPID_SET_NULL (pg_vpid);

  /* read the root page */
  P_vpid.volid = btid->vfid.volid;
  P_vpid.pageid = btid->root_pageid;
  P_page = pgbuf_fix (thread_p, &P_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
  if (P_page == NULL)
    {
      goto error;
    }

  (void) pgbuf_check_page_ptype (thread_p, P_page, PAGE_BTREE);

  key_cnt = btree_node_number_of_keys (thread_p, P_page);

  root_header = btree_get_root_header (thread_p, P_page);
  if (root_header == NULL)
    {
      goto error;
    }

  root_level = root_header->node.node_level;
  node_type = (root_level > 1) ? BTREE_NON_LEAF_NODE : BTREE_LEAF_NODE;

  est_page_size = (int) (DB_PAGESIZE - (spage_header_size () + sizeof (BTREE_NODE_HEADER) + spage_slot_size ()));
  assert (est_page_size > 0);

  while (node_type == BTREE_NON_LEAF_NODE)
    {
      depth++;

      /* get the randomized child page to follow */

      if (key_cnt <= 0)
	{			/* node record underflow */
	  er_log_debug (ARG_FILE_LINE,
			"btree_find_AR_sampling_leaf: node key count underflow: %d. Operation Ignored.", key_cnt);
	  goto error;
	}

      slot_id = (int) (drand48 () * key_cnt);
      slot_id = MAX (slot_id, 1);

      assert (slot_id > 0);
      if (spage_get_record (thread_p, P_page, slot_id, &rec, PEEK) != S_SUCCESS)
	{
	  goto error;
	}

      btree_read_fixed_portion_of_non_leaf_record (&rec, &nleaf);
      C_vpid = nleaf.pnt;
      C_page = pgbuf_fix (thread_p, &C_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
      if (C_page == NULL)
	{
	  goto error;
	}

      (void) pgbuf_check_page_ptype (thread_p, C_page, PAGE_BTREE);

      pgbuf_unfix_and_init (thread_p, P_page);

      key_cnt = btree_node_number_of_keys (thread_p, C_page);

      header = btree_get_node_header (thread_p, C_page);
      if (header == NULL)
	{
	  goto error;
	}

      node_type = (header->node_level > 1) ? BTREE_NON_LEAF_NODE : BTREE_LEAF_NODE;

      /* update Acceptance probability */

      free_space = spage_max_space_for_new_record (thread_p, C_page);
      assert (est_page_size > free_space);

      prob *= (((double) est_page_size) - free_space) / ((double) est_page_size);

      P_page = C_page;
      C_page = NULL;
      P_vpid = C_vpid;
    }

  if (key_cnt != 0)
    {
      goto end;			/* OK */
    }

again:

  header = btree_get_node_header (thread_p, P_page);
  if (header == NULL)
    {
      goto error;
    }

  /* fix the next leaf page and set slot_id and oid_pos if it exists. */
  C_vpid = header->next_vpid;
  if (!VPID_ISNULL (&C_vpid))
    {
      C_page = pgbuf_fix (thread_p, &C_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
      if (C_page == NULL)
	{
	  goto error;
	}

      (void) pgbuf_check_page_ptype (thread_p, C_page, PAGE_BTREE);

      /* unfix the previous leaf page if it is fixed. */
      if (P_page != NULL)
	{
	  pgbuf_unfix_and_init (thread_p, P_page);
	  /* do not clear bts->P_vpid for UNCONDITIONAL lock request handling */
	}
    }

  /* check if the current leaf page has valid slots */
  if (C_page != NULL)
    {
      key_cnt = btree_node_number_of_keys (thread_p, C_page);

      if (key_cnt <= 0)
	{			/* empty page */
	  P_page = C_page;
	  C_page = NULL;
	  goto again;
	}
      P_vpid = C_vpid;
      P_page = C_page;
    }

  /* NOTE that we do NOT release the page latch on P here */
end:

  *pg_vpid = P_vpid;

  assert_release (root_level == depth + 1);

  stat_info_p->height = root_level;

  /* do Acceptance/Rejection sampling */
  if (drand48 () < prob)
    {
      /* Acceptance */
      *found_p = true;
    }
  else
    {
      /* Rejection */
      assert (*found_p == false);
    }

  return P_page;

error:

  if (P_page)
    {
      pgbuf_unfix_and_init (thread_p, P_page);
    }
  if (C_page)
    {
      pgbuf_unfix_and_init (thread_p, C_page);
    }

  return NULL;
}

/*
 * btree_keyval_search () -
 *   return: the number of object identifiers in the set pointed
 *           at by oids_ptr, or -1 if an error occurs. Since there can be
 *           many object identifiers for the given key, to avoid main
 *           memory limitations, the set of object identifiers are returned
 *           iteratively. At each call, the btree_scan is modified, to
 *           remember the old search position.
 *   btid: B+tree index identifier
 *   scan_op_type(in):
 *   bts(in/out): Btree range search scan structure
 *   key(in): Key to be searched for its object identifier set
 *   class_oid(in):
 *   oids_ptr(in): Points to the already allocated storage area to store oids
 *   oids_size(in): Size of allocated area for oid set storage
 *   filter(in):
 *   isidp(in):
 *   is_all_class_srch(in):
 *
 * Note: Finds the set of object identifiers for the given key. if the key is not found, 0 count is returned.
 * Otherwise, the area pointed at by oids_ptr is filled with one group of object identifiers.
 *
 * Note: the btree_scan structure must first be initialized by using the macro BTREE_INIT_SCAN()
 *
 * Note: After the first iteration, caller can use BTREE_END_OF_SCAN() macro to understand the end of range.
 *
 * NOTE: Instead of range scan, this can be replaced with a different function to go to key directly.
 */
int
btree_keyval_search (THREAD_ENTRY * thread_p, BTID * btid, SCAN_OPERATION_TYPE scan_op_type, BTREE_SCAN * bts,
		     key_val_range * kv_range, OID * class_oid, FILTER_INFO * filter, INDX_SCAN_ID * isidp,
		     bool is_all_class_srch)
{
  /* this is just a GE_LE range search with the same key */
  int rc;

  /* Assert expected arguments. */
  assert (btid != NULL);
  assert (bts != NULL);
  assert (isidp != NULL);
  assert (isidp->need_count_only == false);
  assert (kv_range != NULL);
  /* If a class must be matched, class_oid argument must be a valid OID. */
  assert (is_all_class_srch || (class_oid != NULL && !OID_ISNULL (class_oid)));

  /* Execute range scan */
  rc =
    btree_prepare_bts (thread_p, bts, btid, isidp, kv_range, filter, is_all_class_srch ? class_oid : NULL, NULL,
		       NULL, false, NULL);
  if (rc != NO_ERROR)
    {
      ASSERT_ERROR ();
      return rc;
    }
  rc = btree_range_scan (thread_p, bts, btree_range_scan_select_visible_oids);
  if (rc != NO_ERROR)
    {
      ASSERT_ERROR ();
      return rc;
    }
  assert (bts->n_oids_read_last_iteration >= 0);

  return bts->n_oids_read_last_iteration;
}

/*
 * btree_coerce_key () -
 *   return: NO_ERROR or error code
 *   src_keyp(in/out):
 *   keysize(in): term# associated with index key range
 *   btree_domainp(in): B+tree index domain
 *   key_minmax(in): MIN_VALUE or MAX_VALUE
 *
 * Note:
 */
int
btree_coerce_key (DB_VALUE * keyp, int keysize, TP_DOMAIN * btree_domainp, int key_minmax)
{
  DB_TYPE stype, dtype;
  int ssize, dsize;
  TP_DOMAIN *dp;
  DB_MIDXKEY *midxkey;
  TP_DOMAIN *partial_dom;
  int minmax;
  int err = NO_ERROR;
  bool part_key_desc = false;

  /* assuming all parameters are not NULL pointer, and 'src_key' is not NULL value */
  stype = DB_VALUE_TYPE (keyp);
  dtype = TP_DOMAIN_TYPE (btree_domainp);

  if (stype == DB_TYPE_MIDXKEY && dtype == DB_TYPE_MIDXKEY)
    {
      /* if multi-column index */
      /* The type of B+tree key domain can be DB_TYPE_MIDXKEY only in the case of multi-column index. And, if it is,
       * query optimizer makes the search key('src_key') as sequence type even if partial key was specified. One more
       * assumption is that query optimizer make the search key(either complete or partial) in the same order (of
       * sequence) of B+tree key domain. */

      /* get number of elements of sequence type of the 'src_key' */
      midxkey = db_get_midxkey (keyp);
      ssize = midxkey->ncolumns;

      /* count number of elements of sequence type of the B+tree key domain */
      for (dp = btree_domainp->setdomain, dsize = 0; dp; dp = dp->next, dsize++)
	{
	  ;
	}

      if (ssize < 0 || ssize > dsize || dsize == 0 || ssize > keysize)
	{
	  /* something wrong with making search key in query optimizer */
	  err = ER_FAILED;	/* error */
	}
      else if (ssize == dsize)
	{
	  if (midxkey->domain == NULL)	/* checkdb */
	    {
	      midxkey->domain = btree_domainp;
	    }

	  return NO_ERROR;
	}
      else
	{
	  /* do coercing, append min or max value of the coressponding domain type to the partial search key value */
	  DB_VALUE *dbvals = NULL;
	  int num_dbvals;

	  num_dbvals = dsize - ssize;
	  dbvals = (DB_VALUE *) db_private_alloc (NULL, num_dbvals * sizeof (DB_VALUE));
	  if (dbvals == NULL)
	    {
	      return ER_OUT_OF_VIRTUAL_MEMORY;
	    }

	  /* get the last domain element of partial-key */
	  for (dp = btree_domainp->setdomain, dsize = 1; dsize < keysize && dp; dsize++, dp = dp->next)
	    {
	      ;			/* nop */
	    }

	  if (dsize < keysize || dp == NULL)
	    {
	      db_private_free_and_init (NULL, dbvals);
	      return ER_FAILED;
	    }

	  part_key_desc = dp->is_desc;

	  for (dp = btree_domainp->setdomain, dsize = 0; dp && dsize < ssize; dp = dp->next, dsize++)
	    {
	      ;
	    }

	  if (midxkey->min_max_val.position == -1)
	    {
	      /* If min_max_val was not set, set it here. */
	      minmax = key_minmax;	/* init */
	      if (minmax == BTREE_COERCE_KEY_WITH_MIN_VALUE)
		{
		  if (!part_key_desc)
		    {		/* CASE 1, 2 */
		      if (dp->is_desc != true)
			{	/* CASE 1 */
			  minmax = BTREE_COERCE_KEY_WITH_MIN_VALUE;
			}
		      else
			{	/* CASE 2 */
			  minmax = BTREE_COERCE_KEY_WITH_MAX_VALUE;
			}
		    }
		  else
		    {		/* CASE 3, 4 */
		      if (dp->is_desc != true)
			{	/* CASE 3 */
			  minmax = BTREE_COERCE_KEY_WITH_MAX_VALUE;
			}
		      else
			{	/* CASE 4 */
			  minmax = BTREE_COERCE_KEY_WITH_MIN_VALUE;
			}
		    }
		}
	      else if (minmax == BTREE_COERCE_KEY_WITH_MAX_VALUE)
		{
		  if (!part_key_desc)
		    {		/* CASE 1, 2 */
		      if (dp->is_desc != true)
			{	/* CASE 1 */
			  minmax = BTREE_COERCE_KEY_WITH_MAX_VALUE;
			}
		      else
			{	/* CASE 2 */
			  minmax = BTREE_COERCE_KEY_WITH_MIN_VALUE;
			}
		    }
		  else
		    {		/* CASE 3, 4 */
		      if (dp->is_desc != true)
			{	/* CASE 3 */
			  minmax = BTREE_COERCE_KEY_WITH_MIN_VALUE;
			}
		      else
			{	/* CASE 4 */
			  minmax = BTREE_COERCE_KEY_WITH_MAX_VALUE;
			}
		    }
		}

	      if (minmax == BTREE_COERCE_KEY_WITH_MIN_VALUE)
		{
		  midxkey->min_max_val.position = dsize;
		  midxkey->min_max_val.type = MIN_COLUMN;
		}
	      else if (minmax == BTREE_COERCE_KEY_WITH_MAX_VALUE)
		{
		  midxkey->min_max_val.position = dsize;
		  midxkey->min_max_val.type = MAX_COLUMN;
		}
	      else
		{
		  err = ER_FAILED;
		}
	    }

	  num_dbvals = 0;
	  partial_dom = dp;
	  for (err = NO_ERROR; dp && err == NO_ERROR; dp = dp->next, dsize++)
	    {
	      db_make_null (&dbvals[num_dbvals]);
	      num_dbvals++;
	    }

	  if (err == NO_ERROR)
	    {
	      err = pr_midxkey_add_elements (keyp, dbvals, num_dbvals, partial_dom);
	    }

	  db_private_free_and_init (NULL, dbvals);
	}
    }
  else if (
	    /* check if they are string or bit type */
	    /* compatible if two types are same (except for sequence type) */
	    (stype == dtype)
	    /* CHAR type and VARCHAR type are compatible with each other */
	    || ((stype == DB_TYPE_CHAR || stype == DB_TYPE_VARCHAR)
		&& (dtype == DB_TYPE_CHAR || dtype == DB_TYPE_VARCHAR))
	    /* NCHAR type and VARNCHAR type are compatible with each other */
	    || ((stype == DB_TYPE_NCHAR || stype == DB_TYPE_VARNCHAR)
		&& (dtype == DB_TYPE_NCHAR || dtype == DB_TYPE_VARNCHAR))
	    /* BIT type and VARBIT type are compatible with each other */
	    || ((stype == DB_TYPE_BIT || stype == DB_TYPE_VARBIT) && (dtype == DB_TYPE_BIT || dtype == DB_TYPE_VARBIT))
	    /* OID type and OBJECT type are compatible with each other */
	    /* Keys can come in with a type of DB_TYPE_OID, but the B+tree domain itself will always be a
	     * DB_TYPE_OBJECT. The comparison routines can handle OID and OBJECT as compatible type with each other . */
	    || (stype == DB_TYPE_OID || stype == DB_TYPE_OBJECT))
    {
      err = NO_ERROR;
    }
  else
    {
      DB_VALUE temp_val;

      db_make_null (&temp_val);

      if (tp_more_general_type (dtype, stype) > 0)
	{
	  /* the other case, do real coercing using 'tp_value_coerce()' */
	  if (tp_value_coerce (keyp, &temp_val, btree_domainp) == DOMAIN_COMPATIBLE)
	    {
	      pr_clear_value (keyp);
	      pr_clone_value (&temp_val, keyp);
	    }

	  pr_clear_value (&temp_val);
	}
      else if (TP_IS_NUMERIC_TYPE (dtype) || TP_IS_DATE_OR_TIME_TYPE (dtype))
	{
	  /* try to strict cast keyp to dtype */
	  err = tp_value_coerce_strict (keyp, &temp_val, btree_domainp);
	  if (err == NO_ERROR)
	    {
	      pr_clear_value (keyp);
	      pr_clone_value (&temp_val, keyp);
	    }
	  else
	    {
	      /* unsuccessful, */
	      err = NO_ERROR;
	    }

	  pr_clear_value (&temp_val);
	}
      else
	{
	  err = NO_ERROR;
	}
    }

  if (err != NO_ERROR)
    {
      er_set (ER_FATAL_ERROR_SEVERITY, ARG_FILE_LINE, ER_GENERIC_ERROR, 0);
    }

  /* return result */
  return err;
}

/*
 * btree_prepare_bts () - Prepare b-tree scan structure before starting index scan.
 *
 * return		   : Error code.
 * thread_p (in)	   : Thread entry.
 * bts (in)		   : B-tree scan structure.
 * btid (in)		   : B-tree identifier.
 * index_scan_id_p (in)	   : Index scan info.
 * key_val_range (in)	   : Range of scan.
 * filter (in)		   : Key filter.
 * match_class_oid (in)	   : Non-NULL value if class must be matched (unique indexes).
 * key_limit_upper (in)	   : Pointer to upper key limit. NULL if there is no upper key limit.
 * key_limit_lower (in)	   : Pointer to lower key limit. NULL if there is no lower key limit.
 * need_to_check_null (in) : True if midxkey NULL needs to be checked.
 * bts_other (in/out)	   : Sets the argument specific to one type of range search.
 */
int
btree_prepare_bts (THREAD_ENTRY * thread_p, BTREE_SCAN * bts, BTID * btid, INDX_SCAN_ID * index_scan_id_p,
		   key_val_range * kv_range, FILTER_INFO * filter, const OID * match_class_oid,
		   DB_BIGINT * key_limit_upper, DB_BIGINT * key_limit_lower, bool need_to_check_null, void *bts_other)
{
  key_val_range inf_key_val_range;
  PAGE_PTR root_page = NULL;
  VPID root_vpid;
  int error_code = NO_ERROR;
  DB_MIDXKEY *midxkey = NULL;
  DB_VALUE *swap_key = NULL;
  int i = 0;
  static bool oracle_style_empty_string = prm_get_bool_value (PRM_ID_ORACLE_STYLE_EMPTY_STRING);

  /* Assert expected arguments. */
  assert (bts != NULL);
  /* If b-tree info is valid, then topclass_oid must not be NULL. */
  assert (!bts->is_btid_int_valid || !OID_ISNULL (&bts->btid_int.topclass_oid));

  if (bts->is_scan_started)
    {
      /* B-tree scan must have been initialized already. */
      return NO_ERROR;
    }

  assert (VPID_ISNULL (&bts->C_vpid));

  if (kv_range == NULL)
    {
      /* NULL kv_range argument means a full range scan */
      db_make_null (&inf_key_val_range.key1);
      db_make_null (&inf_key_val_range.key2);
      inf_key_val_range.range = INF_INF;
      inf_key_val_range.num_index_term = 0;
      inf_key_val_range.is_truncated = false;

      kv_range = &inf_key_val_range;
    }

  if (!bts->is_btid_int_valid)
    {
      root_vpid.pageid = btid->root_pageid;
      root_vpid.volid = btid->vfid.volid;
      root_page = btree_fix_root_with_info (thread_p, btid, PGBUF_LATCH_READ, NULL, NULL, &bts->btid_int);
      if (root_page == NULL)
	{
	  ASSERT_ERROR_AND_SET (error_code);
	  return error_code;
	}
      /* B-tree info successfully obtained. */

      if (index_scan_id_p != NULL && index_scan_id_p->check_not_vacuumed)
	{
	  /* Not vacuumed check can work properly only after creator MVCCID was vacuumed. Otherwise, checker may find
	   * older MVCCID's that have been logged with creator MVCCID and it will complain (even crash in debug mode). */
	  MVCCID creator_mvccid = btree_get_creator_mvccid (thread_p, root_page);
	  if (MVCCID_IS_VALID (creator_mvccid) && !vacuum_is_mvccid_vacuumed (creator_mvccid))
	    {
	      /* Do not allow check for not vacuumed records. */
	      index_scan_id_p->check_not_vacuumed = false;
	    }
	}

      /* Root page is no longer needed. */
      pgbuf_unfix_and_init (thread_p, root_page);

      /* TODO: Why is the below code here? What does constructing btid have to do with the issue described below?
       * Shouldn't this be always verified? It doesn't look like belonging here. */
      /*
       * The asc/desc properties in midxkey from log_applier may be
       * inaccurate. therefore, we should use btree header's domain while
       * processing btree search request from log_applier.
       */
      if (DB_VALUE_TYPE (&kv_range->key1) == DB_TYPE_MIDXKEY)
	{
	  midxkey = db_get_midxkey (&kv_range->key1);
	  if (midxkey->domain == NULL || LOG_CHECK_LOG_APPLIER (thread_p))
	    {
	      /*
	       * The asc/desc properties in midxkey from log_applier may be
	       * inaccurate. therefore, we should use btree header's domain
	       * while processing btree search request from log_applier.
	       */
	      if (midxkey->domain)
		{
		  tp_domain_free (midxkey->domain);
		}
	      midxkey->domain = bts->btid_int.key_type;
	    }
	}
      if (DB_VALUE_TYPE (&kv_range->key2) == DB_TYPE_MIDXKEY)
	{
	  midxkey = db_get_midxkey (&kv_range->key2);
	  if (midxkey->domain == NULL || LOG_CHECK_LOG_APPLIER (thread_p))
	    {
	      if (midxkey->domain)
		{
		  tp_domain_free (midxkey->domain);
		}
	      midxkey->domain = bts->btid_int.key_type;
	    }
	}

      /* TODO: What does this assert mean? */
      /* is from keyval_search; checkdb or find_unique */
      assert_release (kv_range->num_index_term == 0);

      /* B-tree scan btid_int is now valid. */
      bts->is_btid_int_valid = true;
    }

  if (index_scan_id_p)
    {
      bts->index_scan_idp = index_scan_id_p;
      if (index_scan_id_p->indx_info != NULL)
	{
	  bts->use_desc_index = index_scan_id_p->indx_info->use_desc_index != 0;
	}
      else
	{
	  bts->use_desc_index = false;
	}
      bts->oid_ptr = bts->index_scan_idp->oid_list != NULL ? bts->index_scan_idp->oid_list->oidp : NULL;

      /* set index key copy_buf info; is allocated at btree_keyval_search() or scan_open_index_scan(). */
      /* TODO: Use index_scan_id_p->copy_buf directly. */
      bts->btid_int.copy_buf = index_scan_id_p->copy_buf;
      bts->btid_int.copy_buf_len = index_scan_id_p->copy_buf_len;
    }

  /* initialize the key range with given information */
  switch (kv_range->range)
    {
    case EQ_NA:
    case GT_LT:
    case GT_LE:
    case GE_LT:
    case GE_LE:
    case GE_INF:
    case GT_INF:
    case INF_LE:
    case INF_LT:
    case INF_INF:
      break;
    default:
      assert (false);
      er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_BTREE_INVALID_RANGE, 0);
      return ER_BTREE_INVALID_RANGE;
    }

  /* Set up the keys and make sure that they have the proper domain (by coercing, if necessary). Open-ended searches
   * will have one or both of key1 or key2 set to NULL so that we no longer have to do DB_IS_NULL() tests on them. */
  /* TODO: fix multi-column index NULL problem */
  /* Only used for multi-column index with PRM_ORACLE_STYLE_EMPTY_STRING, otherwise set as zero */

  /* Set key range. */
  bts->key_range.num_index_term = kv_range->num_index_term;

  /* re-check for partial-key domain is desc */
  if (!BTREE_IS_PART_KEY_DESC (&(bts->btid_int)))
    {
      TP_DOMAIN *dom;

      dom = bts->btid_int.key_type;
      if (TP_DOMAIN_TYPE (dom) == DB_TYPE_MIDXKEY)
	{
	  dom = dom->setdomain;
	}

      /* get the last domain element of partial-key */
      for (i = 1; i < kv_range->num_index_term && dom; i++, dom = dom->next)
	{
	  ;			/* nop */
	}

      if (i < kv_range->num_index_term || dom == NULL)
	{
	  assert (false);
	  return ER_FAILED;
	}

      bts->btid_int.part_key_desc = dom->is_desc;
    }

#if !defined(NDEBUG)
  if (DB_VALUE_TYPE (&kv_range->key1) == DB_TYPE_MIDXKEY)
    {
      midxkey = db_get_midxkey (&kv_range->key1);
      assert (midxkey->ncolumns == midxkey->domain->precision);
    }
  if (DB_VALUE_TYPE (&kv_range->key2) == DB_TYPE_MIDXKEY)
    {
      midxkey = db_get_midxkey (&kv_range->key2);
      assert (midxkey->ncolumns == midxkey->domain->precision);
    }
#endif

  /* lower bound key and upper bound key */
  if (DB_IS_NULL (&kv_range->key1) || btree_multicol_key_is_null (&kv_range->key1))
    {
      bts->key_range.lower_key = NULL;
    }
  else
    {
      bts->key_range.lower_key = &kv_range->key1;
    }

  if (DB_IS_NULL (&kv_range->key2) || btree_multicol_key_is_null (&kv_range->key2))
    {
      bts->key_range.upper_key = NULL;
    }
  else
    {
      bts->key_range.upper_key = &kv_range->key2;
    }

  /* range type */
  bts->key_range.range = kv_range->range;

  /* Swap range for scan is descending. */
  if ((bts->use_desc_index && !BTREE_IS_PART_KEY_DESC (&bts->btid_int))
      || (!bts->use_desc_index && BTREE_IS_PART_KEY_DESC (&bts->btid_int)))
    {
      /* Reverse scan and its range. */
      range_reverse (bts->key_range.range);
      swap_key = bts->key_range.lower_key;
      bts->key_range.lower_key = bts->key_range.upper_key;
      bts->key_range.upper_key = swap_key;
    }

  if (oracle_style_empty_string)
    {
      /* TODO: A comment explaining this would be great. */
      int j, ids_size;

      if (filter && (*(filter->num_vstr_ptr) > 0) && filter->vstr_ids != NULL)
	{
	  ids_size = 0;		/* init */
	  for (i = 0; i < kv_range->num_index_term; i++)
	    {
	      filter->vstr_ids[i] = -1;	/* init to false */
	      for (j = 0; j < filter->scan_attrs->num_attrs; j++)
		{
		  if (filter->btree_attr_ids[i] == filter->scan_attrs->attr_ids[j])
		    {
		      filter->vstr_ids[i] = filter->btree_attr_ids[i];
		      ids_size = i + 1;
		      break;
		    }
		}
	    }

	  /* reset num of variable string attr in key range */
	  *(filter->num_vstr_ptr) = ids_size;
	}
    }
  /* Initialize key filter */
  if (filter)			/* Valid pointer or NULL */
    {
      bts->key_filter_storage = *filter;
      bts->key_filter = &bts->key_filter_storage;
    }
  else
    {
      bts->key_filter = NULL;
    }
  /* Reset key_range_max_value_equal */
  bts->key_range_max_value_equal = false;

  bts->read_keys = 0;
  bts->qualified_keys = 0;
  bts->n_oids_read = 0;
  bts->n_oids_read_last_iteration = 0;

  /* Key limits. */
  bts->key_limit_lower = key_limit_lower;
  bts->key_limit_upper = key_limit_upper;

  /* Should class OID be matched? (for hierarchical classes). */
  if (match_class_oid != NULL)
    {
      COPY_OID (&bts->match_class_oid, match_class_oid);
    }

  /* Need to check null? */
  bts->need_to_check_null = need_to_check_null;

  /* Set other arguments specific to scan type. */
  bts->bts_other = bts_other;

  /* Prepare successful. */
  return NO_ERROR;
}

/*
 * btree_scan_update_range () - Update range of b-tree scan.
 *
 * return	      : Error code.
 * thread_p (in)      : Thread entry.
 * bts (in/out)	      : B-tree scan.
 * key_val_range (in) : New range.
 */
static int
btree_scan_update_range (THREAD_ENTRY * thread_p, BTREE_SCAN * bts, key_val_range * kv_range)
{
  DB_MIDXKEY *midxkey = NULL;
  DB_VALUE *swap_key = NULL;

  /* Assert expected arguments. */
  assert (bts != NULL);
  assert (kv_range != NULL);

  /* Check valid range. */
  switch (kv_range->range)
    {
    case EQ_NA:
    case GT_LT:
    case GT_LE:
    case GE_LT:
    case GE_LE:
    case GE_INF:
    case GT_INF:
    case INF_LE:
    case INF_LT:
    case INF_INF:
      break;
    default:
      assert (false);
      er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_BTREE_INVALID_RANGE, 0);
      return ER_BTREE_INVALID_RANGE;
    }

  /* Set key range. */
  bts->key_range.num_index_term = kv_range->num_index_term;

#if !defined(NDEBUG)
  if (DB_VALUE_TYPE (&kv_range->key1) == DB_TYPE_MIDXKEY)
    {
      midxkey = db_get_midxkey (&kv_range->key1);
      assert (midxkey->ncolumns == midxkey->domain->precision);
    }
  if (DB_VALUE_TYPE (&kv_range->key2) == DB_TYPE_MIDXKEY)
    {
      midxkey = db_get_midxkey (&kv_range->key2);
      assert (midxkey->ncolumns == midxkey->domain->precision);
    }
#endif

  /* lower bound key and upper bound key */
  if (DB_IS_NULL (&kv_range->key1) || btree_multicol_key_is_null (&kv_range->key1))
    {
      bts->key_range.lower_key = NULL;
    }
  else
    {
      bts->key_range.lower_key = &kv_range->key1;
    }

  if (DB_IS_NULL (&kv_range->key2) || btree_multicol_key_is_null (&kv_range->key2))
    {
      bts->key_range.upper_key = NULL;
    }
  else
    {
      bts->key_range.upper_key = &kv_range->key2;
    }

  /* range type */
  bts->key_range.range = kv_range->range;

  /* Swap range for scan is descending. */
  if ((bts->use_desc_index && !BTREE_IS_PART_KEY_DESC (&bts->btid_int))
      || (!bts->use_desc_index && BTREE_IS_PART_KEY_DESC (&bts->btid_int)))
    {
      /* Reverse scan and its range. */
      range_reverse (bts->key_range.range);
      swap_key = bts->key_range.lower_key;
      bts->key_range.lower_key = bts->key_range.upper_key;
      bts->key_range.upper_key = swap_key;
    }

  return NO_ERROR;
}

/*
 * btree_find_next_index_record () -
 *   return: NO_ERROR
 *   bts(in):
 *
 * Note: This functions finds the next index record(or slot).
 * Then, it adjusts the slot_id and oid_pos information about the oid-set contained in the found index slot.
 * If next records is located in next page, unfix current page and change C_page as it.
 */
static int
btree_find_next_index_record (THREAD_ENTRY * thread_p, BTREE_SCAN * bts)
{
  PAGE_PTR first_page;
  int ret_val = NO_ERROR;

  first_page = bts->C_page;	/* init */

  ret_val = btree_find_next_index_record_holding_current (thread_p, bts, NULL);
#if 0				/* TODO - need to check return value */
  if (ret_val != NO_ERROR)
    {
      goto error;
    }
#endif

  if (first_page != bts->C_page)
    {
      /* reset common_prefix to recalculate */
      bts->common_prefix = COMMON_PREFIX_UNKNOWN;
    }

  /*
   * unfix first page if fix next page and move to it
   *
   *  case 1: P_page == NULL, C_page == first_page       x do not fix 1 next page
   *  case 2: P_page == first_page, C_page == NULL       x can't fix 1 next page
   *  case 3: P_page == first_page, C_page != first_pag  o fix 1 next
   *  case 4: P_page == NULL, C_page == NULL             o can't fix N next, unfix N-1 prev
   *  case 5: P_page == NULL, C_page != first_page       o fix N next, unfix N-1 prev
   *  other case: imppossible (assert)
   *
   *  in case of 3, 4, 5, unfix first_page
   */

#if !defined(NDEBUG)
  if ((bts->P_page == NULL && bts->C_page == first_page) || (bts->P_page == first_page && bts->C_page == NULL)
      || (bts->P_page == first_page && bts->C_page && bts->C_page != first_page)
      || (bts->P_page == NULL && bts->C_page == NULL)
      || (bts->P_page == NULL && bts->C_page && bts->C_page != first_page))
    {
      /* case 1, 2, 3, 4, 5 */
    }
  else
    {
      assert (false);
    }
#endif

  if ((bts->C_page == NULL && bts->P_page == NULL)	/* case 4 */
      || (bts->C_page != NULL && bts->C_page != first_page))	/* case 3, 5 */
    {
      if (first_page == bts->P_page)
	{
	  /* prevent double unfix by caller */
	  bts->P_page = NULL;
	}

      if (first_page != NULL)
	{
	  pgbuf_unfix_and_init (thread_p, first_page);
	}
    }

  return ret_val;
}

/*
 * btree_find_next_index_record_holding_current () -
 *   return: NO_ERROR
 *   bts(in):
 *
 * Note: This functions finds & peek next index record this function does not unfix first page
 */
static int
btree_find_next_index_record_holding_current (THREAD_ENTRY * thread_p, BTREE_SCAN * bts, RECDES * peek_rec)
{
  RECDES rec;
  int ret = NO_ERROR;
  PAGE_PTR first_page = bts->C_page;

  rec.data = NULL;

  /*
   * Assumptions : last accessed leaf page is fixed.
   *    - bts->C_page != NULL
   *    - bts->O_page : NULL or NOT NULL
   *    - bts->P_page == NULL
   */

  /* unfix the overflow page if it is fixed. */
  if (bts->O_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, bts->O_page);
      VPID_SET_NULL (&(bts->O_vpid));
    }

  /* unfix the previous leaf page if it is fixed. */
  if (bts->P_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, bts->P_page);
      VPID_SET_NULL (&(bts->P_vpid));
    }

  if (bts->C_page == NULL)
    {
      return ER_FAILED;
    }

  bts->P_vpid = bts->C_vpid;	/* save started leaf vpid */

  while (bts->C_page != NULL)
    {
      ret = btree_find_next_index_record_holding_current_helper (thread_p, bts, first_page);
      if (ret != NO_ERROR)
	{
	  goto exit_on_error;
	}

      /* filter out fence_key record */
      if (bts->C_page != NULL)
	{
	  assert (bts->slot_id > 0);
	  if ((bts->slot_id != 1 && bts->slot_id != btree_node_number_of_keys (thread_p, bts->C_page))
	      || !btree_is_fence_key (bts->C_page, bts->slot_id))
	    {
	      /* Found. */
	      /* Safe guard: key cannot be fence if between 1 and key count. */
	      assert (!btree_is_fence_key (bts->C_page, bts->slot_id));
	      break;
	    }
	  /* This is fence key. Continue searching. */
	}
    }

  if (VPID_EQ (&bts->P_vpid, &bts->C_vpid))
    {
      /* set bts->P_vpid to null for unconditional lock request handling */
      VPID_SET_NULL (&bts->P_vpid);
    }

  /* Safe guard: should not stop on fence key. */
  assert (bts->C_page == NULL || !btree_is_fence_key (bts->C_page, bts->slot_id));

  if (bts->C_page == NULL)
    {
      assert (VPID_ISNULL (&bts->C_vpid));
      bts->end_scan = true;
      if (bts->P_page != NULL && bts->P_page != first_page)
	{
	  pgbuf_unfix_and_init (thread_p, bts->P_page);
	}
    }

  if (bts->C_page != NULL && peek_rec != NULL)
    {
      if (spage_get_record (thread_p, bts->C_page, bts->slot_id, peek_rec, PEEK) != S_SUCCESS)
	{
	  assert (false);
	  goto exit_on_error;
	}
    }

  return ret;

exit_on_error:

  assert (ret != NO_ERROR);

  return (ret == NO_ERROR && (ret = er_errid ()) == NO_ERROR) ? ER_FAILED : ret;
}

/*
 * btree_find_next_index_record_holding_current_helper () -
 *   return: NO_ERROR
 *   bts(in):
 *
 * Note: This functions finds the next index record(or slot).
 * Then, it adjusts the slot_id and oid_pos information about the oid-set contained in the found index slot.
 */
static int
btree_find_next_index_record_holding_current_helper (THREAD_ENTRY * thread_p, BTREE_SCAN * bts, PAGE_PTR first_page)
{
  int key_cnt;
  int ret = NO_ERROR;
  PGBUF_LATCH_CONDITION latch_condition;
  BTREE_NODE_HEADER *header = NULL;

  /* get header information (key_cnt) from the current leaf page */
  key_cnt = btree_node_number_of_keys (thread_p, bts->C_page);

#if !defined(NDEBUG)
  header = btree_get_node_header (thread_p, bts->C_page);

  assert (header != NULL);
  assert (header->node_level == 1);	/* BTREE_LEAF_NODE */
#endif

  /*
   * If the next index record exists in the current leaf page,
   * the next index record(slot) and OID position can be identified easily.
   */
  if (key_cnt > 0)
    {
      if (bts->use_desc_index)
	{
	  if (bts->slot_id > 1)
	    {
	      bts->slot_id--;
	      bts->oid_pos = 0;
	      goto end;		/* OK */
	    }
	}
      else
	{
	  if (bts->slot_id < key_cnt)
	    {

	      bts->slot_id++;
	      bts->oid_pos = 0;
	      goto end;		/* OK */
	    }
	}
    }

  while (bts->C_page != NULL)
    {
      header = btree_get_node_header (thread_p, bts->C_page);
      if (header == NULL)
	{
	  if (first_page != bts->P_page)
	    {
	      pgbuf_unfix_and_init (thread_p, bts->P_page);
	    }

	  goto exit_on_error;
	}

      if (bts->use_desc_index)
	{
	  bts->C_vpid = header->prev_vpid;
	  latch_condition = PGBUF_CONDITIONAL_LATCH;
	}
      else
	{
	  bts->C_vpid = header->next_vpid;
	  latch_condition = PGBUF_UNCONDITIONAL_LATCH;
	}

      bts->P_page = bts->C_page;
      bts->C_page = NULL;

      if (!VPID_ISNULL (&(bts->C_vpid)))
	{
	  bts->C_page = pgbuf_fix (thread_p, &bts->C_vpid, OLD_PAGE, PGBUF_LATCH_READ, latch_condition);
	  if (bts->C_page == NULL)
	    {
	      if (bts->use_desc_index)
		{
		  assert (latch_condition == PGBUF_CONDITIONAL_LATCH);
		  er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_DESC_ISCAN_ABORTED, 3,
			  bts->btid_int.sys_btid->vfid.volid, bts->btid_int.sys_btid->vfid.fileid,
			  bts->btid_int.sys_btid->root_pageid);
		}

	      if (first_page != bts->P_page)
		{
		  pgbuf_unfix_and_init (thread_p, bts->P_page);
		}

	      goto exit_on_error;
	    }

	  (void) pgbuf_check_page_ptype (thread_p, bts->C_page, PAGE_BTREE);

	  /* unfix the previous leaf page */
	  assert (bts->P_page != NULL);

	  if (first_page != bts->P_page)
	    {
	      pgbuf_unfix_and_init (thread_p, bts->P_page);
	    }

	  /* do not clear bts->P_vpid for UNCONDITIONAL lock request handling */

	  key_cnt = btree_node_number_of_keys (thread_p, bts->C_page);

	  if (key_cnt > 0)
	    {
	      if (bts->use_desc_index)
		{
		  bts->slot_id = key_cnt;
		  bts->oid_pos = 0;
		}
	      else
		{
		  bts->slot_id = 1;
		  bts->oid_pos = 0;
		}

	      goto end;		/* OK */
	    }
	}
      else
	{
	  if (first_page != bts->P_page)
	    {
	      pgbuf_unfix_and_init (thread_p, bts->P_page);
	    }
	}
    }

end:
  return ret;

exit_on_error:

  return (ret == NO_ERROR && (ret = er_errid ()) == NO_ERROR) ? ER_FAILED : ret;
}

/*
 * btree_apply_key_range_and_filter () - Apply key range and key filter condition
 *   return: NO_ERROR
 *   bts(in)	: pointer to B+-tree scan structure
 *   is_iss(in) : true if this is an index skip scan
 *   is_key_range_satisfied(out): true, or false
 *   is_key_filter_satisfied(out): true, or false
 *
 * Note: This function applies key range condition and key filter condition to the current key value saved
 * in B+-tree scan structure. The results of the evaluation of the given conditions are returned through
 * key_range_satisfied and key_filter_satisfied.
 */
static int
btree_apply_key_range_and_filter (THREAD_ENTRY * thread_p, BTREE_SCAN * bts, bool is_iss, bool * is_key_range_satisfied,
				  bool * is_key_filter_satisfied, bool need_to_check_null)
{
  int c;			/* comparison result */
  DB_LOGICAL ev_res;		/* evaluation result */
  DB_MIDXKEY *mkey;		/* midxkey ptr */
  DB_VALUE ep;			/* element ptr */
  bool allow_null_in_midxkey = false;
  DB_TYPE type;
  int ret = NO_ERROR;

  *is_key_range_satisfied = *is_key_filter_satisfied = false;
  bts->key_range_max_value_equal = false;	/* init as false */

  /* Key Range Checking */
  if (bts->key_range.upper_key == NULL)
    {
      c = DB_GT;
    }
  else
    {
      c = btree_compare_key (bts->key_range.upper_key, &bts->cur_key, bts->btid_int.key_type, 1, 1, NULL);

      if (c == DB_UNK)
	{
	  /* error should have been set */
	  goto exit_on_error;
	}

      /* when using descending index the comparison should be changed again */
      if (bts->use_desc_index)
	{
	  c = -c;
	}
    }

  if (c < 0)
    {
      *is_key_range_satisfied = false;
    }
  else if (c == 0)
    {
      if (bts->key_range.range == GT_LE || bts->key_range.range == GE_LE || bts->key_range.range == INF_LE)
	{
	  *is_key_range_satisfied = true;
	  bts->key_range_max_value_equal = true;
	}
      else
	{
	  *is_key_range_satisfied = false;
	}
    }
  else
    {
      *is_key_range_satisfied = true;
    }

  if (*is_key_range_satisfied)
    {
      if (need_to_check_null && DB_VALUE_DOMAIN_TYPE (&bts->cur_key) == DB_TYPE_MIDXKEY
	  && bts->key_range.num_index_term > 0)
	{
	  mkey = db_get_midxkey (&(bts->cur_key));
	  /* get the last element from key range elements */
	  ret = pr_midxkey_get_element_nocopy (mkey, bts->key_range.num_index_term - 1, &ep, NULL, NULL);
	  if (ret != NO_ERROR)
	    {
	      goto exit_on_error;
	    }

	  if (DB_IS_NULL (&ep))
	    {
	      bool is_desc = false;

	      allow_null_in_midxkey = false;	/* init */

	      /*
	       *  assert_release (bts->key_range.num_index_term == 1);
	       *  todo: We need to understand what this part of the code does, as it is quite ambiguous.
	       *        Also, it should cover the other cases for bts->key_range.num_index_term as well.
	       *        This needs thoroughly checking.
	       */

	      if (prm_get_bool_value (PRM_ID_ORACLE_STYLE_EMPTY_STRING))
		{
		  if (ep.need_clear)
		    {		/* need to check */
		      type = DB_VALUE_DOMAIN_TYPE (&ep);
		      if (QSTR_IS_ANY_CHAR_OR_BIT (type) && ep.data.ch.medium.buf != NULL)
			{
			  allow_null_in_midxkey = true;	/* is Empty-string */
			}
		    }
		}

	      is_desc = (bts->use_desc_index ? true : false);
	      if (bts->btid_int.key_type && bts->btid_int.key_type->setdomain
		  && bts->btid_int.key_type->setdomain->is_desc)
		{
		  is_desc = !is_desc;
		}

	      if (is_iss && is_desc && bts->key_range.num_index_term == 1)
		{
		  /* We're inside an INDEX SKIP SCAN doing a descending scan. We allow the first term of a MIDXKEY to
		   * be NULL since ISS has to return the results for which the first column of the index is NULL. */
		  allow_null_in_midxkey = true;
		}
	      if (!allow_null_in_midxkey)
		{
		  *is_key_filter_satisfied = false;
		  goto end;	/* give up */
		}
	    }
	  if (!DB_IS_NULL (&ep) && ep.need_clear == true)
	    {
	      pr_clear_value (&ep);
	    }
	}

      /*
       * Only in case that key_range_satisfied is true,
       * the key filter can be applied to the current key value.
       */
      *is_key_filter_satisfied = true;
      if (bts->key_filter && bts->key_filter->scan_pred->regu_list)
	{
	  ev_res = eval_key_filter (thread_p, &bts->cur_key, bts->key_filter);
	  if (ev_res != V_TRUE)
	    {
	      *is_key_filter_satisfied = false;
	    }

	  if (ev_res == V_ERROR)
	    {
	      goto exit_on_error;
	    }
	}
    }

end:
  assert ((*is_key_range_satisfied == false && *is_key_filter_satisfied == false)
	  || (*is_key_range_satisfied == true && *is_key_filter_satisfied == false)
	  || (*is_key_range_satisfied == true && *is_key_filter_satisfied == true));

  return ret;

exit_on_error:
  return (ret == NO_ERROR && (ret = er_errid ()) == NO_ERROR) ? ER_FAILED : ret;
}

/*
 * btree_attrinfo_read_dbvalues () -
 *      Find db_values of desired attributes of given key
 *
 *   curr_key(in): the current key
 *   btree_att_ids(in): the btree attributes ids
 *   btree_num_att(in): the btree attributes count
 *   attr_info(in/out): The attribute information structure which describe the desired attributes
 *
 * Note: Find DB_VALUES of desired attributes of given key.
 * The attr_info structure must have already been initialized with the desired attributes.
 */
int
btree_attrinfo_read_dbvalues (THREAD_ENTRY * thread_p, DB_VALUE * curr_key, int *btree_att_ids, int btree_num_att,
			      HEAP_CACHE_ATTRINFO * attr_info, int func_index_col_id)
{
  int i, j, error = NO_ERROR;
  HEAP_ATTRVALUE *attr_value;
  bool found;

  if (curr_key == NULL || btree_att_ids == NULL || btree_num_att < 0 || attr_info == NULL)
    {
      return ER_FAILED;
    }

  if (DB_VALUE_TYPE (curr_key) != DB_TYPE_MIDXKEY)
    {
      if (attr_info->num_values != 1 || btree_num_att != 1 || attr_info->values->attrid != btree_att_ids[0])
	{
	  return ER_FAILED;
	}

      if (pr_clear_value (&(attr_info->values->dbvalue)) != NO_ERROR)
	{
	  attr_info->values->state = HEAP_UNINIT_ATTRVALUE;
	  return ER_FAILED;
	}

      if (pr_clone_value (curr_key, &(attr_info->values->dbvalue)) != NO_ERROR)
	{
	  attr_info->values->state = HEAP_UNINIT_ATTRVALUE;
	  return ER_FAILED;
	}

      attr_info->values->state = HEAP_WRITTEN_ATTRVALUE;
    }
  else
    {
      attr_value = attr_info->values;
      for (i = 0; i < attr_info->num_values; i++)
	{
	  found = false;
	  for (j = 0; j < btree_num_att; j++)
	    {
	      if (attr_value->attrid == btree_att_ids[j])
		{
		  found = true;
		  break;
		}
	    }

	  if (found == false)
	    {
	      error = ER_FAILED;
	      goto error;
	    }

	  if (pr_clear_value (&(attr_value->dbvalue)) != NO_ERROR)
	    {
	      error = ER_FAILED;
	      goto error;
	    }

	  if (func_index_col_id != -1)
	    {
	      /* consider that in the midxkey resides the function result, which must be skipped if we are interested
	       * in attributes */
	      if (j >= func_index_col_id)
		{
		  j++;
		}
	    }
	  if (pr_midxkey_get_element_nocopy (db_get_midxkey (curr_key), j, &(attr_value->dbvalue), NULL, NULL) !=
	      NO_ERROR)
	    {
	      error = ER_FAILED;
	      goto error;
	    }

	  attr_value->state = HEAP_WRITTEN_ATTRVALUE;
	  attr_value++;
	}
    }

  return NO_ERROR;

error:

  attr_value = attr_info->values;
  for (i = 0; i < attr_info->num_values; i++)
    {
      attr_value->state = HEAP_UNINIT_ATTRVALUE;
    }

  return error;
}

/*
 * btree_dump_curr_key () -
 *      Dump the current key
 *
 *   bts(in): pointer to B+-tree scan structure
 *   filter(in): key filter
 *   oid(in): the current oid
 *   iscan_id(in): index scan id
 */
static int
btree_dump_curr_key (THREAD_ENTRY * thread_p, BTREE_SCAN * bts, FILTER_INFO * filter, OID * oid,
		     INDX_SCAN_ID * iscan_id)
{
  HEAP_CACHE_ATTRINFO *attr_info;
  REGU_VARIABLE_LIST regu_list;
  int error;

  if (bts == NULL || iscan_id == NULL || iscan_id->indx_cov.list_id == NULL || iscan_id->indx_cov.val_descr == NULL
      || iscan_id->indx_cov.output_val_list == NULL || iscan_id->indx_cov.tplrec == NULL)
    {
      return ER_FAILED;
    }

  if (iscan_id->rest_attrs.num_attrs > 0)
    {
      /* normal index scan or join index scan */
      attr_info = iscan_id->rest_attrs.attr_cache;
      regu_list = iscan_id->rest_regu_list;
    }
  else if (iscan_id->pred_attrs.num_attrs > 0)
    {
      /* rest_attrs.num_attrs == 0 if index scan term is join index scan with always-true condition. example: SELECT
       * ... FROM X inner join Y on 1 = 1; */
      attr_info = iscan_id->pred_attrs.attr_cache;
      regu_list = iscan_id->scan_pred.regu_list;
    }
  else
    {
      assert_release (false);
      attr_info = NULL;
      regu_list = NULL;
    }

  error =
    btree_attrinfo_read_dbvalues (thread_p, &(bts->cur_key), filter->btree_attr_ids, filter->btree_num_attrs, attr_info,
				  iscan_id->indx_cov.func_index_col_id);
  if (error != NO_ERROR)
    {
      return error;
    }

  error = fetch_val_list (thread_p, regu_list, iscan_id->indx_cov.val_descr, NULL, oid, NULL, PEEK);
  if (error != NO_ERROR)
    {
      return error;
    }

  error =
    qexec_insert_tuple_into_list (thread_p, iscan_id->indx_cov.list_id, iscan_id->indx_cov.output_val_list,
				  iscan_id->indx_cov.val_descr, iscan_id->indx_cov.tplrec);
  if (error != NO_ERROR)
    {
      return error;
    }

  return NO_ERROR;
}

/*
 * btree_get_next_key_info () - Advance to next key in b-tree and obtain information.
 *
 * return		: Scan code.
 * thread_p (in)	: Thread entry.
 * btid (in)		: B-tree identifier.
 * bts (in)		: B-tree scan.
 * num_classes (in)	: Number of class in class_oid_ptr.
 * class_oids_ptr (in)	: Class Object identifiers.
 * index_scan_id_p (in) : Index scan data.
 * key_info (out)	: Array of value pointers to store key information.
 *
 * TODO: Handle unique on hierarchy indexes.
 */
SCAN_CODE
btree_get_next_key_info (THREAD_ENTRY * thread_p, BTID * btid, BTREE_SCAN * bts, int num_classes, OID * class_oids_ptr,
			 INDX_SCAN_ID * index_scan_id_p, DB_VALUE ** key_info)
{
  int error_code = NO_ERROR;
  SCAN_CODE result = S_SUCCESS;
  int oid_size;
  OID class_oid, oid;
  BTREE_SEARCH search_result = BTREE_KEY_NOTFOUND;

#if defined(BTREE_DEBUG)
  if (BTREE_INVALID_INDEX_ID (btid))
    {
      er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_BTREE_INVALID_INDEX_ID, 3, btid->vfid.fileid, btid->vfid.volid,
	      btid->root_pageid);
      return -1;
    }
#endif /* BTREE_DEBUG */

  OID_SET_NULL (&class_oid);

  /* initialize key filter */
  bts->key_filter = NULL;

  /* copy use desc index information in the BTS to have it available in the b-tree functions. */
  if (index_scan_id_p->indx_info)
    {
      bts->use_desc_index = index_scan_id_p->indx_info->use_desc_index != 0;
    }
  else
    {
      bts->use_desc_index = 0;
    }

  if (bts->C_vpid.pageid == NULL_PAGEID)
    {
      /* first btree_get_next_key_info call, initialize bts */
      error_code =
	btree_prepare_bts (thread_p, bts, btid, index_scan_id_p, NULL, NULL, &oid_Null_oid, NULL, NULL, false, NULL);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto error;
	}
      error_code = btree_range_scan_start (thread_p, bts);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto error;
	}
      /* search is positioned on the first key */
    }
  else
    {
      /* resume search */
      perfmon_inc_stat (thread_p, PSTAT_BT_NUM_RESUMES);

      error_code = btree_range_scan_resume (thread_p, bts);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto error;
	}
    }

  if (bts->end_scan)
    {
      /* Reached the end of leaf level */
      result = S_END;
      goto end;
    }

  oid_size = BTREE_IS_UNIQUE (bts->btid_int.unique_pk) ? 2 * OR_OID_SIZE : OR_OID_SIZE;

  /* C_page should be already loaded */
  assert (bts->C_page != NULL);

  /* TODO: Fill the rest of key information here */
  /* TODO: Do we have to get all oids or should we just count them ? Or maybe select only the first OID? Or a maximum
   * number of OIDs... */

  db_make_int (key_info[BTREE_KEY_INFO_VOLUMEID], bts->C_vpid.volid);
  db_make_int (key_info[BTREE_KEY_INFO_PAGEID], bts->C_vpid.pageid);
  db_make_int (key_info[BTREE_KEY_INFO_SLOTID], bts->slot_id);

  /* Get key */
  pr_clear_value (key_info[BTREE_KEY_INFO_KEY]);
  pr_clone_value (&bts->cur_key, key_info[BTREE_KEY_INFO_KEY]);

  /* Get overflow key and overflow oids */
  pr_clear_value (key_info[BTREE_KEY_INFO_OVERFLOW_KEY]);
  db_make_string (key_info[BTREE_KEY_INFO_OVERFLOW_KEY],
		  btree_leaf_is_flaged (&bts->key_record, BTREE_LEAF_RECORD_OVERFLOW_KEY) ? "true" : "false");
  pr_clear_value (key_info[BTREE_KEY_INFO_OVERFLOW_OIDS]);
  db_make_string (key_info[BTREE_KEY_INFO_OVERFLOW_OIDS],
		  btree_leaf_is_flaged (&bts->key_record, BTREE_LEAF_RECORD_OVERFLOW_OIDS) ? "true" : "false");

  /* Get OIDs count -> For now ignore the overflow OIDs */
  db_make_int (key_info[BTREE_KEY_INFO_OID_COUNT],
	       btree_record_get_num_oids (thread_p, &bts->btid_int, &bts->key_record, bts->offset, BTREE_LEAF_NODE));

  /* Get OIDs -> For now just the first OID */
  search_result =
    btree_key_find_first_visible_row (thread_p, &bts->btid_int, &bts->key_record, bts->offset, BTREE_LEAF_NODE, &oid,
				      &class_oid, -1);
  if (search_result == BTREE_KEY_NOTFOUND)
    {
      if (!VPID_ISNULL (&(bts->leaf_rec_info.ovfl)))
	{
	  /* search for visible OID into OID overflow page */
	  search_result =
	    btree_key_find_first_visible_row_from_all_ovf (thread_p, &bts->btid_int, &(bts->leaf_rec_info.ovfl), &oid,
							   &class_oid);
	  if (search_result == BTREE_KEY_NOTFOUND)
	    {
	      OID_SET_NULL (&oid);
	    }
	}
      else
	{
	  OID_SET_NULL (&oid);
	}
    }
  db_make_oid (key_info[BTREE_KEY_INFO_FIRST_OID], &oid);

  /* Key was consumed. */
  bts->key_status = BTS_KEY_IS_CONSUMED;

end:
  if (bts->C_page != NULL)
    {
      LSA_COPY (&bts->cur_leaf_lsa, pgbuf_get_lsa (bts->C_page));
      pgbuf_unfix_and_init (thread_p, bts->C_page);
    }

  if (bts->O_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, bts->C_page);
    }

  if (bts->P_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, bts->P_page);
    }

  if (result == S_END || result == S_ERROR)
    {
      btree_scan_clear_key (bts);
    }

  if (result == S_END)
    {
      VPID_SET_NULL (&bts->C_vpid);
    }

  return result;

error:
  result = S_ERROR;
  goto end;
}

/*
 * btree_find_min_or_max_key () -
 *   return: NO_ERROR
 *   btid(in):
 *   key(in):
 *   find_min_key(in):
 */
int
btree_find_min_or_max_key (THREAD_ENTRY * thread_p, BTID * btid, DB_VALUE * key, int find_min_key)
{
  VPID root_vpid;
  PAGE_PTR root_page_ptr = NULL;
  int offset;
  bool clear_key = false;
  DB_VALUE key_value;
  BTREE_ROOT_HEADER *root_header = NULL;
  RECDES rec;
  LEAF_REC leaf_pnt;
  BTREE_SCAN btree_scan, *BTS;
  int ret = NO_ERROR;

  if (key == NULL)
    {
      return NO_ERROR;
    }

  db_make_null (key);
  btree_init_temp_key_value (&clear_key, &key_value);

  BTS = &btree_scan;
  BTREE_INIT_SCAN (BTS);

  BTS->btid_int.sys_btid = btid;

  root_vpid.pageid = btid->root_pageid;
  root_vpid.volid = btid->vfid.volid;

  root_page_ptr = pgbuf_fix (thread_p, &root_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
  if (root_page_ptr == NULL)
    {
      goto exit_on_error;
    }

  (void) pgbuf_check_page_ptype (thread_p, root_page_ptr, PAGE_BTREE);

  root_header = btree_get_root_header (thread_p, root_page_ptr);
  if (root_header == NULL)
    {
      goto exit_on_error;
    }

  ret = btree_glean_root_header_info (thread_p, root_header, &BTS->btid_int);
  if (ret != NO_ERROR)
    {
      goto exit_on_error;
    }

  pgbuf_unfix_and_init (thread_p, root_page_ptr);

  assert (tp_valid_indextype (TP_DOMAIN_TYPE (BTS->btid_int.key_type)));

  /*
   * in case of desc domain index,
   * we have to find the min/max key in opposite order.
   */
  if (BTS->btid_int.key_type->is_desc)
    {
      find_min_key = !find_min_key;
    }

  if (find_min_key)
    {
      BTS->use_desc_index = 0;
    }
  else
    {
      BTS->use_desc_index = 1;
    }

  ret = btree_find_lower_bound_leaf (thread_p, BTS, NULL);
  if (ret != NO_ERROR)
    {
      goto exit_on_error;
    }

  if (!BTREE_END_OF_SCAN (BTS))
    {
      assert (BTS->slot_id > 0);
      if (spage_get_record (thread_p, BTS->C_page, BTS->slot_id, &rec, PEEK) != S_SUCCESS)
	{
	  goto exit_on_error;
	}

      if (btree_read_record (thread_p, &BTS->btid_int, BTS->C_page, &rec, &key_value, (void *) &leaf_pnt,
			     BTREE_LEAF_NODE, &clear_key, &offset, PEEK_KEY_VALUE, NULL) != NO_ERROR)
	{
	  goto exit_on_error;
	}

      (void) pr_clone_value (&key_value, key);

      btree_clear_key_value (&clear_key, &key_value);
    }

end:

  if (BTS->P_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, BTS->P_page);
    }

  if (BTS->C_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, BTS->C_page);
    }

  if (BTS->O_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, BTS->O_page);
    }

  if (root_page_ptr)
    {
      pgbuf_unfix_and_init (thread_p, root_page_ptr);
    }

  btree_clear_key_value (&clear_key, &key_value);

  return ret;

exit_on_error:

  ret = (ret == NO_ERROR && (ret = er_errid ()) == NO_ERROR) ? ER_FAILED : ret;

  goto end;
}

/*
 * Recovery functions
 */

/*
 * btree_rv_util_save_page_records () - Save a set of page records
 *   return: int
 *   page_ptr(in): Page Pointer
 *   first_slotid(in): First Slot identifier to be saved
 *   rec_cnt(in): Number of slots to be saved
 *   ins_slotid(in): First Slot identifier to reinsert set of records
 *   data(in): Data area where the records will be stored
 *             (Enough space(DB_PAGESIZE) must have been allocated by caller
 *   length(in): Effective length of the data area after save is completed
 *
 * Note: Copy the set of records to designated data area.
 *
 * Note: This is a UTILITY routine, but not an actual recovery routine
 */
int
btree_rv_util_save_page_records (THREAD_ENTRY * thread_p, PAGE_PTR page_ptr, INT16 first_slotid, int rec_cnt,
				 INT16 ins_slotid, char *data, int *length)
{
  RECDES rec;
  int i, offset, wasted;
  char *datap;
  int ret = NO_ERROR;

  *length = 0;
  datap = (char *) data + sizeof (RECSET_HEADER);
  offset = sizeof (RECSET_HEADER);
  wasted = DB_WASTED_ALIGN (offset, BTREE_MAX_ALIGN);
  datap += wasted;
  offset += wasted;

  for (i = 0; i < rec_cnt; i++)
    {
      assert (first_slotid + i > 0);
      if (spage_get_record (thread_p, page_ptr, first_slotid + i, &rec, PEEK) != S_SUCCESS)
	{
	  return ((ret = er_errid ()) == NO_ERROR) ? ER_FAILED : ret;
	}

      *(INT16 *) datap = rec.length;
      datap += 2;
      offset += 2;

      *(INT16 *) datap = rec.type;
      datap += 2;
      offset += 2;

      memcpy (datap, rec.data, rec.length);
      datap += rec.length;
      offset += rec.length;
      wasted = DB_WASTED_ALIGN (offset, BTREE_MAX_ALIGN);
      datap += wasted;
      offset += wasted;
    }

  datap = data;
  ((RECSET_HEADER *) datap)->rec_cnt = rec_cnt;
  ((RECSET_HEADER *) datap)->first_slotid = ins_slotid;
  *length = offset;

  return NO_ERROR;
}

/*
 * btree_rv_save_keyval_for_undo () - Save a < key, value > pair and other information for undo logical log purposes.
 *
 * return	: Error code.
 * btid (in)	: B+tree index identifier.
 * key (in)	: Key to be saved.
 * cls_oid (in) : Class identifier.
 * oid (in)	: Object identifier.
 * mvcc_id (in) : MVCCID for operation (NULL if it is not an MVCC operation).
 * data (out)	: Data area where the above fields will be stored
 *		  (Note: The caller should FREE the allocated area.)
 * length (out) : Length of the data area after save is completed.
 *
 * Note: Copy the adequate key-value information to the data area and return this data area.
 *	 The MVCCID is stored in buffer only if is not null. In this case, an area at the beginning of recovery data
 *	 is reserved for the log lsa of previous MVCC operation (used by vacuum).
 *
 * Note: This is a UTILITY routine, but not an actual recovery routine
 *
 * Warning: This routine assumes that the keyval is from a leaf page and not a non-leaf page. Because of this assumption,
 *          we use the index domain and not the non-leaf domain to write out the key value.
 *	    Currently all calls to this routine are from leaf pages. Be careful if you add a call to this routine.
 */
int
btree_rv_save_keyval_for_undo (BTID_INT * btid, DB_VALUE * key, OID * cls_oid, OID * oid, BTREE_MVCC_INFO * mvcc_info,
			       BTREE_OP_PURPOSE purpose, char *preallocated_buffer, char **data, int *capacity,
			       int *length)
{
  char *datap;
  int key_len;
  OR_BUF buf;
  PR_TYPE *pr_type;
  int ret = NO_ERROR;
  int size;
  OID oid_and_flags;

  assert (key != NULL);
  assert (cls_oid != NULL);
  assert (oid != NULL);

  *length = 0;

  key_len = (int) btree_get_disk_size_of_key (key);

  size = (OR_BTID_ALIGNED_SIZE	/* btid */
	  + BTREE_OBJECT_MAX_SIZE	/* Object OID and all its info. */
	  + key_len		/* key length */
	  + (2 * INT_ALIGNMENT));	/* extra space for alignment */

  /* Allocate enough memory to handle estimated size. */
  if (*data == NULL)
    {
      /* Initialize data */
      if (preallocated_buffer == NULL || *capacity < (int) size)
	{
	  /* No preallocated buffer or not enough capacity. */
	  *data = (char *) db_private_alloc (NULL, size);
	  if (*data == NULL)
	    {
	      ASSERT_ERROR_AND_SET (ret);
	      return ret;
	    }
	  *capacity = size;
	}
      else
	{
	  *data = preallocated_buffer;
	}
    }
  else if (*capacity < (int) size)
    {
      if (*data == preallocated_buffer)
	{
	  /* Allocate a new buffer. */
	  *data = (char *) db_private_alloc (NULL, size);
	  if (*data == NULL)
	    {
	      ASSERT_ERROR_AND_SET (ret);
	      return ret;
	    }
	  *capacity = size;
	}
      else
	{
	  /* Reallocate buffer. */
	  char *new_data = (char *) db_private_realloc (NULL, *data, size);
	  if (new_data == NULL)
	    {
	      ASSERT_ERROR_AND_SET (ret);
	      return ret;
	    }
	  *capacity = size;
	  *data = new_data;
	}
    }
  else
    {
      /* Current data buffer has enough space. */
    }

  /* Start packing recovery data. */
  datap = (char *) (*data);

  ASSERT_ALIGN (datap, INT_ALIGNMENT);

  datap = or_pack_btid (datap, btid->sys_btid);

  COPY_OID (&oid_and_flags, oid);

  /* Based on the purpose of recovery, some MVCC information may require packing. */
  switch (purpose)
    {
    case BTREE_OP_NOTIFY_VACUUM:
      /* Pack delete MVCCID or insert MVCCID. Vacuum will then visit this object and remove it or remove its insert
       * MVCCID. */
      assert (mvcc_info != NULL);
      if (BTREE_MVCC_INFO_IS_DELID_VALID (mvcc_info))
	{
	  /* Save delete MVCCID. */
	  BTREE_OID_SET_MVCC_FLAG (&oid_and_flags, BTREE_OID_HAS_MVCC_DELID);
	}
      else
	{
	  /* Save insert MVCCID. */
	  assert (BTREE_MVCC_INFO_IS_INSID_NOT_ALL_VISIBLE (mvcc_info));
	  BTREE_OID_SET_MVCC_FLAG (&oid_and_flags, BTREE_OID_HAS_MVCC_INSID);
	}
      break;

    case BTREE_OP_DELETE_OBJECT_PHYSICAL:
    case BTREE_OP_ONLINE_INDEX_TRAN_DELETE:
      /* Object is being physically removed. Since on rollback we should also recover MVCC information, it must be
       * packed. */
      assert (mvcc_info != NULL);
      if (BTREE_MVCC_INFO_IS_INSID_NOT_ALL_VISIBLE (mvcc_info))
	{
	  /* Do not pack insert MVCCID if it is all visible. */
	  BTREE_OID_SET_MVCC_FLAG (&oid_and_flags, BTREE_OID_HAS_MVCC_INSID);
	}
      if (BTREE_MVCC_INFO_IS_DELID_VALID (mvcc_info))
	{
	  /* Do not pack delete MVCCID if it is NULL. */
	  BTREE_OID_SET_MVCC_FLAG (&oid_and_flags, BTREE_OID_HAS_MVCC_DELID);
	}
      break;

    case BTREE_OP_INSERT_MARK_DELETED:
      /* We need delete MVCCID to log data since the log record will not be MVCC type and will not include transaction
       * MVCCID. */
      assert (mvcc_info != NULL);
      assert (BTREE_MVCC_INFO_IS_DELID_VALID (mvcc_info)
	      && mvcc_info->delete_mvccid == logtb_get_current_mvccid (NULL));
      BTREE_OID_SET_MVCC_FLAG (&oid_and_flags, BTREE_OID_HAS_MVCC_DELID);
      break;

    default:
      /* No MVCC information needs packing. It doesn't exist or it can be recovered in other ways. */
      break;
    }

  /* Pack class OID for unique indexes, if it is not the same with top class. Undo function should know to treat null
   * class OID as top class. */
  if (BTREE_IS_UNIQUE (btid->unique_pk) && !OID_EQ (cls_oid, &btid->topclass_oid))
    {
      BTREE_OID_SET_RECORD_FLAG (&oid_and_flags, BTREE_LEAF_RECORD_CLASS_OID);
    }

  /* Save OID and all flags. */
  OR_PUT_OID (datap, &oid_and_flags);
  datap += OR_OID_SIZE;

  if (BTREE_IS_UNIQUE (btid->unique_pk) && !OID_EQ (cls_oid, &btid->topclass_oid))
    {
      /* Save class OID. */
      OR_PUT_OID (datap, cls_oid);
      datap += OR_OID_SIZE;
    }

  /* Add required MVCC information. */
  if (BTREE_OID_IS_MVCC_FLAG_SET (&oid_and_flags, BTREE_OID_HAS_MVCC_INSID))
    {
      assert (mvcc_info != NULL && MVCCID_IS_NOT_ALL_VISIBLE (mvcc_info->insert_mvccid));
      OR_PUT_MVCCID (datap, &mvcc_info->insert_mvccid);
      datap += OR_MVCCID_SIZE;
    }
  if (BTREE_OID_IS_MVCC_FLAG_SET (&oid_and_flags, BTREE_OID_HAS_MVCC_DELID))
    {
      assert (mvcc_info != NULL);
      assert (MVCCID_IS_VALID (mvcc_info->delete_mvccid));
      OR_PUT_MVCCID (datap, &mvcc_info->delete_mvccid);
      datap += OR_MVCCID_SIZE;
    }

  ASSERT_ALIGN (datap, INT_ALIGNMENT);

  /* Save key. */
  or_init (&buf, datap, key_len);
  pr_type = btid->key_type->type;
  ret = pr_type->index_writeval (&buf, key);
  if (ret != NO_ERROR)
    {
      ASSERT_ERROR ();
      if (*data != preallocated_buffer)
	{
	  db_private_free_and_init (NULL, *data);
	}
      return ret;
    }
  datap += key_len;

  *length = CAST_BUFLEN (datap - *data);

  /* Safe guard. */
  assert (0 < *length);
  assert (*length <= (int) size);

  /* Success. */
  return NO_ERROR;
}

/*
 * btree_rv_save_keyval_for_undo_two_objects () - Create undo data by storing two objects.
 *
 * return		    : Error code.
 * btid (in)		    : B-tree info.
 * key (in)		    : Key value.
 * first_version (in)	    : First object info.
 * second_version (in)	    : Second object info.
 * preallocated_buffer (in) : Preallocated buffer to store undo data.
 * data (in)		    : Pointer to stored undo data.
 * capacity (in)	    : Capacity of data buffer.
 * length (in)		    : Length of undo data.
 */
int
btree_rv_save_keyval_for_undo_two_objects (BTID_INT * btid, DB_VALUE * key, BTREE_OBJECT_INFO * first_version,
					   BTREE_OBJECT_INFO * second_version, BTREE_OP_PURPOSE purpose,
					   char *preallocated_buffer, char **data, int *capacity, int *length)
{
  int size;
  int key_len;
  int error_code = NO_ERROR;
  char *datap = NULL;
  OR_BUF buf;
  PR_TYPE *pr_type;
  OID oid_and_flags;

  key_len = (int) btree_get_disk_size_of_key (key);

  size = OR_BTID_ALIGNED_SIZE +	/* btid */
    2 * OR_OID_SIZE +		/* first_version */
    2 * OR_OID_SIZE +		/* second_version */
    key_len +			/* key_length */
    2 * INT_ALIGNMENT;		/* extra space for alignment */

  /* Allocate enough memory to handle estimated size. */
  if (*data == NULL)
    {
      /* Initialize data */
      if (preallocated_buffer == NULL || *capacity < (int) size)
	{
	  /* No preallocated buffer or not enough capacity. */
	  *data = (char *) db_private_alloc (NULL, size);
	  if (*data == NULL)
	    {
	      ASSERT_ERROR_AND_SET (error_code);
	      return error_code;
	    }
	  *capacity = size;
	}
      else
	{
	  *data = preallocated_buffer;
	}
    }
  else if (*capacity < size)
    {
      if (*data == preallocated_buffer)
	{
	  /* Allocate a new buffer. */
	  *data = (char *) db_private_alloc (NULL, size);
	  if (*data == NULL)
	    {
	      ASSERT_ERROR_AND_SET (error_code);
	      return error_code;
	    }
	  *capacity = size;
	}
      else
	{
	  /* Reallocate buffer. */
	  char *new_data = (char *) db_private_realloc (NULL, *data, size);
	  if (new_data == NULL)
	    {
	      ASSERT_ERROR_AND_SET (error_code);
	      return error_code;
	    }
	  *capacity = size;
	  *data = new_data;
	}
    }
  else
    {
      /* Current data buffer has enough space. */
    }

  /* Start packing recovery data. */
  datap = (char *) (*data);

  ASSERT_ALIGN (datap, INT_ALIGNMENT);

  datap = or_pack_btid (datap, btid->sys_btid);

  /* Save first object. */
  if (BTREE_IS_UNIQUE (btid->unique_pk) && !OID_EQ (&first_version->class_oid, &btid->topclass_oid))
    {
      /* Mark object OID that class OID is also packed. */
      COPY_OID (&oid_and_flags, &first_version->oid);
      BTREE_OID_SET_RECORD_FLAG (&oid_and_flags, BTREE_LEAF_RECORD_CLASS_OID);
      /* Pack OID. */
      datap = or_pack_oid (datap, &oid_and_flags);
      /* Pack class OID. */
      datap = or_pack_oid (datap, &first_version->class_oid);
    }
  else
    {
      /* Pack OID. */
      datap = or_pack_oid (datap, &first_version->oid);
    }

  /* Save second object. */
  COPY_OID (&oid_and_flags, &second_version->oid);
  /* What MVCC info to save. */
  switch (purpose)
    {
    case BTREE_OP_INSERT_NEW_OBJECT:
      /* We need to save delete MVCCID of object being relocated to be able to find it. */
      if (BTREE_MVCC_INFO_IS_DELID_VALID (&second_version->mvcc_info))
	{
	  BTREE_OID_SET_MVCC_FLAG (&oid_and_flags, BTREE_OID_HAS_MVCC_DELID);
	}
      break;
    default:
      /* Unexpected. */
      assert (false);
      break;
    }

  if (BTREE_IS_UNIQUE (btid->unique_pk) && !OID_EQ (&second_version->class_oid, &btid->topclass_oid))
    {
      /* Mark object OID that class OID is also packed. */
      BTREE_OID_SET_RECORD_FLAG (&oid_and_flags, BTREE_LEAF_RECORD_CLASS_OID);
      /* Pack OID. */
      datap = or_pack_oid (datap, &oid_and_flags);
      /* Pack class OID. */
      datap = or_pack_oid (datap, &second_version->class_oid);
    }
  else
    {
      /* Pack OID. */
      datap = or_pack_oid (datap, &oid_and_flags);
    }

  if (BTREE_OID_IS_MVCC_FLAG_SET (&oid_and_flags, BTREE_OID_HAS_MVCC_INSID))
    {
      /* Pack insert MVCCID. */
      datap = or_pack_mvccid (datap, second_version->mvcc_info.insert_mvccid);
    }
  if (BTREE_OID_IS_MVCC_FLAG_SET (&oid_and_flags, BTREE_OID_HAS_MVCC_DELID))
    {
      /* Pack delete MVCCID. */
      datap = or_pack_mvccid (datap, second_version->mvcc_info.delete_mvccid);
    }

  ASSERT_ALIGN (datap, INT_ALIGNMENT);

  /* Save key. */
  or_init (&buf, datap, key_len);
  pr_type = btid->key_type->type;
  error_code = pr_type->index_writeval (&buf, key);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      if (*data != preallocated_buffer)
	{
	  db_private_free_and_init (NULL, *data);
	}
      return error_code;
    }
  datap += key_len;

  *length = CAST_BUFLEN (datap - *data);

  /* Safe guard. */
  assert (0 < *length);
  assert (*length <= size);

  /* Success. */
  return NO_ERROR;
}

#if defined(ENABLE_UNUSED_FUNCTION)
/*
 * btree_rv_util_dump_leafrec () -
 *   return: nothing
 *   btid(in):
 *   rec(in): Leaf Record
 *
 * Note: Dump a Tree Leaf Node Record
 *
 * Note: This is a UTILITY routine, but not an actual recovery routine
 */
void
btree_rv_util_dump_leafrec (THREAD_ENTRY * thread_p, FILE * fp, BTID_INT * btid, RECDES * rec)
{
  btree_dump_leaf_record (thread_p, fp, btid, rec, 2);
}

/*
 * btree_rv_util_dump_nleafrec () -
 *   return: nothing
 *   btid(in):
 *   rec(in): NonLeaf Record
 *
 * Note: Dump a Tree NonLeaf Node Record
 *
 * Note: This is a UTILITY routine, but not an actual recovery routine
 */
void
btree_rv_util_dump_nleafrec (THREAD_ENTRY * thread_p, FILE * fp, BTID_INT * btid, RECDES * rec)
{
  btree_dump_non_leaf_record (thread_p, fp, btid, rec, 2, 1);
}
#endif

/*
 * btree_rv_update_tran_stats () -
 *   return: int
 *   recv(in): Recovery structure
 *
 * Note: Recover the in-memory unique statistics.
 */
int
btree_rv_update_tran_stats (THREAD_ENTRY * thread_p, LOG_RCV * recv)
{
  char *datap;
  int num_nulls, num_oids, num_keys;
  BTID btid;

  assert (recv->length >= (3 * OR_INT_SIZE) + OR_BTID_ALIGNED_SIZE);

  /* unpack the root statistics */
  datap = (char *) recv->data;

  OR_GET_BTID (datap, &btid);
  datap += OR_BTID_ALIGNED_SIZE;

  num_keys = OR_GET_INT (datap);
  datap += OR_INT_SIZE;

  num_oids = OR_GET_INT (datap);
  datap += OR_INT_SIZE;

  num_nulls = OR_GET_INT (datap);
  datap += OR_INT_SIZE;

  if (logtb_tran_update_unique_stats (thread_p, &btid, num_keys, num_oids, num_nulls, false) != NO_ERROR)
    {
      goto error;
    }

  return NO_ERROR;

error:
  er_set (ER_FATAL_ERROR_SEVERITY, ARG_FILE_LINE, ER_GENERIC_ERROR, 0);

  return ER_GENERIC_ERROR;
}

/*
 * btree_rv_roothdr_undo_update () -
 *   return: int
 *   recv(in): Recovery structure
 *
 * Note: Recover the root header statistics for undo purposes.
 */
int
btree_rv_roothdr_undo_update (THREAD_ENTRY * thread_p, LOG_RCV * recv)
{
  char *datap;
  BTREE_ROOT_HEADER *root_header = NULL;

  if (recv->length < 3 * OR_INT_SIZE)
    {
      assert (false);
      goto error;
    }

  root_header = btree_get_root_header (thread_p, recv->pgptr);
  assert (root_header != NULL);

  if (root_header != NULL)
    {
      /* unpack the root statistics */
      datap = (char *) recv->data;
      root_header->num_nulls += OR_GET_INT (datap);
      datap += OR_INT_SIZE;
      root_header->num_oids += OR_GET_INT (datap);
      datap += OR_INT_SIZE;
      root_header->num_keys += OR_GET_INT (datap);
    }

  pgbuf_set_dirty (thread_p, recv->pgptr, DONT_FREE);

  return NO_ERROR;

error:

  er_set (ER_FATAL_ERROR_SEVERITY, ARG_FILE_LINE, ER_GENERIC_ERROR, 0);

  return ER_GENERIC_ERROR;
}

/*
 * btree_rv_roothdr_dump () -
 *   return:
 *   length(in):
 *   data(in):
 *
 * Note: Dump the root header statistics recovery information.
 */
void
btree_rv_roothdr_dump (FILE * fp, int length, void *data)
{
  char *datap;
  int max_key_len, null_delta, oid_delta, key_delta;

  /* unpack the root statistics */
  datap = (char *) data;
  max_key_len = OR_GET_INT (datap);
  datap += OR_INT_SIZE;
  null_delta = OR_GET_INT (datap);
  datap += OR_INT_SIZE;
  oid_delta = OR_GET_INT (datap);
  datap += OR_INT_SIZE;
  key_delta = OR_GET_INT (datap);
  datap += OR_INT_SIZE;

  fprintf (fp, "\nMAX_KEY_LEN: %d NUM NULLS DELTA: %d NUM OIDS DELTA: %d NUM KEYS DELTA: %d\n\n", max_key_len,
	   null_delta, oid_delta, key_delta);
}

/*
 * btree_rv_ovfid_undoredo_update () -
 *   return: int
 *   recv(in): Recovery structure
 *
 * Note: Recover the overflow VFID in the root header
 */
int
btree_rv_ovfid_undoredo_update (THREAD_ENTRY * thread_p, LOG_RCV * recv)
{
  VFID ovfid;
  BTREE_ROOT_HEADER *root_header = NULL;

  if (recv->length < (int) sizeof (VFID))
    {
      assert (false);
      goto error;
    }

  root_header = btree_get_root_header (thread_p, recv->pgptr);
  assert (root_header != NULL);

  if (root_header != NULL)
    {
      ovfid = *((VFID *) recv->data);	/* structure copy */
      root_header->ovfid = ovfid;
    }

  pgbuf_set_dirty (thread_p, recv->pgptr, DONT_FREE);

  return NO_ERROR;

error:

  er_set (ER_FATAL_ERROR_SEVERITY, ARG_FILE_LINE, ER_GENERIC_ERROR, 0);

  return ER_GENERIC_ERROR;
}

/*
 * btree_rv_ovfid_dump () -
 *   return:
 *   length(in):
 *   data(in):
 *
 * Note: Dump the overflow VFID for the root header.
 */
void
btree_rv_ovfid_dump (FILE * fp, int length, void *data)
{
  VFID ovfid;

  ovfid = *((VFID *) data);	/* structure copy */

  fprintf (fp, "\nOverflow key file VFID: %d|%d\n\n", ovfid.fileid, ovfid.volid);
}

/*
 * btree_rv_nodehdr_undoredo_update () - Recover an update to a node header. used either for undo or redo
 *   return: int
 *   recv(in): Recovery structure
 *
 * Note: Recover the update to a node header
 */
int
btree_rv_nodehdr_undoredo_update (THREAD_ENTRY * thread_p, LOG_RCV * recv)
{
  RECDES rec;
#if !defined(NDEBUG)
  RECDES peek_rec;
#endif
  int sp_success;

  rec.area_size = rec.length = recv->length;
  rec.type = REC_HOME;
  rec.data = (char *) recv->data;

#if !defined(NDEBUG)
  if (spage_get_record (thread_p, recv->pgptr, HEADER, &peek_rec, PEEK) != S_SUCCESS)
    {
      return ER_FAILED;
    }

  assert (rec.length == peek_rec.length);
#endif

  sp_success = spage_update (thread_p, recv->pgptr, HEADER, &rec);
  if (sp_success != SP_SUCCESS)
    {
      if (sp_success != SP_ERROR)
	{
	  er_set (ER_FATAL_ERROR_SEVERITY, ARG_FILE_LINE, ER_GENERIC_ERROR, 0);
	}
      ASSERT_ERROR ();
      assert (false);
      return er_errid ();
    }

  pgbuf_set_dirty (thread_p, recv->pgptr, DONT_FREE);

  return NO_ERROR;
}

/*
 * btree_rv_nodehdr_redo_insert () - Recover a node header insertion. used for redo
 *   return: int
 *   recv(in): Recovery structure
 *
 * Note: Recover a node header insertion by reinserting the node header for redo purposes.
 */
int
btree_rv_nodehdr_redo_insert (THREAD_ENTRY * thread_p, LOG_RCV * recv)
{
  RECDES rec;
  int sp_success;

  rec.area_size = rec.length = recv->length;
  rec.type = REC_HOME;
  rec.data = (char *) recv->data;
  sp_success = spage_insert_at (thread_p, recv->pgptr, HEADER, &rec);
  if (sp_success != SP_SUCCESS)
    {
      if (sp_success != SP_ERROR)
	{
	  er_set (ER_FATAL_ERROR_SEVERITY, ARG_FILE_LINE, ER_GENERIC_ERROR, 0);
	}
      ASSERT_ERROR ();
      assert (false);
      return er_errid ();
    }

  pgbuf_set_dirty (thread_p, recv->pgptr, DONT_FREE);

  return NO_ERROR;
}

/*
 * btree_rv_nodehdr_undo_insert () - Recover a node header insertion. used for undo
 *   return: int
 *   recv(in): Recovery structure
 *
 * Note: Recover a node header insertion by deletion  the node header for undo purposes.
 */
int
btree_rv_nodehdr_undo_insert (THREAD_ENTRY * thread_p, LOG_RCV * recv)
{
  PGSLOTID pg_slotid;

  pg_slotid = spage_delete (thread_p, recv->pgptr, HEADER);

  assert (pg_slotid != NULL_SLOTID);

  pgbuf_set_dirty (thread_p, recv->pgptr, DONT_FREE);

  return NO_ERROR;
}

/*
 * btree_rv_noderec_undoredo_update () - Recover an update to a node record. used either for undo or redo
 *   return:
 *   return: int
 *   recv(in): Recovery structure
 *
 * Note: Recover the update to a node record
 */
int
btree_rv_noderec_undoredo_update (THREAD_ENTRY * thread_p, LOG_RCV * recv)
{
  RECDES rec;
  INT16 slotid;
  int sp_success;

  slotid = recv->offset;
  rec.type = *(INT16 *) ((char *) recv->data + OFFS2);
  rec.area_size = rec.length = recv->length - OFFS3;
  rec.data = (char *) (recv->data) + OFFS3;

  assert (slotid > 0);
  sp_success = spage_update (thread_p, recv->pgptr, slotid, &rec);
  if (sp_success != SP_SUCCESS)
    {
      if (sp_success != SP_ERROR)
	{
	  er_set (ER_FATAL_ERROR_SEVERITY, ARG_FILE_LINE, ER_GENERIC_ERROR, 0);
	}
      ASSERT_ERROR ();
      assert (false);
      return er_errid ();
    }

  pgbuf_set_dirty (thread_p, recv->pgptr, DONT_FREE);

  return NO_ERROR;
}

/*
 * btree_rv_noderec_redo_insert () - Recover a node record insertion. used for redo
 *   return: int
 *   recv(in): Recovery structure
 *
 * Note: Recover a node record insertion by reinserting the record for redo purposes
 */
int
btree_rv_noderec_redo_insert (THREAD_ENTRY * thread_p, LOG_RCV * recv)
{
  RECDES rec;
  INT16 slotid;
  int sp_success;

  slotid = recv->offset;
  rec.type = *(INT16 *) ((char *) recv->data + OFFS2);
  rec.area_size = rec.length = recv->length - OFFS3;
  rec.data = (char *) (recv->data) + OFFS3;

  assert (slotid > 0);
  sp_success = spage_insert_at (thread_p, recv->pgptr, slotid, &rec);
  if (sp_success != SP_SUCCESS)
    {
      if (sp_success != SP_ERROR)
	{
	  er_set (ER_FATAL_ERROR_SEVERITY, ARG_FILE_LINE, ER_GENERIC_ERROR, 0);
	}
      ASSERT_ERROR ();
      assert (false);
      return er_errid ();
    }

  pgbuf_set_dirty (thread_p, recv->pgptr, DONT_FREE);

  return NO_ERROR;
}

/*
 * btree_rv_noderec_undo_insert () - Recover a node record insertion. used for undo
 *   return: int
 *   recv(in): Recovery structure
 *
 * Note: Recover a node record insertion by deleting the record for undo purposes
 */
int
btree_rv_noderec_undo_insert (THREAD_ENTRY * thread_p, LOG_RCV * recv)
{
  INT16 slotid;
  PGSLOTID pg_slotid;

  slotid = recv->offset;
  assert (slotid > 0);
  pg_slotid = spage_delete_for_recovery (thread_p, recv->pgptr, slotid);

  assert (pg_slotid != NULL_SLOTID);

  pgbuf_set_dirty (thread_p, recv->pgptr, DONT_FREE);

  return NO_ERROR;
}

/*
 * btree_rv_noderec_dump () - Dump node record recovery information
 *   return: int
 *   length(in): Length of Recovery Data
 *   data(in): The data being logged
 *
 * Note: Dump node record recovery information
 */
void
btree_rv_noderec_dump (FILE * fp, int length, void *data)
{
#if 0
  /* This needs to be fixed.  The easiest way is for the btid to be packed and sent, but this increases the log record.
   * We may want to allow this routine to know the layout of a node record.  TODO: ??? */

  int Node_Type;
  RECDES rec;

  Node_Type = *(INT16 *) ((char *) data + OFFS1);
  rec.type = *(INT16 *) ((char *) data + OFFS2);
  rec.area_size = DB_PAGESIZE;
  rec.data = (char *) malloc (DB_PAGESIZE);
  memcpy (rec.data, (char *) data + OFFS3, rec.length);

  if (Node_Type == 0)
    {
      btree_rv_util_dump_leafrec (fp, btid, &rec);
    }
  else
    {
      btree_rv_util_dump_nleafrec (fp, btid, &rec);
    }

  free_and_init (rec.data);
#endif
}

/*
 * btree_rv_noderec_dump_slot_id () -
 *   return: int
 *   length(in): Length of Recovery Data
 *   data(in): The data being logged
 *
 * Note: Dump the slot id for the slot to be deleted for undo purposes
 */

void
btree_rv_noderec_dump_slot_id (FILE * fp, int length, void *data)
{
  fprintf (fp, " Slot_id: %d \n", *(INT16 *) data);
}

/*
 * btree_rv_pagerec_insert () -
 *   return: int
 *   recv(in): Recovery structure
 *
 * Note: Put a set of records to the page
 */
int
btree_rv_pagerec_insert (THREAD_ENTRY * thread_p, LOG_RCV * recv)
{
  RECDES rec;
  RECSET_HEADER *recset_header;
  char *datap;
  int i, offset, wasted;
  int sp_success;

  /* initialization */
  recset_header = (RECSET_HEADER *) recv->data;

  /* insert back saved records */
  datap = (char *) recv->data + sizeof (RECSET_HEADER);
  offset = sizeof (RECSET_HEADER);
  wasted = DB_WASTED_ALIGN (offset, BTREE_MAX_ALIGN);
  datap += wasted;
  offset += wasted;
  for (i = 0; i < recset_header->rec_cnt; i++)
    {
      rec.area_size = rec.length = *(INT16 *) datap;
      datap += 2;
      offset += 2;
      rec.type = *(INT16 *) datap;
      datap += 2;
      offset += 2;
      rec.data = datap;
      datap += rec.length;
      offset += rec.length;
      wasted = DB_WASTED_ALIGN (offset, BTREE_MAX_ALIGN);
      datap += wasted;
      offset += wasted;

      assert (recset_header->first_slotid + i > 0);
      sp_success = spage_insert_at (thread_p, recv->pgptr, recset_header->first_slotid + i, &rec);
      if (sp_success != SP_SUCCESS)
	{
	  if (sp_success != SP_ERROR)
	    {
	      er_set (ER_FATAL_ERROR_SEVERITY, ARG_FILE_LINE, ER_GENERIC_ERROR, 0);
	    }
	  assert (false);
	  goto error;
	}			/* if */
    }				/* for */

  pgbuf_set_dirty (thread_p, recv->pgptr, DONT_FREE);

  return NO_ERROR;

error:

  ASSERT_ERROR ();
  return er_errid ();
}

/*
 * btree_rv_pagerec_delete () -
 *   return: int
 *   recv(in): Recovery structure
 *
 * Note: Delete a set of records from the page for undo or redo purpose
 */
int
btree_rv_pagerec_delete (THREAD_ENTRY * thread_p, LOG_RCV * recv)
{
  RECSET_HEADER *recset_header;
  int i;

  recset_header = (RECSET_HEADER *) recv->data;

  /* delete all specified records from the page */
  for (i = 0; i < recset_header->rec_cnt; i++)
    {
      assert (recset_header->first_slotid > 0);
      if (spage_delete (thread_p, recv->pgptr, recset_header->first_slotid) != recset_header->first_slotid)
	{
	  ASSERT_ERROR ();
	  assert (false);
	  return er_errid ();
	}
    }

  pgbuf_set_dirty (thread_p, recv->pgptr, DONT_FREE);

  return NO_ERROR;
}

/*
 * btree_rv_newpage_redo_init () -
 *   return: int
 *   recv(in): Recovery structure
 *
 * Note: Initialize a B+tree page.
 */
int
btree_rv_newpage_redo_init (THREAD_ENTRY * thread_p, LOG_RCV * recv)
{
  (void) pgbuf_set_page_ptype (thread_p, recv->pgptr, PAGE_BTREE);

  spage_initialize (thread_p, recv->pgptr, UNANCHORED_KEEP_SEQUENCE, BTREE_MAX_ALIGN, DONT_SAFEGUARD_RVSPACE);

  return NO_ERROR;
}

/*
 * btree_rv_read_keyval_info_nocopy () - Recover key value and other information on b-tree operation.
 *
 * return	    : Void.
 * thread_p (in)    : Thread entry.
 * datap (in)	    : Buffer containing recovery data.
 * data_size (in)   : Size of recovery data.
 * btid (out)	    : B-tree identifier.
 * cls_oid (out)    : Class identifier.
 * oid (out)	    : Object identifier.
 * mvcc_id (in/out) : Operation MVCCID. It must be NULL for non-MVCC operations and not NULL for MVCC operations.
 * key (out)	    : Key value.
 *
 * Note: If it is an MVCC operation recovery (mvcc_id is not NULL), data will
 *	 start with a log lsa (of a previous MVCC operation in log), which
 *	 is used my vacuum only and must be skipped.
 *
 * Warning: This assumes that the key value has the index's domain and not the
 *	    non-leaf domain. This should be the case since this is a logical
 *	    operation and not a physical one.
 */
int
btree_rv_read_keyval_info_nocopy (THREAD_ENTRY * thread_p, char *datap, int data_size, BTID_INT * btid, OID * cls_oid,
				  OID * oid, BTREE_MVCC_INFO * mvcc_info, DB_VALUE * key)
{
  OR_BUF buf;
  PR_TYPE *pr_type;
  VPID root_vpid;
  PAGE_PTR root = NULL;
  BTREE_ROOT_HEADER *root_header = NULL;
  int key_size = -1;
  int error_code = NO_ERROR;

  assert (mvcc_info != NULL);

  btree_rv_read_keybuf_nocopy (thread_p, datap, data_size, btid, cls_oid, oid, mvcc_info, &buf);

  root_vpid.pageid = btid->sys_btid->root_pageid;	/* read root page */
  root_vpid.volid = btid->sys_btid->vfid.volid;

  root = pgbuf_fix (thread_p, &root_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
  if (root == NULL)
    {
      ASSERT_ERROR_AND_SET (error_code);
      goto error;
    }

  (void) pgbuf_check_page_ptype (thread_p, root, PAGE_BTREE);

  root_header = btree_get_root_header (thread_p, root);
  if (root_header == NULL)
    {
      assert_release (false);
      error_code = ER_FAILED;
      goto error;
    }

  error_code = btree_glean_root_header_info (thread_p, root_header, btid);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto error;
    }

  pgbuf_unfix_and_init (thread_p, root);

  pr_type = btid->key_type->type;

  /* Do not copy the string--just use the pointer.  The pr_ routines for strings and sets have different semantics for
   * length. */
  if (pr_type->id == DB_TYPE_MIDXKEY)
    {
      key_size = CAST_BUFLEN (buf.endptr - buf.ptr);
    }

  error_code = pr_type->index_readval (&buf, key, btid->key_type, key_size, false /* not copy */ , NULL, 0);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto error;
    }

  return NO_ERROR;

error:

  assert (error_code != NO_ERROR);
  if (root != NULL)
    {
      pgbuf_unfix_and_init (thread_p, root);
    }
  return error_code;
}

/*
 * btree_rv_read_keybuf_nocopy () - Initializes a buffer from recovery info
 *
 * return	    : Void.
 * thread_p (in)    : Thread entry.
 * datap (in)	    : Buffer containing recovery data.
 * data_size (in)   : Size of recovery data.
 * btid (out)	    : B-tree identifier.
 * cls_oid (out)    : Class identifier.
 * oid (out)	    : Object identifier.
 * mvcc_id (in/out) : Operation MVCCID. It must be NULL for non-MVCC operations and not NULL for MVCC operations.
 * key_buf (out)    : buffer for packed key.
 *
 * Note: this should be prefered to btree_rv_read_keyval_info_nocopy
 *	 which performs an additional root page latch to retrieve key type.
 *	 Use this, if key type is already available.
 *
 * Warning: This assumes that the key value has the index's domain and not the
 *	    non-leaf domain. This should be the case since this is a logical
 *	    operation and not a physical one.
 */
void
btree_rv_read_keybuf_nocopy (THREAD_ENTRY * thread_p, char *datap, int data_size, BTID_INT * btid, OID * cls_oid,
			     OID * oid, BTREE_MVCC_INFO * mvcc_info, OR_BUF * key_buf)
{
  char *start = datap;

  assert (mvcc_info != NULL);

  /* extract the stored btid, key, oid data */
  datap = or_unpack_btid (datap, btid->sys_btid);

  OR_GET_OID (datap, oid);
  datap += OR_OID_SIZE;

  if (BTREE_OID_IS_RECORD_FLAG_SET (oid, BTREE_LEAF_RECORD_CLASS_OID))
    {
      /* Read class OID from record. */
      OR_GET_OID (datap, cls_oid);
      datap += OR_OID_SIZE;
    }
  else
    {
      /* Set class OID NULL. */
      OID_SET_NULL (cls_oid);
    }

  mvcc_info->flags = BTREE_OID_GET_MVCC_FLAGS (oid);
  if (mvcc_info->flags & BTREE_OID_HAS_MVCC_INSID)
    {
      OR_GET_MVCCID (datap, &mvcc_info->insert_mvccid);
      datap += OR_MVCCID_SIZE;
    }
  else
    {
      mvcc_info->insert_mvccid = MVCCID_ALL_VISIBLE;
    }
  if (mvcc_info->flags & BTREE_OID_HAS_MVCC_DELID)
    {
      OR_GET_MVCCID (datap, &mvcc_info->delete_mvccid);
      datap += OR_MVCCID_SIZE;
    }
  else
    {
      mvcc_info->delete_mvccid = MVCCID_NULL;
    }

  BTREE_OID_CLEAR_ALL_FLAGS (oid);

  datap = PTR_ALIGN (datap, INT_ALIGNMENT);
  or_init (key_buf, datap, (data_size - CAST_BUFLEN (datap - start)));
}

/*
 * btree_rv_read_keybuf_two_objects () - Read undo buffer packed which contains two objects.
 *
 * return		: Void.
 * thread_p (in)	: Thread entry.
 * datap (in)		: Packed data.
 * data_size (in)	: Packed data size.
 * btid_int (out)       : Output BTID for b-tree info.
 * first_version (out)  : First object version.
 * second_version (out) : Second object version.
 * key_buf (out)	: Buffer containing packed key value.
 */
void
btree_rv_read_keybuf_two_objects (THREAD_ENTRY * thread_p, char *datap, int data_size, BTID_INT * btid_int,
				  BTREE_OBJECT_INFO * first_version, BTREE_OBJECT_INFO * second_version,
				  OR_BUF * key_buf)
{
  char *start = datap;

  assert (datap != NULL);
  assert (data_size > 0);
  assert (btid_int != NULL);
  assert (btid_int->sys_btid != NULL);
  assert (first_version != NULL);
  assert (second_version != NULL);
  assert (key_buf != NULL);

  /* extract the stored btid */
  datap = or_unpack_btid (datap, btid_int->sys_btid);

  /* extract first object. */
  datap = or_unpack_oid (datap, &first_version->oid);
  assert (BTREE_OID_GET_MVCC_FLAGS (&first_version->oid) == 0);
  if (BTREE_OID_IS_RECORD_FLAG_SET (&first_version->oid, BTREE_LEAF_RECORD_CLASS_OID))
    {
      datap = or_unpack_oid (datap, &first_version->class_oid);
    }
  else
    {
      OID_SET_NULL (&first_version->class_oid);
    }
  BTREE_OID_CLEAR_ALL_FLAGS (&first_version->oid);

  /* extract second object. */
  datap = or_unpack_oid (datap, &second_version->oid);
  if (BTREE_OID_IS_RECORD_FLAG_SET (&second_version->oid, BTREE_LEAF_RECORD_CLASS_OID))
    {
      datap = or_unpack_oid (datap, &second_version->class_oid);
    }
  else
    {
      OID_SET_NULL (&second_version->class_oid);
    }

  if (BTREE_OID_IS_MVCC_FLAG_SET (&second_version->oid, BTREE_OID_HAS_MVCC_INSID))
    {
      datap = or_unpack_mvccid (datap, &second_version->mvcc_info.insert_mvccid);
      second_version->mvcc_info.flags |= BTREE_OID_HAS_MVCC_INSID;
    }
  if (BTREE_OID_IS_MVCC_FLAG_SET (&second_version->oid, BTREE_OID_HAS_MVCC_DELID))
    {
      datap = or_unpack_mvccid (datap, &second_version->mvcc_info.delete_mvccid);
      second_version->mvcc_info.flags |= BTREE_OID_HAS_MVCC_DELID;
    }
  BTREE_OID_CLEAR_ALL_FLAGS (&second_version->oid);

  datap = PTR_ALIGN (datap, INT_ALIGNMENT);
  or_init (key_buf, datap, (data_size - CAST_BUFLEN (datap - start)));
}

/*
 * btree_rv_keyval_undo_insert () - Undo insert operation.
 *
 * return		  : Error code.
 * thread_p (in)	  : Thread entry.
 * recv (in)		  : Recovery data.
 */
int
btree_rv_keyval_undo_insert (THREAD_ENTRY * thread_p, LOG_RCV * recv)
{
  BTID_INT btid;
  BTID sys_btid;
  OR_BUF key_buf;
  OID cls_oid;
  OID oid;
  char *datap;
  int datasize;
  BTREE_MVCC_INFO dummy_mvcc_info;
  int err = NO_ERROR;
  MVCCID insert_mvccid;

  /* btid needs a place to unpack the sys_btid into.  We'll use stack space. */
  btid.sys_btid = &sys_btid;

  /* extract the stored btid, key, oid data */
  datap = (char *) recv->data;
  datasize = recv->length;
  btree_rv_read_keybuf_nocopy (thread_p, datap, datasize, &btid, &cls_oid, &oid, &dummy_mvcc_info, &key_buf);

  assert (!OID_ISNULL (&oid));

  if (MVCCID_IS_VALID (recv->mvcc_id))
    {
      insert_mvccid = recv->mvcc_id;
    }
  else
    {
      insert_mvccid = MVCCID_ALL_VISIBLE;
    }

  /* Undo insert: just delete object and all its information. */
  err =
    btree_undo_insert_object (thread_p, btid.sys_btid, &key_buf, &oid, &cls_oid, insert_mvccid, &recv->reference_lsa);
  if (err != NO_ERROR)
    {
      ASSERT_ERROR ();
      assert (err == ER_BTREE_UNKNOWN_KEY || err == NO_ERROR || err == ER_INTERRUPTED);
      return err;
    }

  return NO_ERROR;
}

/*
 * btree_rv_keyval_undo_insert_unique () - Undo insert operation. Additional to regular insert, must make sure visible
 *					   object is returned to first position.
 *
 * return		  : Error code.
 * thread_p (in)	  : Thread entry.
 * recv (in)		  : Recovery data.
 */
int
btree_rv_keyval_undo_insert_unique (THREAD_ENTRY * thread_p, LOG_RCV * recv)
{
  BTID_INT btid;
  BTID sys_btid;
  OR_BUF key_buf;
  char *datap;
  int datasize;
  int err = NO_ERROR;
  MVCCID insert_mvccid = MVCCID_NULL;
  BTREE_OBJECT_INFO undo_insert_object = BTREE_OBJECT_INFO_INITIALIZER;
  BTREE_OBJECT_INFO second_object = BTREE_OBJECT_INFO_INITIALIZER;

  /* btid needs a place to unpack the sys_btid into.  We'll use stack space. */
  btid.sys_btid = &sys_btid;

  /* extract the stored btid, key, oid's data */
  datap = (char *) recv->data;
  datasize = recv->length;
  btree_rv_read_keybuf_two_objects (thread_p, datap, datasize, &btid, &undo_insert_object, &second_object, &key_buf);

  if (MVCCID_IS_VALID (recv->mvcc_id))
    {
      insert_mvccid = recv->mvcc_id;
    }
  else
    {
      insert_mvccid = MVCCID_ALL_VISIBLE;
    }

  /* Undo insert. */
  err =
    btree_undo_insert_object_unique_multiupd (thread_p, btid.sys_btid, &key_buf, &undo_insert_object, &second_object,
					      insert_mvccid, &recv->reference_lsa);
  if (err != NO_ERROR)
    {
      assert_release (false);
      return ER_FAILED;
    }

  return NO_ERROR;
}

/*
 * btree_rv_keyval_undo_insert_mvcc_delid () - Recovery function for undo MVCC delete.
 * return   : Error code.
 * recv (in): Recovery data.
 *
 * Note: Undo the insertion of a delete MVCCID by looking up <key, oid, delete_mvccid> pair in B+tree. Sometimes we
 *	 may need to also match the insert MVCCID (if the object was also inserted by this transaction).
 */
int
btree_rv_keyval_undo_insert_mvcc_delid (THREAD_ENTRY * thread_p, LOG_RCV * recv)
{
  BTID_INT btid;
  BTID sys_btid;
  OR_BUF key_buf;
  OID cls_oid;
  OID oid;
  char *datap;
  int datasize;
  BTREE_MVCC_INFO mvcc_info = BTREE_MVCC_INFO_INITIALIZER;
  int err = NO_ERROR;
  BTREE_MVCC_INFO match_mvccinfo = BTREE_MVCC_INFO_INITIALIZER;

  /* btid needs a place to unpack the sys_btid into.  We'll use stack space. */
  btid.sys_btid = &sys_btid;

  /* extract the stored btid, key, oid data */
  datap = (char *) recv->data;
  datasize = recv->length;

  btree_rv_read_keybuf_nocopy (thread_p, datap, datasize, &btid, &cls_oid, &oid, &mvcc_info, &key_buf);
  assert (!OID_ISNULL (&oid));

  if (recv->mvcc_id == MVCCID_NULL)
    {
      /* Not a MVCC log record. MVCCID should be saved in log data. */
      /* TODO: Is this acceptable? I don't think this code is ever touched. */
      assert (BTREE_MVCC_INFO_IS_DELID_VALID (&mvcc_info));
      BTREE_MVCC_INFO_SET_DELID (&match_mvccinfo, mvcc_info.delete_mvccid);
    }
  else
    {
      BTREE_MVCC_INFO_SET_DELID (&match_mvccinfo, recv->mvcc_id);
    }
  assert (MVCCID_IS_VALID (BTREE_MVCC_INFO_DELID (&match_mvccinfo)));

  if (BTREE_RV_IS_UNDO_MVCCDEL_MYOBJ (recv->offset))
    {
      /* We also need to match insert MVCCID, which is the same as delete_mvccid. */
      BTREE_MVCC_INFO_SET_INSID (&match_mvccinfo, match_mvccinfo.delete_mvccid);
    }

  err =
    btree_undo_mvcc_delete (thread_p, btid.sys_btid, &key_buf, &oid, &cls_oid, &match_mvccinfo, &recv->reference_lsa);
  if (err != NO_ERROR)
    {
      ASSERT_ERROR ();
      assert (err == ER_BTREE_UNKNOWN_KEY || err == NO_ERROR || err == ER_INTERRUPTED);
      return err;
    }

  return NO_ERROR;
}

/*
 * btree_rv_keyval_undo_delete () -
 *   return: int
 *   recv(in): Recovery structure
 *
 * Note: undo the deletion of a <key, val> pair to the B+tree,
 * by inserting the <key, val> pair to the tree.
 */
int
btree_rv_keyval_undo_delete (THREAD_ENTRY * thread_p, LOG_RCV * recv)
{
  BTID_INT btid;
  BTID sys_btid;
  DB_VALUE key;
  OID cls_oid;
  OID oid;
  char *datap;
  int datasize;
  BTREE_MVCC_INFO mvcc_info;
  int error_code = NO_ERROR;

  /* btid needs a place to unpack the sys_btid into.  We'll use stack space. */
  btid.sys_btid = &sys_btid;

  /* extract the stored btid, key, oid data */
  datap = (char *) recv->data;
  datasize = recv->length;
  error_code = btree_rv_read_keyval_info_nocopy (thread_p, datap, datasize, &btid, &cls_oid, &oid, &mvcc_info, &key);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      return error_code;
    }

  assert (!OID_ISNULL (&oid));

  /* Insert object and all its info. */
  error_code =
    btree_undo_delete_physical (thread_p, btid.sys_btid, &key, &cls_oid, &oid, &mvcc_info, &recv->reference_lsa);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      assert (error_code == ER_BTREE_DUPLICATE_OID || error_code == ER_INTERRUPTED);
      return error_code;
    }

  return NO_ERROR;
}

/*
 * btree_rv_remove_marked_for_delete () - Part of run postpone to remove an object which was previously marked
 *					  for delete.
 *
 *
 * return	 : Error code.
 * thread_p (in) : Thread entry.
 * rcv (in)	 : Recovery data.
 */
int
btree_rv_remove_marked_for_delete (THREAD_ENTRY * thread_p, LOG_RCV * rcv)
{
  BTID_INT btree_info;
  BTID sys_btid;
  OR_BUF key_buf;
  BTREE_OBJECT_INFO object_info = BTREE_OBJECT_INFO_INITIALIZER;
  int error_code = NO_ERROR;

  assert (!LSA_ISNULL (&rcv->reference_lsa));

  btree_info.sys_btid = &sys_btid;
  btree_rv_read_keybuf_nocopy (thread_p, (char *) rcv->data, rcv->length, &btree_info, &object_info.class_oid,
			       &object_info.oid, &object_info.mvcc_info, &key_buf);

  error_code =
    btree_delete_postponed (thread_p, btree_info.sys_btid, &key_buf, &object_info, object_info.mvcc_info.delete_mvccid,
			    &rcv->reference_lsa);
  if (error_code != NO_ERROR)
    {
      assert_release (false);
    }
  return error_code;
}

/*
 * btree_rv_keyval_dump () - Dump undo information <key-value> insertion.
 *
 * return      : Void.
 * fp (in)     : File pointer.
 * length (in) : Data length.
 * data (in)   : Recovery data.
 */
void
btree_rv_keyval_dump (FILE * fp, int length, void *data)
{
  BTID btid;
  OID oid, class_oid;
  short mvcc_flags;
  MVCCID mvccid;
  char *datap = (char *) data;

  datap = or_unpack_btid (datap, &btid);
  fprintf (fp, " BTID = { { %d , %d }, %d} \n ", btid.vfid.volid, btid.vfid.fileid, btid.root_pageid);

  datap = or_unpack_oid (datap, &oid);
  mvcc_flags = BTREE_OID_GET_MVCC_FLAGS (&oid);

  if (BTREE_OID_IS_RECORD_FLAG_SET (&oid, BTREE_LEAF_RECORD_CLASS_OID))
    {
      datap = or_unpack_oid (datap, &class_oid);
      BTREE_OID_CLEAR_ALL_FLAGS (&oid);
      fprintf (fp, " OID = { %d, %d, %d } \n", oid.volid, oid.pageid, oid.slotid);
      fprintf (fp, " CLASS_OID = { %d, %d, %d } \n", class_oid.volid, class_oid.pageid, class_oid.slotid);
    }
  else
    {
      BTREE_OID_CLEAR_ALL_FLAGS (&oid);
      fprintf (fp, " OID = { %d, %d, %d } \n", oid.volid, oid.pageid, oid.slotid);
    }

  if (mvcc_flags & BTREE_OID_HAS_MVCC_INSID)
    {
      datap = or_unpack_mvccid (datap, &mvccid);
      fprintf (fp, " INSERT MVCCID = %llu \n", (long long unsigned int) mvccid);
    }
  if (mvcc_flags & BTREE_OID_HAS_MVCC_DELID)
    {
      datap = or_unpack_mvccid (datap, &mvccid);
      fprintf (fp, " DELETE MVCCID = %llu \n", (long long unsigned int) mvccid);
    }
  /* Print key as hexa. */
  log_rv_dump_hexa (fp, length - CAST_BUFLEN (datap - (char *) data), datap);
}

/*
 * btree_rv_undoredo_copy_page () -
 *   return: int
 *   recv(in): Recovery structure
 *
 * Note: Copy a whole page back for undo or redo purposes
 */
int
btree_rv_undoredo_copy_page (THREAD_ENTRY * thread_p, LOG_RCV * recv)
{
  (void) pgbuf_set_page_ptype (thread_p, recv->pgptr, PAGE_BTREE);	/* redo */

  (void) memcpy (recv->pgptr, recv->data, DB_PAGESIZE);

  pgbuf_set_dirty (thread_p, recv->pgptr, DONT_FREE);

  return NO_ERROR;
}

/*
 * btree_rv_nop () -
 *   return: int
 *   recv(in): Recovery structure
 *
 *
 * Note: Does nothing. This routine is used for to accompany some compensating redo logs which are supposed
 * to do nothing.
 */
int
btree_rv_nop (THREAD_ENTRY * thread_p, LOG_RCV * recv)
{
  assert (recv->pgptr != NULL);
  pgbuf_set_dirty (thread_p, recv->pgptr, DONT_FREE);
  return NO_ERROR;
}

/*
 * btree_multicol_key_is_null () -
 *   return: Return true if DB_VALUE is a NULL multi-column key and false otherwise.
 *   key(in): Pointer to multi-column key
 *
 * Note: Check the multi-column key for a NULL value. In terms of the B-tree,
 * a NULL multi-column key is a sequence in which each element is NULL.
 */
bool
btree_multicol_key_is_null (DB_VALUE * key)
{
  bool status = false;
  DB_MIDXKEY *midxkey;
  unsigned char *bits;
  int nbytes, i;

  if (DB_VALUE_TYPE (key) == DB_TYPE_MIDXKEY)
    {
      assert (!DB_IS_NULL (key));

      midxkey = db_get_midxkey (key);
      assert (midxkey != NULL);

      /* ncolumns == -1 means already constructing step */
      if (midxkey && midxkey->ncolumns != -1)
	{
	  bits = (unsigned char *) midxkey->buf;
	  nbytes = OR_MULTI_BOUND_BIT_BYTES (midxkey->ncolumns);
	  for (i = 0; i < nbytes; i++)
	    {
	      if (bits[i] != (unsigned char) 0)
		{
		  return false;
		}
	    }

	  status = true;
	}
      if (midxkey->min_max_val.position != -1)
	{
	  return false;
	}
    }

  return status;
}

/*
 * btree_multicol_key_has_null () -
 *   return: Return true if DB_VALUE is a multi-column key and has a NULL element in it and false otherwise.
 *   key(in): Pointer to multi-column key
 *
 * Note: Check the multi-column  key has a NULL element.
 */
int
btree_multicol_key_has_null (DB_VALUE * key)
{
  int status = 0;
  DB_MIDXKEY *midxkey;
  int i;

  if (DB_VALUE_TYPE (key) == DB_TYPE_MIDXKEY)
    {
      assert (!DB_IS_NULL (key));

      midxkey = db_get_midxkey (key);
      assert (midxkey != NULL);

      /* ncolumns == -1 means already constructing step */
      if (midxkey && midxkey->ncolumns != -1)
	{
	  for (i = 0; i < midxkey->ncolumns; i++)
	    {
	      if (OR_MULTI_ATT_IS_UNBOUND (midxkey->buf, i))
		{
		  return 1;
		}
	    }

	  return 0;
	}
    }

  return status;
}

/*
 * btree_find_key_from_leaf () -
 *   return:
 *   btid(in):
 *   pg_ptr(in):
 *   key_cnt(in):
 *   oid(in):
 *   key(in):
 *   clear_key(in):
 */
static DISK_ISVALID
btree_find_key_from_leaf (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR pg_ptr, int key_cnt, OID * oid,
			  DB_VALUE * key, bool * clear_key)
{
  RECDES rec;
  LEAF_REC leaf_pnt;
  VPID ovfl_vpid;
  int i, offset;
  int error_code;
  PAGE_PTR found_page = NULL;
  int offset_to_object = NOT_FOUND;

  VPID_SET_NULL (&leaf_pnt.ovfl);

  for (i = 1; i <= key_cnt; i++)
    {
      if (spage_get_record (thread_p, pg_ptr, i, &rec, PEEK) != S_SUCCESS)
	{
	  return DISK_ERROR;
	}

      if (btree_read_record (thread_p, btid, pg_ptr, &rec, key, &leaf_pnt, BTREE_LEAF_NODE, clear_key, &offset,
			     PEEK_KEY_VALUE, NULL) != NO_ERROR)
	{
	  return DISK_ERROR;
	}
      ovfl_vpid = leaf_pnt.ovfl;

      error_code =
	btree_find_oid_and_its_page (thread_p, btid, oid, pg_ptr, BTREE_OP_DELETE_OBJECT_PHYSICAL, NULL, &rec,
				     &leaf_pnt, offset, &found_page, NULL, &offset_to_object, NULL);
      if (error_code != NO_ERROR)
	{
	  assert (found_page == NULL);
	  return DISK_ERROR;
	}
      if (offset_to_object != NOT_FOUND)
	{
	  /* key will be cleared by caller */
	  assert (found_page != NULL);
	  if (found_page != pg_ptr)
	    {
	      pgbuf_unfix_and_init (thread_p, found_page);
	    }
	  return DISK_VALID;
	}

      btree_clear_key_value (clear_key, key);
    }

  return DISK_INVALID;
}

/*
 * btree_find_key_from_nleaf () -
 *   return:
 *   btid(in):
 *   pg_ptr(in):
 *   key_cnt(in):
 *   oid(in):
 *   key(in):
 *   clear_key(in):
 */
static DISK_ISVALID
btree_find_key_from_nleaf (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR pg_ptr, int key_cnt, OID * oid,
			   DB_VALUE * key, bool * clear_key)
{
  int i;
  NON_LEAF_REC nleaf_ptr;
  VPID page_vpid;
  PAGE_PTR page = NULL;
  RECDES rec;
  DISK_ISVALID status = DISK_INVALID;

  for (i = 1; i <= key_cnt; i++)
    {
      if (spage_get_record (thread_p, pg_ptr, i, &rec, PEEK) != S_SUCCESS)
	{
	  return DISK_ERROR;
	}

      btree_read_fixed_portion_of_non_leaf_record (&rec, &nleaf_ptr);
      page_vpid = nleaf_ptr.pnt;

      page = pgbuf_fix (thread_p, &page_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
      if (page == NULL)
	{
	  return DISK_ERROR;
	}

      (void) pgbuf_check_page_ptype (thread_p, page, PAGE_BTREE);

      status = btree_find_key_from_page (thread_p, btid, page, oid, key, clear_key);
      pgbuf_unfix_and_init (thread_p, page);

      if (status == DISK_VALID)
	{
	  break;
	}
    }

  return status;
}

/*
 * btree_find_key_from_page () -
 *   return:
 *   btid(in):
 *   pg_ptr(in):
 *   oid(in):
 *   key(in):
 *   clear_key(in):
 */
static DISK_ISVALID
btree_find_key_from_page (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR pg_ptr, OID * oid, DB_VALUE * key,
			  bool * clear_key)
{
  BTREE_NODE_HEADER *header = NULL;
  BTREE_NODE_TYPE node_type;
  int key_cnt;
  DISK_ISVALID status;

  key_cnt = btree_node_number_of_keys (thread_p, pg_ptr);

  header = btree_get_node_header (thread_p, pg_ptr);
  if (header == NULL)
    {
      return DISK_ERROR;
    }

  node_type = (header->node_level > 1) ? BTREE_NON_LEAF_NODE : BTREE_LEAF_NODE;

  if (node_type == BTREE_NON_LEAF_NODE)
    {
      status = btree_find_key_from_nleaf (thread_p, btid, pg_ptr, key_cnt, oid, key, clear_key);
    }
  else
    {
      status = btree_find_key_from_leaf (thread_p, btid, pg_ptr, key_cnt, oid, key, clear_key);
    }

  return status;
}

/*
 * btree_find_key () -
 *   return:
 *   btid(in):
 *   oid(in):
 *   key(in):
 *   clear_key(in):
 */
DISK_ISVALID
btree_find_key (THREAD_ENTRY * thread_p, BTID * btid, OID * oid, DB_VALUE * key, bool * clear_key)
{
  VPID root_vpid;
  PAGE_PTR root = NULL;
  BTREE_ROOT_HEADER *root_header = NULL;
  BTID_INT btid_int;
  DISK_ISVALID status;

  root_vpid.pageid = btid->root_pageid;	/* read root page */
  root_vpid.volid = btid->vfid.volid;
  root = pgbuf_fix (thread_p, &root_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
  if (root == NULL)
    {
      return DISK_ERROR;
    }

  (void) pgbuf_check_page_ptype (thread_p, root, PAGE_BTREE);

  root_header = btree_get_root_header (thread_p, root);
  if (root_header == NULL)
    {
      status = DISK_ERROR;
      goto end;
    }

  btid_int.sys_btid = btid;
  btree_glean_root_header_info (thread_p, root_header, &btid_int);
  status = btree_find_key_from_page (thread_p, &btid_int, root, oid, key, clear_key);

end:

  assert (root != NULL);
  pgbuf_unfix_and_init (thread_p, root);

  return status;
}


int
btree_set_error (THREAD_ENTRY * thread_p, const DB_VALUE * key, const OID * obj_oid, const OID * class_oid,
		 const BTID * btid, const char *bt_name, int severity, int err_id, const char *filename, int lineno)
{
  char btid_msg_buf[OID_MSG_BUF_SIZE];
  char class_oid_msg_buf[OID_MSG_BUF_SIZE];
  char oid_msg_buf[OID_MSG_BUF_SIZE];
  char *index_name;
  char *class_name = NULL;
  char *keyval;

  assert (btid != NULL);

  /* init as empty string */
  btid_msg_buf[0] = class_oid_msg_buf[0] = oid_msg_buf[0] = 0;
  index_name = class_name = keyval = NULL;

  /* fetch index name from the class representation */
  if (class_oid != NULL && !OID_ISNULL (class_oid))
    {
      if (heap_get_indexinfo_of_btid (thread_p, class_oid, btid, NULL, NULL, NULL, NULL, &index_name, NULL) != NO_ERROR)
	{
	  er_clear ();
	  index_name = NULL;
	}
    }

  if (index_name && btid)
    {
      /* print valid btid */
      snprintf (btid_msg_buf, OID_MSG_BUF_SIZE, "(B+tree: %d|%d|%d)", btid->vfid.volid, btid->vfid.fileid,
		btid->root_pageid);
    }

  if (class_oid != NULL && !OID_ISNULL (class_oid))
    {
      int save_old_wait;

      snprintf (class_oid_msg_buf, OID_MSG_BUF_SIZE, "(CLASS_OID: %d|%d|%d)", class_oid->volid, class_oid->pageid,
		class_oid->slotid);

      /* we have latch on b-tree page. although unlikely, trying to get class name can lead to a dead latch. that is
       * undesirable, so we'll force no wait for latch here. if the latch fails, the notification will miss class name,
       * but it will have class OID. */

      /* We don't provide classname for VACUUM operations, since it may prevent other vacuums from fixing a page. */
      if (!VACUUM_IS_THREAD_VACUUM (thread_p))
	{
	  save_old_wait = xlogtb_reset_wait_msecs (thread_p, LK_FORCE_ZERO_WAIT);
	  if (heap_get_class_name (thread_p, class_oid, &class_name) != NO_ERROR)
	    {
	      /* ignore */
	      er_clear ();
	    }
	  (void) xlogtb_reset_wait_msecs (thread_p, save_old_wait);
	}
    }

  if (key && obj_oid)
    {
      keyval = pr_valstring (key);
      if (keyval)
	{
	  snprintf (oid_msg_buf, OID_MSG_BUF_SIZE, "(OID: %d|%d|%d)", obj_oid->volid, obj_oid->pageid, obj_oid->slotid);
	}
    }

  er_set (severity, filename, lineno, err_id, 6, (index_name) ? index_name : ((bt_name) ? bt_name : "*UNKNOWN-INDEX*"),
	  btid_msg_buf, (class_name) ? class_name : "*UNKNOWN-CLASS*", class_oid_msg_buf,
	  (keyval) ? keyval : "*UNKNOWN-KEY*", oid_msg_buf);

  if (keyval)
    {
      db_private_free (thread_p, keyval);
    }
  if (class_name)
    {
      free_and_init (class_name);
    }
  if (index_name)
    {
      free_and_init (index_name);
    }

  return NO_ERROR;
}

/*
 * btree_get_asc_desc - get asc/desc for column index from BTREE
 *
 *   return:  error code
 *   thread_p(in): THREAD_ENTRY
 *   btid(in): BTID
 *   col_idx(in): column index
 *   asc_desc(out): asc/desc for column index
 */
int
btree_get_asc_desc (THREAD_ENTRY * thread_p, BTID * btid, int col_idx, int *asc_desc)
{
  VPID r_vpid;			/* root page identifier */
  PAGE_PTR r_pgptr = NULL;	/* root page pointer */
  BTID_INT btid_int;
  BTREE_ROOT_HEADER *root_header = NULL;
  TP_DOMAIN *domain;
  int k, ret = NO_ERROR;

  if (btid == NULL || asc_desc == NULL)
    {
      return ER_FAILED;
    }

  ret = NO_ERROR;
  *asc_desc = 0;

  r_vpid.pageid = btid->root_pageid;
  r_vpid.volid = btid->vfid.volid;

  r_pgptr = pgbuf_fix (thread_p, &r_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
  if (r_pgptr == NULL)
    {
      goto exit_on_error;
    }

  (void) pgbuf_check_page_ptype (thread_p, r_pgptr, PAGE_BTREE);

  root_header = btree_get_root_header (thread_p, r_pgptr);
  if (root_header == NULL)
    {
      goto exit_on_error;
    }

  btid_int.sys_btid = btid;

  ret = btree_glean_root_header_info (thread_p, root_header, &btid_int);
  if (ret != NO_ERROR)
    {
      goto exit_on_error;
    }

  if (btid_int.key_type->setdomain)
    {
      domain = btid_int.key_type->setdomain;
      for (k = 1; k <= col_idx; k++)
	{
	  domain = domain->next;
	  if (domain == NULL)
	    {
	      goto exit_on_error;
	    }
	}
    }
  else
    {
      domain = btid_int.key_type;
      if (col_idx != 0)
	{
	  return ER_FAILED;
	}
    }

  *asc_desc = domain->is_desc;
  pgbuf_unfix_and_init (thread_p, r_pgptr);

  return NO_ERROR;

exit_on_error:

  if (r_pgptr != NULL)
    {
      pgbuf_unfix_and_init (thread_p, r_pgptr);
    }

  return (ret == NO_ERROR && (ret = er_errid ()) == NO_ERROR) ? ER_FAILED : ret;
}

static void
btree_set_unknown_key_error (THREAD_ENTRY * thread_p, BTID * btid, DB_VALUE * key, const char *debug_msg)
{
  int severity;
  PR_TYPE *pr_type;
  char *err_key;

  assert (btid != NULL);
  assert (key != NULL);

  /* If this is vacuum worker, we can expect many such error. Don't spam the log with them. */
  if (VACUUM_IS_THREAD_VACUUM_WORKER (thread_p))
    {
      return;
    }

  if (log_is_in_crash_recovery ())
    {
      severity = ER_WARNING_SEVERITY;
    }
  else
    {
      severity = ER_ERROR_SEVERITY;
    }

  err_key = pr_valstring (key);
  pr_type = pr_type_from_id (DB_VALUE_DOMAIN_TYPE (key));

  er_set (severity, ARG_FILE_LINE, ER_BTREE_UNKNOWN_KEY, 5, (err_key != NULL) ? err_key : "_NULL_KEY",
	  btid->vfid.fileid, btid->vfid.volid, btid->root_pageid,
	  (pr_type != NULL) ? pr_type->name : "INVALID KEY TYPE");

  er_log_debug (ARG_FILE_LINE, debug_msg);

  if (err_key != NULL)
    {
      db_private_free (thread_p, err_key);
    }
}

/*
 * btree_get_next_page_vpid () - Get VPID of next leaf node in b-tree.
 *
 * return	   : Error code.
 * thread_p (in)   : Thread entry.
 * leaf_page (in)  : Leaf node.
 * next_vpid (out) : Outputs VPID of next leaf node.
 */
static int
btree_get_next_page_vpid (THREAD_ENTRY * thread_p, PAGE_PTR leaf_page, VPID * next_vpid)
{
  BTREE_NODE_HEADER *header = NULL;

  assert (leaf_page != NULL);
  assert (btree_get_node_level (thread_p, leaf_page) == 1);
  assert (next_vpid != NULL);

  header = btree_get_node_header (thread_p, leaf_page);
  if (header == NULL)
    {
      assert (false);
      return ER_FAILED;
    }
  VPID_COPY (next_vpid, &header->next_vpid);
  return NO_ERROR;
}

/*
 * btree_get_next_page () -
 *   return:
 *
 *   page_p(in):
 */
static PAGE_PTR
btree_get_next_page (THREAD_ENTRY * thread_p, PAGE_PTR page_p)
{
  BTREE_NODE_HEADER *header = NULL;
  PAGE_PTR next_page = NULL;
  VPID next_vpid;

  if (page_p == NULL)
    {
      assert (page_p != NULL);
      return NULL;
    }

  header = btree_get_node_header (thread_p, page_p);
  if (header == NULL)
    {
      return NULL;
    }

  next_vpid = header->next_vpid;
  if (VPID_ISNULL (&next_vpid))
    {
      goto exit_on_error;
    }

  next_page = pgbuf_fix (thread_p, &next_vpid, OLD_PAGE, PGBUF_LATCH_WRITE, PGBUF_UNCONDITIONAL_LATCH);
  if (next_page == NULL)
    {
      goto exit_on_error;
    }

  (void) pgbuf_check_page_ptype (thread_p, next_page, PAGE_BTREE);

  return next_page;

exit_on_error:

  if (next_page)
    {
      pgbuf_unfix_and_init (thread_p, next_page);
    }
  return NULL;
}

/*
 * btree_set_vpid_previous_vpid () - Sets the prev VPID of a page
 *   return: error code
 *   btid(in): BTID
 *   page_p(in):
 *   prev(in): a vpid to be set as previous for the input page
 */
static int
btree_set_vpid_previous_vpid (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR page_p, VPID * prev)
{
  BTREE_NODE_HEADER *header = NULL;

  if (page_p == NULL)
    {
      return NO_ERROR;
    }

  header = btree_get_node_header (thread_p, page_p);
  if (header == NULL)
    {
      return ER_FAILED;
    }

  btree_node_header_undo_log (thread_p, &btid->sys_btid->vfid, page_p);
  header->prev_vpid = *prev;
  btree_node_header_redo_log (thread_p, &btid->sys_btid->vfid, page_p);

  pgbuf_set_dirty (thread_p, page_p, DONT_FREE);

  return NO_ERROR;
}

DB_VALUE_COMPARE_RESULT
btree_compare_key (DB_VALUE * key1, DB_VALUE * key2, TP_DOMAIN * key_domain, int do_coercion, int total_order,
		   int *start_colp)
{
  DB_VALUE_COMPARE_RESULT c = DB_UNK;
  DB_TYPE key1_type, key2_type;
  DB_TYPE dom_type;
  int dummy_diff_column;
  bool dom_is_desc = false, dummy_next_dom_is_desc;
  bool comparable = true;

  assert (key1 != NULL && key2 != NULL && key_domain != NULL);

  key1_type = DB_VALUE_DOMAIN_TYPE (key1);
  key2_type = DB_VALUE_DOMAIN_TYPE (key2);
  dom_type = TP_DOMAIN_TYPE (key_domain);

  if (DB_IS_NULL (key1))
    {
      if (DB_IS_NULL (key2))
	{
	  assert (false);
	  return DB_UNK;
	}

      return DB_LT;
    }

  if (DB_IS_NULL (key2))
    {
      if (DB_IS_NULL (key1))
	{
	  assert (false);
	  return DB_UNK;
	}

      return DB_GT;
    }

  if (dom_type == DB_TYPE_MIDXKEY)
    {
      /* safe code */
      if (key1_type != DB_TYPE_MIDXKEY)
	{
	  er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_TP_CANT_COERCE, 2, pr_type_name (key1_type),
		  pr_type_name (dom_type));
	  assert (false);
	  return DB_UNK;
	}
      if (key2_type != DB_TYPE_MIDXKEY)
	{
	  er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_TP_CANT_COERCE, 2, pr_type_name (key2_type),
		  pr_type_name (dom_type));
	  assert (false);
	  return DB_UNK;
	}

      c = pr_midxkey_compare (db_get_midxkey (key1), db_get_midxkey (key2), do_coercion, total_order, -1, start_colp,
			      NULL, NULL, &dummy_diff_column, &dom_is_desc, &dummy_next_dom_is_desc);
      assert_release (c == DB_UNK || (DB_LT <= c && c <= DB_GT));

      if (dom_is_desc)
	{
	  c = ((c == DB_GT) ? DB_LT : (c == DB_LT) ? DB_GT : c);
	}
    }
  else
    {
      assert (key1_type != DB_TYPE_MIDXKEY);
      assert (key2_type != DB_TYPE_MIDXKEY);

      assert (tp_valid_indextype (key1_type));
      assert (tp_valid_indextype (key2_type));

      /* safe code */
      if (key1_type == DB_TYPE_MIDXKEY)
	{
	  er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_TP_CANT_COERCE, 2, pr_type_name (key1_type),
		  pr_type_name (dom_type));
	  assert (false);
	  return DB_UNK;
	}
      if (key2_type == DB_TYPE_MIDXKEY)
	{
	  er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_TP_CANT_COERCE, 2, pr_type_name (key2_type),
		  pr_type_name (dom_type));
	  assert (false);
	  return DB_UNK;
	}

      bool are_types_comparable = (TP_ARE_COMPARABLE_KEY_TYPES (key1_type, key2_type)
				   && TP_ARE_COMPARABLE_KEY_TYPES (key1_type, dom_type)
				   && TP_ARE_COMPARABLE_KEY_TYPES (key2_type, dom_type));
      if (are_types_comparable)
	{
	  // check strings collation
	  if (TP_IS_STRING_TYPE (key1_type) && TP_IS_STRING_TYPE (key2_type)
	      && db_get_string_collation (key1) != db_get_string_collation (key2))
	    {
	      // not comparable
	      are_types_comparable = false;
	    }
	}

      if (are_types_comparable)
	{
	  /*
	   * for do_coercion = 2, we need to process key comparing as char-type
	   * in case that one of two arguments has varchar-type
	   * if the other argument has char-type
	   */
	  do_coercion = 2;
	  c = key_domain->type->cmpval (key1, key2, do_coercion, total_order, NULL, key_domain->collation_id);
	}
      else
	{
	  c = tp_value_compare_with_error (key1, key2, do_coercion, total_order, &comparable);

	  if (!comparable)
	    {
	      return DB_UNK;
	    }
	}

      assert_release (c == DB_UNK || (DB_LT <= c && c <= DB_GT));

      /* for single-column desc index */
      if (key_domain->is_desc)
	{
	  c = ((c == DB_GT) ? DB_LT : (c == DB_LT) ? DB_GT : c);
	}
    }

  assert_release (c == DB_UNK || (DB_LT <= c && c <= DB_GT));

  return c;
}

/*
 * btree_compare_individual_key_value - Compare individual key values
 *
 * return : comparison result
 * key1 (in) :
 * key2 (in) :
 * key_domain (in) :
 *
 * Function expects that both keys are not MIDXKEY. Please also look at btree_compare_key_value.
 */
static int
btree_compare_individual_key_value (DB_VALUE * key1, DB_VALUE * key2, TP_DOMAIN * key_domain)
{
  int c;
  bool key1_is_null, key2_is_null;

  /* should not be MIDXKEY */
  assert (DB_VALUE_DOMAIN_TYPE (key1) != DB_TYPE_MIDXKEY);
  assert (DB_VALUE_DOMAIN_TYPE (key2) != DB_TYPE_MIDXKEY);

  key1_is_null = DB_IS_NULL (key1);
  key2_is_null = DB_IS_NULL (key2);

  if (key1_is_null)
    {
      if (key2_is_null)
	{
	  return DB_EQ;
	}
      else
	{
	  /* NULL vs. key2 */
	  return key_domain->is_desc ? DB_GT : DB_LT;
	}
    }
  else
    {
      if (key2_is_null)
	{
	  /* key1 vs. NULL */
	  return key_domain->is_desc ? DB_LT : DB_GT;
	}
    }

  /* both are not null values */
  /* 
   * for do_coercion = 2, we need to process key comparing as char-type
   * in case that one of two arguments has varchar-type
   * if the other argument has char-type 
   */
  c = key_domain->type->cmpval (key1, key2, 2, 1, NULL, key_domain->collation_id);

  if (key_domain->is_desc)
    {
      c = ((c == DB_GT) ? DB_LT : (c == DB_LT) ? DB_GT : c);
    }

  assert (DB_LT <= c && c <= DB_GT);
  return c;
}

/*
 * btree_range_opt_check_add_index_key () - Add key in the array of top N keys for multiple range search optimization.
 *
 * return		    : Error code.
 * thread_p (in)	    : Thread entry.
 * bts (in)		    : B-tree scan structure.
 * multi_range_opt (in/out) : Multiple range optimization structure.
 * p_new_oid (in)	    : New candidate OID for top N keys.
 * key_added (out)	    : Outputs true if object made it to top N keys.
 */
static int
btree_range_opt_check_add_index_key (THREAD_ENTRY * thread_p, BTREE_SCAN * bts, MULTI_RANGE_OPT * multi_range_opt,
				     OID * p_new_oid, bool * key_added)
{
  DB_MIDXKEY *new_mkey = NULL;
  DB_VALUE *new_key_value = NULL;
  int error = NO_ERROR, i = 0;
  TP_DOMAIN *domain;
  bool has_null_domain;

  assert (multi_range_opt->use == true);

  if (DB_VALUE_DOMAIN_TYPE (&(bts->cur_key)) != DB_TYPE_MIDXKEY || multi_range_opt->sort_att_idx == NULL)
    {
      return ER_FAILED;
    }

  *key_added = true;

  assert (multi_range_opt->num_attrs != 0);
  if (multi_range_opt->num_attrs == 0)
    {
      return ER_FAILED;
    }

  new_mkey = db_get_midxkey (&(bts->cur_key));
  new_key_value = (DB_VALUE *) db_private_alloc (thread_p, multi_range_opt->num_attrs * sizeof (DB_VALUE));
  if (new_key_value == NULL)
    {
      er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_OUT_OF_VIRTUAL_MEMORY, 1,
	      sizeof (DB_VALUE *) * multi_range_opt->num_attrs);
      return ER_OUT_OF_VIRTUAL_MEMORY;
    }

  for (i = 0; i < multi_range_opt->num_attrs; i++)
    {
      db_make_null (&new_key_value[i]);
    }

  for (i = 0; i < multi_range_opt->num_attrs; i++)
    {
      error = pr_midxkey_get_element_nocopy (new_mkey, multi_range_opt->sort_att_idx[i], &new_key_value[i], NULL, NULL);
      if (error != NO_ERROR)
	{
	  goto exit;
	}
    }

  /* resolve domains */
  if (multi_range_opt->sort_col_dom == NULL)
    {
      multi_range_opt->sort_col_dom =
	(TP_DOMAIN **) db_private_alloc (thread_p, multi_range_opt->num_attrs * sizeof (TP_DOMAIN *));
      if (multi_range_opt->sort_col_dom == NULL)
	{
	  error = ER_OUT_OF_VIRTUAL_MEMORY;
	  goto exit;
	}

      for (i = 0; i < multi_range_opt->num_attrs; i++)
	{
	  multi_range_opt->sort_col_dom[i] = &tp_Null_domain;
	}
      multi_range_opt->has_null_domain = true;
    }

  if (multi_range_opt->has_null_domain)
    {
      has_null_domain = false;
      for (i = 0; i < multi_range_opt->num_attrs; i++)
	{
	  assert (multi_range_opt->sort_col_dom[i] != NULL);
	  if (multi_range_opt->sort_col_dom[i] == &tp_Null_domain)
	    {
	      domain = tp_domain_resolve_value (&new_key_value[i], NULL);
	      if (domain != &tp_Null_domain)
		{
		  multi_range_opt->sort_col_dom[i] = domain;
		}
	      else
		{
		  has_null_domain = true;
		}
	    }
	}
      multi_range_opt->has_null_domain = has_null_domain;
    }

  if (multi_range_opt->cnt == multi_range_opt->size)
    {
      int c = 0;
      DB_MIDXKEY *comp_mkey = NULL;
      DB_VALUE comp_key_value;
      bool reject_new_elem = false;
      RANGE_OPT_ITEM *last_item = NULL;

      last_item = multi_range_opt->top_n_items[multi_range_opt->size - 1];
      assert (last_item != NULL);

      comp_mkey = db_get_midxkey (&(last_item->index_value));

      /* if all keys are equal, the new element is rejected */
      reject_new_elem = true;
      for (i = 0; i < multi_range_opt->num_attrs; i++)
	{
	  db_make_null (&comp_key_value);
	  error = pr_midxkey_get_element_nocopy (comp_mkey, multi_range_opt->sort_att_idx[i], &comp_key_value, NULL,
						 NULL);
	  if (error != NO_ERROR)
	    {
	      goto exit;
	    }

	  c = btree_compare_individual_key_value (&comp_key_value, &new_key_value[i], multi_range_opt->sort_col_dom[i]);

	  pr_clear_value (&comp_key_value);
	  if (c != 0)
	    {
	      /* see if new element should be rejected or accepted and stop checking keys */
	      reject_new_elem = (multi_range_opt->is_desc_order[i]) ? (c > 0) : (c < 0);
	      break;
	    }
	}

      if (reject_new_elem)
	{
	  /* do not add */
	  *key_added = false;

	  if (new_key_value != NULL)
	    {
	      for (i = 0; i < multi_range_opt->num_attrs; i++)
		{
		  pr_clear_value (&new_key_value[i]);
		}
	      db_private_free_and_init (thread_p, new_key_value);
	    }

	  return NO_ERROR;
	}

      /* overwrite the last item with the new key and OIDs */
      pr_clear_value (&(last_item->index_value));
      pr_clone_value (&(bts->cur_key), &(last_item->index_value));
      COPY_OID (&(last_item->inst_oid), p_new_oid);
    }
  else
    {
      RANGE_OPT_ITEM *curr_item = NULL;
      /* just insert on last position available */
      assert (multi_range_opt->cnt < multi_range_opt->size);

      curr_item = (RANGE_OPT_ITEM *) db_private_alloc (thread_p, sizeof (RANGE_OPT_ITEM));
      if (curr_item == NULL)
	{
	  error = ER_OUT_OF_VIRTUAL_MEMORY;
	  goto exit;
	}

      multi_range_opt->top_n_items[multi_range_opt->cnt] = curr_item;
      pr_clone_value (&(bts->cur_key), &(curr_item->index_value));

      COPY_OID (&(curr_item->inst_oid), p_new_oid);

      multi_range_opt->cnt++;
    }

  /* find the position for this element */
  /* if there is only one element => nothing to do */
  if (multi_range_opt->cnt > 1)
    {
      int pos = 0;
      error =
	btree_top_n_items_binary_search (multi_range_opt->top_n_items, multi_range_opt->sort_att_idx,
					 multi_range_opt->sort_col_dom, multi_range_opt->is_desc_order, new_key_value,
					 multi_range_opt->num_attrs, 0, multi_range_opt->cnt - 1, &pos);
      if (error != NO_ERROR)
	{
	  goto exit;
	}
      if (pos != multi_range_opt->cnt - 1)
	{
	  RANGE_OPT_ITEM *temp_item;
	  int mem_size = (multi_range_opt->cnt - 1 - pos) * sizeof (RANGE_OPT_ITEM *);

	  /* copy last item to temp */
	  temp_item = multi_range_opt->top_n_items[multi_range_opt->cnt - 1];

	  /* move all items one position to the right in order to free the position for the new item */
	  memcpy (multi_range_opt->buffer, &multi_range_opt->top_n_items[pos], mem_size);
	  memcpy (&multi_range_opt->top_n_items[pos + 1], multi_range_opt->buffer, mem_size);

	  /* put new item at its designated position */
	  multi_range_opt->top_n_items[pos] = temp_item;
	}
      else
	{
	  /* the new item is already in the correct position */
	}
    }

exit:
  if (new_key_value != NULL)
    {
      for (i = 0; i < multi_range_opt->num_attrs; i++)
	{
	  pr_clear_value (&new_key_value[i]);
	}

      db_private_free_and_init (thread_p, new_key_value);
    }
  return error;
}

/*
 * btree_top_n_items_binary_search () - searches for the right position for the keys in new_key_values in top N items
 *
 * return	       : error code
 * top_n_items (in)    : current top N item list
 * att_idxs (in)       : indexes for midxkey attributes
 * domains (in)	       : domains for midxkey attributes
 * desc_order (in)     : is descending order for midxkey attributes if NULL, ascending order will be considered
 * new_key_values (in) : key values for the new item
 * num_keys (in)       : number of keys that are compared
 * first (in)	       : position of the first item in current range
 * last (in)	       : position of the last item in current range
 * new_pos (out)       : the position where the new item fits
 *
 * NOTE	: At each step, split current range in half and compare with the
 *	  middle item. If all keys are equal save the position of middle item.
 *	  If middle item is better, look between middle and last, otherwise
 *	  look between first and middle.
 *	  The recursion stops when the range cannot be split anymore
 *	  (first + 1 <= last), when normally first is better and last is worse
 *	  and the new item should replace last. There is a special case when
 *	  the new item is better than all items in top N. In this case,
 *	  first must be 0 and an extra compare is made (to see if new item
 *	  should in fact replace first).
 */
static int
btree_top_n_items_binary_search (RANGE_OPT_ITEM ** top_n_items, int *att_idxs, TP_DOMAIN ** domains, bool * desc_order,
				 DB_VALUE * new_key_values, int num_keys, int first, int last, int *new_pos)
{
  DB_MIDXKEY *comp_mkey = NULL;
  DB_VALUE comp_key_value;
  RANGE_OPT_ITEM *comp_item;
  int i, c, error = NO_ERROR;

  int middle;

  assert (last >= first && new_pos != NULL);
  if (last <= first + 1)
    {
      if (first == 0)
	{
	  /* need to check if the new key is smaller than the first */
	  comp_item = top_n_items[0];
	  comp_mkey = db_get_midxkey (&(comp_item->index_value));

	  for (i = 0; i < num_keys; i++)
	    {
	      db_make_null (&comp_key_value);
	      error = pr_midxkey_get_element_nocopy (comp_mkey, att_idxs[i], &comp_key_value, NULL, NULL);
	      if (error != NO_ERROR)
		{
		  return error;
		}

	      c = btree_compare_individual_key_value (&comp_key_value, &new_key_values[i], domains[i]);

	      pr_clear_value (&comp_key_value);
	      if (c != 0)
		{
		  if ((desc_order != NULL && desc_order[i] ? c > 0 : c < 0))
		    {
		      /* new value is not better than the first */
		      break;
		    }
		  else
		    {
		      /* new value is better than the first */
		      new_pos = 0;
		      return NO_ERROR;
		    }
		}
	    }
	  /* new value is equal to first, fall through */
	}
      /* here: the new values should be between first and last */
      *new_pos = last;
      return NO_ERROR;
    }

  /* compare new value with the value in the middle of the current range */
  middle = (last + first) / 2;
  comp_item = top_n_items[middle];
  comp_mkey = db_get_midxkey (&(comp_item->index_value));

  for (i = 0; i < num_keys; i++)
    {
      db_make_null (&comp_key_value);
      error = pr_midxkey_get_element_nocopy (comp_mkey, att_idxs[i], &comp_key_value, NULL, NULL);
      if (error != NO_ERROR)
	{
	  return error;
	}

      c = btree_compare_individual_key_value (&comp_key_value, &new_key_values[i], domains[i]);

      pr_clear_value (&comp_key_value);
      if (c != 0)
	{
	  if ((desc_order != NULL && desc_order[i] ? c > 0 : c < 0))
	    {
	      /* the new value is worse than the one in the middle */
	      first = middle;
	    }
	  else
	    {
	      /* the new value is better than the one in the middle */
	      last = middle;
	    }
	  return btree_top_n_items_binary_search (top_n_items, att_idxs, domains, desc_order, new_key_values, num_keys,
						  first, last, new_pos);
	}
    }
  /* all keys were equal, the new item can be put in current position */
  *new_pos = middle;
  return NO_ERROR;
}

/*
 * btree_iss_set_key () - save the current key
 *
 *   return: error code
 *   bts(in):
 *   iss(in):
 */
static int
btree_iss_set_key (BTREE_SCAN * bts, INDEX_SKIP_SCAN * iss)
{
  regu_variable_node *key = NULL;
  int ret = NO_ERROR;

  /* check environment */
  if (DB_VALUE_DOMAIN_TYPE (&bts->cur_key) != DB_TYPE_MIDXKEY || iss == NULL || iss->skipped_range == NULL)
    {
      assert_release (false);
      er_set (ER_FATAL_ERROR_SEVERITY, ARG_FILE_LINE, ER_GENERIC_ERROR, 0);

      return ER_FAILED;
    }

  /* get correct key to update value to (key1 for normal scan or key2 for reverse scan); the fetch range will have one
   * of the keys NULLed */
  if (iss->skipped_range->key1 == NULL)
    {
      key = iss->skipped_range->key2;
    }
  else
    {
      key = iss->skipped_range->key1;
    }

  /* check the key */
  if (key == NULL || key->value.funcp == NULL || key->value.funcp->operand == NULL
      || key->value.funcp->operand->value.type != TYPE_DBVAL)
    {
      assert_release (false);
      return ER_FAILED;
    }

  /* save the found key as bound for next fetch */
  pr_clear_value (&key->value.funcp->operand->value.value.dbval);
  ret = pr_clone_value (&bts->cur_key, &key->value.funcp->operand->value.value.dbval);
  if (ret != NO_ERROR)
    {
      return ret;
    }

  return NO_ERROR;
}

/*****************************************************************************/
/* For migrate_90beta_to_91                                                  */
/*****************************************************************************/
#define MIGRATE_90BETA_TO_91

#if defined(MIGRATE_90BETA_TO_91)

static int btree_fix_ovfl_oid_pages_by_btid (THREAD_ENTRY * thread_p, BTID * btid);
static int btree_fix_ovfl_oid_pages_tree (THREAD_ENTRY * thread_p, BTID * btid, char *btname);
static int btree_fix_ovfl_oid_page (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR pg_ptr, char *btname);
static int btree_compare_oid (const void *oid_mem1, const void *oid_mem2);

static int fixed_pages;

static int
btree_fix_ovfl_oid_pages_by_btid (THREAD_ENTRY * thread_p, BTID * btid)
{
  char *btname;
  FILE_DESCRIPTORS fdes;
  int ret = NO_ERROR;

  assert (!BTID_IS_NULL (btid));
  assert (btid->root_pageid != NULL_PAGEID);

  ret = file_descriptor_get (thread_p, &btid->vfid, &fdes);
  if (ret != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto exit_on_end;
    }

  /* get the index name of the index key */
  ret = heap_get_indexinfo_of_btid (thread_p, &fdes.btree.class_oid, btid, NULL, NULL, NULL, NULL, &btname, NULL);
  if (ret != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto exit_on_end;
    }

  ret = btree_fix_ovfl_oid_pages_tree (thread_p, btid, btname);
  if (ret != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto exit_on_end;
    }

exit_on_end:

  if (btname)
    {
      free_and_init (btname);
    }

  return ret;
}

static int
btree_fix_ovfl_oid_pages_tree (THREAD_ENTRY * thread_p, BTID * btid, char *btname)
{
  VPID vpid;
  PAGE_PTR pgptr = NULL;
  BTREE_ROOT_HEADER *root_header = NULL;
  BTREE_NODE_HEADER *header = NULL;
  BTID_INT btid_int;

  /* fetch the root page */

  vpid.pageid = btid->root_pageid;
  vpid.volid = btid->vfid.volid;

  pgptr = pgbuf_fix (thread_p, &vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
  if (pgptr == NULL)
    {
      return ER_FAILED;
    }

  (void) pgbuf_check_page_ptype (thread_p, pgptr, PAGE_BTREE);

  root_header = btree_get_root_header (thread_p, pgptr);
  if (root_header == NULL)
    {
      pgbuf_unfix_and_init (thread_p, pgptr);
      return ER_FAILED;
    }

  btid_int.sys_btid = btid;
  if (btree_glean_root_header_info (thread_p, root_header, &btid_int) != NO_ERROR)
    {
      pgbuf_unfix_and_init (thread_p, pgptr);
      return ER_FAILED;
    }

  pgbuf_unfix_and_init (thread_p, pgptr);

  if (BTREE_IS_UNIQUE (btid_int.unique_pk))
    {
      return NO_ERROR;
    }

  pgptr = btree_find_leftmost_leaf (thread_p, btid, &vpid, NULL);
  if (pgptr == NULL)
    {
      return ER_FAILED;
    }

  fixed_pages = 0;
  fprintf (stdout, "Index: %-50s %8d", btname, fixed_pages);

  /* traverse leaf page links */

  while (true)
    {
      if (btree_fix_ovfl_oid_page (thread_p, &btid_int, pgptr, btname) != NO_ERROR)
	{
	  pgbuf_unfix_and_init (thread_p, pgptr);
	  fprintf (stdout, "\n");
	  return ER_FAILED;
	}

      header = btree_get_node_header (thread_p, pgptr);
      if (header == NULL)
	{
	  pgbuf_unfix_and_init (thread_p, pgptr);
	  fprintf (stdout, "\n");
	  return ER_FAILED;
	}

      vpid = header->next_vpid;

      pgbuf_unfix_and_init (thread_p, pgptr);

      if (VPID_ISNULL (&vpid))
	{
	  break;
	}

      pgptr = pgbuf_fix (thread_p, &vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
      if (pgptr == NULL)
	{
	  fprintf (stdout, "\n");
	  return ER_FAILED;
	}

      (void) pgbuf_check_page_ptype (thread_p, pgptr, PAGE_BTREE);
    }

  fprintf (stdout, "\n");

  return NO_ERROR;
}

static int
btree_fix_ovfl_oid_page (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR pg_ptr, char *btname)
{
  RECDES leaf_rec, ovfl_rec;
  int key_cnt, i, offset;
  LEAF_REC leaf_pnt;
  bool dummy;
  VPID ovfl_vpid;
  PAGE_PTR ovfl_page = NULL;
  char *rv_data = NULL;
  int rv_data_len;
  char rv_data_buf[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  BTREE_NODE_HEADER *header = NULL;
  int size = BTREE_OBJECT_FIXED_SIZE (btid);

  rv_data = PTR_ALIGN (rv_data_buf, BTREE_MAX_ALIGN);

  key_cnt = btree_node_number_of_keys (thread_p, pg_ptr);

  header = btree_get_node_header (thread_p, pg_ptr);

  assert_release (header != NULL);
  assert_release (header->node_level == 1);	/* BTREE_LEAF_NODE */

  for (i = 1; i <= key_cnt; i++)
    {
      if (spage_get_record (thread_p, pg_ptr, i, &leaf_rec, PEEK) != S_SUCCESS)
	{
	  return ER_FAILED;
	}

      VPID_SET_NULL (&leaf_pnt.ovfl);
      if (btree_read_record (thread_p, btid, pg_ptr, &leaf_rec, NULL, &leaf_pnt, BTREE_LEAF_NODE, &dummy, &offset,
			     PEEK_KEY_VALUE, NULL) != NO_ERROR)
	{
	  return ER_FAILED;
	}

      ovfl_vpid = leaf_pnt.ovfl;

      while (!VPID_ISNULL (&ovfl_vpid))
	{
	  ovfl_page = pgbuf_fix (thread_p, &ovfl_vpid, OLD_PAGE, PGBUF_LATCH_WRITE, PGBUF_UNCONDITIONAL_LATCH);
	  if (ovfl_page == NULL)
	    {
	      return ER_FAILED;
	    }

	  (void) pgbuf_check_page_ptype (thread_p, ovfl_page, PAGE_BTREE);

	  btree_get_next_overflow_vpid (thread_p, ovfl_page, &ovfl_vpid);

	  if (spage_get_record (thread_p, ovfl_page, 1, &ovfl_rec, PEEK) != S_SUCCESS)
	    {
	      pgbuf_unfix_and_init (thread_p, ovfl_page);
	      return ER_FAILED;
	    }

	  /* undo log only */
	  btree_rv_write_log_record (rv_data, &rv_data_len, &ovfl_rec, BTREE_LEAF_NODE);
	  log_append_undo_data2 (thread_p, RVBT_NDRECORD_UPD, &btid->sys_btid->vfid, ovfl_page, 1, rv_data_len,
				 rv_data);

	  qsort (ovfl_rec.data, CEIL_PTVDIV (ovfl_rec.length, size), size, btree_compare_oid);

	  pgbuf_set_dirty (thread_p, ovfl_page, FREE);

	  fprintf (stdout, "\rIndex: %-50s %8d", btname, ++fixed_pages);
	  if (fixed_pages % 100 == 0)
	    {
	      fflush (stdout);
	    }
	}
    }

  fflush (stdout);
  return NO_ERROR;
}

static int
btree_compare_oid (const void *oid_mem1, const void *oid_mem2)
{
  OID oid1, oid2;

  BTREE_GET_OID (oid_mem1, &oid1);
  BTREE_OID_CLEAR_RECORD_FLAGS (&oid1);

  BTREE_GET_OID (oid_mem2, &oid2);
  BTREE_OID_CLEAR_RECORD_FLAGS (&oid2);

  return oid_compare (&oid1, &oid2);
}
#endif /* MIGRATE_90BETA_TO_91 */

#if !defined(NDEBUG)
static int
btree_verify_node (THREAD_ENTRY * thread_p, BTID_INT * btid_int, PAGE_PTR page_ptr)
{
  int ret = NO_ERROR;
  int key_cnt;
  BTREE_NODE_HEADER *header = NULL;
  BTREE_NODE_TYPE node_type;
  bool check_interrupt = false;

  assert_release (btid_int != NULL);
  assert_release (page_ptr != NULL);

  /* check header validation */

  key_cnt = btree_node_number_of_keys (thread_p, page_ptr);

  header = btree_get_node_header (thread_p, page_ptr);
  if (header == NULL)
    {
      assert (false);
      return ER_FAILED;
    }

  if (key_cnt > 0)
    {
      assert (header->max_key_len > 0);
    }

  assert (header->split_info.pivot >= 0 && header->split_info.pivot <= 1);
  assert (header->split_info.index >= 0);
  assert (header->node_level > 0);

  assert (header->prev_vpid.volid >= NULL_VOLID);
  assert (header->prev_vpid.pageid >= NULL_PAGEID);
  assert (header->next_vpid.volid >= NULL_VOLID);
  assert (header->next_vpid.pageid >= NULL_PAGEID);

#if 0				/* DO NOT DELETE ME */
  /*
   * FOR TEST
   *   usually should admit below assertions.
   *   but assert is possible in normal case rarely.
   *   so, turn on this block in develop stage if you want.
   */

  assert (header->node_level < 20);

  assert (header->prev_vpid.volid < 1000);
  assert (header->prev_vpid.pageid < 1000000);
  assert (header->next_vpid.volid < 1000);
  assert (header->next_vpid.pageid < 1000000);
#endif

  if ((prm_get_integer_value (PRM_ID_ER_BTREE_DEBUG) & BTREE_DEBUG_HEALTH_FULL) == 0)
    {
      return NO_ERROR;
    }

  /* don't let interrupts break our verification */
  check_interrupt = logtb_set_check_interrupt (thread_p, false);

  node_type = (header->node_level > 1) ? BTREE_NON_LEAF_NODE : BTREE_LEAF_NODE;

  if (node_type == BTREE_NON_LEAF_NODE)
    {
      ret = btree_verify_nonleaf_node (thread_p, btid_int, page_ptr);
    }
  else
    {
      ret = btree_verify_leaf_node (thread_p, btid_int, page_ptr);
    }

  assert_release (ret == NO_ERROR);
  (void) logtb_set_check_interrupt (thread_p, check_interrupt);

  return ret;
}

static int
btree_verify_nonleaf_node (THREAD_ENTRY * thread_p, BTID_INT * btid_int, PAGE_PTR page_ptr)
{
  BTREE_NODE_HEADER *header = NULL;
  TP_DOMAIN *key_domain;
  int key_cnt;
  int i;
  int offset;
  int c;
  bool clear_prev_key, clear_curr_key;
  DB_VALUE prev_key, curr_key;
  RECDES rec;
  NON_LEAF_REC non_leaf_pnt;
  int error = NO_ERROR;

  assert_release (btid_int != NULL);
  assert_release (page_ptr != NULL);

  key_domain = btid_int->key_type;

  key_cnt = btree_node_number_of_keys (thread_p, page_ptr);
  assert_release (key_cnt >= 1);

  btree_init_temp_key_value (&clear_prev_key, &prev_key);
  btree_init_temp_key_value (&clear_curr_key, &curr_key);

  /* check key order; exclude neg-inf separator */
  for (i = 1; i < key_cnt; i++)
    {
      if (spage_get_record (thread_p, page_ptr, i, &rec, PEEK) != S_SUCCESS)
	{
	  assert (false);
	  return ER_FAILED;
	}

      error =
	btree_read_record_without_decompression (thread_p, btid_int, &rec, &prev_key, &non_leaf_pnt,
						 BTREE_NON_LEAF_NODE, &clear_prev_key, &offset, PEEK_KEY_VALUE);
      if (error != NO_ERROR)
	{
	  assert (false);
	  return error;
	}

      if (spage_get_record (thread_p, page_ptr, i + 1, &rec, PEEK) != S_SUCCESS)
	{
	  assert (false);
	  btree_clear_key_value (&clear_prev_key, &prev_key);
	  return ER_FAILED;
	}

      error =
	btree_read_record_without_decompression (thread_p, btid_int, &rec, &curr_key, &non_leaf_pnt,
						 BTREE_NON_LEAF_NODE, &clear_curr_key, &offset, PEEK_KEY_VALUE);
      if (error != NO_ERROR)
	{
	  assert (false);
	  btree_clear_key_value (&clear_prev_key, &prev_key);
	  return error;
	}

      c = btree_compare_key (&prev_key, &curr_key, btid_int->key_type, 1, 1, NULL);

      btree_clear_key_value (&clear_curr_key, &curr_key);
      btree_clear_key_value (&clear_prev_key, &prev_key);

      if (c != DB_LT)
	{
	  if (i == 1)
	    {
	      header = btree_get_node_header (thread_p, page_ptr);
	      if (header == NULL)
		{
		  return ER_FAILED;
		}

	      if (VPID_ISNULL (&(header->next_vpid)))
		{
		  /* This page is first non-leaf page. So, this key is neg-inf dummy key */

		  assert (header->next_vpid.volid == NULL_VOLID);

		  return NO_ERROR;
		}
	    }

	  btree_dump_page (thread_p, stdout, NULL, btid_int, NULL, page_ptr, NULL, 2, 2);
	  assert (false);
	  return ER_FAILED;
	}
    }

  return NO_ERROR;
}

static int
btree_verify_leaf_node (THREAD_ENTRY * thread_p, BTID_INT * btid_int, PAGE_PTR page_ptr)
{
  BTREE_NODE_HEADER *header = NULL;
  TP_DOMAIN *key_domain;
  VPID prev_vpid, next_vpid;
  int key_cnt, offset, oid_cnt;
  int i, k, c;
  bool clear_prev_key, clear_curr_key;
  DB_VALUE prev_key, curr_key;
  RECDES rec;
  LEAF_REC leaf_pnt;
  OID oid, class_oid;
  OR_BUF buf;
  int oid_size;
  short mvcc_flags;
  int error = NO_ERROR;
  BTREE_MVCC_INFO mvcc_info;
  int common_prefix = 0;
  DB_VALUE lower_fence_key;
  bool clear_lower_fence_key = false;
  DB_VALUE uncompressed_value;

  assert_release (btid_int != NULL);
  assert_release (page_ptr != NULL);

  if (BTREE_IS_UNIQUE (btid_int->unique_pk))
    {
      oid_size = (2 * OR_OID_SIZE);
    }
  else
    {
      oid_size = OR_OID_SIZE;
    }

  clear_prev_key = clear_curr_key = false;

  key_domain = btid_int->key_type;

  key_cnt = btree_node_number_of_keys (thread_p, page_ptr);

  /* read the header record */
  header = btree_get_node_header (thread_p, page_ptr);
  if (header == NULL)
    {
      assert (false);
      goto exit_on_error;
    }

  prev_vpid = header->prev_vpid;
  next_vpid = header->next_vpid;

  btree_init_temp_key_value (&clear_curr_key, &curr_key);
  btree_init_temp_key_value (&clear_prev_key, &prev_key);
  btree_init_temp_key_value (&clear_lower_fence_key, &lower_fence_key);
  db_make_null (&uncompressed_value);

  common_prefix = btree_node_common_prefix (thread_p, btid_int, page_ptr);
  if (common_prefix > 0)
    {
      assert (btree_is_fence_key (page_ptr, 1));
      if (spage_get_record (thread_p, page_ptr, 1, &rec, PEEK) != S_SUCCESS)
	{
	  btree_dump_page (thread_p, stdout, NULL, btid_int, NULL, page_ptr, NULL, 2, 2);
	  assert (false);
	  goto exit_on_error;
	}
      error =
	btree_read_record_without_decompression (thread_p, btid_int, &rec, &lower_fence_key, &leaf_pnt, BTREE_LEAF_NODE,
						 &clear_lower_fence_key, &offset, PEEK_KEY_VALUE);
      if (error != NO_ERROR)
	{
	  btree_dump_page (thread_p, stdout, NULL, btid_int, NULL, page_ptr, NULL, 2, 2);
	  assert (false);
	  goto exit_on_error;
	}
    }
  /* There must be two fences to have common prefix. */
  assert (common_prefix == 0 || (btree_is_fence_key (page_ptr, 1) && btree_is_fence_key (page_ptr, key_cnt)));

  /* check key order */
  for (i = 1; i < key_cnt; i++)
    {
      if (spage_get_record (thread_p, page_ptr, i, &rec, PEEK) != S_SUCCESS)
	{
	  btree_dump_page (thread_p, stdout, NULL, btid_int, NULL, page_ptr, NULL, 2, 2);
	  assert (false);
	  goto exit_on_error;
	}

      error =
	btree_read_record_without_decompression (thread_p, btid_int, &rec, &prev_key, &leaf_pnt, BTREE_LEAF_NODE,
						 &clear_prev_key, &offset, PEEK_KEY_VALUE);
      if (error != NO_ERROR)
	{
	  btree_dump_page (thread_p, stdout, NULL, btid_int, NULL, page_ptr, NULL, 2, 2);
	  assert (false);
	  goto exit_on_error;
	}

      /*
       * record oid check
       */
      oid_cnt = btree_record_get_num_oids (thread_p, btid_int, &rec, offset, BTREE_LEAF_NODE);

      (void) btree_leaf_get_first_object (btid_int, &rec, &oid, &class_oid, &mvcc_info);
      if (btree_leaf_is_flaged (&rec, BTREE_LEAF_RECORD_FENCE))
	{
	  if (oid.pageid != NULL_PAGEID || oid.volid != 0 || oid.slotid != 0)
	    {
	      btree_dump_page (thread_p, stdout, NULL, btid_int, NULL, page_ptr, NULL, 2, 2);
	      assert (false);
	    }
	  if (i > 1 && i < key_cnt)
	    {
	      /* Fence key cannot be in the middle of the node. */
	      btree_dump_page (thread_p, stdout, NULL, btid_int, NULL, page_ptr, NULL, 2, 2);
	      assert (false);
	    }
	  if (i > 1 && VPID_ISNULL (&header->next_vpid))
	    {
	      /* Fence key cannot be at the end of index (unless it is the only record in page). */
	      btree_dump_page (thread_p, stdout, NULL, btid_int, NULL, page_ptr, NULL, 2, 2);
	      assert (false);
	    }
	  if (i < key_cnt && VPID_ISNULL (&header->prev_vpid))
	    {
	      /* Fence key cannot be at the beginning of index (unless it is the only record in page). */
	      btree_dump_page (thread_p, stdout, NULL, btid_int, NULL, page_ptr, NULL, 2, 2);
	      assert (false);
	    }
	}
      else
	{
	  if (oid.pageid <= NULL_PAGEID || oid.volid <= NULL_VOLID || oid.slotid <= NULL_SLOTID)
	    {
	      btree_dump_page (thread_p, stdout, NULL, btid_int, NULL, page_ptr, NULL, 2, 2);
	      assert (false);
	    }

	  if (BTREE_IS_UNIQUE (btid_int->unique_pk))
	    {
	      if (class_oid.pageid <= NULL_PAGEID || class_oid.volid <= NULL_VOLID || class_oid.slotid <= NULL_SLOTID)
		{
		  btree_dump_page (thread_p, stdout, NULL, btid_int, NULL, page_ptr, NULL, 2, 2);
		  assert (false);
		}
	    }

	  if (common_prefix > 0)
	    {
	      /* Check uncompress works. */
	      error = pr_midxkey_add_prefix (&uncompressed_value, &lower_fence_key, &prev_key, common_prefix);
	      pr_clear_value (&uncompressed_value);
	      if (error != NO_ERROR)
		{
		  assert (false);
		  goto exit_on_error;
		}
	    }
	}

      or_init (&buf, rec.data + offset, rec.length - offset);
      {
	if ((rec.length - offset) == 4)
	  {
	    int key_len = btree_get_disk_size_of_key (&prev_key);
	    printf ("## key_len: %d, offset: %d, reclen: %d\n", key_len, offset, rec.length);
	    db_value_print (&prev_key);
	    printf ("\n");
	    btree_dump_page (thread_p, stdout, NULL, btid_int, NULL, page_ptr, NULL, 2, 2);
	    assert (false);
	  }

	for (k = 1; k < oid_cnt; k++)
	  {
	    mvcc_flags = btree_record_object_get_mvcc_flags (buf.ptr);
	    or_get_oid (&buf, &oid);
	    oid.volid = oid.volid & ~BTREE_OID_MVCC_FLAGS_MASK;

	    if (BTREE_IS_UNIQUE (btid_int->unique_pk))
	      {
		or_get_oid (&buf, &class_oid);
	      }
	    buf.ptr += BTREE_GET_MVCC_INFO_SIZE_FROM_FLAGS (mvcc_flags);

	    if (oid.pageid <= NULL_PAGEID && oid.volid <= NULL_VOLID && oid.slotid <= NULL_SLOTID)
	      {
		btree_dump_page (thread_p, stdout, NULL, btid_int, NULL, page_ptr, NULL, 2, 2);
		assert (false);
	      }
	  }
      }

      /*
       * key order check
       */
      if (btree_leaf_is_flaged (&rec, BTREE_LEAF_RECORD_FENCE))
	{
	  continue;
	}

      if (spage_get_record (thread_p, page_ptr, i + 1, &rec, PEEK) != S_SUCCESS)
	{
	  btree_dump_page (thread_p, stdout, NULL, btid_int, NULL, page_ptr, NULL, 2, 2);
	  assert (false);
	  btree_clear_key_value (&clear_prev_key, &prev_key);
	  goto exit_on_error;
	}

      if (btree_leaf_is_flaged (&rec, BTREE_LEAF_RECORD_FENCE))
	{
	  btree_clear_key_value (&clear_prev_key, &prev_key);
	  continue;
	}

      error =
	btree_read_record_without_decompression (thread_p, btid_int, &rec, &curr_key, &leaf_pnt, BTREE_LEAF_NODE,
						 &clear_curr_key, &offset, PEEK_KEY_VALUE);
      if (error != NO_ERROR)
	{
	  btree_dump_page (thread_p, stdout, NULL, btid_int, NULL, page_ptr, NULL, 2, 2);
	  assert (false);
	  goto exit_on_error;
	}

      c = btree_compare_key (&prev_key, &curr_key, btid_int->key_type, 1, 1, NULL);

      btree_clear_key_value (&clear_curr_key, &curr_key);
      btree_clear_key_value (&clear_prev_key, &prev_key);

      if (c != DB_LT)
	{
	  btree_dump_page (thread_p, stdout, NULL, btid_int, NULL, page_ptr, NULL, 2, 2);
	  assert (false);
	  goto exit_on_error;
	}
    }

  return NO_ERROR;

exit_on_error:
  btree_clear_key_value (&clear_curr_key, &curr_key);
  btree_clear_key_value (&clear_prev_key, &prev_key);
  btree_clear_key_value (&clear_lower_fence_key, &lower_fence_key);

  return error == NO_ERROR ? ER_FAILED : error;
}
#endif

/*
 * btree_ils_adjust_range () - Adjust scanning range for loose index scan.
 *
 * return	 : Error code.
 * thread_p (in) : Thread entry.
 * bts (in/out)	 : B-tree scan.
 */
static int
btree_ils_adjust_range (THREAD_ENTRY * thread_p, BTREE_SCAN * bts)
{
  DB_VALUE new_key, *new_key_dbvals, *target_key;
  TP_DOMAIN *dom;
  DB_MIDXKEY midxkey;
  RANGE old_range;
  bool swap_ranges = false;
  int i;
  key_val_range *key_range = NULL;
  DB_VALUE *curr_key = NULL;
  int prefix_len = 0;
  bool use_desc_index, part_key_desc;

  /* Assert expected arguments. */
  assert (bts != NULL);

  key_range = &bts->index_scan_idp->key_vals[bts->index_scan_idp->curr_keyno];
  curr_key = &bts->cur_key;
  prefix_len = bts->index_scan_idp->indx_info->ils_prefix_len;
  use_desc_index = bts->use_desc_index;
  part_key_desc = BTREE_IS_PART_KEY_DESC (&bts->btid_int);

  /* check environment */
  if (DB_VALUE_DOMAIN_TYPE (curr_key) != DB_TYPE_MIDXKEY)
    {
      assert_release (false);
      er_set (ER_FATAL_ERROR_SEVERITY, ARG_FILE_LINE, ER_GENERIC_ERROR, 0);

      return ER_FAILED;
    }

  /* fetch target key */
  if (use_desc_index)
    {
      if (!part_key_desc)
	{
	  swap_ranges = true;
	}
    }
  else
    {
      if (part_key_desc)
	{
	  swap_ranges = true;
	}
    }

  if (swap_ranges)
    {
      /* descending index scan, we adjust upper bound */
      target_key = &key_range->key2;
    }
  else
    {
      /* ascending index scan, we adjust lower bound */
      target_key = &key_range->key1;
    }

  /* allocate key buffer */
  new_key_dbvals = (DB_VALUE *) db_private_alloc (thread_p, curr_key->data.midxkey.ncolumns * sizeof (DB_VALUE));
  if (new_key_dbvals == NULL)
    {
      er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_OUT_OF_VIRTUAL_MEMORY, 1,
	      curr_key->data.midxkey.ncolumns * sizeof (DB_VALUE));
      return ER_FAILED;
    }

  /* determine target key and adjust range */
  old_range = key_range->range;
  switch (key_range->range)
    {
    case INF_INF:
      if (swap_ranges)
	{
	  key_range->range = INF_LT;	/* (INF, INF) => (INF, ?) */
	}
      else
	{
	  key_range->range = GT_INF;	/* (INF, INF) => (?, INF) */
	}
      break;

    case INF_LE:
      if (swap_ranges)
	{
	  key_range->range = INF_LT;	/* (INF, ?] => (INF, ?) */
	}
      else
	{
	  key_range->range = GT_LE;	/* (INF, ?] => (?, ?] */
	}
      break;

    case INF_LT:
      if (swap_ranges)
	{
	  /* range remains unchanged */
	}
      else
	{
	  key_range->range = GT_LT;	/* (INF, ?) => (?, ?) */
	}
      break;

    case GE_LE:
      if (swap_ranges)
	{
	  key_range->range = GE_LT;	/* [?, ?] => [?, ?) */
	}
      else
	{
	  key_range->range = GT_LE;	/* [?, ?] => (?, ?] */
	}
      break;

    case GE_LT:
      if (swap_ranges)
	{
	  /* range remains unchanged */
	}
      else
	{
	  key_range->range = GT_LT;	/* [?, ?) => (?, ?) */
	}
      break;

    case GE_INF:
      if (swap_ranges)
	{
	  key_range->range = GE_LT;	/* [?, INF) => [?, ?) */
	}
      else
	{
	  key_range->range = GT_INF;	/* [?, INF) => (?, INF) */
	}
      break;

    case GT_LE:
      if (swap_ranges)
	{
	  key_range->range = GT_LT;	/* (?, ?] => (?, ?) */
	}
      else
	{
	  /* range remains unchanged */
	}
      break;

    case GT_LT:
      /* range remains unchanged */
      break;

    case GT_INF:
      if (swap_ranges)
	{
	  key_range->range = GT_LT;	/* (?, INF) => (?, ?) */
	}
      else
	{
	  /* range remains unchanged */
	}
      break;

    default:
      assert_release (false);	/* should not happen */
      break;
    }

  /* copy prefix of current key into target key */
  for (i = 0; i < prefix_len; i++)
    {
      pr_midxkey_get_element_nocopy (&curr_key->data.midxkey, i, &new_key_dbvals[i], NULL, NULL);
    }

  /* build suffix */

  dom = curr_key->data.midxkey.domain->setdomain;

  /* get to domain */
  for (i = 0; i < prefix_len; i++)
    {
      dom = dom->next;
    }

  /* set maximum suffix (min_max_val), the minimum is NULL */
  if ((prefix_len < curr_key->data.midxkey.ncolumns)
      && ((dom->is_desc && use_desc_index) || (!dom->is_desc && !use_desc_index)))
    {
      midxkey.min_max_val.position = prefix_len;
      midxkey.min_max_val.type = MAX_COLUMN;
    }
  else
    {
      midxkey.min_max_val.position = -1;
    }

  for (i = prefix_len; i < curr_key->data.midxkey.ncolumns; i++)
    {
      db_make_null (&new_key_dbvals[i]);
    }

  /* build midxkey */
  midxkey.buf = NULL;
  midxkey.domain = curr_key->data.midxkey.domain;
  midxkey.ncolumns = 0;
  midxkey.size = 0;
  db_make_midxkey (&new_key, &midxkey);
  new_key.need_clear = true;
  pr_midxkey_add_elements (&new_key, new_key_dbvals, curr_key->data.midxkey.ncolumns,
			   curr_key->data.midxkey.domain->setdomain);

#if !defined(NDEBUG)
  if (DB_IS_NULL (target_key))
    {
      assert (!DB_IS_NULL (&new_key));
    }
  else if (old_range == key_range->range)
    {
      int cmp_res;

      /* range did not modify, check if we're advancing */
      cmp_res = btree_compare_key (target_key, &new_key, midxkey.domain, 1, 1, NULL);
      if (use_desc_index)
	{
	  assert (cmp_res == DB_GT);
	}
      else
	{
	  assert (cmp_res == DB_LT);
	}
    }
#endif

  /* register key in range */
  pr_clear_value (target_key);
  pr_clone_value (&new_key, target_key);
  pr_clear_value (&new_key);

  for (i = 0; i < prefix_len; i++)
    {
      pr_clear_value (&new_key_dbvals[i]);	/* it might be alloced/copied */
    }
  db_private_free (thread_p, new_key_dbvals);

  /* all ok */
  return btree_scan_update_range (thread_p, bts, key_range);
}

/*
 * btree_get_next_node_info () - Scans b-tree node by node and obtains info.
 *
 * return	  : Scan code.
 * thread_p (in)  : Thread entry.
 * btid (in)	  : B-tree identifier.
 * btns (in)	  : B-tree node scan data.
 * node_info (in) : Array of value pointers to store b-tree node information.
 */
SCAN_CODE
btree_get_next_node_info (THREAD_ENTRY * thread_p, BTID * btid, BTREE_NODE_SCAN * btns, DB_VALUE ** node_info)
{
  RECDES rec;
  SCAN_CODE result;
  BTREE_NODE_HEADER *node_header;
  BTREE_NODE_TYPE node_type;
  BTREE_NODE_SCAN_QUEUE_ITEM *new_item = NULL, *crt_item = NULL;
  int key_cnt, i;
  NON_LEAF_REC nleaf;
  LEAF_REC leaf_pnt;
  void *rec_header = NULL;
  DB_VALUE key_value;
  bool clear_key = false;
  int dummy;

  assert (btns->crt_page == NULL);

  if (BTREE_NODE_SCAN_IS_QUEUE_EMPTY (btns))
    {
      if (!btns->first_call)
	{
	  /* Finished scanning for b-tree pages */
	  result = S_END;
	  goto end;
	}

      /* First call */

      /* Add root page to queue */
      new_item = (BTREE_NODE_SCAN_QUEUE_ITEM *) malloc (sizeof (BTREE_NODE_SCAN_QUEUE_ITEM));
      if (new_item == NULL)
	{
	  er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_OUT_OF_VIRTUAL_MEMORY, 1, sizeof (BTREE_NODE_SCAN_QUEUE_ITEM));
	  goto error;
	}
      new_item->crt_vpid.pageid = btid->root_pageid;
      new_item->crt_vpid.volid = btid->vfid.volid;
      new_item->next = NULL;
      BTREE_NODE_SCAN_ADD_PAGE_TO_QUEUE (btns, new_item);

      btns->first_call = false;
    }

  BTREE_NODE_SCAN_POP_PAGE_FROM_QUEUE (btns, crt_item);
  btns->crt_vpid = crt_item->crt_vpid;
  btns->crt_page = pgbuf_fix (thread_p, &btns->crt_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
  if (btns->crt_page == NULL)
    {
      goto error;
    }

  node_header = btree_get_node_header (thread_p, btns->crt_page);
  node_type = (node_header->node_level > 1) ? BTREE_NON_LEAF_NODE : BTREE_LEAF_NODE;
  key_cnt = btree_node_number_of_keys (thread_p, btns->crt_page);

  rec_header = (node_type == BTREE_NON_LEAF_NODE) ? (void *) &nleaf : (void *) &leaf_pnt;

  if (node_type == BTREE_NON_LEAF_NODE)
    {
      /* Add children to queue */
      for (i = 1; i <= key_cnt; i++)
	{
	  if (spage_get_record (thread_p, btns->crt_page, i, &rec, PEEK) != S_SUCCESS)
	    {
	      goto error;
	    }
	  btree_read_fixed_portion_of_non_leaf_record (&rec, &nleaf);
	  new_item = (BTREE_NODE_SCAN_QUEUE_ITEM *) malloc (sizeof (BTREE_NODE_SCAN_QUEUE_ITEM));
	  if (new_item == NULL)
	    {
	      er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_OUT_OF_VIRTUAL_MEMORY, 1,
		      sizeof (BTREE_NODE_SCAN_QUEUE_ITEM));
	      goto error;
	    }
	  new_item->crt_vpid.pageid = nleaf.pnt.pageid;
	  new_item->crt_vpid.volid = nleaf.pnt.volid;
	  new_item->next = NULL;
	  BTREE_NODE_SCAN_ADD_PAGE_TO_QUEUE (btns, new_item);
	}
    }

  /* Get b-tree page info */

  /* Get volume id and page id */
  db_make_int (node_info[BTREE_NODE_INFO_VOLUMEID], btns->crt_vpid.volid);
  db_make_int (node_info[BTREE_NODE_INFO_PAGEID], btns->crt_vpid.pageid);

  /* Get node type */
  pr_clear_value (node_info[BTREE_NODE_INFO_NODE_TYPE]);
  db_make_string (node_info[BTREE_NODE_INFO_NODE_TYPE], (node_type == BTREE_NON_LEAF_NODE) ? "non-leaf" : "leaf");

  /* Get key count */
  db_make_int (node_info[BTREE_NODE_INFO_KEY_COUNT], key_cnt);

  if (key_cnt > 0)
    {
      btree_init_temp_key_value (&clear_key, &key_value);

      /* Get first key */
      if (spage_get_record (thread_p, btns->crt_page, 1, &rec, PEEK) != S_SUCCESS)
	{
	  goto error;
	}
      if (btree_read_record (thread_p, &btns->btid_int, btns->crt_page, &rec, &key_value, rec_header, node_type,
			     &clear_key, &dummy, PEEK_KEY_VALUE, NULL) != NO_ERROR)
	{
	  goto error;
	}

      pr_clear_value (node_info[BTREE_NODE_INFO_FIRST_KEY]);
      pr_clone_value (&key_value, node_info[BTREE_NODE_INFO_FIRST_KEY]);
      btree_clear_key_value (&clear_key, &key_value);

      /* Get last key */
      if (spage_get_record (thread_p, btns->crt_page, key_cnt, &rec, PEEK) != S_SUCCESS)
	{
	  goto error;
	}
      if (btree_read_record (thread_p, &btns->btid_int, btns->crt_page, &rec, &key_value, rec_header, node_type,
			     &clear_key, &dummy, PEEK_KEY_VALUE, NULL) != NO_ERROR)
	{
	  goto error;
	}

      pr_clear_value (node_info[BTREE_NODE_INFO_LAST_KEY]);
      pr_clone_value (&key_value, node_info[BTREE_NODE_INFO_LAST_KEY]);
      btree_clear_key_value (&clear_key, &key_value);
    }
  else
    {
      /* Empty node */
      pr_clear_value (node_info[BTREE_NODE_INFO_FIRST_KEY]);
      db_make_null (node_info[BTREE_NODE_INFO_FIRST_KEY]);

      pr_clear_value (node_info[BTREE_NODE_INFO_LAST_KEY]);
      db_make_null (node_info[BTREE_NODE_INFO_LAST_KEY]);
    }

  result = S_SUCCESS;

end:
  if (btns->crt_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, btns->crt_page);
    }

  if (crt_item != NULL)
    {
      free_and_init (crt_item);
    }
  return result;

error:
  result = S_ERROR;
  goto end;
}

static const char *
node_type_to_string (short node_type)
{
  return (node_type == BTREE_LEAF_NODE) ? "LEAF" : "NON_LEAF";
}

/*
 * key_type_to_string () -  convert key_type to string
 *   return: the converted string
 *
 *   buf(in/out):
 *   buf_size(in):
 *   key_type(in):
 */
static char *
key_type_to_string (char *buf, int buf_size, TP_DOMAIN * key_type)
{
  int n, remain_size;
  char *buf_p = NULL;
  TP_DOMAIN *elem = NULL;
  const char *format = NULL;
  char temp_buf[256] = { 0 };

  assert (key_type != NULL);

  switch (TP_DOMAIN_TYPE (key_type))
    {
    case DB_TYPE_INTEGER:
    case DB_TYPE_FLOAT:
    case DB_TYPE_DOUBLE:
    case DB_TYPE_OBJECT:
    case DB_TYPE_TIME:
    case DB_TYPE_TIMESTAMP:
    case DB_TYPE_TIMESTAMPTZ:
    case DB_TYPE_TIMESTAMPLTZ:
    case DB_TYPE_DATETIME:
    case DB_TYPE_DATETIMETZ:
    case DB_TYPE_DATETIMELTZ:
    case DB_TYPE_DATE:
    case DB_TYPE_MONETARY:
    case DB_TYPE_SHORT:
    case DB_TYPE_BIGINT:
    case DB_TYPE_OID:
    case DB_TYPE_ENUMERATION:
      snprintf (buf, buf_size, "%s", pr_type_name (TP_DOMAIN_TYPE (key_type)));
      break;

    case DB_TYPE_BIT:
    case DB_TYPE_VARBIT:
    case DB_TYPE_CHAR:
    case DB_TYPE_NCHAR:
    case DB_TYPE_VARCHAR:
    case DB_TYPE_VARNCHAR:
      snprintf (buf, buf_size, "%s(%d)", pr_type_name (TP_DOMAIN_TYPE (key_type)), key_type->precision);
      break;

    case DB_TYPE_NUMERIC:
      snprintf (buf, buf_size, "%s(%d,%d)", pr_type_name (TP_DOMAIN_TYPE (key_type)), key_type->precision,
		key_type->scale);
      break;

    case DB_TYPE_MIDXKEY:
      n = snprintf (buf, buf_size, "%s(", pr_type_name (TP_DOMAIN_TYPE (key_type)));
      buf_p = buf + n;
      remain_size = buf_size - n - 1;	/* reserve 1 byte for ')' */

      assert_release (remain_size > 0);

      for (elem = key_type->setdomain; elem != NULL; elem = elem->next)
	{
	  format = (elem == key_type->setdomain) ? "%s" : ",%s";
	  n = snprintf (buf_p, remain_size, format, key_type_to_string (temp_buf, sizeof (temp_buf), elem));

	  if (n >= remain_size)	/* The buffer has not enough space */
	    {
	      strcpy (buf_p + remain_size - sizeof ("..."), "...");
	      buf_p += remain_size - 1;
	      break;
	    }
	  else
	    {
	      buf_p += n;
	      remain_size -= n;
	    }
	}

      *buf_p = ')';
      break;

    default:
      /* It is invalid index type? */
      assert (!tp_valid_indextype (TP_DOMAIN_TYPE (key_type)));

      buf[0] = '\0';
      break;
    }

  buf[buf_size - 1] = 0;

  return buf;
}

/*
 * index_attrs_to_string () -  convert the attributes info of index to string
 *   return: NO_ERROR, or ER_code
 *
 *   buf(in/out):
 *   buf_size(in):
 *   index_p(in):
 *   recdes(in):
 */
static int
index_attrs_to_string (char *buf, int buf_size, OR_INDEX * index_p, RECDES * recdes)
{
  int i, n, remain_size;
  char *buf_p = NULL;
  char *attr_name;
  char format[20];
  int error = NO_ERROR;
  int alloced_string = 0;
  char *string = NULL;

  buf_p = buf;
  remain_size = buf_size;

  for (i = 0; i < index_p->n_atts; i++)
    {
      bool set_break = false;
      alloced_string = 0;
      string = NULL;

      error = or_get_attrname (recdes, index_p->atts[i]->id, &string, &alloced_string);
      if (error != NO_ERROR)
	{
	  set_break = true;
	  goto clean_string;
	}
      attr_name = string;

      if (attr_name == NULL)
	{
	  error = ER_FAILED;
	  set_break = true;
	  goto clean_string;
	}

      format[0] = '\0';
      if (strchr (attr_name, ',') != NULL || strchr (attr_name, ' ') != NULL)
	{
	  strcpy (format, (i == 0) ? "[%s]" : ",[%s]");
	}
      else
	{
	  strcpy (format, (i == 0) ? "%s" : ",%s");
	}

      /* Show nothing for default order(ascending), show DESC for descending */
      if (index_p->asc_desc[i] != 0)
	{
	  strcat (format, " DESC");
	}

      n = snprintf (buf_p, remain_size, format, attr_name);

    clean_string:
      if (string != NULL && alloced_string == 1)
	{
	  db_private_free_and_init (NULL, string);
	}

      if (set_break == true)
	{
	  break;
	}

      if (n >= remain_size)	/* The buffer has not enough space */
	{
	  assert_release (buf_size >= (int) sizeof ("..."));
	  strcpy (buf + buf_size - sizeof ("..."), "...");
	  break;
	}
      else
	{
	  buf_p += n;
	  remain_size -= n;
	}
    }

  buf[buf_size - 1] = 0;

  return error;
}

/*
 * btree_index_start_scan () -  start scan function for show index header/capacity
 *   return: NO_ERROR, or ER_code
 *
 *   thread_p(in):
 *   show_type(in):
 *   arg_values(in):
 *   arg_cnt(in):
 *   ptr(in/out): index header/capacity context
 */
int
btree_index_start_scan (THREAD_ENTRY * thread_p, int show_type, DB_VALUE ** arg_values, int arg_cnt, void **ptr)
{
  int i, error = NO_ERROR;
  OID oid;
  OR_CLASSREP *classrep = NULL;
  int idx_in_cache = -1;
  SHOW_INDEX_SCAN_CTX *ctx = NULL;
  LC_FIND_CLASSNAME status;
  OR_PARTITION *parts = NULL;
  int parts_count = 0;
  DB_CLASS_PARTITION_TYPE partition_type;
  const char *class_name = NULL;

  *ptr = NULL;
  ctx = (SHOW_INDEX_SCAN_CTX *) db_private_alloc (thread_p, sizeof (SHOW_INDEX_SCAN_CTX));
  if (ctx == NULL)
    {
      ASSERT_ERROR_AND_SET (error);
      goto cleanup;
    }
  memset (ctx, 0, sizeof (SHOW_INDEX_SCAN_CTX));

  ctx->show_type = show_type;
  ctx->is_all = (show_type == SHOWSTMT_ALL_INDEXES_HEADER || show_type == SHOWSTMT_ALL_INDEXES_CAPACITY);

  class_name = db_get_string (arg_values[0]);

  // if you want consitent results, S_LOCK is required.
  status = xlocator_find_class_oid (thread_p, class_name, &oid, ctx->is_all ? S_LOCK : SCH_S_LOCK);
  if (status == LC_CLASSNAME_ERROR || status == LC_CLASSNAME_DELETED)
    {
      error = ER_LC_UNKNOWN_CLASSNAME;
      er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, error, 1, class_name);
      goto cleanup;
    }

  classrep = heap_classrepr_get (thread_p, &oid, NULL, NULL_REPRID, &idx_in_cache);
  if (classrep == NULL)
    {
      ASSERT_ERROR_AND_SET (error);
      goto cleanup;
    }

  if (ctx->is_all)
    {
      assert (arg_cnt == 2);

      partition_type = (DB_CLASS_PARTITION_TYPE) db_get_int (arg_values[1]);
      ctx->indexes_count = classrep->n_indexes;
    }
  else
    {
      assert (arg_cnt == 3);

      /* get index name which user specified */
      ctx->index_name = db_private_strdup (thread_p, db_get_string (arg_values[1]));
      if (ctx->index_name == NULL)
	{
	  ASSERT_ERROR_AND_SET (error);
	  goto cleanup;
	}

      partition_type = (DB_CLASS_PARTITION_TYPE) db_get_int (arg_values[2]);
      ctx->indexes_count = 1;
    }

  /* save oids to context so that we can get btree info when scan next */
  if (partition_type == DB_PARTITIONED_CLASS)
    {
      error = heap_get_class_partitions (thread_p, &oid, &parts, &parts_count);
      if (error != NO_ERROR)
	{
	  goto cleanup;
	}

      ctx->class_oids = (OID *) db_private_alloc (thread_p, sizeof (OID) * parts_count);
      if (ctx->class_oids == NULL)
	{
	  ASSERT_ERROR_AND_SET (error);
	  goto cleanup;
	}

      for (i = 0; i < parts_count; i++)
	{
	  COPY_OID (&ctx->class_oids[i], &parts[i].class_oid);
	}

      ctx->class_oid_count = parts_count;
    }
  else
    {
      ctx->class_oids = (OID *) db_private_alloc (thread_p, sizeof (OID));
      if (ctx->class_oids == NULL)
	{
	  ASSERT_ERROR_AND_SET (error);
	  goto cleanup;
	}

      COPY_OID (&ctx->class_oids[0], &oid);
      ctx->class_oid_count = 1;
    }

  *ptr = ctx;
  ctx = NULL;

cleanup:

  if (classrep != NULL)
    {
      heap_classrepr_free_and_init (classrep, &idx_in_cache);
    }

  if (parts != NULL)
    {
      heap_clear_partition_info (thread_p, parts, parts_count);
    }

  if (ctx != NULL)
    {
      if (ctx->index_name != NULL)
	{
	  db_private_free_and_init (thread_p, ctx->index_name);
	}

      if (ctx->class_oids != NULL)
	{
	  db_private_free_and_init (thread_p, ctx->class_oids);
	}

      db_private_free_and_init (thread_p, ctx);
    }

  return error;
}

/*
 * btree_index_next_scan () -  next scan function for show index header/capacity
 *   return: S_ERROR, S_SUCCESS, or S_END
 *
 *   thread_p(in):
 *   cursor(in):
 *   out_values(out):
 *   out_cnt(in):
 *   ptr(in): index header/capacity context
 */
SCAN_CODE
btree_index_next_scan (THREAD_ENTRY * thread_p, int cursor, DB_VALUE ** out_values, int out_cnt, void *ptr)
{
  SCAN_CODE ret;
  char *class_name = NULL;
  OR_CLASSREP *classrep = NULL;
  SHOW_INDEX_SCAN_CTX *ctx = NULL;
  OID *class_oid_p = NULL;
  int idx_in_cache = -1;
  int selected_index = 0;
  int i, index_idx, oid_idx;
  OR_INDEX *index_p = NULL;

  ctx = (SHOW_INDEX_SCAN_CTX *) ptr;
  if (cursor >= ctx->indexes_count * ctx->class_oid_count)
    {
      return S_END;
    }

  assert (ctx->indexes_count >= 1);
  index_idx = cursor % ctx->indexes_count;
  oid_idx = cursor / ctx->indexes_count;

  class_oid_p = &ctx->class_oids[oid_idx];

  if (heap_get_class_name (thread_p, class_oid_p, &class_name) != NO_ERROR || class_name == NULL)
    {
      ret = S_ERROR;
      goto cleanup;
    }

  classrep = heap_classrepr_get (thread_p, class_oid_p, NULL, NULL_REPRID, &idx_in_cache);
  if (classrep == NULL)
    {
      ret = S_ERROR;
      goto cleanup;
    }

  if (ctx->is_all)
    {
      index_p = &classrep->indexes[index_idx];
    }
  else
    {
      selected_index = -1;
      for (i = 0; i < classrep->n_indexes; i++)
	{
	  if (intl_identifier_casecmp (classrep->indexes[i].btname, ctx->index_name) == 0)
	    {
	      selected_index = i;
	      break;
	    }
	}

      if (selected_index == -1)
	{
	  /* it must be found since passed semantic check */
	  assert (false);

	  er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_OBJ_INDEX_NOT_FOUND, 0);
	  ret = S_ERROR;
	  goto cleanup;
	}

      index_p = &classrep->indexes[selected_index];
    }

  if (ctx->show_type == SHOWSTMT_INDEX_HEADER || ctx->show_type == SHOWSTMT_ALL_INDEXES_HEADER)
    {
      ret = btree_scan_for_show_index_header (thread_p, out_values, out_cnt, class_name, index_p, class_oid_p);
    }
  else
    {
      assert (ctx->show_type == SHOWSTMT_INDEX_CAPACITY || ctx->show_type == SHOWSTMT_ALL_INDEXES_CAPACITY);

      ret = btree_scan_for_show_index_capacity (thread_p, out_values, out_cnt, class_name, index_p);
    }

cleanup:

  if (classrep != NULL)
    {
      heap_classrepr_free_and_init (classrep, &idx_in_cache);
    }

  if (class_name != NULL)
    {
      free_and_init (class_name);
    }

  return ret;
}

/*
 * btree_index_end_scan () -  end scan function for show index header/capacity
 *   return: NO_ERROR, or ER_code
 *
 *   thread_p(in):
 *   ptr(in/out): index header/capacity context
 */
int
btree_index_end_scan (THREAD_ENTRY * thread_p, void **ptr)
{
  SHOW_INDEX_SCAN_CTX *ctx = NULL;

  ctx = (SHOW_INDEX_SCAN_CTX *) (*ptr);
  if (ctx != NULL)
    {
      if (ctx->index_name != NULL)
	{
	  db_private_free_and_init (thread_p, ctx->index_name);
	}

      if (ctx->class_oids != NULL)
	{
	  db_private_free_and_init (thread_p, ctx->class_oids);
	}

      db_private_free_and_init (thread_p, ctx);
    }

  *ptr = NULL;

  return NO_ERROR;
}

/*
 * btree_scan_for_show_index_header () - scan index header information
 *   return: S_ERROR, S_SUCCESS, or S_END
 *
 *   thread_p(in):
 *   out_values(out):
 *   out_cnt(in):
 *   class_name(in);
 *   index_p(in);
 *   class_oid_p(in);
 */
static SCAN_CODE
btree_scan_for_show_index_header (THREAD_ENTRY * thread_p, DB_VALUE ** out_values, int out_cnt, const char *class_name,
				  OR_INDEX * index_p, OID * class_oid_p)
{
  int idx = 0;
  int error = NO_ERROR;
  VPID root_vpid;
  PAGE_PTR root_page_ptr = NULL;
  BTREE_ROOT_HEADER *root_header = NULL;
  char buf[256] = { 0 };
  OR_BUF or_buf;
  TP_DOMAIN *key_type;
  int num_oids = 0, num_nulls = 0, num_keys = 0;
  bool fetch_unique_stats = false;
  int unique_stats_idx = -1;
  RECDES recdes = RECDES_INITIALIZER;
  BTID *btid_p = NULL;
  HEAP_SCANCACHE scan_cache;
  bool scan_cache_inited = false;

  assert_release (index_p != NULL);

  /* get root header point */
  btid_p = &index_p->btid;
  root_vpid.pageid = btid_p->root_pageid;
  root_vpid.volid = btid_p->vfid.volid;

  root_page_ptr = pgbuf_fix (thread_p, &root_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
  if (root_page_ptr == NULL)
    {
      ASSERT_ERROR_AND_SET (error);
      goto error;
    }

  root_header = btree_get_root_header (thread_p, root_page_ptr);
  if (root_header == NULL)
    {
      ASSERT_ERROR_AND_SET (error);
      goto error;
    }

  /* scan index header into out_values */
  error = db_make_string_copy (out_values[idx], class_name);
  idx++;
  if (error != NO_ERROR)
    {
      goto error;
    }

  error = db_make_string_copy (out_values[idx], index_p->btname);
  idx++;
  if (error != NO_ERROR)
    {
      goto error;
    }

  (void) btid_to_string (buf, sizeof (buf), btid_p);
  error = db_make_string_copy (out_values[idx], buf);
  idx++;
  if (error != NO_ERROR)
    {
      goto error;
    }

  db_make_int (out_values[idx], root_header->node.node_level);
  idx++;

  db_make_int (out_values[idx], root_header->node.max_key_len);
  idx++;

  if (root_header->unique_pk)
    {
      /* unique stats fetching must not be done under header page latch; reserve space in buffer and defer fetching
       * after page unfix */
      fetch_unique_stats = true;
      unique_stats_idx = idx;
      idx += 3;
    }
  else
    {
      db_make_int (out_values[idx], root_header->num_oids);
      idx++;

      db_make_int (out_values[idx], root_header->num_nulls);
      idx++;

      db_make_int (out_values[idx], root_header->num_keys);
      idx++;
    }

  buf[0] = '\0';
  if (!OID_ISNULL (&root_header->topclass_oid))
    {
      oid_to_string (buf, sizeof (buf), &root_header->topclass_oid);
    }
  error = db_make_string_copy (out_values[idx], buf);
  idx++;
  if (error != NO_ERROR)
    {
      goto error;
    }

  db_make_int (out_values[idx], root_header->unique_pk);
  idx++;

  (void) vfid_to_string (buf, sizeof (buf), &root_header->ovfid);
  error = db_make_string_copy (out_values[idx], buf);
  idx++;
  if (error != NO_ERROR)
    {
      goto error;
    }

  or_init (&or_buf, root_header->packed_key_domain, -1);
  key_type = or_get_domain (&or_buf, NULL, NULL);
  (void) key_type_to_string (buf, sizeof (buf), key_type);
  error = db_make_string_copy (out_values[idx], buf);
  idx++;
  if (error != NO_ERROR)
    {
      goto error;
    }

  /* unfix page buffer before heap_get_class_record() */
  if (root_page_ptr != NULL)
    {
      pgbuf_unfix_and_init (thread_p, root_page_ptr);
    }

  /* Init scan_cache for heap object retrieving */
  (void) heap_scancache_quick_start_root_hfid (thread_p, &scan_cache);
  scan_cache_inited = true;

  /* Get the name list with asc/desc info of attributes */
  if (heap_get_class_record (thread_p, class_oid_p, &recdes, &scan_cache, COPY) != S_SUCCESS)
    {
      goto error;
    }

  error = index_attrs_to_string (buf, sizeof (buf), index_p, &recdes);
  if (error != NO_ERROR)
    {
      goto error;
    }

  error = db_make_string_copy (out_values[idx], buf);
  idx++;
  if (error != NO_ERROR)
    {
      goto error;
    }

  assert (idx == out_cnt);

  if (fetch_unique_stats)
    {
      error = logtb_get_global_unique_stats (thread_p, btid_p, &num_oids, &num_nulls, &num_keys);
      if (error != NO_ERROR)
	{
	  goto error;
	}

      db_make_int (out_values[unique_stats_idx], num_oids);
      db_make_int (out_values[unique_stats_idx + 1], num_nulls);
      db_make_int (out_values[unique_stats_idx + 2], num_keys);
    }

  (void) heap_scancache_end (thread_p, &scan_cache);

  return S_SUCCESS;

error:

  if (root_page_ptr != NULL)
    {
      pgbuf_unfix_and_init (thread_p, root_page_ptr);
    }

  if (scan_cache_inited)
    {
      (void) heap_scancache_end (thread_p, &scan_cache);
    }

  return S_ERROR;
}

/*
 * btree_key_find_first_visible_row () - MVCC find first visible row
 *   return: whether the visible row has been found
 *   btid(in): B+tree index identifier
 *   rec(in): Record descriptor
 *   offset(in): Offset of the second OID in key buffer
 *   node_type(in): node type
 *   oid(out): Object identifier of the visible row or NULL_OID
 *   class_oid(out): Object class identifier
 *   max_oids(in): max OIDs to search for
 */
static BTREE_SEARCH
btree_key_find_first_visible_row (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * rec, int offset,
				  BTREE_NODE_TYPE node_type, OID * oid, OID * class_oid, int max_oids)
{
  MVCC_REC_HEADER mvcc_rec_header;
  BTREE_MVCC_INFO mvcc_info;
  OR_BUF buf;
  int mvcc_flags = 0, length = 0;
  bool is_first = true;
  MVCC_SNAPSHOT mvcc_snapshot_dirty;
  int oids_count = 0;

  assert (btid_int != NULL && rec != NULL && rec->data != NULL && oid != NULL && class_oid != NULL);

  OID_SET_NULL (oid);
  OID_SET_NULL (class_oid);
  mvcc_snapshot_dirty.snapshot_fnc = mvcc_satisfies_dirty;

  length = rec->length;
  if (btree_leaf_is_flaged (rec, BTREE_LEAF_RECORD_OVERFLOW_OIDS))
    {
      length -= DB_ALIGN (DISK_VPID_SIZE, INT_ALIGNMENT);
    }

  or_init (&buf, rec->data, length);
  while (buf.ptr < buf.endptr)
    {
      /* Get MVCC flags */
      mvcc_flags = btree_record_object_get_mvcc_flags (buf.ptr);

      /* Read object OID */
      if (or_get_oid (&buf, oid) != NO_ERROR)
	{
	  goto error;
	}
      /* Clear flags */
      BTREE_OID_CLEAR_ALL_FLAGS (oid);

      if (btree_is_class_oid_packed (btid_int, rec, node_type, is_first))
	{
	  /* Read class OID */
	  if (or_get_oid (&buf, class_oid) != NO_ERROR)
	    {
	      goto error;
	    }
	}
      else if (BTREE_IS_UNIQUE (btid_int->unique_pk))
	{
	  /* Class OID is top class OID */
	  COPY_OID (class_oid, &btid_int->topclass_oid);
	}

      /* Get MVCC information */
      if (btree_or_get_mvccinfo (&buf, &mvcc_info, mvcc_flags) != NO_ERROR)
	{
	  goto error;
	}

      btree_mvcc_info_to_heap_mvcc_header (&mvcc_info, &mvcc_rec_header);
      if (mvcc_snapshot_dirty.snapshot_fnc (thread_p, &mvcc_rec_header, &mvcc_snapshot_dirty) == SNAPSHOT_SATISFIED)
	{
	  /* visible row found it */
	  if (MVCCID_IS_VALID (mvcc_snapshot_dirty.lowest_active_mvccid)
	      || MVCCID_IS_VALID (mvcc_snapshot_dirty.highest_completed_mvccid))
	    {
	      /* oid is modified by other active transaction */
	      return BTREE_ACTIVE_KEY_FOUND;
	    }
	  else
	    {
	      /* inserted by committed transaction */
	      return BTREE_KEY_FOUND;
	    }
	}

      if (max_oids > 0)
	{
	  oids_count++;
	  if (oids_count >= max_oids)
	    {
	      /* the maximum number of OIDs has been reached => key not found */
	      break;
	    }
	}

      if (node_type == BTREE_LEAF_NODE && is_first)
	{
	  /* Must skip over the key value to the next object */
	  or_seek (&buf, offset);
	}

      is_first = false;
    }

  return BTREE_KEY_NOTFOUND;

error:
  OID_SET_NULL (oid);
  OID_SET_NULL (class_oid);
  return BTREE_ERROR_OCCURRED;
}

/*
 * btree_insert_mvcc_delid_into_page () - Insert delete MVCCID info.
 *
 * return	      : Error code.
 * thread_p (in)      : Thread entry.
 * btid (in)	      : B-tree info.
 * page_ptr (in)      : Leaf or overflow page.
 * node_type (in)     : Leaf or overflow node type.
 * key (in)	      : Key value.
 * insert_helper (in) : B-tree insert helper.
 * slot_id (in)	      : Slot ID for b-tree record.
 * rec (in)	      : B-tree record.
 * oid_offset (in)    : Offset to object being deleted.
 */
static int
btree_insert_mvcc_delid_into_page (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR page_ptr,
				   BTREE_NODE_TYPE node_type, DB_VALUE * key, BTREE_INSERT_HELPER * insert_helper,
				   PGSLOTID slot_id, RECDES * rec, int oid_offset)
{
  int ret = NO_ERROR;
  LOG_LSA prev_lsa;

  /* Recovery data. */
  LOG_DATA_ADDR addr;

  char *rv_undo_data = NULL;
  int rv_undo_data_length;
  int rv_undo_data_capacity = IO_MAX_PAGE_SIZE;
  char rv_undo_data_buffer[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  char *rv_undo_data_bufalign = PTR_ALIGN (rv_undo_data_buffer, BTREE_MAX_ALIGN);

  char rv_redo_data_buffer[BTREE_RV_BUFFER_SIZE + BTREE_MAX_ALIGN];
  char *rv_redo_data = PTR_ALIGN (rv_redo_data_buffer, BTREE_MAX_ALIGN);
  char *rv_redo_data_ptr = rv_redo_data;
  int rv_redo_data_length = 0;

  /* Assert expected arguments. */
  assert (btid != NULL);
  assert (page_ptr != NULL);
  assert (node_type == BTREE_LEAF_NODE || node_type == BTREE_OVERFLOW_NODE);
  assert (key != NULL);
  assert (insert_helper != NULL);
  assert (slot_id > 0);
  assert (rec != NULL);
  assert (oid_offset >= 0);
  assert (insert_helper != NULL);
  assert (insert_helper->purpose == BTREE_OP_INSERT_MVCC_DELID
	  || insert_helper->purpose == BTREE_OP_INSERT_MARK_DELETED);

  /* Prepare logging. */
  /* Initialize log address data */
  addr.pgptr = page_ptr;
  addr.offset = slot_id;
  addr.vfid = &btid->sys_btid->vfid;

  /* Undo logging. */
  rv_undo_data = rv_undo_data_bufalign;
  ret =
    btree_rv_save_keyval_for_undo (btid, key, BTREE_INSERT_CLASS_OID (insert_helper), BTREE_INSERT_OID (insert_helper),
				   BTREE_INSERT_MVCC_INFO (insert_helper), insert_helper->purpose,
				   rv_undo_data_bufalign, &rv_undo_data, &rv_undo_data_capacity, &rv_undo_data_length);
  if (ret != NO_ERROR)
    {
      return ret;
    }

  /* Redo logging. */
#if !defined (NDEBUG)
  /* For debugging recovery. */
  BTREE_RV_REDO_SET_DEBUG_INFO (&addr, rv_redo_data_ptr, btid, BTREE_RV_DEBUG_ID_INSERT_DELID);
#endif /* !NDEBUG */
  if (node_type == BTREE_OVERFLOW_NODE)
    {
      BTREE_RV_SET_OVERFLOW_NODE (&addr);
    }
  LOG_RV_RECORD_SET_MODIFY_MODE (&addr, LOG_RV_RECORD_UPDATE_PARTIAL);

  /* We need to check if insert MVCCID is the same as delete MVCCID for recovery purposes. Take next scenario:
   *
   * context:
   * auto-commit off
   * table t (a int), index on t(a)
   * table t has row with a value 1.
   *
   * scenario:
   * 1.   update t set a = 2 where a = 1;
   * 2.   update t set a = 1 where a = 2;
   * 3=1. update t set a = 2 where a = 1;
   * 4.   rollback;
   *
   * Let's follow what happens in key 1:
   * Before scenario: OID1-MVCCID1-MVCCID_NULL
   * After update#1:  OID1-MVCCID1-MVCCID2
   * After update#2:  OID1-MVCCID1-MVCCID2, OID1-MVCCID2-MVCCID_NULL.
   * After update#3:  OID1-MVCCID1-MVCCID2, OID1-MVCCID2-MVCCID2.
   *
   * At rollback, we should execute undo MVCC delete key1,OID1,delid=MVCCID2, undo insert key1,OID1,insid=MVCCID2,
   * and again undo MVCC delete key1,OID1,delid=MVCCID2.
   * To undo MVCC delete, we usually match by key, OID and delete MVCCID. But in above case this is ambiguous, because
   * we have two entries that can match the criteria. And this happens:
   * Undo#1:          OID1-MVCCID1-MVCCID_NULL, OID1-MVCCID2-MVCCID2.
   * This is obviously an invalid state, since the key never looked this way before rollback. Undo insert would not
   * find a valid object and would fail.
   *
   * Somehow, we need to remove the ambiguity. Since this is a rather unlikely case, we prefer to keep the key, OID
   * and delete MVCCID matching as a general criteria and do something special just for this case.
   * The first MVCC delete undo should match an object that has same insert MVCCID. So, we will hack logging and
   * rollback/undo recovery to do the right matching.
   *
   * Here we need to check insert MVCCID == delete MVCCID. If true, we will mark LOG_DATA_ADDR offset with a special
   * flag.
   *
   * NOTE: If update#1 and update#2 are repeated several times, we end up with several OID1-MVCCID2-MVCCID2 entries.
   *       At rollback, it does not matter which entry we pick to undo first, as long as we don't undo the original
   *       entry.
   */
  assert (BTREE_MVCC_INFO_HAS_DELID (BTREE_INSERT_MVCC_INFO (insert_helper)));
  if (BTREE_MVCC_INFO_INSID (BTREE_INSERT_MVCC_INFO (insert_helper))
      == BTREE_INSERT_MVCC_INFO (insert_helper)->delete_mvccid)
    {
      /* Mark addr that we need to undo MVCC delete of my object - insert MVCCID must also match. */
      BTREE_RV_SET_UNDO_MVCCDEL_MYOBJ (&addr);

      /* Should only be possible for BTREE_OP_INSERT_MVCC_DELID. */
      assert (insert_helper->purpose == BTREE_OP_INSERT_MVCC_DELID);
    }

  btree_record_add_delid (thread_p, btid, rec, node_type, oid_offset,
			  BTREE_INSERT_MVCC_INFO (insert_helper)->delete_mvccid, NULL, &rv_redo_data_ptr);

  if (spage_update (thread_p, page_ptr, slot_id, rec) != SP_SUCCESS)
    {
      assert_release (false);
      ret = ER_FAILED;
      goto exit_on_error;
    }

  /* We need to log previous lsa. */
  LSA_COPY (&prev_lsa, pgbuf_get_lsa (page_ptr));

  /* Logging. */
  BTREE_RV_GET_DATA_LENGTH (rv_redo_data_ptr, rv_redo_data, rv_redo_data_length);
  if (insert_helper->purpose == BTREE_OP_INSERT_MVCC_DELID)
    {
      log_append_undoredo_data (thread_p, RVBT_MVCC_DELETE_OBJECT, &addr, rv_undo_data_length, rv_redo_data_length,
				rv_undo_data, rv_redo_data);
    }
  else				/* BTREE_OP_INSERT_MARK_DELETED */
    {
      assert (insert_helper->purpose == BTREE_OP_INSERT_MARK_DELETED);
      log_append_undoredo_data (thread_p, RVBT_MARK_DELETED, &addr, rv_undo_data_length, rv_redo_data_length,
				rv_undo_data, rv_redo_data);
      log_append_postpone (thread_p, RVBT_DELETE_OBJECT_POSTPONE, &addr, rv_undo_data_length, rv_undo_data);
    }

  btree_insert_log (insert_helper, BTREE_INSERT_MODIFY_MSG ("add delete MVCCID %llu"),
		    insert_helper->obj_info.mvcc_info.delete_mvccid,
		    BTREE_INSERT_MODIFY_ARGS (thread_p, insert_helper, page_ptr, &prev_lsa,
					      node_type == BTREE_LEAF_NODE, slot_id, rec->length, btid->sys_btid));

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  pgbuf_set_dirty (thread_p, page_ptr, DONT_FREE);

  if (rv_undo_data != NULL && rv_undo_data != rv_undo_data_bufalign)
    {
      db_private_free_and_init (thread_p, rv_undo_data);
    }

  return NO_ERROR;

exit_on_error:

  if (rv_undo_data != NULL && rv_undo_data != rv_undo_data_bufalign)
    {
      db_private_free_and_init (thread_p, rv_undo_data);
    }

  return ret;
}

/*
 * btree_set_mvcc_header_ids_for_update () - set ids of mvcc header for update
 *   return: nothing
 *   thread_p(in): thread entry
 *   do_delete_only(in):	true, if need to set del_id only
 *   do_insert_only(in): true, if need to set ins_id only
 *   mvcc_id(in): mvcc id to set
 *   mvcc_rec_header(in):  mvcc record header
 *
 * Note: do_delete_only and do_insert_only can't be both true
 */
void
btree_set_mvcc_header_ids_for_update (THREAD_ENTRY * thread_p, bool do_delete_only, bool do_insert_only,
				      MVCCID * mvcc_id, MVCC_REC_HEADER * mvcc_rec_header)
{
  assert (mvcc_rec_header != NULL);
  assert (do_delete_only == false || do_insert_only == false);

  BTREE_INIT_MVCC_HEADER (&mvcc_rec_header[0]);
  if (do_delete_only == false && do_insert_only == false)
    {
      MVCC_SET_FLAG_BITS (&mvcc_rec_header[0], OR_MVCC_FLAG_VALID_DELID);
      MVCC_SET_DELID (&mvcc_rec_header[0], *mvcc_id);

      BTREE_INIT_MVCC_HEADER (&mvcc_rec_header[1]);
      MVCC_SET_FLAG_BITS (&mvcc_rec_header[1], OR_MVCC_FLAG_VALID_INSID);
      MVCC_SET_INSID (&mvcc_rec_header[1], *mvcc_id);

      return;
    }

  if (do_delete_only == true)
    {
      MVCC_SET_FLAG_BITS (&mvcc_rec_header[0], OR_MVCC_FLAG_VALID_DELID);
      MVCC_SET_DELID (&mvcc_rec_header[0], *mvcc_id);

      return;
    }

  /* insert only case */
  MVCC_SET_FLAG_BITS (&mvcc_rec_header[0], OR_MVCC_FLAG_VALID_INSID);
  MVCC_SET_INSID (&mvcc_rec_header[0], *mvcc_id);
}

/*
 * btree_unpack_mvccinfo () - Check b-tree MVCC flags and unpack any MVCC info into MVCC header.
 *
 * return		 : Pointer after the packed MVCC info.
 * ptr (in)		 : Pointer to packed MVCC info.
 * mvcc_info (out)	 : Outputs MVCC info.
 * btree_mvcc_flags (in) : Flags that describe the packed MVCC info.
 */
char *
btree_unpack_mvccinfo (char *ptr, BTREE_MVCC_INFO * mvcc_info, short btree_mvcc_flags)
{
  assert (mvcc_info != NULL && ptr != NULL);

  mvcc_info->flags = btree_mvcc_flags;
  mvcc_info->insert_mvccid = MVCCID_ALL_VISIBLE;
  mvcc_info->delete_mvccid = MVCCID_NULL;

  if (BTREE_MVCC_INFO_HAS_INSID (mvcc_info))
    {
      /* Get insert MVCCID */
      ptr = or_unpack_mvccid (ptr, &mvcc_info->insert_mvccid);
    }

  if (BTREE_MVCC_INFO_HAS_DELID (mvcc_info))
    {
      /* Get delete MVCCID */
      ptr = or_unpack_mvccid (ptr, &mvcc_info->delete_mvccid);
    }

  return ptr;
}

/*
 * btree_pack_mvccinfo () - Pack MVCC information into b-tree record.
 *
 * return	  : Pointer after the packed MVCC information.
 * ptr (in)	  : Pointer where MVCC information will be packed.
 * mvcc_info (in) : MVCC information (saved as a record header).
 */
char *
btree_pack_mvccinfo (char *ptr, BTREE_MVCC_INFO * mvcc_info)
{
  if (mvcc_info == NULL)
    {
      /* No MVCC info to pack */
      return ptr;
    }
  if (BTREE_MVCC_INFO_HAS_INSID (mvcc_info))
    {
      ptr = or_pack_mvccid (ptr, mvcc_info->insert_mvccid);
    }
  if (BTREE_MVCC_INFO_HAS_DELID (mvcc_info))
    {
      ptr = or_pack_mvccid (ptr, mvcc_info->delete_mvccid);
    }
  return ptr;
}

/*
 * btree_packed_mvccinfo_size () - Packed MVCC info size.
 *
 * return	  : Packed MVCC info size.
 * mvcc_info (in) : MVCC info.
 */
int
btree_packed_mvccinfo_size (BTREE_MVCC_INFO * mvcc_info)
{
  int size = 0;

  if (mvcc_info == NULL)
    {
      /* Nothing to pack */
      return size;
    }

  if (BTREE_MVCC_INFO_HAS_INSID (mvcc_info))
    {
      size += OR_MVCCID_SIZE;
    }

  if (BTREE_MVCC_INFO_HAS_DELID (mvcc_info))
    {
      size += OR_MVCCID_SIZE;
    }

  return size;
}

/*
 * btree_or_get_mvccinfo () - Check b-tree MVCC flags and unpack any MVCC info into MVCC header.
 *
 * return		 : Error code.
 * buf (in/out)		 : OR Buffer.
 * mvcc_info (out)	 : MVCC Record header.
 * btree_mvcc_flags (in) : Flags that describe the packed MVCC info.
 */
static int
btree_or_get_mvccinfo (OR_BUF * buf, BTREE_MVCC_INFO * mvcc_info, short btree_mvcc_flags)
{
  int size = BTREE_GET_MVCC_INFO_SIZE_FROM_FLAGS (btree_mvcc_flags);

  if (buf->ptr + size > buf->endptr)
    {
      /* Overflow error */
      return or_overflow (buf);
    }

  /* Unpack and update pointer */
  buf->ptr = btree_unpack_mvccinfo (buf->ptr, mvcc_info, btree_mvcc_flags);

  return NO_ERROR;
}

/*
 * btree_or_put_mvccinfo () - Set MVCC information into buffer (should be used for b-tree records).
 *                            Only insert/delete MVCCID's will be set depending on MVCC flags.
 *
 * return	  : Error code.
 * buf (in/out)	  : OR Buffer.
 * mvcc_info (in) : MVCC info (saved as record header).
 */
static int
btree_or_put_mvccinfo (OR_BUF * buf, BTREE_MVCC_INFO * mvcc_info)
{
  int error_code = NO_ERROR;

  if (BTREE_MVCC_INFO_HAS_INSID (mvcc_info))
    {
      error_code = or_put_mvccid (buf, mvcc_info->insert_mvccid);
      if (error_code != NO_ERROR)
	{
	  return error_code;
	}
    }

  if (BTREE_MVCC_INFO_HAS_DELID (mvcc_info))
    {
      error_code = or_put_mvccid (buf, mvcc_info->delete_mvccid);
      if (error_code != NO_ERROR)
	{
	  return error_code;
	}
    }

  return error_code;
}

/*
 * btree_unpack_object () - Unpack a b-tree object from the given pointer. Pointer should belong to a b-tree record.
 *
 * return		 : Error code.
 * ptr (in)		 : Pointer in b-tree record to unpack object.
 * btid_int (in)	 : B-tree info.
 * node_type (in)	 : Leaf or overflow node type.
 * record (in)		 : B-tree record.
 * after_key_offset (in) : Offset in record after packed key.
 * oid (out)		 : Unpacked OID.
 * class_oid (out)	 : Unpacked class OID.
 * mvcc_info (out)	 : Unpacked MVCC info.
 */
static char *
btree_unpack_object (char *ptr, BTID_INT * btid_int, BTREE_NODE_TYPE node_type, RECDES * record, int after_key_offset,
		     OID * oid, OID * class_oid, BTREE_MVCC_INFO * mvcc_info)
{
  OR_BUF buffer;

  BTREE_RECORD_OR_BUF_INIT (buffer, record);
  buffer.ptr = ptr;

  if (btree_or_get_object (&buffer, btid_int, node_type, after_key_offset, oid, class_oid, mvcc_info) != NO_ERROR)
    {
      assert (false);
      return NULL;
    }

  return buffer.ptr;
}

/*
 * btree_pack_object () - Pack a b-tree object into the given pointer. Pointer should belong to a b-tree record.
 *
 * return		 : Error code.
 * ptr (in)		 : Pointer in b-tree record to pack object.
 * btid_int (in)	 : B-tree info.
 * node_type (in)	 : Leaf or overflow node type.
 * record (in)		 : B-tree record.
 * object_info (in)	 : B-tree object info.
 */
static char *
btree_pack_object (char *ptr, BTID_INT * btid_int, BTREE_NODE_TYPE node_type, RECDES * record,
		   BTREE_OBJECT_INFO * object_info)
{
  OR_BUF buffer;

  OR_BUF_INIT (buffer, record->data, record->area_size);
  buffer.ptr = ptr;

  if (btree_or_put_object (&buffer, btid_int, node_type, object_info) != NO_ERROR)
    {
      assert (false);
      return NULL;
    }

  return buffer.ptr;
}

/*
 * btree_or_get_object () - Get object, class OID and its MVCC info from buffer pointing in a b-tree record.
 *
 * return		  : Error code.
 * buf (in/out)		  : Buffer pointing to object in b-tree record.
 * btid_int (in)	  : B-tree info.
 * node_type (in)	  : Leaf or overflow node type.
 * after_key_offset (int) : Offset to end of packed key for leaf records.
 * oid (out)		  : Outputs OID of object.
 * class_oid (out)	  : Outputs OID of object's class.
 * mvcc_info (out)	  : Outputs MVCC info for object.
 *
 * NOTE: Buffer.buffer should point to start of b-tree record.
 * NOTE: Buffer pointer will be moved after read object.
 *	 If object is first in leaf record, buffer pointer will be moved after the packed key
 *	 (where second objects starts).
 */
static int
btree_or_get_object (OR_BUF * buf, BTID_INT * btid_int, BTREE_NODE_TYPE node_type, int after_key_offset, OID * oid,
		     OID * class_oid, BTREE_MVCC_INFO * mvcc_info)
{
  short mvcc_flags = 0;		/* MVCC flags read from object OID. */
  int error_code = NO_ERROR;	/* Error code. */
  bool is_first_of_leaf;	/* True if the object is first in leaf record. */

  /* Assert arguments meet expectations. */
  assert (buf != NULL);
  assert (node_type == BTREE_LEAF_NODE || node_type == BTREE_OVERFLOW_NODE);
  /* Should any of these be optional? */
  assert (oid != NULL);
  assert (class_oid != NULL);
  assert (mvcc_info != NULL);

  /* Assert buffer has expected alignment. */
  ASSERT_ALIGN (buf->ptr, INT_ALIGNMENT);

  /* Is this the first object of leaf record? */
  is_first_of_leaf = buf->ptr == buf->buffer && node_type == BTREE_LEAF_NODE;

  /* Read MVCC flags. */
  mvcc_flags = btree_record_object_get_mvcc_flags (buf->ptr);

  /* Get OID. */
  error_code = or_get_oid (buf, oid);
  if (error_code != NO_ERROR)
    {
      return error_code;
    }

  if (BTREE_IS_UNIQUE (btid_int->unique_pk))
    {
      /* Get/set class OID. If this is the first object in leaf record and if record is not marked with
       * BTREE_LEAF_RECORD_CLASS_OID, class OID must be top class OID. Otherwise, read it from record. */
      if (is_first_of_leaf && !BTREE_OID_IS_RECORD_FLAG_SET (oid, BTREE_LEAF_RECORD_CLASS_OID))
	{
	  COPY_OID (class_oid, &btid_int->topclass_oid);
	}
      else
	{
	  error_code = or_get_oid (buf, class_oid);
	  if (error_code != NO_ERROR)
	    {
	      assert (false);
	      return error_code;
	    }
	}
    }
  else
    {
      /* Non-unique indexes can be part only of top class. */
      COPY_OID (class_oid, &btid_int->topclass_oid);
    }

  /* Clear all flags from object. */
  BTREE_OID_CLEAR_ALL_FLAGS (oid);

  /* Read MVCC info */
  error_code = btree_or_get_mvccinfo (buf, mvcc_info, mvcc_flags);
  if (error_code != NO_ERROR)
    {
      assert (false);
      return error_code;
    }

  if (is_first_of_leaf)
    {
      /* Advance after the first key. */
      error_code = or_seek (buf, after_key_offset);
      if (error_code != NO_ERROR)
	{
	  assert (false);
	  return error_code;
	}
    }

  /* Successful read. */
  return NO_ERROR;
}

/*
 * btree_or_put_object () - Put object data in buffer (of b-tree record).
 *
 * return	    : Error code.
 * buf (in/out)	    : Buffer pointing to destination of object data.
 * btid_int (in)    : B-tree info.
 * node_type (in)   : Leaf or overflow node type.
 * object_info (in) : B-tree object info.
 *
 * NOTE: Buffer will point at the end of packed object after execution.
 */
static int
btree_or_put_object (OR_BUF * buf, BTID_INT * btid_int, BTREE_NODE_TYPE node_type, BTREE_OBJECT_INFO * object_info)
{
  bool is_first_of_leaf;	/* True if object is first in a leaf record. */
  OID flagged_oid;		/* OID of object including flags. */
  int error_code = NO_ERROR;	/* Error code. */

  /* Assert expected arguments. */
  assert (object_info != NULL);
  /* All overflow objects must be fixed size. */
  assert (node_type == BTREE_LEAF_NODE
	  || (BTREE_MVCC_INFO_HAS_INSID (&object_info->mvcc_info)
	      && BTREE_MVCC_INFO_HAS_DELID (&object_info->mvcc_info)));

  /* Is this the first object of leaf record? */
  is_first_of_leaf = (buf->ptr == buf->buffer) && node_type == BTREE_LEAF_NODE;

  /* All objects in unique key index except first must be fixed size. */
  assert (!BTREE_IS_UNIQUE (btid_int->unique_pk) || !is_first_of_leaf
	  || (BTREE_MVCC_INFO_HAS_INSID (&object_info->mvcc_info)
	      && BTREE_MVCC_INFO_HAS_DELID (&object_info->mvcc_info)));

  /* Set MVCC flags into OID. */
  COPY_OID (&flagged_oid, &object_info->oid);
  BTREE_OID_SET_MVCC_FLAG (&flagged_oid, object_info->mvcc_info.flags);

  if (BTREE_IS_UNIQUE (btid_int->unique_pk))
    {
      /* Class OID may have to be packed. */
      if (is_first_of_leaf)
	{
	  if (OID_EQ (&btid_int->topclass_oid, &object_info->class_oid))
	    {
	      /* Don't add class oid. Top class OID will be considered as default. */
	      error_code = or_put_oid (buf, &flagged_oid);
	      if (error_code != NO_ERROR)
		{
		  return error_code;
		}
	    }
	  else
	    {
	      /* Flag object with BTREE_LEAF_RECORD_CLASS_OID and also add class OID. */
	      flagged_oid.slotid |= BTREE_LEAF_RECORD_CLASS_OID;
	      error_code = or_put_oid (buf, &flagged_oid);
	      if (error_code != NO_ERROR)
		{
		  return error_code;
		}
	      error_code = or_put_oid (buf, &object_info->class_oid);
	      if (error_code != NO_ERROR)
		{
		  return error_code;
		}
	    }
	}
      else
	{
	  /* Add oid and class OID. */
	  error_code = or_put_oid (buf, &flagged_oid);
	  if (error_code != NO_ERROR)
	    {
	      return error_code;
	    }
	  error_code = or_put_oid (buf, &object_info->class_oid);
	  if (error_code != NO_ERROR)
	    {
	      return error_code;
	    }
	}
    }
  else
    {
      /* Add OID only */
      error_code = or_put_oid (buf, &flagged_oid);
      if (error_code != NO_ERROR)
	{
	  return error_code;
	}
    }

  /* Add MVCC info */
  error_code = btree_or_put_mvccinfo (buf, &object_info->mvcc_info);
  return error_code;
}

/*
 * btree_set_mvcc_flags_into_oid () - Set MVCC info flags in the volid field of OID.
 *
 * return	      : Void.
 * p_mvcc_header (in) : MVCC info.
 * oid (in/out)	      : Object identifier.
 */
void
btree_set_mvcc_flags_into_oid (MVCC_REC_HEADER * p_mvcc_header, OID * oid)
{
  if (p_mvcc_header == NULL)
    {
      /* No flag to set */
      return;
    }
  if (MVCC_IS_FLAG_SET (p_mvcc_header, OR_MVCC_FLAG_VALID_INSID))
    {
      oid->volid |= BTREE_OID_HAS_MVCC_INSID;
    }
  if (MVCC_IS_FLAG_SET (p_mvcc_header, OR_MVCC_FLAG_VALID_DELID))
    {
      oid->volid |= BTREE_OID_HAS_MVCC_DELID;
    }
}

/*
 * btree_clear_mvcc_flags_from_oid () -
 *
 * return	      : Void.
 * oid (in/out)	      : Object identifier.
 */
void
btree_clear_mvcc_flags_from_oid (OID * oid)
{
  oid->volid &= ~BTREE_OID_MVCC_FLAGS_MASK;
}

/*
 * btree_compare_btids () - B-tree identifier comparator.
 *
 * return	  : Positive value is the first identifier is bigger,
 *		    negative if the second identifier is bigger and 0 if the identifiers are equal.
 * mem_btid1 (in) : Pointer to first btid value.
 * mem_btid2 (in) : Pointer to second btid value.
 */
int
btree_compare_btids (void *mem_btid1, void *mem_btid2)
{
  const BTID *btid1 = (const BTID *) mem_btid1;
  const BTID *btid2 = (const BTID *) mem_btid2;
  if (btid1 == btid2)
    {
      return 0;
    }

  if (btid1->root_pageid > btid2->root_pageid)
    {
      return 1;
    }
  else if (btid1->root_pageid < btid2->root_pageid)
    {
      return -1;
    }

  if (btid1->vfid.fileid > btid2->vfid.fileid)
    {
      return 1;
    }
  else if (btid1->vfid.fileid < btid2->vfid.fileid)
    {
      return -1;
    }

  if (btid1->vfid.volid > btid2->vfid.volid)
    {
      return 1;
    }
  else if (btid1->vfid.volid < btid2->vfid.volid)
    {
      return -1;
    }

  return 0;
}

/*
 * btree_check_valid_record () - Check that record data is valid.
 *
 * return		: Error code.
 * thread_p (in)	: Thread entry.
 * btid (in)		: B-tree data.
 * recp (in)		: Record descriptor.
 * node_type (in)	: Node type (overflow or leaf).
 * key (in)		: Expected key value (will be checked if not null,
 *			  and if node type is leaf and if key doesn't have overflow pages).
 */
int
btree_check_valid_record (THREAD_ENTRY * thread_p, BTID_INT * btid, RECDES * recp, BTREE_NODE_TYPE node_type,
			  DB_VALUE * key)
{
#define BTREE_CHECK_VALID_PRINT_REC_MAX_LENGTH 1024
  OID oid, class_oid;
  MVCCID mvccid;
  int vpid_size = 0;
  OR_BUF buffer;
  short mvcc_flags;
  bool is_first_oid = true;
  bool has_fixed_size = false;
  bool has_overflow_pages = false;
  VPID first_overflow_vpid = VPID_INITIALIZER;

  assert (btid != NULL);
  assert (recp != NULL && recp->data != NULL && recp->length > 0);
  assert (node_type == BTREE_LEAF_NODE || node_type == BTREE_OVERFLOW_NODE);

  if (btid == NULL || btid->key_type == NULL)
    {
      /* We don't have access to b-tree information to check the record. */
      return NO_ERROR;
    }

  if (btree_leaf_is_flaged (recp, BTREE_LEAF_RECORD_OVERFLOW_OIDS))
    {
      char *vpid_ptr = NULL;

      has_overflow_pages = true;
      vpid_size = DISK_VPID_ALIGNED_SIZE;

      vpid_ptr = recp->data + recp->length - vpid_size;
      OR_GET_VPID (vpid_ptr, &first_overflow_vpid);
      if (!log_is_in_crash_recovery ()
	  && pgbuf_is_valid_page (thread_p, &first_overflow_vpid, true, NULL, NULL) == DISK_INVALID)
	{
	  assert (false);
	  return ER_FAILED;
	}
    }

  or_init (&buffer, recp->data, recp->length - vpid_size);
  while (buffer.ptr < buffer.endptr)
    {
      /* Get mvcc flags */
      mvcc_flags = btree_record_object_get_mvcc_flags (buffer.ptr);
      /* If MVCC is enabled, there are several cases when the object entry must have fixed size, which means that
       * insert/delete MVCCID must be present: 1. Overflow objects. 2. First object if leaf record if there are
       * overflow OID's. 3. Any non-first object if index is unique. */
      has_fixed_size = ((node_type == BTREE_OVERFLOW_NODE) || (has_overflow_pages && is_first_oid)
			|| (BTREE_IS_UNIQUE (btid->unique_pk) && !is_first_oid));
      if (has_fixed_size)
	{
	  assert ((mvcc_flags & BTREE_OID_HAS_MVCC_INSID) && (mvcc_flags & BTREE_OID_HAS_MVCC_DELID));
	}
      /* Get and check OID */
      if (or_get_oid (&buffer, &oid) != NO_ERROR)
	{
	  assert (false);
	  return ER_FAILED;
	}
      BTREE_OID_CLEAR_ALL_FLAGS (&oid);
      if (oid.pageid <= 0 || oid.slotid <= 0 || oid.slotid > ((short) (DB_PAGESIZE / sizeof (PGSLOTID)))
	  || oid.volid < 0)
	{
	  assert (false);
	  return ER_FAILED;
	}
      if (btree_is_class_oid_packed (btid, recp, node_type, is_first_oid))
	{
	  /* Get and check class OID */
	  if (or_get_oid (&buffer, &class_oid) != NO_ERROR)
	    {
	      assert (false);
	      return ER_FAILED;
	    }
	  if (class_oid.pageid <= 0 || class_oid.slotid <= 0
	      || class_oid.slotid > ((short) (DB_PAGESIZE / sizeof (PGSLOTID))) || class_oid.volid < 0)
	    {
	      assert (false);
	      return ER_FAILED;
	    }
	}
      if (mvcc_flags & BTREE_OID_HAS_MVCC_INSID)
	{
	  /* Get and check insert MVCCID */
	  if (or_get_mvccid (&buffer, &mvccid) != NO_ERROR)
	    {
	      assert (false);
	      return ER_FAILED;
	    }

	  /* Remove any possible online_index flags. */
	  mvccid &= BTREE_ONLINE_INDEX_MVCCID_MASK;
	  if (!MVCCID_IS_VALID (mvccid))
	    {
	      assert (false);
	      return ER_FAILED;
	    }
	  if (!MVCC_ID_PRECEDES (mvccid, log_Gl.hdr.mvcc_next_id) && !log_is_in_crash_recovery ())
	    {
	      assert (false);
	      return ER_FAILED;
	    }
	}
      if (mvcc_flags & BTREE_OID_HAS_MVCC_DELID)
	{
	  /* Get and check delete MVCCID */
	  if (or_get_mvccid (&buffer, &mvccid) != NO_ERROR)
	    {
	      assert (false);
	      return ER_FAILED;
	    }
	  if (mvccid != MVCCID_NULL && !MVCC_ID_PRECEDES (mvccid, log_Gl.hdr.mvcc_next_id)
	      && !log_is_in_crash_recovery ())
	    {
	      assert (false);
	      return ER_FAILED;
	    }
	}
      if (is_first_oid && (node_type == BTREE_LEAF_NODE))
	{
	  /* Key value is also saved */
	  if (!btree_leaf_is_flaged (recp, BTREE_LEAF_RECORD_OVERFLOW_KEY))
	    {
	      /* Get key value */
	      DB_VALUE rec_key_value;
	      TP_DOMAIN *key_domain = NULL;
	      PR_TYPE *pr_type = NULL;

	      db_make_null (&rec_key_value);
	      key_domain = btid->key_type;
	      pr_type = key_domain->type;
	      if (pr_type->index_readval (&buffer, &rec_key_value, key_domain, -1, true, NULL, 0) != NO_ERROR)
		{
		  assert (false);
		  return ER_FAILED;
		}
	      if (key != NULL && btree_compare_key (key, &rec_key_value, key_domain, 1, 1, NULL) != 0)
		{
		  /* Expected key is not the same with the key found in record data. */
		  /* This is possible when key fence is used. Should disable this verification or should include the
		   * fence for compare */
		  /* For now, do nothing */
		}
	      pr_clear_value (&rec_key_value);
	    }
	  else
	    {
	      /* Skip overflow key vpid */
	      buffer.ptr += DISK_VPID_SIZE;
	    }
	  buffer.ptr = PTR_ALIGN (buffer.ptr, OR_INT_SIZE);
	}
      is_first_oid = false;
    }
  if (buffer.ptr != buffer.endptr)
    {
      assert (false);
      return ER_FAILED;
    }
  return NO_ERROR;
}

/*
 * btree_check_foreign_key () -
 *   return: NO_ERROR
 *   cls_oid(in):
 *   hfid(in):
 *   oid(in):
 *   keyval(in):
 *   n_attrs(in):
 *   pk_cls_oid(in):
 *   pk_btid(in):
 *   fk_name(in):
 */
int
btree_check_foreign_key (THREAD_ENTRY * thread_p, OID * cls_oid, HFID * hfid, OID * oid, DB_VALUE * keyval, int n_attrs,
			 OID * pk_cls_oid, BTID * pk_btid, const char *fk_name)
{
  OID unique_oid;
  bool has_null;
  DB_VALUE val;
  int ret = NO_ERROR;
  OID part_oid;
  HFID class_hfid;
  BTID local_btid;
  PRUNING_CONTEXT pcontext;
  bool clear_pcontext = false;
  OR_CLASSREP *classrepr = NULL;
  int classrepr_cacheindex = -1;
  BTREE_SEARCH ret_search;

  db_make_null (&val);
  OID_SET_NULL (&unique_oid);

  /* SQL standard defines as follows:
   * If no <match type> was specified then, for each row R1 of the referencing table,
   * either at least one of the values of the referencing columns in R1 shall be a null value,
   * or the value of each referencing column in R1 shall be equal to the value of
   * the corresponding referenced column in some row of the referenced table.
   * Please notice that we don't currently support <match type>.
   */
  if (n_attrs > 1)
    {
      has_null = btree_multicol_key_has_null (keyval);
    }
  else
    {
      has_null = DB_IS_NULL (keyval);
    }

  if (has_null == true)
    {
      return NO_ERROR;
    }

  /* get class representation to find partition information */
  classrepr = heap_classrepr_get (thread_p, pk_cls_oid, NULL, NULL_REPRID, &classrepr_cacheindex);
  if (classrepr == NULL)
    {
      goto exit_on_error;
    }

  if (classrepr->has_partition_info > 0)
    {
      (void) partition_init_pruning_context (&pcontext);
      clear_pcontext = true;

      ret = partition_load_pruning_context (thread_p, pk_cls_oid, DB_PARTITIONED_CLASS, &pcontext);
      if (ret != NO_ERROR)
	{
	  goto exit_on_error;
	}
    }

  BTID_COPY (&local_btid, pk_btid);
  COPY_OID (&part_oid, pk_cls_oid);

  if (classrepr->has_partition_info > 0 && pcontext.partitions != NULL)
    {
      ret = partition_prune_unique_btid (&pcontext, keyval, &part_oid, &class_hfid, &local_btid);
      if (ret != NO_ERROR)
	{
	  goto exit_on_error;
	}
    }

  ret_search = xbtree_find_unique (thread_p, &local_btid, S_SELECT_WITH_LOCK, keyval, &part_oid, &unique_oid, true);
  if (ret_search == BTREE_KEY_NOTFOUND)
    {
      char *val_print = NULL;

      val_print = pr_valstring (keyval);
      er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_FK_INVALID, 2, fk_name, (val_print ? val_print : "unknown value"));
      if (val_print)
	{
	  db_private_free (thread_p, val_print);
	}
      ret = ER_FK_INVALID;
      goto exit_on_error;
    }
  else if (ret_search == BTREE_ERROR_OCCURRED)
    {
      ASSERT_ERROR_AND_SET (ret);
      goto exit_on_error;
    }

  assert (ret_search == BTREE_KEY_FOUND);
  /* TODO: For read committed... Do we need to keep the lock? */

  if (clear_pcontext == true)
    {
      partition_clear_pruning_context (&pcontext);
    }
  if (classrepr != NULL)
    {
      heap_classrepr_free_and_init (classrepr, &classrepr_cacheindex);
    }

  return ret;

exit_on_error:

  if (clear_pcontext == true)
    {
      partition_clear_pruning_context (&pcontext);
    }
  if (classrepr != NULL)
    {
      heap_classrepr_free_and_init (classrepr, &classrepr_cacheindex);
    }

  return (ret == NO_ERROR && (ret = er_errid ()) == NO_ERROR) ? ER_FAILED : ret;
}

/*
 * btree_scan_for_show_index_capacity () - scan index capacity information
 *   return: S_ERROR, S_SUCCESS, or S_END
 *
 *   thread_p(in):
 *   out_values(out):
 *   out_cnt(in):
 *   class_name(in);
 *   index_p(in);
 */
static SCAN_CODE
btree_scan_for_show_index_capacity (THREAD_ENTRY * thread_p, DB_VALUE ** out_values, int out_cnt,
				    const char *class_name, OR_INDEX * index_p)
{
  int idx = 0;
  int error = NO_ERROR;
  BTREE_CAPACITY cpc;
  PAGE_PTR root_page_ptr = NULL;
  VPID root_vpid;
  char buf[256] = { 0 };
  BTID *btid_p = NULL;

  assert_release (index_p != NULL);

  /* get btree capacity */
  btid_p = &index_p->btid;
  root_vpid.pageid = btid_p->root_pageid;
  root_vpid.volid = btid_p->vfid.volid;
  root_page_ptr = pgbuf_fix (thread_p, &root_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
  if (root_page_ptr == NULL)
    {
      ASSERT_ERROR_AND_SET (error);
      goto cleanup;
    }

  error = btree_index_capacity (thread_p, btid_p, &cpc);
  if (error != NO_ERROR)
    {
      goto cleanup;
    }

  /* scan index capacity into out_values */
  error = db_make_string_copy (out_values[idx], class_name);
  idx++;
  if (error != NO_ERROR)
    {
      goto cleanup;
    }

  error = db_make_string_copy (out_values[idx], index_p->btname);
  idx++;
  if (error != NO_ERROR)
    {
      goto cleanup;
    }

  (void) btid_to_string (buf, sizeof (buf), btid_p);
  error = db_make_string_copy (out_values[idx], buf);
  idx++;
  if (error != NO_ERROR)
    {
      goto cleanup;
    }

  db_make_int (out_values[idx], cpc.dis_key_cnt);
  idx++;

  db_make_int (out_values[idx], cpc.tot_val_cnt);
  idx++;

  db_make_int (out_values[idx], cpc.avg_val_per_key);
  idx++;

  db_make_int (out_values[idx], cpc.leaf_pg_cnt);
  idx++;

  db_make_int (out_values[idx], cpc.nleaf_pg_cnt);
  idx++;

  db_make_int (out_values[idx], cpc.tot_pg_cnt);
  idx++;

  db_make_int (out_values[idx], cpc.height);
  idx++;

  db_make_int (out_values[idx], cpc.avg_key_len);
  idx++;

  db_make_int (out_values[idx], cpc.avg_rec_len);
  idx++;

  (void) util_byte_to_size_string (buf, 64, (UINT64) (cpc.tot_space));
  error = db_make_string_copy (out_values[idx], buf);
  idx++;
  if (error != NO_ERROR)
    {
      goto cleanup;
    }

  (void) util_byte_to_size_string (buf, 64, (UINT64) (cpc.tot_used_space));
  error = db_make_string_copy (out_values[idx], buf);
  idx++;
  if (error != NO_ERROR)
    {
      goto cleanup;
    }

  (void) util_byte_to_size_string (buf, 64, (UINT64) (cpc.tot_free_space));
  error = db_make_string_copy (out_values[idx], buf);
  idx++;
  if (error != NO_ERROR)
    {
      goto cleanup;
    }

  db_make_int (out_values[idx], cpc.avg_pg_key_cnt);
  idx++;

  (void) util_byte_to_size_string (buf, 64, (UINT64) (cpc.avg_pg_free_sp));
  error = db_make_string_copy (out_values[idx], buf);
  idx++;
  if (error != NO_ERROR)
    {
      goto cleanup;
    }

  assert (idx == out_cnt);

cleanup:

  if (root_page_ptr != NULL)
    {
      pgbuf_unfix_and_init (thread_p, root_page_ptr);
    }

  return (error == NO_ERROR) ? S_SUCCESS : S_ERROR;
}

static bool
btree_leaf_lsa_eq (THREAD_ENTRY * thread_p, LOG_LSA * a, LOG_LSA * b)
{
  assert (a != NULL);
  assert (b != NULL);

#if !defined(SERVER_MODE)
  assert_release (LSA_EQ (a, b));
#endif

  return LSA_EQ (a, b) ? true : false;
}

/*
 * btree_key_find_first_visible_row_from_all_ovf () - MVCC find first visible row in OID overflow pages
 *   return: whether the visible row has been found
 *   btid_int(in): B+tree index identifier
 *   first_ovfl_vpid(in): First overflow vpid
 *   oid(out): Object identifier of the visible row or NULL_OID
 *   class_oid(out): Object class identifier
 */
static BTREE_SEARCH
btree_key_find_first_visible_row_from_all_ovf (THREAD_ENTRY * thread_p, BTID_INT * btid_int, VPID * first_ovfl_vpid,
					       OID * oid, OID * class_oid)
{
  RECDES ovfl_copy_rec;
  char ovfl_copy_rec_buf[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  VPID next_ovfl_vpid;
  PAGE_PTR ovfl_page = NULL;
  BTREE_SEARCH result = BTREE_KEY_NOTFOUND;

  assert (btid_int != NULL);
  assert (first_ovfl_vpid != NULL);
  assert (oid != NULL && class_oid != NULL);

  ovfl_copy_rec.area_size = DB_PAGESIZE;
  ovfl_copy_rec.data = PTR_ALIGN (ovfl_copy_rec_buf, BTREE_MAX_ALIGN);
  next_ovfl_vpid = *first_ovfl_vpid;

  /* find first visible OID into overflow page */
  while (!VPID_ISNULL (&next_ovfl_vpid))
    {
      ovfl_page = pgbuf_fix (thread_p, &next_ovfl_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
      if (ovfl_page == NULL)
	{
	  ASSERT_ERROR ();
	  goto error;
	}

      (void) pgbuf_check_page_ptype (thread_p, ovfl_page, PAGE_BTREE);

      if (spage_get_record (thread_p, ovfl_page, 1, &ovfl_copy_rec, COPY) != S_SUCCESS)
	{
	  goto error;
	}
      assert (ovfl_copy_rec.length % 4 == 0);

      result =
	btree_key_find_first_visible_row (thread_p, btid_int, &ovfl_copy_rec, 0, BTREE_OVERFLOW_NODE, oid, class_oid,
					  -1);
      if (result == BTREE_ERROR_OCCURRED)
	{
	  goto error;
	}
      else if (result != BTREE_KEY_NOTFOUND)
	{
	  pgbuf_unfix_and_init (thread_p, ovfl_page);
	  return result;
	}

      btree_get_next_overflow_vpid (thread_p, ovfl_page, &next_ovfl_vpid);
      pgbuf_unfix_and_init (thread_p, ovfl_page);
    }

  return BTREE_KEY_NOTFOUND;

error:

  if (ovfl_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, ovfl_page);
    }

  return BTREE_ERROR_OCCURRED;
}

/*
 * btree_rv_undo_global_unique_stats_commit () -
 *   return: int
 *   recv(in): Recovery structure
 *
 * Note: Decrement the in-memory global unique statistics.
 */
int
btree_rv_undo_global_unique_stats_commit (THREAD_ENTRY * thread_p, LOG_RCV * recv)
{
  char *datap;
  int num_nulls, num_oids, num_keys;
  BTID btid;

  assert (recv->length >= (3 * OR_INT_SIZE) + OR_BTID_ALIGNED_SIZE);

  /* unpack the root statistics */
  datap = (char *) recv->data;

  OR_GET_BTID (datap, &btid);
  datap += OR_BTID_ALIGNED_SIZE;

  num_nulls = OR_GET_INT (datap);
  datap += OR_INT_SIZE;

  num_oids = OR_GET_INT (datap);
  datap += OR_INT_SIZE;

  num_keys = OR_GET_INT (datap);
  datap += OR_INT_SIZE;

  /* Because this log record is logical, it will be processed even if the B-tree was deleted. If the B-tree was deleted
   * then skip update of unique statistics in global hash. */
  if (log_Gl.rcv_phase == LOG_RECOVERY_UNDO_PHASE)
    {
      /* Only in recovery this is possible */
      if (disk_is_page_sector_reserved (thread_p, btid.vfid.volid, btid.root_pageid) != DISK_VALID)
	{
	  /* The B-tree was already deleted */
	  return NO_ERROR;
	}
    }
  else
    {
      /* This should not happen */
      assert (disk_is_page_sector_reserved (thread_p, btid.vfid.volid, btid.root_pageid) == DISK_VALID);
    }
  if (logtb_update_global_unique_stats_by_delta (thread_p, &btid, -num_oids, -num_nulls, -num_keys, false) != NO_ERROR)
    {
      goto error;
    }

  if (prm_get_bool_value (PRM_ID_LOG_UNIQUE_STATS))
    {
      _er_log_debug (ARG_FILE_LINE,
		     "Recover undo unique statistics for index (%d, %d|%d): "
		     "nulls=%d, oids=%d, keys=%d. LSA=%lld|%d.\n", btid.root_pageid, btid.vfid.volid, btid.vfid.fileid,
		     num_nulls, num_oids, num_keys, (long long int) log_Gl.unique_stats_table.curr_rcv_rec_lsa.pageid,
		     (int) log_Gl.unique_stats_table.curr_rcv_rec_lsa.offset);
    }

  return NO_ERROR;

error:
  er_set (ER_FATAL_ERROR_SEVERITY, ARG_FILE_LINE, ER_GENERIC_ERROR, 0);

  return ER_GENERIC_ERROR;
}

/*
 * btree_rv_redo_global_unique_stats_commit () -
 *   return: int
 *   recv(in): Recovery structure
 *
 * Note: Recover the in-memory global unique statistics.
 */
int
btree_rv_redo_global_unique_stats_commit (THREAD_ENTRY * thread_p, LOG_RCV * recv)
{
  char *datap;
  int num_nulls, num_oids, num_keys;
  BTID btid;

  assert (recv->length >= (3 * OR_INT_SIZE) + OR_BTID_ALIGNED_SIZE);

  /* unpack the root statistics */
  datap = (char *) recv->data;

  OR_GET_BTID (datap, &btid);
  datap += OR_BTID_ALIGNED_SIZE;

  num_nulls = OR_GET_INT (datap);
  datap += OR_INT_SIZE;

  num_oids = OR_GET_INT (datap);
  datap += OR_INT_SIZE;

  num_keys = OR_GET_INT (datap);
  datap += OR_INT_SIZE;

  /* Because this log record is logical, it will be processed even if the B-tree was deleted. If the B-tree was deleted
   * then skip update of unique statistics in global hash. */
  if (disk_is_page_sector_reserved (thread_p, btid.vfid.volid, btid.root_pageid) != DISK_VALID)
    {
      /* The B-tree was already deleted */
      return NO_ERROR;
    }
  if (logtb_rv_update_global_unique_stats_by_abs (thread_p, &btid, num_oids, num_nulls, num_keys) != NO_ERROR)
    {
      goto error;
    }

  if (prm_get_bool_value (PRM_ID_LOG_UNIQUE_STATS))
    {
      _er_log_debug (ARG_FILE_LINE,
		     "Recover redo unique statistics for index (%d, %d|%d): "
		     "nulls=%d, oids=%d, keys=%d. LSA=%lld|%d.\n", btid.root_pageid, btid.vfid.volid, btid.vfid.fileid,
		     num_nulls, num_oids, num_keys, (long long int) log_Gl.unique_stats_table.curr_rcv_rec_lsa.pageid,
		     (int) log_Gl.unique_stats_table.curr_rcv_rec_lsa.offset);
    }

  return NO_ERROR;

error:
  er_set (ER_FATAL_ERROR_SEVERITY, ARG_FILE_LINE, ER_GENERIC_ERROR, 0);

  return ER_GENERIC_ERROR;
}

/*
 * btree_search_key_and_apply_functions () - B-tree internal function to traverse the tree in the direction given by
 * 					     a key and calling three types of function: one to fix/handle root page,
 * 					     one on the traversed nodes and one on the leaf node pointed by key.
 *
 * return		     : Error code.
 * thread_p (in)	     : Thread entry.
 * btid (in)		     : B-tree identifier.
 * btid_int (out)	     : Output b-tree info if not NULL.
 * key (in)		     : Search key value.
 * root_function (in)	     : Function called to fix/process root node.
 * root_args (in/out)	     : Arguments for root function.
 * advance_function (in)     : Function called to advance and process nodes discovered nodes.
 * advance_args (in/out)     : Arguments for advance function.
 * key_function (in)	     : Function to process key record (and its leaf and overflow nodes).
 * process_key_args (in/out) : Arguments for key function.
 * search_key (out)	     : Search key result.
 * leaf_page_ptr (out)	     : If not NULL, it will output the leaf node page where key lead the search.
 */
static int
btree_search_key_and_apply_functions (THREAD_ENTRY * thread_p, BTID * btid, BTID_INT * btid_int, DB_VALUE * key,
				      BTREE_ROOT_WITH_KEY_FUNCTION * root_function, void *root_args,
				      BTREE_ADVANCE_WITH_KEY_FUNCTION * advance_function, void *advance_args,
				      BTREE_PROCESS_KEY_FUNCTION * key_function, void *process_key_args,
				      BTREE_SEARCH_KEY_HELPER * search_key, PAGE_PTR * leaf_page_ptr)
{
  PAGE_PTR crt_page = NULL;	/* Currently fixed page. */
  PAGE_PTR advance_page = NULL;	/* Next level page. */
  int error_code = NO_ERROR;	/* Error code. */
  BTID_INT local_btid_int;	/* Store b-tree info if b-tree info pointer argument is NULL. */
  bool is_leaf = false;		/* Set to true if crt_page is a leaf node. */
  bool stop = false;		/* Set to true to stop advancing in b-tree. */
  bool restart = false;		/* Set to true to restart b-tree traversal from root. */
  BTREE_SEARCH_KEY_HELPER local_search_key;	/* Store search key result if search key pointer argument is NULL. */

  /* Assert expected arguments. */
  assert (btid != NULL);
  assert (key != NULL);
  assert (advance_function != NULL);

  if (leaf_page_ptr != NULL)
    {
      /* Initialize leaf_page_ptr as NULL. */
      *leaf_page_ptr = NULL;
    }

  if (btid_int == NULL)
    {
      /* Use local variable to store b-tree info. */
      btid_int = &local_btid_int;
    }
  if (search_key == NULL)
    {
      /* Use local variable to store search key result. */
      search_key = &local_search_key;
    }

start_btree_traversal:
  /* Traversal starting point. The function will try to locate key while calling 3 types of manipulation functions: 1.
   * Root function: It may be used to fix and modify root page. If no such function is provided,
   * btree_get_root_with_key is used by default. 2. Advance function: It is used to determine the path to follow in
   * order to locate the key in leaf node. It can manipulate the nodes it passes (merge, split). 3. Process key
   * function: It must process the leaf and overflow key/OIDs pages where key is/should be found. It can be a read-only
   * function or it can insert/delete/modify the key. */

  /* Reset restart flag. */
  restart = false;
  is_leaf = false;
  search_key->result = BTREE_KEY_NOTFOUND;
  search_key->slotid = NULL_SLOTID;

  /* Make sure current page has been unfixed before restarting traversal. */
  if (crt_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, crt_page);
    }

  /* Fix b-tree root page. */
  if (root_function == NULL)
    {
      /* No root function is provided. Use default function that gets root page and b-tree data
       * (btree_get_root_with_key). */
      root_function = btree_get_root_with_key;
    }
  /* Call root function. */
  error_code =
    root_function (thread_p, btid, btid_int, key, &crt_page, &is_leaf, search_key, &stop, &restart, root_args);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto error;
    }
  if (stop)
    {
      /* Stop condition was met. Do not advance. */
      goto end;
    }
  if (restart)
    {
      /* Restart from top. */
      goto start_btree_traversal;
    }
  /* Root page must be fixed. */
  assert (crt_page != NULL);

  /* Advance until leaf page is found. */
  while (!is_leaf)
    {
      /* Call advance function. */
      error_code =
	advance_function (thread_p, btid_int, key, &crt_page, &advance_page, &is_leaf, search_key, &stop, &restart,
			  advance_args);
      if (error_code != NO_ERROR)
	{
	  /* Error! */
	  ASSERT_ERROR ();
	  goto error;
	}
      if (stop)
	{
	  /* Stop search here */
	  goto end;
	}
      if (restart)
	{
	  /* Search must be restarted from top. */
	  if (advance_page != NULL)
	    {
	      pgbuf_unfix_and_init (thread_p, advance_page);
	    }
	  goto start_btree_traversal;
	}

      /* Advance if not leaf. */
      if (!is_leaf)
	{
	  /* Free current node page and set advance_page as current. */
	  assert (advance_page != NULL);
	  if (crt_page != NULL)
	    {
	      pgbuf_unfix (thread_p, crt_page);
	    }
	  crt_page = advance_page;
	  advance_page = NULL;
	}
    }

  /* Leaf page is reached. */

  assert (is_leaf && !stop && !restart);
  assert (crt_page != NULL);
  assert (btree_get_node_header (thread_p, crt_page) != NULL
	  && btree_get_node_header (thread_p, crt_page)->node_level == 1);

  if (key_function != NULL)
    {
      /* Call key_function. */
      /* Key args must be also provided. */
      assert (process_key_args != NULL);
      error_code = key_function (thread_p, btid_int, key, &crt_page, search_key, &restart, process_key_args);
      if (error_code != NO_ERROR)
	{
	  /* Error! */
	  ASSERT_ERROR ();
	  goto error;
	}
      if (restart)
	{
	  /* Search must be restarted. */
	  goto start_btree_traversal;
	}
    }

  /* Finished */

end:
  /* Safe guard: don't leak fixed pages. */
  assert (advance_page == NULL);

  if (is_leaf && leaf_page_ptr != NULL)
    {
      /* Output leaf page. */
      *leaf_page_ptr = crt_page;
    }
  else if (crt_page != NULL)
    {
      /* Unfix leaf page. */
      pgbuf_unfix (thread_p, crt_page);
    }
  return NO_ERROR;

error:
  /* Error! */
  /* Unfix all used pages. */
  if (crt_page != NULL)
    {
      pgbuf_unfix (thread_p, crt_page);
    }
  if (advance_page != NULL)
    {
      pgbuf_unfix (thread_p, advance_page);
    }
  assert (error_code != NO_ERROR);
  ASSERT_ERROR ();
  return error_code;
}

/*
 * btree_get_root_with_key () - BTREE_ROOT_WITH_KEY_FUNCTION used by default to read root page header and get b-tree
 * 				data from header.
 *
 * return	       : Error code.
 * thread_p (in)       : Thread entry.
 * btid (in)	       : B-tree identifier.
 * btid_int (out)      : BTID_INT (B-tree data).
 * key (in)	       : Key value.
 * root_page (out)     : Output b-tree root page.
 * is_leaf (out)       : Output true if root is leaf page.
 * search_key (out)    : Output key search result (if root is also leaf).
 * stop (out)	       : Output true if advancing in b-tree should stop.
 * restart (out)       : Output true if advancing in b-tree should be restarted.
 * other_args (in/out) : BTREE_ROOT_WITH_KEY_ARGS (outputs BTID_INT).
 */
static int
btree_get_root_with_key (THREAD_ENTRY * thread_p, BTID * btid, BTID_INT * btid_int, DB_VALUE * key,
			 PAGE_PTR * root_page, bool * is_leaf, BTREE_SEARCH_KEY_HELPER * search_key, bool * stop,
			 bool * restart, void *other_args)
{
  BTREE_ROOT_HEADER *root_header = NULL;
  int error_code = NO_ERROR;

  /* Assert expected arguments. */
  assert (btid != NULL);
  assert (key != NULL);
  assert (root_page != NULL && *root_page == NULL);
  assert (is_leaf != NULL);
  assert (search_key != NULL);

  bool reuse_btid_int = other_args ? *((bool *) other_args) : false;

  /* Get root page and BTID_INT. */
  *root_page =
    btree_fix_root_with_info (thread_p, btid, PGBUF_LATCH_READ, NULL, &root_header, (reuse_btid_int ? NULL : btid_int));
  if (*root_page == NULL)
    {
      /* Error! */
      ASSERT_ERROR_AND_SET (error_code);
      return error_code;
    }
  assert (btid_int != NULL);

  if (DB_VALUE_TYPE (key) == DB_TYPE_MIDXKEY && key->data.midxkey.domain == NULL)
    {
      /* Use domain from b-tree info. */
      key->data.midxkey.domain = btid_int->key_type;
    }

  *is_leaf = (root_header->node.node_level == 1);
  if (*is_leaf)
    {
      /* Check if key is found in page. */
      error_code = btree_search_leaf_page (thread_p, btid_int, *root_page, key, search_key);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return error_code;
	}
    }
  /* Success. */
  return NO_ERROR;
}

/*
 * btree_advance_and_find_key () - Fix next node in b-tree following given key.
 *				   If argument is leaf-node, return if key is found and the slot if key instead.
 *
 * return		 : Error code.
 * thread_p (in)	 : Thread entry.
 * btid_int (in)	 : B-tree data.
 * key (in)		 : Search key value.
 * crt_page (in)	 : Page of current node.
 * advance_to_page (out) : Fixed page of child node found by following key.
 * is_leaf (out)	 : Output true if current page is leaf node.
 * key_slotid (out)	 : Output slotid of key if found, otherwise NULL_SLOTID.
 * stop (out)		 : Output true if advancing in b-tree should be stopped.
 * restart (out)	 : Output true if advancing in b-tree should be restarted from top.
 * other_args (in/out)	 : Not used.
 */
static int
btree_advance_and_find_key (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key, PAGE_PTR * crt_page,
			    PAGE_PTR * advance_to_page, bool * is_leaf, BTREE_SEARCH_KEY_HELPER * search_key,
			    bool * stop, bool * restart, void *other_args)
{
  BTREE_NODE_HEADER *node_header;
  BTREE_NODE_TYPE node_type;
  VPID child_vpid;
  int error_code;

  assert (btid_int != NULL);
  assert (key != NULL);
  assert (crt_page != NULL && *crt_page != NULL);
  assert (advance_to_page != NULL && *advance_to_page == NULL);
  assert (search_key != NULL);

  /* Get node header. */
  node_header = btree_get_node_header (thread_p, *crt_page);
  if (node_header == NULL)
    {
      assert_release (false);
      return ER_FAILED;
    }
  node_type = node_header->node_level > 1 ? BTREE_NON_LEAF_NODE : BTREE_LEAF_NODE;

  if (node_type == BTREE_LEAF_NODE)
    {
      /* Leaf level was reached, stop advancing. */
      *is_leaf = true;

      /* Is key in page */
      error_code = btree_search_leaf_page (thread_p, btid_int, *crt_page, key, search_key);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return error_code;
	}

      /* Make sure slot ID is set if key was found. */
      assert (search_key->result != BTREE_KEY_FOUND || search_key->slotid != NULL_SLOTID);
    }
  else
    {
      /* Non-leaf page. */
      *is_leaf = false;

      error_code = btree_search_nonleaf_page (thread_p, btid_int, *crt_page, key, &search_key->slotid, &child_vpid,
					      NULL);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return error_code;
	}

      /* Advance to child. */
      assert (!VPID_ISNULL (&child_vpid));
      *advance_to_page = pgbuf_fix (thread_p, &child_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
      if (*advance_to_page == NULL)
	{
	  /* Error fixing child. */
	  ASSERT_ERROR_AND_SET (error_code);
	  return error_code;
	}
    }

  /* Success. */
  return NO_ERROR;
}

/*
 * btree_key_find_unique_version_oid () - Find the visible object version from key. Since the index is unique,
 *					  there must be at most one visible version.
 *
 * return	       : Error code.
 * thread_p (in)       : Thread entry.
 * btid_int (in)       : B-tree info.
 * key (in)	       : Key value.
 * leaf_page (in/out)  : Leaf page pointer.
 * search_key (in)     : Search key result.
 * restart (out)       : Set to true if index must be traversed again from root node.
 * other_args (in/out) : BTREE_FIND_UNIQUE_HELPER *.
 */
static int
btree_key_find_unique_version_oid (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key, PAGE_PTR * leaf_page,
				   BTREE_SEARCH_KEY_HELPER * search_key, bool * restart, void *other_args)
{
  RECDES record;		/* Key record (leaf or overflow). */
  LEAF_REC leaf_info;		/* Leaf record info (key_len & ovfl). */
  int error_code = NO_ERROR;	/* Error code. */
  int offset;			/* Offset in record data where key is ended and OID list is started. */
  /* Helper used to process record and find visible object. */
  BTREE_REC_SATISFIES_SNAPSHOT_HELPER rec_process_helper = BTREE_REC_SATISFIES_SNAPSHOT_HELPER_INITIALIZER;
  /* Helper used to describe find unique process and to output results. */
  BTREE_FIND_UNIQUE_HELPER *find_unique_helper = (BTREE_FIND_UNIQUE_HELPER *) other_args;
  OID unique_oid = OID_INITIALIZER;	/* OID of unique object. */
  bool clear_key = false;	/* Clear key */

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (key != NULL);
  assert (leaf_page != NULL && *leaf_page != NULL);
  assert (find_unique_helper != NULL);

  PERF_UTIME_TRACKER_TIME (thread_p, &find_unique_helper->time_track, PSTAT_BT_TRAVERSE);
  PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, &find_unique_helper->time_track, PSTAT_BT_FIND_UNIQUE_TRAVERSE);

  /* Initialize find unique helper. */
  find_unique_helper->found_object = false;

  /* Normally, this function should be called only on unique indexes. However there are some exceptions in catalog
   * classes (e.g. db_user, db_class) that have alternative mechanisms to ensure unicity. They still call find unique
   * on index to quickly get OID with name. This function does work for these cases. So, asserting index is unique is
   * not necessary here. */

  if (search_key->result != BTREE_KEY_FOUND)
    {
      /* Key was not found. */
      return NO_ERROR;
    }

  /* Find unique visible object version. Since the index is unique, there can only be one visible version in the key.
   * Parse all key objects until the one visible to current transaction is found. NOTE: The newest object version in
   * the key is always kept first. This is also usually the object being manipulated by running transactions.  However,
   * this isn't always the visible object for current transaction. The visible version for current transaction may be
   * deleted by another, but still visible due to snapshot. */

  /* Get key leaf record. */
  if (spage_get_record (thread_p, *leaf_page, search_key->slotid, &record, PEEK) != S_SUCCESS)
    {
      /* Unexpected error. */
      assert_release (false);
      return ER_FAILED;
    }
  /* Read key leaf record. */
  error_code =
    btree_read_record (thread_p, btid_int, *leaf_page, &record, NULL, &leaf_info, BTREE_LEAF_NODE, &clear_key, &offset,
		       PEEK_KEY_VALUE, NULL);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      return error_code;
    }

  /* Initialize the helper for btree_record_satisfies_snapshot. */
  /* OID buffer. Only one OID will be copied. */
  rec_process_helper.oid_ptr = &unique_oid;
  rec_process_helper.oid_capacity = 1;
  /* MVCC snapshot. */
  rec_process_helper.snapshot = find_unique_helper->snapshot;

  /* Match class OID. */
  COPY_OID (&rec_process_helper.match_class_oid, &find_unique_helper->match_class_oid);

  /* Call btree_record_satisfies_snapshot on each object found in key. */
  error_code =
    btree_key_process_objects (thread_p, btid_int, &record, offset, &leaf_info, btree_record_satisfies_snapshot,
			       &rec_process_helper);
  if (error_code != NO_ERROR)
    {
      /* Error! */
      ASSERT_ERROR ();
      return error_code;
    }
  if (rec_process_helper.oid_cnt > 0)
    {
      /* Found visible object. */
      assert (rec_process_helper.oid_cnt == 1);
      assert (!OID_ISNULL (&unique_oid));
      find_unique_helper->found_object = true;
      COPY_OID (&find_unique_helper->oid, &unique_oid);
    }

  PERF_UTIME_TRACKER_TIME (thread_p, &find_unique_helper->time_track, PSTAT_BT_LEAF);
  PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, &find_unique_helper->time_track, PSTAT_BT_FIND_UNIQUE);
  return NO_ERROR;
}

/*
 * btree_key_find_and_lock_unique () - Find key and lock its unique non-dirty version.
 *
 * return	       : Error code.
 * thread_p (in)       : Thread entry.
 * btid_int (in)       : B-tree info.
 * key (in)	       : Key value.
 * leaf_page (in/out)  : Leaf node page (where key would normally belong).
 * search_key (in)     : Search key result.
 * restart (out)       : Set to true if b-tree traversal must be restarted from root.
 * other_args (in/out) : BTREE_FIND_UNIQUE_HELPER *.
 */
static int
btree_key_find_and_lock_unique (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key, PAGE_PTR * leaf_page,
				BTREE_SEARCH_KEY_HELPER * search_key, bool * restart, void *other_args)
{
  if (BTREE_IS_UNIQUE (btid_int->unique_pk))
    {
      return btree_key_find_and_lock_unique_of_unique (thread_p, btid_int, key, leaf_page, search_key, restart,
						       other_args);
    }
  else
    {
      return btree_key_find_and_lock_unique_of_non_unique (thread_p, btid_int, key, leaf_page, search_key, restart,
							   other_args);
    }
}

/*
 * btree_key_find_and_lock_unique_of_unique () - Find key and lock its first object (if not deleted or dirty).
 *
 * return	       : Error code.
 * thread_p (in)       : Thread entry.
 * btid_int (in)       : B-tree info.
 * key (in)	       : Key value.
 * leaf_page (in/out)  : Leaf node page (where key would normally belong).
 * search_key (in)     : Search key result.
 * restart (out)       : Set to true if b-tree traversal must be restarted from root.
 * other_args (in/out) : BTREE_FIND_UNIQUE_HELPER *.
 */
static int
btree_key_find_and_lock_unique_of_unique (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
					  PAGE_PTR * leaf_page, BTREE_SEARCH_KEY_HELPER * search_key, bool * restart,
					  void *other_args)
{
  OID unique_oid, unique_class_oid;	/* Unique object OID and class OID. */
  /* Unique object MVCC info. */
  BTREE_MVCC_INFO mvcc_info = BTREE_MVCC_INFO_INITIALIZER;
  /* Converted from b-tree MVCC info to check if object satisfies delete. */
  MVCC_REC_HEADER mvcc_header = MVCC_REC_HEADER_INITIALIZER;
  /* Helper used to describe find unique process and to output results. */
  BTREE_FIND_UNIQUE_HELPER *find_unique_helper = NULL;
  RECDES record;		/* Key leaf record. */
  int error_code = NO_ERROR;	/* Error code. */
  MVCC_SATISFIES_DELETE_RESULT satisfies_delete;	/* Satisfies delete result. */
#if defined (SERVER_MODE)
  /* Next variables are not required for stand-alone mode. */
  bool try_cond_lock = false;	/* Try conditional lock. */
  bool was_page_refixed = false;	/* Set to true if conditional lock failed and page had to be re-fixed. */
#endif /* SERVER_MODE */

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (BTREE_IS_UNIQUE (btid_int->unique_pk));
  assert (key != NULL);
  assert (leaf_page != NULL && *leaf_page != NULL);
  assert (restart != NULL);
  assert (other_args != NULL);

  /* other_args is find unique helper. */
  find_unique_helper = (BTREE_FIND_UNIQUE_HELPER *) other_args;

  PERF_UTIME_TRACKER_TIME (thread_p, &find_unique_helper->time_track, PSTAT_BT_TRAVERSE);
  PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, &find_unique_helper->time_track, PSTAT_BT_FIND_UNIQUE_TRAVERSE);

  /* Locking is required. */
  assert (find_unique_helper->lock_mode >= S_LOCK);

  /* Assume result is BTREE_KEY_NOTFOUND. It will be set to BTREE_KEY_FOUND if key is found and its first object is
   * successfully locked. */
  find_unique_helper->found_object = false;

  if (search_key->result != BTREE_KEY_FOUND)
    {
      /* Key doesn't exist. Exit. */
      goto error_or_not_found;
    }

  /* Lock key non-dirty version to protect it. Non-dirty or newest key version is always kept first. Locking object is
   * possible if object is not deleted and it is not dirty (its inserter/deleter is not active). If inserter or
   * deleter is active, or if conditional lock on object failed, current transaction must suspend until the object lock
   * holder is completed. This also means unfixing leaf page first. Current algorithm tries to avoid traversing the
   * b-tree back from root after resume. If conditional lock on object fails, leaf node must be unfixed and then fixed
   * again after object is locked. If page no longer exists or if the page is no longer usable (key is not in page),
   * the process is restarted (while holding the lock however). NOTE: Stand-alone mode doesn't require locking. It
   * should only check whether the first key object is deleted or not. */

  /* Initialize unique_oid */
  OID_SET_NULL (&unique_oid);

  /* Loop until first object is successfully locked or until it is found as deleted. */
  while (true)
    {
      /* Safe guard: leaf node page must be fixed. */
      assert (*leaf_page != NULL);

      /* Get key record. */
      if (spage_get_record (thread_p, *leaf_page, search_key->slotid, &record, PEEK) != S_SUCCESS)
	{
	  /* Unexpected error. */
	  assert (false);
	  er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_GENERIC_ERROR, 0);
	  error_code = ER_FAILED;
	  goto error_or_not_found;
	}
      /* Get first object */
      error_code = btree_leaf_get_first_object (btid_int, &record, &unique_oid, &unique_class_oid, &mvcc_info);
      if (error_code != NO_ERROR)
	{
	  /* Error! */
	  ASSERT_ERROR ();
	  goto error_or_not_found;
	}

      if (!OID_ISNULL (&find_unique_helper->match_class_oid)
	  && !OID_EQ (&find_unique_helper->match_class_oid, &unique_class_oid))
	{
	  /* Class OID didn't match. */
	  /* Consider key not found. */
	  goto error_or_not_found;
	}

#if defined (SERVER_MODE)
      /* Did we already lock an object and was the object changed? If so, unlock it. */
      if (!OID_ISNULL (&find_unique_helper->locked_oid) && !OID_EQ (&find_unique_helper->locked_oid, &unique_oid))
	{
	  lock_unlock_object_donot_move_to_non2pl (thread_p, &find_unique_helper->locked_oid,
						   &find_unique_helper->locked_class_oid,
						   find_unique_helper->lock_mode);
	  OID_SET_NULL (&find_unique_helper->locked_oid);
	}
#endif /* SERVER_MODE */

      /* Check whether object can be locked. */
      btree_mvcc_info_to_heap_mvcc_header (&mvcc_info, &mvcc_header);
      satisfies_delete = mvcc_satisfies_delete (thread_p, &mvcc_header);
      switch (satisfies_delete)
	{
	case DELETE_RECORD_INSERT_IN_PROGRESS:
	case DELETE_RECORD_DELETE_IN_PROGRESS:
#if defined (SA_MODE)
	  /* Impossible. */
	  assert_release (false);
	  error_code = ER_FAILED;
	  goto error_or_not_found;
#else	/* !SA_MODE */	       /* SERVER_MODE */
	  /* Object is being inserted/deleted. We need to lock and suspend until it's fate is decided. */
	  assert (!lock_has_lock_on_object (&unique_oid, &unique_class_oid, find_unique_helper->lock_mode));
#endif /* SERVER_MODE */
	  /* Fall through. */
	case DELETE_RECORD_CAN_DELETE:
#if defined (SERVER_MODE)
	  /* Must lock object. */
	  if (!OID_ISNULL (&find_unique_helper->locked_oid))
	    {
	      /* Object already locked. */
	      /* Safe guard. */
	      assert (OID_EQ (&find_unique_helper->locked_oid, &unique_oid));
	      assert (satisfies_delete == DELETE_RECORD_CAN_DELETE);

	      /* Return result. */
	      COPY_OID (&find_unique_helper->oid, &unique_oid);
	      find_unique_helper->found_object = true;
	      return NO_ERROR;
	    }
	  /* Don't try conditional lock if DELETE_RECORD_INSERT_IN_PROGRESS or DELETE_RECORD_DELETE_IN_PROGRESS. Most likely it will
	   * fail. */
	  try_cond_lock = (satisfies_delete == DELETE_RECORD_CAN_DELETE);
	  /* Lock object. */
	  error_code =
	    btree_key_lock_object (thread_p, btid_int, key, leaf_page, NULL, &unique_oid, &unique_class_oid,
				   find_unique_helper->lock_mode, search_key, try_cond_lock, restart,
				   &was_page_refixed);
	  if (error_code != NO_ERROR)
	    {
	      ASSERT_ERROR ();
	      goto error_or_not_found;
	    }
	  /* Object locked. */
	  assert (lock_has_lock_on_object (&unique_oid, &unique_class_oid, find_unique_helper->lock_mode) > 0);
	  COPY_OID (&find_unique_helper->locked_oid, &unique_oid);
	  COPY_OID (&find_unique_helper->locked_class_oid, &unique_class_oid);
	  if (*restart)
	    {
	      /* Need to restart from top. */
	      return NO_ERROR;
	    }
	  if (search_key->result == BTREE_KEY_BETWEEN)
	    {
	      /* Key no longer exist. */
	      goto error_or_not_found;
	    }
	  assert (search_key->result == BTREE_KEY_FOUND);
	  if (was_page_refixed)
	    {
	      /* Key was found but we still need to re-check first object. Since page was re-fixed, it may have
	       * changed. */
	      break;		/* switch (satisfies_delete) */
	    }
	  else
	    {
	      /* Safe guard */
	      assert (satisfies_delete == DELETE_RECORD_CAN_DELETE);
	    }
#endif /* SERVER_MODE */

	  /* Object was found. Return result. */
	  COPY_OID (&find_unique_helper->oid, &unique_oid);
	  find_unique_helper->found_object = true;
	  return NO_ERROR;

	case DELETE_RECORD_DELETED:
	case DELETE_RECORD_SELF_DELETED:
	  /* Key object is deleted. */
	  goto error_or_not_found;

	default:
	  /* Unhandled/unexpected case. */
	  assert_release (false);
	  error_code = ER_FAILED;
	  goto error_or_not_found;
	}			/* switch (satisfies_delete) */
    }
  /* Impossible to reach. Loop can only be broken by returns or jumps to error_or_not_found label. */
  assert_release (false);
  error_code = ER_FAILED;
  /* Fall through. */

error_or_not_found:
  assert (find_unique_helper->found_object == false);

#if defined (SERVER_MODE)
  if (!OID_ISNULL (&find_unique_helper->locked_oid))
    {
      /* Unlock object. */
      lock_unlock_object_donot_move_to_non2pl (thread_p, &find_unique_helper->locked_oid,
					       &find_unique_helper->locked_class_oid, find_unique_helper->lock_mode);
      OID_SET_NULL (&find_unique_helper->locked_oid);
    }
#endif

  PERF_UTIME_TRACKER_TIME (thread_p, &find_unique_helper->time_track, PSTAT_BT_LEAF);
  PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, &find_unique_helper->time_track, PSTAT_BT_FIND_UNIQUE);
  return error_code;
}

/*
 * btree_key_find_and_lock_unique_of_non_unique () - Find key non-dirty version and lock it.
 *						     This is usually called in indexes of system classes
 *						     that should be unique but are not.
 *
 * return	       : Error code.
 * thread_p (in)       : Thread entry.
 * btid_int (in)       : B-tree info.
 * key (in)	       : Key value.
 * leaf_page (in/out)  : Leaf node page (where key would normally belong).
 * search_key (in)     : Search key result.
 * restart (out)       : Set to true if b-tree traversal must be restarted from root.
 * other_args (in/out) : BTREE_FIND_UNIQUE_HELPER *.
 */
static int
btree_key_find_and_lock_unique_of_non_unique (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
					      PAGE_PTR * leaf_page, BTREE_SEARCH_KEY_HELPER * search_key,
					      bool * restart, void *other_args)
{
  OID unique_oid, unique_class_oid;	/* Unique object OID and class OID. */
  /* Unique object MVCC info. */
  BTREE_MVCC_INFO mvcc_info = BTREE_MVCC_INFO_INITIALIZER;
  /* Converted from b-tree MVCC info to check if object satisfies delete. */
  MVCC_REC_HEADER mvcc_header = MVCC_REC_HEADER_INITIALIZER;
  /* Helper used to describe find unique process and to output results. */
  BTREE_FIND_UNIQUE_HELPER *find_unique_helper = NULL;
  RECDES record;		/* Key leaf record. */
  int error_code = NO_ERROR;	/* Error code. */
  MVCC_SATISFIES_DELETE_RESULT satisfies_delete;	/* Satisfies delete result. */
  PAGE_PTR overflow_page = NULL;	/* Overflow page. */
  VPID next_overflow_vpid = VPID_INITIALIZER;	/* VPID of next overflow page. */
  OR_BUF buf;			/* Buffer used to read b-tree records. */
  bool start_reading_leaf_record = true;	/* Set to true when needs to start reading from first leaf object. */
  PAGE_PTR prev_overflow_page = NULL;	/* Saved pointer to previous overflow page when next is fixed. */
  int offset_after_key = 0;	/* For leaf record, offset where packed key is ended. */
  BTREE_NODE_TYPE node_type;	/* Current node type. */
  LEAF_REC leaf_rec_info;	/* Leaf record info. */
  bool dummy_clear_key;		/* Dummy. */
#if defined (SERVER_MODE)
  /* Next variables are not required for stand-alone mode. */
  bool try_cond_lock = false;	/* Try conditional lock. */
  bool was_page_refixed = false;	/* Set to true if conditional lock failed and page had to be re-fixed. */
#endif /* SERVER_MODE */
  PERF_UTIME_TRACKER ovf_fix_time_track;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (!BTREE_IS_UNIQUE (btid_int->unique_pk));
  assert (key != NULL);
  assert (leaf_page != NULL && *leaf_page != NULL);
  assert (restart != NULL);
  assert (other_args != NULL);

  /* other_args is find unique helper. */
  find_unique_helper = (BTREE_FIND_UNIQUE_HELPER *) other_args;

  PERF_UTIME_TRACKER_TIME (thread_p, &find_unique_helper->time_track, PSTAT_BT_TRAVERSE);
  PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, &find_unique_helper->time_track, PSTAT_BT_FIND_UNIQUE_TRAVERSE);

  /* Locking is required. */
  assert (find_unique_helper->lock_mode >= S_LOCK);

  /* Assume result is BTREE_KEY_NOTFOUND. It will be set to BTREE_KEY_FOUND if key is found and its first object is
   * successfully locked. */
  find_unique_helper->found_object = false;

  if (search_key->result != BTREE_KEY_FOUND)
    {
      /* Key doesn't exist. Exit. */
      goto error_or_not_found;
    }

  /* Lock key non-dirty version to protect it. Since this is not an unique index, but can have only one non-dirty
   * version, this must be searched through the leaf/overflow records. Locking object is possible if object is not
   * deleted and it is not dirty (its inserter/deleter is not active). If inserter or deleter is active, or if
   * conditional lock on object failed, current transaction must suspend until the object lock holder is completed.
   * This also means unfixing leaf/overflow pages first. Current algorithm tries to avoid traversing the b-tree back
   * from root after resume. If conditional lock on object fails, leaf/overflow nodes must be unfixed and then fixed
   * again after object is locked. If leaf page no longer exists or if the page is no longer usable (key is not in
   * page), the process is restarted from root. If leaf page is still valid, leaf/overflow records are processed again.
   * NOTE: Stand-alone mode doesn't require locking. It should only check whether the first key object is deleted or not. */

  /* Initialize unique_oid */
  OID_SET_NULL (&unique_oid);
  OID_SET_NULL (&unique_class_oid);

  /* Loop until a visible object is successfully locked or if the entire key is processed. */
  while (true)
    {
      /* Safe guard: leaf node page must be fixed. */
      assert (*leaf_page != NULL);

      if (start_reading_leaf_record)
	{
	  /* Read leaf record. */
	  if (spage_get_record (thread_p, *leaf_page, search_key->slotid, &record, PEEK) != S_SUCCESS)
	    {
	      assert_release (false);
	      error_code = ER_FAILED;
	      goto error_or_not_found;
	    }
	  node_type = BTREE_LEAF_NODE;
	  error_code =
	    btree_read_record (thread_p, btid_int, *leaf_page, &record, NULL, &leaf_rec_info, node_type,
			       &dummy_clear_key, &offset_after_key, PEEK_KEY_VALUE, NULL);
	  if (error_code != NO_ERROR)
	    {
	      ASSERT_ERROR ();
	      goto error_or_not_found;
	    }
	  /* Get first overflow vpid. */
	  VPID_COPY (&next_overflow_vpid, &leaf_rec_info.ovfl);
	  /* Initialize buffer to read from record. */
	  BTREE_RECORD_OR_BUF_INIT (buf, &record);
	  /* Get first object. */
	  error_code =
	    btree_or_get_object (&buf, btid_int, node_type, offset_after_key, &unique_oid, &unique_class_oid,
				 &mvcc_info);
	  if (error_code != NO_ERROR)
	    {
	      ASSERT_ERROR ();
	      goto error_or_not_found;
	    }
	  start_reading_leaf_record = false;
	}
      else
	{
	  /* Get next object. */

	  if (buf.ptr == buf.endptr)
	    {
	      /* Processed all objects in this record. */
	      if (VPID_ISNULL (&next_overflow_vpid))
		{
		  /* Not other overflow pages. Not found. */
		  goto error_or_not_found;
		}
	      /* Fix next overflow page. */
	      if (overflow_page != NULL)
		{
		  /* Save this overflow page. */
		  prev_overflow_page = overflow_page;
		}
	      PERF_UTIME_TRACKER_START (thread_p, &ovf_fix_time_track);
	      /* Fix next overflow page. */
	      overflow_page =
		pgbuf_fix (thread_p, &next_overflow_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
	      btree_perf_ovf_oids_fix_time (thread_p, &ovf_fix_time_track);
	      if (overflow_page == NULL)
		{
		  ASSERT_ERROR_AND_SET (error_code);
		  goto error_or_not_found;
		}
	      if (prev_overflow_page != NULL)
		{
		  pgbuf_unfix_and_init (thread_p, prev_overflow_page);
		}
	      /* Now read leaf record. */
	      if (spage_get_record (thread_p, overflow_page, 1, &record, PEEK) != S_SUCCESS)
		{
		  assert_release (false);
		  error_code = ER_FAILED;
		  goto error_or_not_found;
		}
	      /* Initialize buffer to read record. */
	      BTREE_RECORD_OR_BUF_INIT (buf, &record);
	      /* Key is not kept in overflow pages. */
	      offset_after_key = 0;
	      node_type = BTREE_OVERFLOW_NODE;
	      /* Get VPID of next overflow page. */
	      error_code = btree_get_next_overflow_vpid (thread_p, overflow_page, &next_overflow_vpid);
	      if (error_code != NO_ERROR)
		{
		  ASSERT_ERROR ();
		  goto error_or_not_found;
		}
	    }
	  /* Assert there are objects in current record. */
	  assert (buf.ptr < buf.endptr);
	  error_code =
	    btree_or_get_object (&buf, btid_int, node_type, offset_after_key, &unique_oid, &unique_class_oid,
				 &mvcc_info);
	  if (error_code != NO_ERROR)
	    {
	      ASSERT_ERROR ();
	      goto error_or_not_found;
	    }
	}
      /* Safe guard: object was read. */
      assert (!OID_ISNULL (&unique_oid));
      assert (!OID_ISNULL (&unique_class_oid));

      if (!OID_ISNULL (&find_unique_helper->match_class_oid)
	  && !OID_EQ (&find_unique_helper->match_class_oid, &unique_class_oid))
	{
	  /* Class does not match. Try another object. */
	  continue;
	}

      /* Check whether object can be locked. */
      btree_mvcc_info_to_heap_mvcc_header (&mvcc_info, &mvcc_header);
      satisfies_delete = mvcc_satisfies_delete (thread_p, &mvcc_header);
      switch (satisfies_delete)
	{
	case DELETE_RECORD_INSERT_IN_PROGRESS:
	case DELETE_RECORD_DELETE_IN_PROGRESS:
#if defined (SA_MODE)
	  /* Impossible. */
	  assert_release (false);
	  error_code = ER_FAILED;
	  goto error_or_not_found;
#else	/* !SA_MODE */	       /* SERVER_MODE */
	  /* Object is being inserted/deleted. We need to lock and suspend until it's fate is decided. */
	  assert (!lock_has_lock_on_object (&unique_oid, &unique_class_oid, find_unique_helper->lock_mode));
#endif /* SERVER_MODE */
	  /* Fall through. */
	case DELETE_RECORD_CAN_DELETE:
#if defined (SERVER_MODE)
	  /* Must lock object. */
	  if (!OID_ISNULL (&find_unique_helper->locked_oid))
	    {
	      if (OID_EQ (&find_unique_helper->locked_oid, &unique_oid))
		{
		  /* Object already locked. */
		  assert (satisfies_delete == DELETE_RECORD_CAN_DELETE);

		  /* Return result. */
		  COPY_OID (&find_unique_helper->oid, &unique_oid);
		  find_unique_helper->found_object = true;
		  if (overflow_page != NULL)
		    {
		      pgbuf_unfix_and_init (thread_p, overflow_page);
		    }
		  /* Leaf page will be unfixed by caller. */
		  return NO_ERROR;
		}
	      else
		{
		  /* Unlock object. */
		  lock_unlock_object_donot_move_to_non2pl (thread_p, &find_unique_helper->locked_oid,
							   &find_unique_helper->locked_class_oid,
							   find_unique_helper->lock_mode);
		  OID_SET_NULL (&find_unique_helper->locked_oid);
		}
	    }
	  /* Don't try conditional lock if DELETE_RECORD_INSERT_IN_PROGRESS or DELETE_RECORD_DELETE_IN_PROGRESS.
	   * Most likely it will fail. */
	  try_cond_lock = (satisfies_delete == DELETE_RECORD_CAN_DELETE);
	  /* Lock object. */
	  error_code =
	    btree_key_lock_object (thread_p, btid_int, key, leaf_page, &overflow_page, &unique_oid, &unique_class_oid,
				   find_unique_helper->lock_mode, search_key, try_cond_lock, restart,
				   &was_page_refixed);
	  if (error_code != NO_ERROR)
	    {
	      ASSERT_ERROR ();
	      goto error_or_not_found;
	    }
	  /* Object locked. */
	  assert (lock_has_lock_on_object (&unique_oid, &unique_class_oid, find_unique_helper->lock_mode) > 0);
	  COPY_OID (&find_unique_helper->locked_oid, &unique_oid);
	  COPY_OID (&find_unique_helper->locked_class_oid, &unique_class_oid);
	  if (*restart)
	    {
	      /* Need to restart from top. */
	      assert (overflow_page == NULL);
	      return NO_ERROR;
	    }
	  if (search_key->result == BTREE_KEY_BETWEEN)
	    {
	      /* Key no longer exist. */
	      goto error_or_not_found;
	    }
	  assert (search_key->result == BTREE_KEY_FOUND);
	  if (was_page_refixed)
	    {
	      /* Key was found but we still need to re-check objects. Since page was re-fixed, record may have changed
	       * (and also positions of objects). */
	      start_reading_leaf_record = true;
	      was_page_refixed = false;
	      /* Safe guard: overflow page must be unfixed. */
	      assert (overflow_page == NULL);
	      break;		/* switch (satisfies_delete) */
	    }
	  else
	    {
	      /* Safe guard */
	      assert (satisfies_delete == DELETE_RECORD_CAN_DELETE);
	    }
#endif /* SERVER_MODE */

	  /* Object was found. Return result. */
	  COPY_OID (&find_unique_helper->oid, &unique_oid);
	  find_unique_helper->found_object = true;
	  if (overflow_page != NULL)
	    {
	      pgbuf_unfix_and_init (thread_p, overflow_page);
	    }
	  /* Leaf page will be unfixed by caller. */
	  return NO_ERROR;

	case DELETE_RECORD_DELETED:
	case DELETE_RECORD_SELF_DELETED:
	  /* This object is deleted. */
	  /* Continue to next object. */
	  break;

	default:
	  /* Unhandled/unexpected case. */
	  assert_release (false);
	  error_code = ER_FAILED;
	  goto error_or_not_found;
	}			/* switch (satisfies_delete) */
    }
  /* Impossible to reach. Loop can only be broken by returns or jumps to error_or_not_found label. */
  assert_release (false);
  error_code = ER_FAILED;
  /* Fall through. */

error_or_not_found:
  assert (find_unique_helper->found_object == false);

  if (overflow_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, overflow_page);
    }
  if (prev_overflow_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, prev_overflow_page);
    }

#if defined (SERVER_MODE)
  if (!OID_ISNULL (&find_unique_helper->locked_oid))
    {
      /* Unlock object. */
      lock_unlock_object_donot_move_to_non2pl (thread_p, &find_unique_helper->locked_oid,
					       &find_unique_helper->locked_class_oid, find_unique_helper->lock_mode);
      OID_SET_NULL (&find_unique_helper->locked_oid);
    }
#endif

  PERF_UTIME_TRACKER_TIME (thread_p, &find_unique_helper->time_track, PSTAT_BT_LEAF);
  PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, &find_unique_helper->time_track, PSTAT_BT_FIND_UNIQUE);

  return error_code;
}

#if defined (SERVER_MODE)
/*
 * btree_key_lock_object () - Lock object when its leaf page is held.
 *
 * return		  : Error code.
 * thread_p (in)	  : Thread entry.
 * btid_int (in)	  : B-tree identifier.
 * key (in)		  : Key.
 * leaf_page (in/out)     : Pointer to leaf node page.
 * overflow_page (in/out) : Pointer to fixed overflow page. If leaf page must be unfixed, this will be unfixed too
 * 			    (without fixing it again).
 * oid (in)		  : OID of object to lock.
 * class_oid (in)	  : Class OID of object to lock.
 * lock_mode (in)	  : Lock mode.
 * search_key (in.out)	  : Search key result. Can change if page is unfixed.
 * try_cond_lock (in)	  : True to try conditional lock first. If false, page is unfixed directly.
 * restart (out)	  : Outputs true when page had to be unfixed and was not considered valid to be reused.
 * was_page_refixed (out) : Outputs true if page had to be unfixed.
 *
 * TODO: Extend this function to handle overflow OID's page too.
 */
static int
btree_key_lock_object (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key, PAGE_PTR * leaf_page,
		       PAGE_PTR * overflow_page, OID * oid, OID * class_oid, LOCK lock_mode,
		       BTREE_SEARCH_KEY_HELPER * search_key, bool try_cond_lock, bool * restart,
		       bool * was_page_refixed)
{
  VPID leaf_vpid;		/* VPID of leaf page. */
  int lock_result;		/* Result of tried locks. */
  int error_code = NO_ERROR;	/* Error code. */
  PGBUF_LATCH_MODE latch_mode;	/* Leaf page latch mode. */
  LOG_LSA page_lsa;		/* Leaf page LSA before is unfixed. */
  PERF_UTIME_TRACKER lock_time_track;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (key != NULL && !DB_IS_NULL (key) && !btree_multicol_key_is_null (key));
  assert (leaf_page != NULL && *leaf_page != NULL);
  assert (oid != NULL && !OID_ISNULL (oid));
  assert (class_oid != NULL && !OID_ISNULL (class_oid));
  assert (lock_mode >= S_LOCK);
  assert (search_key != NULL && search_key->result == BTREE_KEY_FOUND);

  if (try_cond_lock)
    {
      /* Try conditional lock. */
      lock_result = lock_object (thread_p, oid, class_oid, lock_mode, LK_COND_LOCK);
      if (lock_result == LK_GRANTED)
	{
	  /* Successful locking. */
	  return NO_ERROR;
	}
    }

  /* In order to avoid keeping latched pages while being suspended on locks, leaf page must be unfixed. After lock is
   * obtained, page can be re-fixed and re-used. */
  /* If an overflow page is also fixed, when leaf page is unfixed, overflow page is also unfixed. It is up to the
   * caller to handle re-fix and resume. */
  if (overflow_page != NULL && *overflow_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, *overflow_page);
    }

  /* Save page VPID. */
  pgbuf_get_vpid (*leaf_page, &leaf_vpid);
  assert (!VPID_ISNULL (&leaf_vpid));
  /* Save page LSA. */
  LSA_COPY (&page_lsa, pgbuf_get_lsa (*leaf_page));
  /* Save page latch mode for re-fix. */
  latch_mode = pgbuf_get_latch_mode (*leaf_page);
  /* Unfix page. */
  pgbuf_unfix_and_init (thread_p, *leaf_page);
  if (was_page_refixed != NULL)
    {
      /* Output page was unfixed. */
      *was_page_refixed = true;
    }

  /* Lock object. */
  PERF_UTIME_TRACKER_START (thread_p, &lock_time_track);
  lock_result = lock_object (thread_p, oid, class_oid, lock_mode, LK_UNCOND_LOCK);
  btree_perf_unique_lock_time (thread_p, &lock_time_track, lock_mode);
  if (lock_result != LK_GRANTED)
    {
      ASSERT_ERROR_AND_SET (error_code);
      return error_code;
    }
  /* Lock granted. */

  /* Try to re-fix page. */
  error_code = pgbuf_fix_if_not_deallocated (thread_p, &leaf_vpid, latch_mode, PGBUF_UNCONDITIONAL_LATCH, leaf_page);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto error;
    }
  if (*leaf_page == NULL)
    {
      /* deallocated */
      *restart = true;
      return NO_ERROR;
    }
  /* Page successfully re-fixed. */

  /* Check if page is changed. */
  if (LSA_EQ (&page_lsa, pgbuf_get_lsa (*leaf_page)))
    {
      /* Page not changed. */
      return NO_ERROR;
    }
  /* Page has changed. */

  /* Check if page is still valid for our key. */
  if (!BTREE_IS_PAGE_VALID_LEAF (thread_p, *leaf_page))
    {
      /* Page was deallocated/reused for other purposes. Very unlikely, but had to check. */
      *restart = true;
      return NO_ERROR;
    }

  /* Page is a b-tree leaf. */
  /* Make sure key still belongs to the page. */
  error_code = btree_leaf_is_key_between_min_max (thread_p, btid_int, *leaf_page, key, search_key);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto error;
    }
  if (search_key->result == BTREE_KEY_BETWEEN)
    {
      /* Search key to find slot. */
      error_code = btree_search_leaf_page (thread_p, btid_int, *leaf_page, key, search_key);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto error;
	}
    }
  switch (search_key->result)
    {
    case BTREE_KEY_FOUND:
    case BTREE_KEY_BETWEEN:
      /* Key belongs to this page. */
      return NO_ERROR;
    case BTREE_KEY_SMALLER:
    case BTREE_KEY_NOTFOUND:
    case BTREE_KEY_BIGGER:
      /* Key is no longer in this page. Need to restart. */
      *restart = true;
      return NO_ERROR;
    default:
      /* Unexpected. */
      assert_release (false);
      return ER_FAILED;
    }

  /* Shouldn't be here: Unhandled case. */
  assert_release (false);
  error_code = ER_FAILED;
  /* Fall through. */

error:
  assert (error_code != NO_ERROR);
  ASSERT_ERROR ();

  lock_unlock_object_donot_move_to_non2pl (thread_p, oid, class_oid, lock_mode);
  return error_code;
}
#endif /* SERVER_MODE */

/*
 * btree_record_process_objects () - Generic routine to process the objects of a record (leaf or overflow).
 *
 * return		 : Error code.
 * thread_p (in)	 : Thread entry.
 * btid_int (in)	 : B-tree info.
 * node_type (in)	 : Node type - LEAF or OVERFLOW.
 * record (in)		 : Record descriptor.
 * after_key_offset (in) : Offset in record where key value is ended (for leaf record).
 * func (in)		 : BTREE_PROCESS_OBJECT_FUNCTION *.
 * args (in/out)	 : Arguments for internal function.
 */
static int
btree_record_process_objects (THREAD_ENTRY * thread_p, BTID_INT * btid_int, BTREE_NODE_TYPE node_type, RECDES * record,
			      int after_key_offset, bool * stop, BTREE_PROCESS_OBJECT_FUNCTION * func, void *args)
{
  OR_BUF buffer;		/* Buffer used to process record data. */
  int error_code = NO_ERROR;	/* Error code. */
  char *object_ptr = NULL;	/* Pointer in record data where current object starts. */
  OID oid;			/* OID of current object. */
  OID class_oid;		/* Class OID of current object. */
  BTREE_MVCC_INFO mvcc_info;	/* MVCC info of current object. */

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (node_type == BTREE_LEAF_NODE || node_type == BTREE_OVERFLOW_NODE);
  assert (record != NULL);
  assert (func != NULL);

  /* Initialize buffer. */
  BTREE_RECORD_OR_BUF_INIT (buffer, record);

  /* Loop for all objects in buffer. */
  while (buffer.ptr < buffer.endptr)
    {
      /* Save current object pointer in record data. */
      object_ptr = buffer.ptr;

      /* Get object data: OID, class OID and MVCC info. */
      error_code = btree_or_get_object (&buffer, btid_int, node_type, after_key_offset, &oid, &class_oid, &mvcc_info);
      if (error_code != NO_ERROR)
	{
	  /* Unexpected error. */
	  assert (false);
	  return error_code;
	}

      /* Call internal function. */
      error_code = func (thread_p, btid_int, record, object_ptr, &oid, &class_oid, &mvcc_info, stop, args);
      if (error_code != NO_ERROR)
	{
	  /* Error! */
	  return error_code;
	}

      if (*stop)
	{
	  /* Stop processing the record objects */
	  return NO_ERROR;
	}
    }
  /* Finished processing buffer. */

  /* Safe guard: current pointer should point to expected end of buffer. */
  assert (buffer.ptr == buffer.endptr);

  /* Success. */
  return NO_ERROR;
}

/*
 * btree_key_process_objects () - Generic key processing function that calls given BTREE_PROCESS_OBJECT_FUNCTION function
 *				  on all key objects (unless an error or stop argument forces an early out).
 *
 * return		 : Error code.
 * thread_p (in)	 : Thread entry.
 * btid_int (in)	 : B-tree identifier.
 * leaf_record (in)	 : Leaf record.
 * after_key_offset (in) : Offset to OID list, where packed key is ended.
 * leaf_info (in)	 : Leaf info.
 * func (in)		 : Internal function to process each key object.
 * args (in/out)	 : Arguments for internal function.
 *
 * NOTE: Leaf record of objects must be obtained before calling this function.
 * TODO: Consider using write latch for overflow pages.
 */
static int
btree_key_process_objects (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * leaf_record, int after_key_offset,
			   LEAF_REC * leaf_info, BTREE_PROCESS_OBJECT_FUNCTION * func, void *args)
{
  int error_code = NO_ERROR;
  bool stop = false;
  RECDES peeked_ovf_recdes;
  VPID ovf_vpid;
  PAGE_PTR ovf_page = NULL, prev_ovf_page = NULL;
  PERF_UTIME_TRACKER ovf_fix_time_track;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (leaf_record != NULL);
  assert (leaf_info != NULL);
  assert (func != NULL);

  /* Start by processing leaf record. */
  error_code =
    btree_record_process_objects (thread_p, btid_int, BTREE_LEAF_NODE, leaf_record, after_key_offset, &stop, func,
				  args);
  if (error_code != NO_ERROR || stop)
    {
      /* Error or just stop with NO_ERROR. */
      assert (error_code == NO_ERROR || er_errid () != NO_ERROR);
      return error_code;
    }

  /* Process overflow OID's. */
  VPID_COPY (&ovf_vpid, &leaf_info->ovfl);
  while (!VPID_ISNULL (&ovf_vpid))
    {
      /* Fix overflow page. */
      PERF_UTIME_TRACKER_START (thread_p, &ovf_fix_time_track);
      ovf_page = pgbuf_fix (thread_p, &ovf_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
      btree_perf_ovf_oids_fix_time (thread_p, &ovf_fix_time_track);
      if (ovf_page == NULL)
	{
	  ASSERT_ERROR_AND_SET (error_code);
	  if (prev_ovf_page != NULL)
	    {
	      pgbuf_unfix_and_init (thread_p, prev_ovf_page);
	    }
	  return error_code;
	}
      if (prev_ovf_page != NULL)
	{
	  /* Now unfix previous overflow page. */
	  pgbuf_unfix_and_init (thread_p, prev_ovf_page);
	}
      /* Get overflow OID's record. */
      if (spage_get_record (thread_p, ovf_page, 1, &peeked_ovf_recdes, PEEK) != S_SUCCESS)
	{
	  assert_release (false);
	  pgbuf_unfix_and_init (thread_p, ovf_page);
	  return ER_FAILED;
	}
      /* Call internal function on overflow record. */
      error_code =
	btree_record_process_objects (thread_p, btid_int, BTREE_OVERFLOW_NODE, &peeked_ovf_recdes, 0, &stop, func,
				      args);
      if (error_code != NO_ERROR)
	{
	  /* Error . */
	  ASSERT_ERROR ();
	  pgbuf_unfix_and_init (thread_p, ovf_page);
	  return error_code;
	}
      else if (stop)
	{
	  /* Stop. */
	  pgbuf_unfix_and_init (thread_p, ovf_page);
	  return NO_ERROR;
	}
      /* Get VPID of next overflow page */
      error_code = btree_get_next_overflow_vpid (thread_p, ovf_page, &ovf_vpid);
      if (error_code != NO_ERROR)
	{
	  assert_release (false);
	  pgbuf_unfix_and_init (thread_p, ovf_page);
	  return error_code;
	}
      /* Save overflow page until next one is fixed to protect the link between them. */
      prev_ovf_page = ovf_page;
    }
  /* All objects have been processed. If overflow page is fixed, unfix it. */
  if (ovf_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, ovf_page);
    }
  /* Successfully processed all key objects. */
  return NO_ERROR;
}

/*
 * btree_record_satisfies_snapshot () - BTREE_PROCESS_OBJECT_FUNCTION.
 *					Output visible objects according to snapshot. If snapshot is NULL, all
 *					objects are saved.
 *
 * return	   : Error code.
 * thread_p (in)   : Thread entry.
 * btid_int (in)   : B-tree info.
 * record (in)	   : B-tree leaf/overflow record.
 * object_ptr (in) : Pointer to object in record data.
 * oid (in)	   : Object OID.
 * class_oid (in)  : Object class OID.
 * mvcc_info (in)  : Object MVCC info.
 * stop (out)	   : Set to true if index is unique and visible object is found and if this is not a debug build.
 * args (in/out)   : BTREE_REC_SATISFIES_SNAPSHOT_HELPER *.
 */
static int
btree_record_satisfies_snapshot (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * record, char *object_ptr,
				 OID * oid, OID * class_oid, BTREE_MVCC_INFO * mvcc_info, bool * stop, void *args)
{
  /* Helper used to filter objects and OID's of visible ones. */
  BTREE_REC_SATISFIES_SNAPSHOT_HELPER *helper = NULL;
  MVCC_REC_HEADER mvcc_header_for_snapshot;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (record != NULL);
  assert (object_ptr != NULL);
  assert (oid != NULL);
  assert (class_oid != NULL);
  assert (mvcc_info != NULL);
  assert (stop != NULL);
  assert (args != NULL);

  helper = (BTREE_REC_SATISFIES_SNAPSHOT_HELPER *) args;

  btree_mvcc_info_to_heap_mvcc_header (mvcc_info, &mvcc_header_for_snapshot);
  if (helper->snapshot == NULL
      || helper->snapshot->snapshot_fnc (thread_p, &mvcc_header_for_snapshot, helper->snapshot) == SNAPSHOT_SATISFIED)
    {
      /* Snapshot satisfied or not required. */

      /* If unique index, we may need to match class OID. */
      if (BTREE_IS_UNIQUE (btid_int->unique_pk) && !OID_ISNULL (&helper->match_class_oid)
	  && !OID_EQ (&helper->match_class_oid, class_oid))
	{
	  /* Class OID did not match. Ignore this object. */
	  return NO_ERROR;
	}

      /* Make sure that if this is unique index, only one visible object is found. */
      assert (!BTREE_IS_UNIQUE (btid_int->unique_pk) || helper->oid_cnt == 0);

      if (helper->oid_cnt >= helper->oid_capacity)
	{
	  /* OID buffer is not big enough. There was a mistake estimating the number of objects. */
	  assert (false);
	  er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_GENERIC_ERROR, 0);
	  return ER_FAILED;
	}

      /* Save OID in buffer. */
      memcpy (helper->oid_ptr, oid, sizeof (*oid));
      /* Increment buffer pointer and OID counter. */
      helper->oid_ptr++;
      helper->oid_cnt++;

#if defined (NDEBUG)
      if (BTREE_IS_UNIQUE (btid_int->unique_pk))
	{
	  /* Stop after first visible object. Since this is a unique index, there shouldn't be more than one visible
	   * anyway. */
	  *stop = true;
	  /* Debug doesn't stop. It will continue to check there are no other visible objects. */
	}
#endif
    }

  /* Success */
  return NO_ERROR;
}

/*
 * xbtree_find_unique () - Find (and sometimes lock) object in key of unique index.
 *
 * return		  : BTREE_SEARCH result.
 * thread_p (in)	  : Thread entry.
 * btid (in)		  : B-tree identifier.
 * scan_op_type (in)	  : Operation type (purpose) of finding unique key object.
 * key (in)		  : Key value.
 * class_oid (in)	  : Class OID.
 * oid (out)		  : Found (and sometimes locked) object OID.
 * is_all_class_srch (in) : True if search is based on all classes contained in the class hierarchy.
 */
BTREE_SEARCH
xbtree_find_unique (THREAD_ENTRY * thread_p, BTID * btid, SCAN_OPERATION_TYPE scan_op_type, DB_VALUE * key,
		    OID * class_oid, OID * oid, bool is_all_class_srch)
{
  /* Helper used to describe find unique process and to output results. */
  BTREE_FIND_UNIQUE_HELPER find_unique_helper = BTREE_FIND_UNIQUE_HELPER_INITIALIZER;
  int error_code = NO_ERROR;
  BTREE_ADVANCE_WITH_KEY_FUNCTION *advance_function = btree_advance_and_find_key;
  BTREE_PROCESS_KEY_FUNCTION *key_function = NULL;
  MVCC_SNAPSHOT dirty_snapshot;
#if defined (SERVER_MODE)
  int lock_result;
  LOCK class_lock;
#endif

  /* Assert expected arguments. */
  assert (btid != NULL);
  assert (scan_op_type == S_SELECT || scan_op_type == S_SELECT_WITH_LOCK || scan_op_type == S_DELETE
	  || scan_op_type == S_UPDATE);
  assert (class_oid != NULL && !OID_ISNULL (class_oid));
  assert (oid != NULL);

  PERF_UTIME_TRACKER_START (thread_p, &find_unique_helper.time_track);

  /* Initialize oid as NULL. */
  OID_SET_NULL (oid);

  if (key == NULL || db_value_is_null (key) || btree_multicol_key_is_null (key))
    {
      /* Early out: Consider key is not found. */
      return BTREE_KEY_NOTFOUND;
    }

  if (!is_all_class_srch)
    {
      /* Object class must match class_oid argument. */
      COPY_OID (&find_unique_helper.match_class_oid, class_oid);
    }

#if defined (SERVER_MODE)
  /* Make sure transaction has intention lock on table. */
  class_lock = (scan_op_type == S_SELECT || scan_op_type == S_SELECT_WITH_LOCK) ? IS_LOCK : IX_LOCK;
  lock_result = lock_object (thread_p, class_oid, oid_Root_class_oid, class_lock, LK_UNCOND_LOCK);
  if (lock_result != LK_GRANTED)
    {
      return BTREE_ERROR_OCCURRED;
    }
#endif /* SERVER_MODE */

  if (scan_op_type == S_SELECT)
    {
      /*
       * If MVCC disabled, do not use snapshot and lock. If MVCC enabled and
       * find unique in catalog classes, use dirty version without lock.
       * Otherwise, use dirty version with lock since need to check whether the
       * object exists.
       */
      if (mvcc_is_mvcc_disabled_class (class_oid))
	{
	  find_unique_helper.snapshot = logtb_get_mvcc_snapshot (thread_p);
	  key_function = btree_key_find_unique_version_oid;
	  find_unique_helper.lock_mode = NULL_LOCK;
	}
      else
	{
	  dirty_snapshot.snapshot_fnc = mvcc_satisfies_dirty;
	  find_unique_helper.snapshot = &dirty_snapshot;

	  if (tf_is_catalog_class (class_oid))
	    {
	      /* find the key without lock */
	      key_function = btree_key_find_unique_version_oid;
	      find_unique_helper.lock_mode = NULL_LOCK;
	    }
	  else
	    {
	      /* find the key with lock */
	      key_function = btree_key_find_and_lock_unique;
	      find_unique_helper.lock_mode = S_LOCK;
	      scan_op_type = S_SELECT_WITH_LOCK;
	    }
	}
    }
  else
    {
      /* S_SELECT_LOCK_DIRTY, S_DELETE, S_UPDATE. */
      assert (scan_op_type == S_SELECT_WITH_LOCK || scan_op_type == S_DELETE || scan_op_type == S_UPDATE);

      /* First key object must be locked and returned. */
      find_unique_helper.lock_mode = (scan_op_type == S_SELECT_WITH_LOCK) ? S_LOCK : X_LOCK;
      key_function = btree_key_find_and_lock_unique;
    }

  if (logtb_find_current_isolation (thread_p) >= TRAN_REP_READ || (find_unique_helper.lock_mode >= S_LOCK))
    {
      /*
       * Acquire snapshot in RR if not already acquired. This is needed since
       * the transaction need to know the actual visible objects - before
       * instance locking. In this way future commands of current transaction
       * may correctly detect visible objects.
       */
      (void) logtb_get_mvcc_snapshot (thread_p);
    }

  /* Find unique key and object. */
  error_code =
    btree_search_key_and_apply_functions (thread_p, btid, NULL, key, NULL, NULL, advance_function, NULL, key_function,
					  &find_unique_helper, NULL, NULL);
  if (error_code != NO_ERROR)
    {
      /* Error! */
      /* Error must be set! */
      ASSERT_ERROR ();
#if defined (SERVER_MODE)
      /* Safe guard: don't keep lock if error has occurred. */
      if (!OID_ISNULL (&find_unique_helper.locked_oid))
	{
	  /* Make sure to unlock the object. */
	  lock_unlock_object_donot_move_to_non2pl (thread_p, &find_unique_helper.locked_oid,
						   &find_unique_helper.locked_class_oid, find_unique_helper.lock_mode);
	  OID_SET_NULL (&find_unique_helper.locked_oid);
	}
#endif /* SERVER_MODE */
      return BTREE_ERROR_OCCURRED;
    }

#if defined (SERVER_MODE)
  /* Safe guard: if op is S_SELECT, nothing should be locked. */
  assert (scan_op_type != S_SELECT || OID_ISNULL (&find_unique_helper.locked_oid));
#endif /* SERVER_MODE */

  if (find_unique_helper.found_object)
    {
      /* Key found. */
      /* Output found object OID. */
      assert (!OID_ISNULL (&find_unique_helper.oid));
      COPY_OID (oid, &find_unique_helper.oid);

#if defined (SERVER_MODE)
      /* Safe guard: object is supposed to be locked. */
      assert (scan_op_type == S_SELECT || lock_has_lock_on_object (oid, class_oid, find_unique_helper.lock_mode) > 0);
#endif /* SERVER_MODE */

      return BTREE_KEY_FOUND;
    }
  /* Key/object not found. */

#if defined (SERVER_MODE)
  /* Safe guard: no lock is kept if object was not found. */
  assert (OID_ISNULL (&find_unique_helper.locked_oid));
#endif /* SERVER_MODE */
  return BTREE_KEY_NOTFOUND;
}

/*
 * btree_count_oids () - BTREE_PROCESS_OBJECT_FUNCTION - Increment object counter.
 *
 * return	   : Error code.
 * thread_p (in)   : Thread entry.
 * btid_int (in)   : B-tree info.
 * record (in)	   : B-tree leaf/overflow record.
 * object_ptr (in) : Pointer to object in record data.
 * oid (in)	   : Object OID.
 * class_oid (in)  : Object class OID.
 * mvcc_info (in)  : Object MVCC info.
 * stop (out)	   : Set to true if index is unique and visible object is found and if this is not a debug build.
 * args (in/out)   : Integer object counter. Outputs incremented value.
 */
STATIC_INLINE int
btree_count_oids (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * record, char *object_ptr, OID * oid,
		  OID * class_oid, MVCC_REC_HEADER * mvcc_header, bool * stop, void *args)
{
  /* Assert expected arguments. */
  assert (args != NULL);

  /* Increment counter. */
  (*((int *) args))++;
  return NO_ERROR;
}

/*
 * btree_range_scan_count_oids_leaf_and_one_ovf () - Count key objects from leaf record and if it has an overflow page,
 *						     also add its full capacity.
 *
 * return	 : OID count or error code.
 * thread_p (in) : Thread entry.
 * bts (in)	 : B-tree scan.
 */
static int
btree_range_scan_count_oids_leaf_and_one_ovf (THREAD_ENTRY * thread_p, BTREE_SCAN * bts)
{
  int leaf_oids_count = 0;

  /* Count leaf objects. */
  leaf_oids_count =
    btree_record_get_num_oids (thread_p, &bts->btid_int, &bts->key_record, bts->offset, BTREE_LEAF_NODE);
  if (leaf_oids_count < 0)
    {
      /* Error */
      ASSERT_ERROR ();
      return leaf_oids_count;
    }

  if (VPID_ISNULL (&bts->leaf_rec_info.ovfl))
    {
      /* No overflow. */
      return leaf_oids_count;
    }

  /* Estimate one overflow. Do not just count first overflow records. They may be all invisible, in which case we need
   * to proceed to next overflow. Just to be on the safe side, take into consideration one full overflow page. */
  return leaf_oids_count + BTREE_MAX_OIDCOUNT_IN_OVERFLOW_RECORD (&bts->btid_int);
}

/*
 * btree_range_scan_start () - Start a range scan by finding the first eligible key.
 *
 * return	 : Error code.
 * thread_p (in) : Thread entry.
 * bts (in)	 : B-tree scan structure.
 *
 * NOTE: Key is considered eligible if:
 *	 - Key is within desired range.
 *	 - Key is not a fence key.
 *	 - Key passes filter.
 */
static int
btree_range_scan_start (THREAD_ENTRY * thread_p, BTREE_SCAN * bts)
{
  int error_code = NO_ERROR;
  bool found = false;

  /* Assert expected arguments. */
  assert (bts != NULL);
  assert (VPID_ISNULL (&bts->C_vpid));
  assert (bts->C_page == NULL);

  /* Find starting key. */
  /* Starting key must be checked and pass filters first. */
  bts->key_status = BTS_KEY_IS_NOT_VERIFIED;
  if (bts->key_range.lower_key == NULL)
    {
      /* No lower limit. Just find lowest key in index. */
      error_code = btree_find_lower_bound_leaf (thread_p, bts, NULL);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return error_code;
	}
      if (bts->end_scan)
	{
	  return NO_ERROR;
	}
    }
  else
    {
      /* Has lower limit. Try to locate the key. */
      error_code =
	btree_locate_key (thread_p, &bts->btid_int, bts->key_range.lower_key, &bts->C_vpid, &bts->slot_id,
			  &bts->C_page, &found);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return error_code;
	}
      if (!found && bts->use_desc_index)
	{
	  /* Key was not found and the bts->slot_id was positioned to next key bigger than bts->key_range.lower_key.
	   * For descending scan, we should be positioned on the first smaller when key is not found. Update
	   * bts->slot_id. */
	  bts->slot_id--;
	}
      if (found && (bts->key_range.range == GT_LT || bts->key_range.range == GT_LE || bts->key_range.range == GT_INF))
	{
	  /* Lower limit key was found, but the scan range must be bigger than the limit. Go to next key. */
	  /* Mark the key as consumed and let btree_range_scan_advance_over_filtered_keys handle it. */
	  bts->key_status = BTS_KEY_IS_CONSUMED;
	}
    }
  /* Found starting key. */
  error_code = btree_range_scan_advance_over_filtered_keys (thread_p, bts);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      return error_code;
    }
  if (bts->force_restart_from_root)
    {
      /* Scan is not yet started. Descending scan failed to position on first key. Restart scan. */
      assert (bts->use_desc_index);
      if (bts->C_page != NULL)
	{
	  pgbuf_unfix_and_init (thread_p, bts->C_page);
	}
      VPID_SET_NULL (&bts->C_vpid);
      btree_scan_clear_key (bts);
      bts->key_status = BTS_KEY_IS_NOT_VERIFIED;
      return NO_ERROR;
    }

  /* Start scanning */
  bts->is_scan_started = true;
  return NO_ERROR;
}

/*
 * btree_range_scan_resume () - Function used to resume range scans after being interrupted. It will try to resume from
 *				saved leaf node (if possible). Otherwise, current key must looked up starting from
 *				b-tree root.
 *
 * return	 : Error code.
 * thread_p (in) : Thread entry.
 * bts (in)	 : B-tree scan helper.
 */
static int
btree_range_scan_resume (THREAD_ENTRY * thread_p, BTREE_SCAN * bts)
{
  int error_code = NO_ERROR;
  BTREE_SEARCH_KEY_HELPER search_key = BTREE_SEARCH_KEY_HELPER_INITIALIZER;
  bool found = false;

  assert (bts->force_restart_from_root || !VPID_ISNULL (&bts->C_vpid));
  assert (bts->C_page == NULL);
  assert (!DB_IS_NULL (&bts->cur_key));
  assert (!BTS_IS_INDEX_ILS (bts));

  /* Resume range scan. It can be resumed from same leaf or by looking up the key again from root. */
  if (!bts->force_restart_from_root)
    {
      /* Try to resume from saved leaf node. */
      error_code =
	pgbuf_fix_if_not_deallocated (thread_p, &bts->C_vpid, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH,
				      &bts->C_page);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return error_code;
	}
      if (bts->C_page != NULL)
	{
	  /* Try to resume from this page  */
	  if (LSA_EQ (&bts->cur_leaf_lsa, pgbuf_get_lsa (bts->C_page)))
	    {
	      /* Leaf page suffered no changes while range search was interrupted. Range search can be resumed using
	       * current position. */
	      return btree_range_scan_advance_over_filtered_keys (thread_p, bts);
	    }

	  /* Page suffered some changes. */
	  if (BTREE_IS_PAGE_VALID_LEAF (thread_p, bts->C_page))
	    {
	      /* Page is still a valid leaf page. Check if key still exists. */
	      /* Is key still in this page? */
	      error_code =
		btree_leaf_is_key_between_min_max (thread_p, &bts->btid_int, bts->C_page, &bts->cur_key, &search_key);
	      if (error_code != NO_ERROR)
		{
		  /* Error! */
		  pgbuf_unfix_and_init (thread_p, bts->C_page);
		  ASSERT_ERROR ();
		  return error_code;
		}
	      if (search_key.result == BTREE_KEY_BETWEEN)
		{
		  /* We need to find slot of key. */
		  error_code =
		    btree_search_leaf_page (thread_p, &bts->btid_int, bts->C_page, &bts->cur_key, &search_key);
		  if (error_code != NO_ERROR)
		    {
		      /* Error! */
		      pgbuf_unfix_and_init (thread_p, bts->C_page);
		      ASSERT_ERROR ();
		      return error_code;
		    }
		  assert (search_key.result != BTREE_KEY_NOTFOUND);
		}
	      switch (search_key.result)
		{
		case BTREE_KEY_FOUND:
		  /* Key was found. Use this key. */
		  bts->slot_id = search_key.slotid;
		  return btree_range_scan_advance_over_filtered_keys (thread_p, bts);

		case BTREE_KEY_BETWEEN:
		  /* Key should have been in this page, but it was removed. Proceed to next key. */
		  if (bts->use_desc_index)
		    {
		      /* Use previous slot. */
		      bts->slot_id = search_key.slotid - 1;
		      assert (bts->slot_id >= 1 && bts->slot_id <= btree_node_number_of_keys (thread_p, bts->C_page));
		    }
		  else
		    {
		      /* Use next slotid. */
		      bts->slot_id = search_key.slotid;
		      assert (bts->slot_id >= 1 && bts->slot_id <= btree_node_number_of_keys (thread_p, bts->C_page));
		    }
		  bts->key_status = BTS_KEY_IS_NOT_VERIFIED;
		  return btree_range_scan_advance_over_filtered_keys (thread_p, bts);

		case BTREE_KEY_SMALLER:
		case BTREE_KEY_BIGGER:
		case BTREE_KEY_NOTFOUND:
		  /* Key is no longer in this leaf node. Locate key by advancing from root. */
		  /* Fall through. */
		  break;

		default:
		  /* Unexpected. */
		  assert (false);
		  pgbuf_unfix_and_init (thread_p, bts->C_page);
		  return ER_FAILED;
		}
	    }
	  else			/* !BTREE_IS_PAGE_VALID_LEAF (bts->C_page) */
	    {
	      /* Page must have been deallocated/reused for other purposes. */
	      /* Fall through. */
	    }
	  pgbuf_unfix_and_init (thread_p, bts->C_page);
	}
      else
	{
	  /* bts->C_Page is null because it was deallocated. we need to search the key again. fall through */
	}
    }
  /* Couldn't resume from saved leaf node. */

  /* No page should be fixed. */
  assert (bts->C_page == NULL);

  /* Reset bts->force_restart_from_root flag. */
  bts->force_restart_from_root = false;

  /* Search key from top. */
  error_code = btree_locate_key (thread_p, &bts->btid_int, &bts->cur_key, &bts->C_vpid, &bts->slot_id,
				 &bts->C_page, &found);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      return error_code;
    }
  /* Safe guard. */
  assert (btree_get_node_level (thread_p, bts->C_page) == 1);
  if (found)
    {
      /* Found key. Resume from here. */
      return btree_range_scan_advance_over_filtered_keys (thread_p, bts);
    }
  if (btree_node_number_of_keys (thread_p, bts->C_page) < 1)
    {
      assert (btree_node_number_of_keys (thread_p, bts->C_page) == 0);
      /* No more keys. */
      bts->end_scan = true;
      return NO_ERROR;
    }
  /* Not found. */
  if (bts->use_desc_index)
    {
      bts->slot_id = bts->slot_id - 1;
    }
  bts->key_status = BTS_KEY_IS_NOT_VERIFIED;
  return btree_range_scan_advance_over_filtered_keys (thread_p, bts);
}

/*
 * btree_range_scan_read_record () - Read b-tree record for b-tree range scan.
 *
 * return	 : Error code.
 * thread_p (in) : Thread entry.
 * bts (in/out)	 : B-tree scan.
 */
static int
btree_range_scan_read_record (THREAD_ENTRY * thread_p, BTREE_SCAN * bts)
{
  /* Clear current key value if needed. */
  btree_scan_clear_key (bts);
  /* Read record key (and other info). */
  return btree_read_record (thread_p, &bts->btid_int, bts->C_page, &bts->key_record, &bts->cur_key, &bts->leaf_rec_info,
			    bts->node_type, &bts->clear_cur_key, &bts->offset, COPY_KEY_VALUE, bts);
}

/*
 * btree_range_scan_advance_over_filtered_keys () - Find a key to pass all all filters.
 *
 * return	  : Error code.
 * thread_p (in)  : Thread entry.
 * bts (in/out)	  : B-tree scan helper.
 */
static int
btree_range_scan_advance_over_filtered_keys (THREAD_ENTRY * thread_p, BTREE_SCAN * bts)
{
  int inc_slot;			/* Slot incremental value to advance to next key. */
  VPID next_vpid;		/* VPID of next leaf. */
  BTREE_NODE_HEADER *node_header;	/* Leaf node header. */
  int key_count;		/* Node key count. */
  PAGE_PTR next_node_page = NULL;	/* Page pointer to next leaf node. */
  int error_code;		/* Error code. */
  bool is_range_satisfied;	/* True if range is satisfied. */
  bool is_filter_satisfied;	/* True if filter is satisfied. */

  /* Assert expected arguments. */
  assert (bts != NULL);
  assert (bts->C_page != NULL);

  /* Initialize. */
  node_header = btree_get_node_header (thread_p, bts->C_page);
  assert (node_header != NULL);
  assert (node_header->node_level == 1);

  if (bts->key_status == BTS_KEY_IS_VERIFIED)
    {
      /* Current key is not yet consumed, but it already passed range/filter checks. Resume scan on current key. */

      /* Safe guard: this is not a fence key. */
      assert (!btree_is_fence_key (bts->C_page, bts->slot_id));

      /* This must be a resumed scan. Page was probably unfixed since last key read and may be changed. To be sure,
       * obtain record again. */

      /* Read record. */
      /* Get current key. */
      if (spage_get_record (thread_p, bts->C_page, bts->slot_id, &bts->key_record, PEEK) != S_SUCCESS)
	{
	  /* Unexpected error. */
	  assert (false);
	  return ER_FAILED;
	}
      /* TODO: Don't clear/copy key again. */
      error_code = btree_range_scan_read_record (thread_p, bts);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return error_code;
	}
      /* Continue with current key. */
      return NO_ERROR;
    }
  /* Current key is completely consumed or is a new key. */
  assert (bts->key_status == BTS_KEY_IS_CONSUMED || bts->key_status == BTS_KEY_IS_NOT_VERIFIED);

  if (bts->key_range_max_value_equal)
    {
      /* Range was already consumed. End the scan. */
      bts->end_scan = true;
      return NO_ERROR;
    }

  /* If current key is not new and is completely consumed, go to next key. */
  inc_slot = bts->use_desc_index ? -1 : 1;
  if (bts->key_status == BTS_KEY_IS_CONSUMED)
    {
      /* Go to next key. */
      bts->slot_id += inc_slot;
    }
  else
    {
      /* Assert expected key status. */
      assert (bts->key_status == BTS_KEY_IS_NOT_VERIFIED);
    }

  /* Get VPID of next leaf and key count in current leaf. */
  next_vpid = bts->use_desc_index ? node_header->prev_vpid : node_header->next_vpid;
  key_count = btree_node_number_of_keys (thread_p, bts->C_page);
  assert (key_count >= 0);

  while (true)
    {
      /* Safe guard: current leaf is fixed. */
      assert (bts->C_page != NULL);

      /* If key is not in the range 1 -> key count, a different leaf node must be fixed. This while should pass over
       * all empty or consumed leaf nodes. */
      while (bts->slot_id <= 0 || bts->slot_id > key_count || key_count == 0)
	{
	  /* Current leaf node was consumed (or was empty). Try next leaf node. */

	  /* If scan is descending, current slot_id is expected to be 0, if it is ascending, then slot_id must be
	   * key_count + 1. */
	  assert ((bts->use_desc_index && bts->slot_id == 0)
		  || (!bts->use_desc_index && bts->slot_id == key_count + 1));
	  if (VPID_ISNULL (&next_vpid))
	    {
	      /* Index was consumed. */
	      bts->end_scan = true;
	      return NO_ERROR;
	    }
	  if (bts->use_desc_index)
	    {
	      /* Descending index will try conditional latch on previous leaf. If that fails, current leaf will be
	       * unfixed and pages fixed in normal order. However, until pages are successfully fixed, it is possible
	       * that they are not reusable and scan must be restarted from root. We assume and hope this is does not
	       * happen too often (must see). */
	      error_code =
		btree_range_scan_descending_fix_prev_leaf (thread_p, bts, &key_count, &node_header, &next_vpid);
	      if (error_code != NO_ERROR)
		{
		  ASSERT_ERROR ();
		  return ER_FAILED;
		}
	      if (bts->force_restart_from_root)
		{
		  /* Failed to continue descending scan. Restart from root. */
		  return NO_ERROR;
		}
	    }
	  else
	    {
	      /* Fix next leaf page. */
	      next_node_page = pgbuf_fix (thread_p, &next_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
	      if (next_node_page == NULL)
		{
		  ASSERT_ERROR_AND_SET (error_code);
		  return error_code;
		}
	      /* Advance to next node. */
	      pgbuf_unfix (thread_p, bts->C_page);
	      bts->C_page = next_node_page;
	      VPID_COPY (&bts->C_vpid, &next_vpid);
	      next_node_page = NULL;
	      /* Initialize stuff. */
	      key_count = btree_node_number_of_keys (thread_p, bts->C_page);
	      node_header = btree_get_node_header (thread_p, bts->C_page);
	      assert (node_header != NULL);
	      assert (node_header->node_level == 1);
	      /* Ascending scan: start from first key in page and then advance to next page. */
	      bts->slot_id = 1;
	      next_vpid = node_header->next_vpid;
	    }
	}

      /* Get current key. */
      if (spage_get_record (thread_p, bts->C_page, bts->slot_id, &bts->key_record, PEEK) != S_SUCCESS)
	{
	  /* Unexpected error. */
	  assert (false);
	  return ER_FAILED;
	}

      if (!btree_leaf_is_flaged (&bts->key_record, BTREE_LEAF_RECORD_FENCE))
	{
	  /* Not a fence key. */
	  /* Handle. */
	  error_code = btree_range_scan_read_record (thread_p, bts);
	  if (error_code != NO_ERROR)
	    {
	      ASSERT_ERROR ();
	      return error_code;
	    }
	  error_code =
	    btree_apply_key_range_and_filter (thread_p, bts, BTS_IS_INDEX_ISS (bts), &is_range_satisfied,
					      &is_filter_satisfied, bts->need_to_check_null);
	  if (error_code != NO_ERROR)
	    {
	      ASSERT_ERROR ();
	      return error_code;
	    }

	  if (!is_range_satisfied)
	    {
	      /* Range is not satisfied, which means scan is ended. */
	      bts->end_scan = true;
	      return NO_ERROR;
	    }
	  /* Range satisfied. */

	  if (is_filter_satisfied)
	    {
	      /* Filter is satisfied, which means key can be used. */
	      bts->read_keys++;
	      bts->key_status = BTS_KEY_IS_VERIFIED;
	      return NO_ERROR;
	    }
	  /* Filter not satisfied. Try next key. */
	  /* Fall through. */
	}
      else
	{
	  /* Key is fence and must be filtered. */
	  /* Safe guard: Fence keys can be only first or last keys in page, but never first or last in entire index. */
	  assert ((bts->slot_id == 1 && !VPID_ISNULL (&node_header->prev_vpid))
		  || (bts->slot_id == key_count && !VPID_ISNULL (&node_header->next_vpid)));
	  /* Fall through. */

	  /* TODO: Get key info should be able to obtain fences too. */
	}

      /* Key is not usable. Advance. */
      bts->slot_id += inc_slot;
    }
  /* Impossible to reach. */
  assert (false);
  return ER_FAILED;
}

/*
 * btree_range_scan_descending_fix_prev_leaf () - Fix previous leaf node without generating cross latches with regular
 * 						  scans and by trying to avoid a key lookup from root.
 *
 * return		    : Error code.
 * thread_p (in)	    : Thread entry.
 * bts (in)		    : B-tree scan data.
 * key_count (in/out)	    : Current page key count.
 * node_header_ptr (in/out) : Current page node header.
 * next_vpid (in/out)	    : Next (actually previous) leaf VPID.
 */
static int
btree_range_scan_descending_fix_prev_leaf (THREAD_ENTRY * thread_p, BTREE_SCAN * bts, int *key_count,
					   BTREE_NODE_HEADER ** node_header_ptr, VPID * next_vpid)
{
  PAGE_PTR prev_leaf = NULL;	/* Page pointer to previous leaf node. */
  VPID prev_leaf_vpid;		/* VPID of previous leaf node. */
  int error_code = NO_ERROR;	/* Error code. */
  /* Search key result. */
  BTREE_SEARCH_KEY_HELPER search_key = BTREE_SEARCH_KEY_HELPER_INITIALIZER;

  /* Assert expected arguments. */
  assert (bts != NULL && bts->use_desc_index == true);
  assert (key_count != NULL);
  assert (next_vpid != NULL);

  VPID_COPY (&prev_leaf_vpid, next_vpid);

  /* Conditional latch for previous page. */
  prev_leaf = pgbuf_fix (thread_p, &prev_leaf_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_CONDITIONAL_LATCH);
  if (prev_leaf != NULL)
    {
      /* Previous leaf was successfully latched. Advance. */
      pgbuf_unfix_and_init (thread_p, bts->C_page);
      bts->C_page = prev_leaf;
      VPID_COPY (&bts->C_vpid, &prev_leaf_vpid);
      *key_count = btree_node_number_of_keys (thread_p, bts->C_page);
      bts->slot_id = *key_count;
      *node_header_ptr = btree_get_node_header (thread_p, bts->C_page);
      VPID_COPY (next_vpid, &(*node_header_ptr)->prev_vpid);
      return NO_ERROR;
    }
  /* Conditional latch failed. */

  /* Unfix current page and retry. */
  pgbuf_unfix_and_init (thread_p, bts->C_page);
  error_code =
    pgbuf_fix_if_not_deallocated (thread_p, &prev_leaf_vpid, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH, &prev_leaf);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      return error_code;
    }
  if (prev_leaf == NULL)
    {
      /* deallocated */
      bts->force_restart_from_root = true;
      return NO_ERROR;
    }
  if (!BTREE_IS_PAGE_VALID_LEAF (thread_p, prev_leaf))
    {
      /* Page deallocated/reused, but not currently a valid b-tree leaf. */
      /* Try again from top. */
      bts->force_restart_from_root = true;
      pgbuf_unfix_and_init (thread_p, prev_leaf);
      return NO_ERROR;
    }
  /* Valid leaf. */

  *node_header_ptr = btree_get_node_header (thread_p, prev_leaf);
  if (!VPID_EQ (&(*node_header_ptr)->next_vpid, &bts->C_vpid))
    {
      /* No longer linked leaves. Restart search from top. */
      bts->force_restart_from_root = true;
      pgbuf_unfix_and_init (thread_p, prev_leaf);
      return NO_ERROR;
    }
  /* Pages are still linked. */

  /* Fix current page too. */
  bts->C_page = pgbuf_fix (thread_p, &bts->C_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
  if (bts->C_page == NULL)
    {
      ASSERT_ERROR_AND_SET (error_code);
      pgbuf_unfix_and_init (thread_p, prev_leaf);
      return error_code;
    }

  /* Before searching the key in leaf page, we must make sure to handle this next peculiar case: 1. First key search of
   * descending scan. Lower key limit is located as first in leaf page. 2. Range scan says strictly less than lower key
   * limit. 3. The algorithm tries to fix go to previous leaf. However, bts->cur_key does not yet store any key values.
   * Set bts->cur_key to lower key limit of range. NOTE: If there is no lower limit, this case cannot happen. */
  if (!bts->is_scan_started && bts->key_range.lower_key != NULL && DB_IS_NULL (&bts->cur_key))
    {
      pr_clone_value (bts->key_range.lower_key, &bts->cur_key);
      bts->clear_cur_key = true;
      /* Next steps will go before bts->key_range.lower_key. */
    }
  /* We must have a non-null current key. */
  assert (!DB_IS_NULL (&bts->cur_key));

  /* Normally, key is found in current page. */
  error_code = btree_leaf_is_key_between_min_max (thread_p, &bts->btid_int, bts->C_page, &bts->cur_key, &search_key);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      pgbuf_unfix_and_init (thread_p, prev_leaf);
      return error_code;
    }
  if (search_key.result == BTREE_KEY_BETWEEN)
    {
      /* Search to find slot. */
      error_code = btree_search_leaf_page (thread_p, &bts->btid_int, bts->C_page, &bts->cur_key, &search_key);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  pgbuf_unfix_and_init (thread_p, prev_leaf);
	  return error_code;
	}
    }
  switch (search_key.result)
    {
    case BTREE_KEY_BETWEEN:
      /* Still in current page. Current slotid cannot be 1. */
      assert (search_key.slotid > 1);
      /* Fall through to advance to previous key. Search function returned the first bigger key. */
    case BTREE_KEY_FOUND:
      if (search_key.slotid > 1)
	{
	  /* Must check remaining keys in current page. */
	  bts->slot_id = search_key.slotid - 1;

	  *key_count = btree_node_number_of_keys (thread_p, bts->C_page);
	  *node_header_ptr = btree_get_node_header (thread_p, bts->C_page);
	  VPID_COPY (next_vpid, &(*node_header_ptr)->prev_vpid);

	  /* Unfix previous page. */
	  pgbuf_unfix_and_init (thread_p, prev_leaf);
	  return NO_ERROR;
	}

      /* Found key in the first slot. */
      /* Safe guard: could not fall through from BTREE_KEY_BETWEEN. */
      assert (search_key.result == BTREE_KEY_FOUND);
      /* Move to previous page. */
      pgbuf_unfix_and_init (thread_p, bts->C_page);
      bts->C_page = prev_leaf;
      VPID_COPY (&bts->C_vpid, &prev_leaf_vpid);
      *key_count = btree_node_number_of_keys (thread_p, bts->C_page);
      VPID_COPY (next_vpid, &(*node_header_ptr)->prev_vpid);
      bts->slot_id = *key_count;
      return NO_ERROR;

    case BTREE_KEY_BIGGER:
      /* TODO: Go to next page until key is found? */
      /* For now just fall through to restart. */
    case BTREE_KEY_NOTFOUND:
      /* Unknown key fate. */
      bts->force_restart_from_root = true;
      pgbuf_unfix_and_init (thread_p, prev_leaf);
      return NO_ERROR;

    case BTREE_KEY_SMALLER:
      /* Fall through to try search key in previous page. */
      break;

    default:
      /* Unhandled. */
      assert_release (false);
      pgbuf_unfix_and_init (thread_p, prev_leaf);
      return ER_FAILED;
    }
  /* Search key in previous page. */
  assert (search_key.result == BTREE_KEY_SMALLER);
  /* Unfix current page. */
  pgbuf_unfix_and_init (thread_p, bts->C_page);
  error_code = btree_leaf_is_key_between_min_max (thread_p, &bts->btid_int, prev_leaf, &bts->cur_key, &search_key);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      pgbuf_unfix_and_init (thread_p, prev_leaf);
      return error_code;
    }
  if (search_key.result == BTREE_KEY_BETWEEN)
    {
      /* Search to find slot. */
      error_code = btree_search_leaf_page (thread_p, &bts->btid_int, prev_leaf, &bts->cur_key, &search_key);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  pgbuf_unfix_and_init (thread_p, prev_leaf);
	  return error_code;
	}
    }
  switch (search_key.result)
    {
    case BTREE_KEY_BIGGER:
    case BTREE_KEY_BETWEEN:
      /* First bigger key. */
      assert (search_key.slotid > 1);
      /* Fall through to advance to previous key. */
    case BTREE_KEY_FOUND:
      /* Update bts and advance to previous key. */
      bts->C_page = prev_leaf;
      VPID_COPY (&bts->C_vpid, &prev_leaf_vpid);
      *key_count = btree_node_number_of_keys (thread_p, bts->C_page);
      VPID_COPY (next_vpid, &(*node_header_ptr)->prev_vpid);
      bts->slot_id = search_key.slotid - 1;

      /* If this was the first key in page, now slot_id will be 0. */
      /* This function should get called again, but looking for another previous leaf node. */
      return NO_ERROR;

    default:
      /* BTREE_KEY_SMALLER */
      /* BTREE_KEY_NOTFOUND */
      /* Unknown key fate. */
      bts->force_restart_from_root = true;
      pgbuf_unfix_and_init (thread_p, prev_leaf);
      return NO_ERROR;
    }

  /* Impossible to reach. */
  assert_release (false);
  return ER_FAILED;
}

/*
 * btree_range_scan () - Generic function to do a range scan on b-tree. It can scan key by key starting with first
 * 			 (or last key for descending scans). For each key, it calls an internal function to process
 * 			 the key.
 *
 * return	      : Error code.
 * thread_p (in)      : Thread entry.
 * bts (in)	      : B-tree scan structure.
 * key_func (in)      : Internal function to call when an eligible key is found.
 */
int
btree_range_scan (THREAD_ENTRY * thread_p, BTREE_SCAN * bts, BTREE_RANGE_SCAN_PROCESS_KEY_FUNC * key_func)
{
  int error_code = NO_ERROR;	/* Error code. */

  /* Assert expected arguments. */
  assert (bts != NULL);
  assert (key_func != NULL);

  PERF_UTIME_TRACKER_START (thread_p, &bts->time_track);

  /* Reset end_scan and end_one_iteration flags. */
  bts->end_scan = false;
  bts->end_one_iteration = false;

  /* Reset read counters for iteration. */
  bts->n_oids_read_last_iteration = 0;

  if (bts->index_scan_idp != NULL && bts->index_scan_idp->oid_list != NULL)
    {
      /* Reset oid_ptr. */
      bts->oid_ptr = bts->index_scan_idp->oid_list->oidp;
    }

  while (!bts->end_scan && !bts->end_one_iteration)
    {
      bts->is_interrupted = false;

      /* Start from top or resume. */
      if (!bts->is_scan_started)
	{
	  /* Must find a starting key. */
	  error_code = btree_range_scan_start (thread_p, bts);
	}
      else
	{
	  /* Resume from current key. */
	  error_code = btree_range_scan_resume (thread_p, bts);
	}

      PERF_UTIME_TRACKER_TIME (thread_p, &bts->time_track, PSTAT_BT_TRAVERSE);
      PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, &bts->time_track, PSTAT_BT_RANGE_SEARCH_TRAVERSE);

      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto exit_on_error;
	}
      if (bts->end_scan)
	{
	  /* Scan is finished. */
	  break;
	}
      if (bts->force_restart_from_root)
	{
	  /* Couldn't advance. Restart from root. */
	  assert (bts->use_desc_index);
	  btree_log_if_enabled ("Notification: descending range scan had to be interrupted and restarted from root.\n");
	  if (bts->C_page != NULL)
	    {
	      pgbuf_unfix_and_init (thread_p, bts->C_page);
	    }
	  if (BTS_IS_INDEX_ILS (bts))
	    {
	      /* Reset scan to avoid using btree_range_scan_resume () */
	      bts_reset_scan (thread_p, bts);
	    }
	  continue;
	}

      /* Scan is now positioned on an usable key; consumed/fence/filtered keys have been skipped. */

      while (true)
	{
	  /* For each valid key */
	  assert (bts->C_page != NULL);
	  assert (!VPID_ISNULL (&bts->C_vpid));
	  assert (bts->O_page == NULL);
	  /* Do we need P_page here? */
	  assert (bts->P_page == NULL);
	  assert (bts->key_status == BTS_KEY_IS_VERIFIED);
	  assert (!bts->is_interrupted && !bts->end_one_iteration && !bts->end_scan);

	  /* Call internal key function. */
	  error_code = key_func (thread_p, bts);
	  if (error_code != NO_ERROR)
	    {
	      ASSERT_ERROR ();
	      goto exit_on_error;
	    }
	  if (bts->is_interrupted || bts->end_one_iteration || bts->end_scan)
	    {
	      /* Interrupt key processing loop. */
	      break;
	    }
	  /* Current key must be consumed. Find a new valid key. */
	  assert (bts->key_status == BTS_KEY_IS_CONSUMED);
	  error_code = btree_range_scan_advance_over_filtered_keys (thread_p, bts);
	  if (error_code != NO_ERROR)
	    {
	      ASSERT_ERROR ();
	      goto exit_on_error;
	    }
	  if (bts->end_scan)
	    {
	      /* Finished scan. */
	      break;
	    }
	  if (bts->force_restart_from_root)
	    {
	      /* Couldn't advance. Restart from root. */
	      assert (bts->use_desc_index);
	      btree_log_if_enabled ("Notification: descending range scan had to be interrupted and restarted from "
				    "root.\n");
	      if (bts->C_page != NULL)
		{
		  pgbuf_unfix_and_init (thread_p, bts->C_page);
		}
	      break;
	    }
	}

      PERF_UTIME_TRACKER_TIME (thread_p, &bts->time_track, PSTAT_BT_LEAF);
      PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, &bts->time_track, PSTAT_BT_RANGE_SEARCH);
    }

end:
  /* End scan or end one iteration or maybe an error case. */
  assert (bts->end_scan || bts->end_one_iteration || error_code != NO_ERROR);

  if (error_code != NO_ERROR)
    {
      /* Clear current key (if not already cleared). */
      btree_scan_clear_key (bts);
    }

  if (bts->end_scan)
    {
      /* Scan is ended. Reset current page VPID and is_scan_started flag */
      VPID_SET_NULL (&bts->C_vpid);
      bts->is_scan_started = false;

      /* Clear current key (if not already cleared). */
      btree_scan_clear_key (bts);

      assert (VPID_ISNULL (&bts->O_vpid));
    }

  if (bts->C_page != NULL)
    {
      /* Unfix current page and save its LSA. */
      assert (bts->end_scan || VPID_EQ (pgbuf_get_vpid_ptr (bts->C_page), &bts->C_vpid));
      LSA_COPY (&bts->cur_leaf_lsa, pgbuf_get_lsa (bts->C_page));
      pgbuf_unfix_and_init (thread_p, bts->C_page);
    }
  else
    {
      /* No current page fixed. */
      LSA_SET_NULL (&bts->cur_leaf_lsa);
    }
  assert (bts->O_page == NULL);

  if (bts->P_page != NULL)
    {
      /* bts->P_page is still used by btree_find_boundary_leaf. Make sure it is unfixed. */
      VPID_SET_NULL (&bts->P_vpid);
      pgbuf_unfix_and_init (thread_p, bts->P_page);
    }

  if (bts->key_limit_upper != NULL)
    {
      /* Update upper limit for next scans. */
      (*bts->key_limit_upper) -= bts->n_oids_read_last_iteration;
      assert ((*bts->key_limit_upper) >= 0);
    }

  PERF_UTIME_TRACKER_TIME (thread_p, &bts->time_track, PSTAT_BT_LEAF);
  PERF_UTIME_TRACKER_TIME_AND_RESTART (thread_p, &bts->time_track, PSTAT_BT_RANGE_SEARCH);

  return error_code;

exit_on_error:
  error_code = error_code != NO_ERROR ? error_code : ER_FAILED;
  goto end;
}

/*
 * btree_range_scan_select_visible_oids () - BTREE_RANGE_SCAN_PROCESS_KEY_FUNC
 *					     Used internally by btree_range_scan to select visible objects from key
 *					     OID's.
 *					     Handling depends on the type of scan:
 *					     1. Multiple ranges optimization.
 *					     2. Covering index.
 *					     3. Index skip scan.
 *					     4. Regular index scan.
 *
 * return	   : Error code.
 * thread_p (in)   : Thread entry.
 * bts (in)	   : B-tree scan info.
 */
int
btree_range_scan_select_visible_oids (THREAD_ENTRY * thread_p, BTREE_SCAN * bts)
{
  int error_code = NO_ERROR;	/* Returned error code. */
  int oid_count;		/* Total number of objects of this key. Overflow OID's are also considered. For unique
				 * indexes, only one object is considered (we know for sure there can not be more than
				 * one visible). */
  int total_oid_count;		/* Total count of key OID's considering OID's already read and all OID's of current
				 * key. */
  bool stop = false;		/* Set to true when processing record should stop. */
  VPID overflow_vpid = VPID_INITIALIZER;	/* Overflow VPID. */
  PAGE_PTR overflow_page = NULL;	/* Current overflow page. */
  PAGE_PTR prev_overflow_page = NULL;	/* Previous overflow page. */
  RECDES ovf_record;		/* Overflow page record. */
  int oid_size = OR_OID_SIZE;	/* Object size (OID/class OID). */
  int save_oid_count = 0;	/* While processing the overflow pages we are required to save the last page that had
				 * any visible objects. Use this to save object counter before processing overflow and
				 * compare with the count of objects after processing the overflow. */
  VPID last_visible_overflow;	/* VPID of last overflow page that had at least one visible OID. If the scan is
				 * interrupted because too many objects were processed, it will be resumed after this
				 * overflow page. */
  PERF_UTIME_TRACKER ovf_fix_time_track;

  /* Assert b-tree scan is valid. */
  assert (bts != NULL);
  assert (!VPID_ISNULL (&bts->C_vpid));
  assert (bts->C_page != NULL);
  /* MRO and covering index optimization are not compatible with bts->need_count_only. */
  assert (!BTS_NEED_COUNT_ONLY (bts) || (!BTS_IS_INDEX_MRO (bts) && !BTS_IS_INDEX_COVERED (bts)));

  /* Index skip scan optimization has an early out when a new key is found: */
  if (BTS_IS_INDEX_ISS (bts)
      && (bts->index_scan_idp->iss.current_op == ISS_OP_GET_FIRST_KEY
	  || bts->index_scan_idp->iss.current_op == ISS_OP_SEARCH_NEXT_DISTINCT_KEY))
    {
      /* A new key was found. End current scan here (another range scan will be started after a range based on current
       * key is defined. */
      /* Set key. */
      error_code = btree_iss_set_key (bts, &bts->index_scan_idp->iss);
      if (error_code != NO_ERROR)
	{
	  return error_code;
	}
      /* Set oid_cnt to 1. */
      bts->n_oids_read_last_iteration = 1;

      /* End this scan here. */
      bts->end_scan = true;
      return NO_ERROR;
    }
  /* Not an early out of ISS optimization. */
  /* Safe guard: Not an ISS or ISS current op is ISS_OP_DO_RANGE_SEARCH. */
  assert (!BTS_IS_INDEX_ISS (bts) || bts->index_scan_idp->iss.current_op == ISS_OP_DO_RANGE_SEARCH);

  /* ISS and regular scans can use a buffer to store read OID's. Covering index optimization uses a list file, while
   * MRO uses a Top N structure. When OID buffer is used, it can be filled during scan. If this happens, interrupt
   * range scan, handle currently buffered objects and resume with an empty buffer. NOTE: There are two types of limits
   * used here. A soft limit and hard limit. Hard limit is used when key has too many objects and don't fit soft limit.
   * Hard limit is necessary to handle key processing interrupt/resume.  Soft key limit is ignored if no objects have
   * been processed in this iteration. */
  /* Don't do any checks for MRO or if objects only have to be counted. */
  if (!BTS_IS_INDEX_MRO (bts) && !BTS_NEED_COUNT_ONLY (bts))
    {
      if (!bts->is_key_partially_processed)
	{
	  /* If no objects have been processed this iteration, don't count. If already processed more than soft limit,
	   * don't count. If currently process + key's leaf and first overflow count exceed soft limit, stop iteration
	   * before processing key. */
	  if (bts->n_oids_read_last_iteration > 0 && BTS_IS_SOFT_CAPACITY_ENOUGH (bts, bts->n_oids_read_last_iteration))
	    {
	      /* Count the objects. */
	      if (BTREE_IS_UNIQUE (bts->btid_int.unique_pk))
		{
		  /* Only one object can be visible for each key. */
		  oid_count = 1;
		}
	      else
		{
		  /* Get the number of OID in current key's leaf and first overflow page. */
		  oid_count = btree_range_scan_count_oids_leaf_and_one_ovf (thread_p, bts);
		  if (oid_count < 0)
		    {
		      /* Unexpected error. */
		      ASSERT_ERROR ();
		      return oid_count;
		    }
		}
	      total_oid_count = bts->n_oids_read_last_iteration + oid_count;

	      if (!BTS_IS_SOFT_CAPACITY_ENOUGH (bts, total_oid_count))
		{
		  /* Stop this iteration and resume with an empty buffer. */
		  bts->end_one_iteration = true;
		  return NO_ERROR;
		}
	      else
		{
		  /* Safe guard: if soft capacity is enough, then hard limit must also be enough. */
		  assert (BTS_IS_HARD_CAPACITY_ENOUGH (bts, total_oid_count));
		}
	      /* There is enough space to handle key objects at least in its leaf and first overflow. */
	    }
	}
      else
	{
	  /* Key was not fully processed. Resume from its current overflow. */
	  /* The interrupt algorithm is based on next facts: 1. Objects can be vacuumed. Overflow pages can be
	   * deallocated when all its objects are vacuumed. Entire key cannot be vacuumed while interrupted (because at
	   * least one visible object existed in previous iteration). 2. Objects can be swapped from overflow page to
	   * leaf record.  Only one object from first overflow page is swapped. If this object is not visible, it can
	   * be vacuumed again and another object is swapped. This can continue until this thread resumes scan or until
	   * a visible object is swapped.  Note that first overflow page will be deallocated if all its objects have
	   * been swapped. This is possible if page has at most one visible object that cannot be vacuumed. 3. New
	   * objects can be inserted and new overflow pages can be created. Interrupt/resume system tries to work with
	   * constants in this behavior: 1. A key without overflow pages is never interrupted (actually a key without
	   * at least four overflow pages is never interrupted since all its objects can be processed in default
	   * buffer). 2. If interrupted, the buffer should have at least default number of OID's - one overflow page of
	   * OID's. This means roughly default_buffer_size / OR_OID_SIZE - db_page_size / OID_WITH_MVCC_INFO_SIZE =
	   * 16k*4/8 - 16k/32 with default parameters = ~7.5k objects. 3. When interrupted, bts saves last overflow
	   * page with at least one visible object to make sure it is not deallocated.  How can an overflow page be
	   * deallocated? Well first of all if all its objects are invisible and vacuumed. If it had any visible
	   * objects, it should be swapped to leaf record. Since only one visible object can be swapped to leaf, the
	   * page must have at most one visible object.  However, swapping starts with first overflow page. But this
	   * scan has processed at least 7.5k visible objects, worth at least several full pages. The last page, even
	   * if it had only one visible object, it wouldn't get swapped to leaf. 4. Can swapping objects to leaf be a
	   * problem? No. It can be considered already processed and ignored. Since there have been at least 7.5k
	   * visible objects processed in previous iteration, the first leaf object, if visible, must be one of these.
	   * 5. Inserting new OID's will not affect our scan in any way. If they are found after resume, they will be
	   * ignored by visibility test. If not found, they are again ignored (as they should). Even creating new
	   * overflow pages, does not affect us. The above statements are true for default buffer. In order to make it
	   * true for small buffers, there are two limits used by scan: a soft limit and a hard limit. The hard limit
	   * is used when key has too many objects. See comment from BTS_IS_HARD_CAPACITY_ENOUGH. */
	  /* Resume from next page of last overflow page. */
	  prev_overflow_page =
	    pgbuf_fix (thread_p, &bts->O_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
	  if (prev_overflow_page == NULL)
	    {
	      ASSERT_ERROR_AND_SET (error_code);
	      return error_code;
	    }
	  error_code = btree_get_next_overflow_vpid (thread_p, prev_overflow_page, &overflow_vpid);
	  if (error_code != NO_ERROR)
	    {
	      assert_release (false);
	      pgbuf_unfix_and_init (thread_p, prev_overflow_page);
	      return error_code;
	    }
	}
    }
  else
    {
      assert (!bts->is_key_partially_processed);
    }

  /* Start processing key objects. */

  if (!bts->is_key_partially_processed)
    {
      /* Start processing key with leaf record objects. */
      error_code =
	btree_record_process_objects (thread_p, &bts->btid_int, BTREE_LEAF_NODE, &bts->key_record, bts->offset, &stop,
				      btree_select_visible_object_for_range_scan, bts);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return error_code;
	}
      if (stop || bts->end_one_iteration || bts->end_scan || bts->is_interrupted)
	{
	  /* Early out. */
	  return NO_ERROR;
	}
      /* Process overflow objects. */
      /* Start processing overflow with first one. */
      VPID_COPY (&overflow_vpid, &bts->leaf_rec_info.ovfl);
      /* Fall through. */
    }
  else
    {
      /* Start processing key with an overflow page. */
      /* Overflow VPID is already set. */
      /* Assume key will be entirely processed. It will be changed if it interrupted again. */
      bts->is_key_partially_processed = false;
    }

  /* Prepare required data. */
  if (BTREE_IS_UNIQUE (bts->btid_int.unique_pk))
    {
      /* Class OID included. */
      oid_size += OR_OID_SIZE;
    }
  /* Initialize last visible overflow. */
  VPID_SET_NULL (&last_visible_overflow);
  /* Process overflow pages. */
  while (!VPID_ISNULL (&overflow_vpid))
    {
      /* Fix next overflow page. */
      PERF_UTIME_TRACKER_START (thread_p, &ovf_fix_time_track);
      overflow_page = pgbuf_fix (thread_p, &overflow_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
      btree_perf_ovf_oids_fix_time (thread_p, &ovf_fix_time_track);
      if (overflow_page == NULL)
	{
	  ASSERT_ERROR_AND_SET (error_code);
	  if (prev_overflow_page != NULL)
	    {
	      pgbuf_unfix_and_init (thread_p, prev_overflow_page);
	    }
	  return error_code;
	}
      /* Previous overflow page (if any) can be unfixed, now that next overflow page was fixed. */
      if (prev_overflow_page != NULL)
	{
	  pgbuf_unfix_and_init (thread_p, prev_overflow_page);
	}

      /* Save current object count. */
      save_oid_count = bts->n_oids_read_last_iteration;

      /* Get record. */
      if (spage_get_record (thread_p, overflow_page, 1, &ovf_record, PEEK) != S_SUCCESS)
	{
	  assert_release (false);
	  pgbuf_unfix_and_init (thread_p, overflow_page);
	  return ER_FAILED;
	}
      if (!BTS_IS_INDEX_MRO (bts) && !BTS_NEED_COUNT_ONLY (bts))
	{
	  /* Can we save all objects? */
	  if (BTREE_IS_UNIQUE (bts->btid_int.unique_pk))
	    {
	      /* There can be only one visible object. */
	      oid_count = 1;
	    }
	  else
	    {
	      oid_count = btree_record_get_num_oids (thread_p, &bts->btid_int, &ovf_record, 0, BTREE_OVERFLOW_NODE);
	    }
	  if (!BTS_IS_HARD_CAPACITY_ENOUGH (bts, bts->n_oids_read_last_iteration + oid_count))
	    {
	      /* We don't know how many visible objects there are in this page, and we don't want to process the page
	       * partially. Stop here and we will continue from last overflow page that had visible objects. */
	      /* Index coverage uses a list file and can handle all objects for this key. */

	      assert (bts->n_oids_read_last_iteration > 0);
	      assert (!VPID_ISNULL (&last_visible_overflow));

	      /* Save page to resume. */
	      VPID_COPY (&bts->O_vpid, &last_visible_overflow);
	      /* Mark key as partially processed to know to resume from an overflow page. */
	      bts->is_key_partially_processed = true;
	      /* End current iteration. */
	      bts->end_one_iteration = true;

	      /* Unfix current overflow page. */
	      pgbuf_unfix_and_init (thread_p, overflow_page);
	      return NO_ERROR;
	    }
	  /* We can handle all current objects. */
	}

      /* Process this overflow OID's. */
      error_code =
	btree_record_process_objects (thread_p, &bts->btid_int, BTREE_OVERFLOW_NODE, &ovf_record, 0, &stop,
				      btree_select_visible_object_for_range_scan, bts);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  pgbuf_unfix_and_init (thread_p, overflow_page);
	  return error_code;
	}
      /* Successful processing. */
      if (stop || bts->end_one_iteration || bts->end_scan || bts->is_interrupted)
	{
	  /* Early out. */
	  pgbuf_unfix_and_init (thread_p, overflow_page);
	  VPID_SET_NULL (&bts->O_vpid);
	  return NO_ERROR;
	}
      if (save_oid_count < bts->n_oids_read_last_iteration)
	{
	  /* Page had at least one visible object. */
	  VPID_COPY (&last_visible_overflow, &overflow_vpid);
	}
      /* Process next overflow page. */
      error_code = btree_get_next_overflow_vpid (thread_p, overflow_page, &overflow_vpid);
      if (error_code != NO_ERROR)
	{
	  assert_release (false);
	  pgbuf_unfix_and_init (thread_p, overflow_page);
	  return error_code;
	}
      prev_overflow_page = overflow_page;
      overflow_page = NULL;
    }
  if (prev_overflow_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, prev_overflow_page);
    }
  /* Entire key has been processed. */
  VPID_SET_NULL (&bts->O_vpid);

  /* Key has been consumed. */
  bts->key_status = BTS_KEY_IS_CONSUMED;
  /* Success. */
  return NO_ERROR;
}

/*
 * btree_select_visible_object_for_range_scan () - BTREE_PROCESS_OBJECT_FUNCTION
 *						   Function handles each found object based on type of index scan.
 *
 * return	   : Error code.
 * thread_p (in)   : Thread entry.
 * btid_int (in)   : B-tree info.
 * record (in)	   : Index record containing one key's objects.
 * object_ptr (in) : Pointer in record to current object (not used).
 * oid (in)	   : Current object OID.
 * class_oid (in)  : Current object class OID.
 * mvcc_info (in)  : Current object MVCC info.
 * stop (out)	   : Set to true if processing record should stop after this function execution.
 * args (in/out)   : BTREE_SCAN *.
 */
static int
btree_select_visible_object_for_range_scan (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * record,
					    char *object_ptr, OID * oid, OID * class_oid, BTREE_MVCC_INFO * mvcc_info,
					    bool * stop, void *args)
{
  BTREE_SCAN *bts = NULL;
  int error_code = NO_ERROR;
  MVCC_SNAPSHOT *snapshot = NULL;
  MVCC_REC_HEADER mvcc_header_for_snapshot;

  /* Assert expected arguments. */
  assert (args != NULL);
  assert (btid_int != NULL);
  assert (oid != NULL);
  assert (class_oid != NULL);
  assert (mvcc_info != NULL);
  assert (stop != NULL);

  /* args is the b-tree scan structure. */
  bts = (BTREE_SCAN *) args;

  /* This function first checks object eligibility. If eligible it will be then saved. Eligibility must pass several
   * filters: 1. Snapshot: object must be visible. 2. Match class: for unique indexes of hierarchical classes, query
   * may be executed on one class only. The class must be matched. 3. Key limit filters: First lower key limit and all
   * after upper key limit objects are ignored. Then object will be saved/processed differently depending on type of
   * scan: 1. MRO - object is checked against the current Top N objects. 2. Covering index: object and key are saved in
   * a list file. 3. ISS/regular scan: OID is saved in a buffer. NOTE: Unique indexes will stop after the first
   * visible objects. */

  /* Verify snapshot. */
  btree_mvcc_info_to_heap_mvcc_header (mvcc_info, &mvcc_header_for_snapshot);
  snapshot = bts->index_scan_idp != NULL ? bts->index_scan_idp->scan_cache.mvcc_snapshot : NULL;

  if (bts->index_scan_idp->check_not_vacuumed)
    {
      /* Check if object should have been vacuumed. */
      DISK_ISVALID disk_result = DISK_VALID;

      disk_result = vacuum_check_not_vacuumed_rec_header (thread_p, oid, class_oid, &mvcc_header_for_snapshot,
							  /* TODO: Actually node type is not accurate. */
							  bts->node_type);
      if (disk_result != DISK_VALID)
	{
	  /* Error or object should have been vacuumed. */
	  bts->index_scan_idp->not_vacuumed_res = disk_result;
	  if (disk_result == DISK_ERROR)
	    {
	      /* Error. */
	      ASSERT_ERROR_AND_SET (error_code);
	      return error_code;
	    }
	}
    }

  /* Check snapshot. */
  if (snapshot != NULL && snapshot->snapshot_fnc != NULL
      && snapshot->snapshot_fnc (thread_p, &mvcc_header_for_snapshot, snapshot) != SNAPSHOT_SATISFIED)
    {
      /* Snapshot not satisfied. Ignore object. */
      return NO_ERROR;
    }
  /* No snapshot or snapshot was satisfied. */

  if (BTREE_IS_UNIQUE (btid_int->unique_pk))
    {
      /* Key can have only one visible object. */
      bts->key_status = BTS_KEY_IS_CONSUMED;
      *stop = true;
      /* Fall through to handle current object. Processing this key will stop afterwards. */

      /* Verify class match. */
      if (!OID_ISNULL (&bts->match_class_oid) && !OID_EQ (&bts->match_class_oid, class_oid))
	{
	  /* Class not matched. */
	  return NO_ERROR;
	}
      /* Class was matched. */
    }

  /* Select object. */

  /* Check key limit filters */
  /* Only objects between lower key limit and lower+upper key limit are selected. First lower key limit objects are
   * skipped, and after another upper key limit objects scan is ended. */

  /* Lower key limit */
  if (bts->key_limit_lower != NULL && *bts->key_limit_lower > 0)
    {
      /* Do not copy object. Just decrement key_limit_lower until it is 0. */
      assert (!BTS_IS_INDEX_ILS (bts));
      (*bts->key_limit_lower)--;
      return NO_ERROR;
    }
  /* No lower key limit or lower key limit was already reached. */

  /* Upper key limit */
  if (bts->key_limit_upper != NULL && bts->n_oids_read_last_iteration >= *bts->key_limit_upper)
    {
      /* Upper limit reached. Stop scan. */
      assert (!BTS_IS_INDEX_ILS (bts));
      bts->end_scan = true;
      *stop = true;
      return NO_ERROR;
    }
  /* No upper key limit or upper key limit was not reached yet. */

  /* Must objects be read or just counted? */
  if (BTS_NEED_COUNT_ONLY (bts))
    {
      /* Just count. */
      assert (!BTS_IS_INDEX_ILS (bts));
      BTS_INCREMENT_READ_OIDS (bts);
      return NO_ERROR;
    }
  /* Read object. */

  /* Possible scans that can reach this code: - Multi-range-optimization. - Covering index. - ISS, if current op is
   * ISS_OP_DO_RANGE_SEARCH. - Regular index range scan. */

  if (BTS_IS_INDEX_MRO (bts))
    {
      /* Multiple range optimization */
      /* Add current key to TOP N sorted keys */
      /* Pass current key and next pseudo OID's to handle lock release when a candidate is thrown out of TOP N
       * structure. */
      bool mro_continue = true;
      error_code =
	btree_range_opt_check_add_index_key (thread_p, bts, &bts->index_scan_idp->multi_range_opt, oid, &mro_continue);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return error_code;
	}
      if (!mro_continue)
	{
	  /* Current item didn't fit in the TOP N keys, and the following items in current btree_range_search iteration
	   * will not be better. Go to end of scan. */
	  bts->end_scan = true;
	  *stop = true;
	}
      else
	{
	  /* Increment OID counter. */
	  BTS_INCREMENT_READ_OIDS (bts);
	}
      /* Finished handling object for MRO. */
      return NO_ERROR;
    }

  /* Possible scans that can reach this code: - Covering index. - ISS, if current op is ISS_OP_DO_RANGE_SEARCH. -
   * Regular index range scan. */

  if (BTS_IS_INDEX_COVERED (bts))
    {
      if (BTS_IS_INDEX_ILS (bts))
	{
	  /* Index loose scan. */
	  *stop = true;
	  bts->key_status = BTS_KEY_IS_CONSUMED;
	  /* Interrupt range scan. It must be restarted with a new range. */
	  bts->is_interrupted = true;

	  /* Since range scan must be moved on a totally different range, it must restart by looking for the first
	   * eligible key of the new range. Trick it to think this a new call of btree_range_scan. */
	  bts_reset_scan (thread_p, bts);

	  /* Adjust range of scan. */
	  error_code = btree_ils_adjust_range (thread_p, bts);
	  if (error_code != NO_ERROR)
	    {
	      ASSERT_ERROR ();
	      return error_code;
	    }

	  /* Covering index. */
	  error_code = btree_dump_curr_key (thread_p, bts, bts->key_filter, oid, bts->index_scan_idp);
	  if (error_code != NO_ERROR)
	    {
	      ASSERT_ERROR ();
	      return error_code;
	    }
	  btree_clear_key_value (&bts->clear_cur_key, &bts->cur_key);
	}
      else
	{
	  error_code = btree_dump_curr_key (thread_p, bts, bts->key_filter, oid, bts->index_scan_idp);
	  if (error_code != NO_ERROR)
	    {
	      ASSERT_ERROR ();
	      return error_code;
	    }
	}

      BTS_INCREMENT_READ_OIDS (bts);
      return NO_ERROR;
    }

  /* Possible scans that can reach this code: - ISS, if current op is ISS_OP_DO_RANGE_SEARCH. - Regular index range
   * scan. They are both treated in the same way (copied to OID buffer). */
  BTS_SAVE_OID_IN_BUFFER (bts, oid);

  assert (HEAP_ISVALID_OID (thread_p, oid) != DISK_INVALID);
  assert (HEAP_ISVALID_OID (thread_p, bts->index_scan_idp->oid_list->oidp) != DISK_INVALID);

  return NO_ERROR;
}

/*
 * btree_range_scan_find_fk_any_object () - BTREE_RANGE_SCAN_PROCESS_KEY_FUNC
 *
 * return	   : Error code.
 * thread_p (in)   : Thread entry.
 * bts (in)	   : B-tree scan info.
 */
static int
btree_range_scan_find_fk_any_object (THREAD_ENTRY * thread_p, BTREE_SCAN * bts)
{
  int error_code = NO_ERROR;	/* Error code. */
  bool stop = false;
  PAGE_PTR prev_ovf_page = NULL;
  RECDES peeked_ovf_recdes;
  VPID ovf_vpid = VPID_INITIALIZER;

  /* Assert expected arguments. */
  assert (bts != NULL);
  assert (bts->bts_other != NULL);

  /* Search and lock one object in key. */
  error_code =
    btree_record_process_objects (thread_p, &bts->btid_int, BTREE_LEAF_NODE, &bts->key_record, bts->offset, &stop,
				  btree_fk_object_does_exist, bts);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      return error_code;
    }
  if (stop == true)
    {
      return NO_ERROR;
    }

  /* Process overflow OID's. */
  VPID_COPY (&ovf_vpid, &bts->leaf_rec_info.ovfl);
  while (!VPID_ISNULL (&ovf_vpid))
    {
      /* Fix overflow page. */
      bts->O_page = pgbuf_fix (thread_p, &ovf_vpid, OLD_PAGE, PGBUF_LATCH_READ, PGBUF_UNCONDITIONAL_LATCH);
      if (bts->O_page == NULL)
	{
	  ASSERT_ERROR_AND_SET (error_code);
	  if (prev_ovf_page != NULL)
	    {
	      pgbuf_unfix_and_init (thread_p, prev_ovf_page);
	    }
	  return error_code;
	}
      if (prev_ovf_page != NULL)
	{
	  /* Now unfix previous overflow page. */
	  pgbuf_unfix_and_init (thread_p, prev_ovf_page);
	}
      /* Get overflow OID's record. */
      if (spage_get_record (thread_p, bts->O_page, 1, &peeked_ovf_recdes, PEEK) != S_SUCCESS)
	{
	  assert_release (false);
	  pgbuf_unfix_and_init (thread_p, bts->O_page);
	  return ER_FAILED;
	}
      /* Call internal function on overflow record. */
      error_code =
	btree_record_process_objects (thread_p, &bts->btid_int, BTREE_OVERFLOW_NODE, &peeked_ovf_recdes, 0, &stop,
				      btree_fk_object_does_exist, bts);
      if (error_code != NO_ERROR)
	{
	  /* Error . */
	  ASSERT_ERROR ();
	  if (bts->O_page != NULL)
	    {
	      pgbuf_unfix_and_init (thread_p, bts->O_page);
	    }
	  return error_code;
	}
      else if (stop)
	{
	  /* Stop. */
	  break;
	}
      assert (bts->O_page != NULL);

      /* Get VPID of next overflow page */
      error_code = btree_get_next_overflow_vpid (thread_p, bts->O_page, &ovf_vpid);
      if (error_code != NO_ERROR)
	{
	  assert_release (false);
	  pgbuf_unfix_and_init (thread_p, bts->O_page);
	  return error_code;
	}
      /* Save overflow page until next one is fixed to protect the link between them. */
      prev_ovf_page = bts->O_page;
    }

  /* Object processing stopped or ended. */
  assert (error_code == NO_ERROR);

  /* If overflow page is fixed, unfix it. */
  if (bts->O_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, bts->O_page);
    }
  if (bts->end_scan)
    {
      return NO_ERROR;
    }
  if (!bts->is_interrupted)
    {
      /* Key was fully consumed. We are here because no object was found. Since this key was the only one of interest,
       * scan can be stopped. */
      assert (OID_ISNULL (&((BTREE_FIND_FK_OBJECT *) bts->bts_other)->found_oid));
      bts->end_scan = true;
    }
  return NO_ERROR;
}

/*
 * btree_fk_object_does_exist () - Check whether current object exists (it must not be deleted and successfully locked).
 *
 * return	   : Error code.
 * thread_p (in)   : Thread entry.
 * btid_int (in)   : B-tree info.
 * record (in)	   : Index record containing one key's objects.
 * object_ptr (in) : Pointer in record to current object (not used).
 * oid (in)	   : Current object OID.
 * class_oid (in)  : Current object class OID.
 * mvcc_info (in)  : Current object MVCC info.
 * stop (out)	   : Set to true if processing record should stop after this function execution.
 * args (in/out)   : BTREE_SCAN *
 */
static int
btree_fk_object_does_exist (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * record, char *object_ptr, OID * oid,
			    OID * class_oid, BTREE_MVCC_INFO * mvcc_info, bool * stop, void *args)
{
  BTREE_SCAN *bts = (BTREE_SCAN *) args;
  BTREE_FIND_FK_OBJECT *find_fk_obj = NULL;
  MVCC_SATISFIES_DELETE_RESULT satisfy_delete;
  MVCC_REC_HEADER mvcc_header_for_check_delete;
  int lock_result;

  /* Assert expected arguments. */
  assert (bts != NULL);
  assert (bts->bts_other != NULL);
  assert (oid != NULL);
  assert (class_oid != NULL && !OID_ISNULL (class_oid));
  assert (mvcc_info != NULL);

  find_fk_obj = (BTREE_FIND_FK_OBJECT *) bts->bts_other;

  /* Is object not dirty and lockable? */

  btree_mvcc_info_to_heap_mvcc_header (mvcc_info, &mvcc_header_for_check_delete);
  satisfy_delete = mvcc_satisfies_delete (thread_p, &mvcc_header_for_check_delete);
  switch (satisfy_delete)
    {
    case DELETE_RECORD_DELETED:
    case DELETE_RECORD_SELF_DELETED:
      /* Object is already deleted. It doesn't exist. */
      return NO_ERROR;

    case DELETE_RECORD_INSERT_IN_PROGRESS:
#if defined (SERVER_MODE)
      /* Recently inserted. This can be ignored, since it is not inserted yet. To successfully insert, the inserter
       * should also obtain lock on primary key object (which is already held by current transaction). Current
       * transaction can consider that this object doesn't exist yet. */
      return NO_ERROR;
#else	/* !SERVER_MODE */		   /* SA_MODE */
      /* Impossible: no other active transactions. */
      assert_release (false);
      return ER_FAILED;
#endif /* SA_MODE */

    case DELETE_RECORD_DELETE_IN_PROGRESS:
#if defined (SERVER_MODE)
      /* Object is being deleted by an active transaction. We have to wait for that transaction to commit. Fall through
       * to suspend. */
      break;
#else	/* !SERVER_MODE */		   /* SA_MODE */
      /* Impossible: no other active transactions. */
      assert_release (false);
      return ER_FAILED;
#endif /* SA_MODE */

    case DELETE_RECORD_CAN_DELETE:
#if defined (SERVER_MODE)
      /* Try conditional lock */
      /* Make sure there is no other object already locked. */
      if (!OID_ISNULL (&find_fk_obj->locked_object))
	{
	  if (OID_EQ (&find_fk_obj->locked_object, oid))
	    {
	      /* Object already locked. */
	      assert (lock_has_lock_on_object (oid, class_oid, find_fk_obj->lock_mode) > 0);
	      lock_result = LK_GRANTED;
	    }
	  else
	    {
	      /* Current object must be unlocked. */
	      lock_unlock_object_donot_move_to_non2pl (thread_p, &find_fk_obj->locked_object, class_oid,
						       find_fk_obj->lock_mode);
	      OID_SET_NULL (&find_fk_obj->locked_object);
	    }
	}
      if (OID_ISNULL (&find_fk_obj->locked_object))
	{
	  /* Get conditional lock. */
	  lock_result = lock_object (thread_p, oid, class_oid, find_fk_obj->lock_mode, LK_COND_LOCK);
	}
#else	/* !SERVER_MODE */		   /* SA_MODE */
      lock_result = LK_GRANTED;
#endif /* SA_MODE */
      if (lock_result == LK_GRANTED)
	{
	  /* Object was successfully locked. Stop now. */
	  COPY_OID (&find_fk_obj->found_oid, oid);
	  bts->end_scan = true;
	  *stop = true;
#if defined (SERVER_MODE)
	  COPY_OID (&find_fk_obj->locked_object, oid);
#endif /* SERVER_MODE */
	  return NO_ERROR;
	}
      /* Conditional lock failed. Fall through to suspend. */
      break;
    }

#if defined (SA_MODE)
  /* Impossible to reach. */
  assert_release (false);
  return ER_FAILED;
#else	/* !SA_MODE */	       /* SERVER_MODE */
  /* Object may exist but could not be locked conditionally. */
  /* Unconditional lock on object. */
  /* Must release fixed pages first. */
  bts->is_interrupted = true;
  pgbuf_unfix_and_init (thread_p, bts->C_page);
  if (bts->O_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, bts->O_page);
    }

  /* Make sure another object was not already fixed. */
  if (!OID_ISNULL (&find_fk_obj->locked_object))
    {
      lock_unlock_object_donot_move_to_non2pl (thread_p, &find_fk_obj->locked_object, class_oid,
					       find_fk_obj->lock_mode);
      OID_SET_NULL (&find_fk_obj->locked_object);
    }
  lock_result = lock_object (thread_p, oid, class_oid, find_fk_obj->lock_mode, LK_UNCOND_LOCK);
  if (lock_result != LK_GRANTED)
    {
      int error_code = NO_ERROR;

      /* Lock failed. */
      error_code = er_errid ();
      if (error_code == NO_ERROR)
	{
	  /* Set an error code. */
	  error_code = ER_CANNOT_GET_LOCK;
	  er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, error_code, 0);
	}
      return error_code;
    }
  /* Lock successful. */
  /* Key will be checked again just to make sure object was not deleted or moved while current thread was suspended. */
  *stop = true;
  return NO_ERROR;
#endif /* SERVER_MODE */
}

/*
 * btree_undo_delete_physical () - Undo of physical delete from b-tree. Must insert back object and other required
 *				   information (class OID, MVCC info).
 *
 * return	   : Error code.
 * thread_p (in)   : Thread entry.
 * btid (in)	   : B-tree identifier.
 * key (in)	   : Key value.
 * class_oid (in)  : Class OID.
 * oid (in)	   : Instance OID.
 * mvcc_info (in)  : B-tree MVCC information.
 * undo_nxlsa (in) : UNDO next lsa for logical compensate.
 */
static int
btree_undo_delete_physical (THREAD_ENTRY * thread_p, BTID * btid, DB_VALUE * key, OID * class_oid, OID * oid,
			    BTREE_MVCC_INFO * mvcc_info, LOG_LSA * undo_nxlsa)
{
  if (prm_get_bool_value (PRM_ID_LOG_BTREE_OPS))
    {
      if (class_oid == NULL)
	{
	  class_oid = (OID *) (&oid_Null_oid);
	}
      _er_log_debug (ARG_FILE_LINE,
		     "BTREE_INSERT: Start undo physical delete %d|%d|%d, "
		     "class_oid %d|%d|%d, insert MVCCID=%llu delete MVCCID=%llu into index (%d, %d|%d).\n",
		     oid->volid, oid->pageid, oid->slotid, class_oid->volid, class_oid->pageid, class_oid->slotid,
		     mvcc_info->insert_mvccid, mvcc_info->delete_mvccid, btid->root_pageid, btid->vfid.volid,
		     btid->vfid.fileid);
    }
  return btree_insert_internal (thread_p, btid, key, class_oid, oid, SINGLE_ROW_INSERT, NULL, NULL, mvcc_info,
				undo_nxlsa, BTREE_OP_INSERT_UNDO_PHYSICAL_DELETE);
}

/*
 * btree_insert () - Insert new object into b-tree.
 *
 * return		  : Error code.
 * thread_p (in)	  : Thread entry.
 * btid (in)		  : B-tree identifier.
 * key (in)		  : Key value.
 * cls_oid (in)		  : Class OID.
 * oid (in)		  : Instance OID.
 * op_type (in)		  : Single-multi row operations.
 * unique_stat_info (in)  : Statistics collector used multi row operations.
 * unique (out)		  : Outputs if b-tree is unique when not NULL.
 * p_mvcc_rec_header (in) : Heap MVCC record header.
 */
int
btree_insert (THREAD_ENTRY * thread_p, BTID * btid, DB_VALUE * key, OID * cls_oid, OID * oid, int op_type,
	      btree_unique_stats * unique_stat_info, int *unique, MVCC_REC_HEADER * p_mvcc_rec_header)
{
  BTREE_MVCC_INFO mvcc_info = BTREE_MVCC_INFO_INITIALIZER;

  /* Assert expected arguments. */
  assert (oid != NULL);

  if (p_mvcc_rec_header != NULL)
    {
#if !defined (SERVER_MODE)
      assert_release (false);
#endif /* SERVER_MODE */
      btree_mvcc_info_from_heap_mvcc_header (p_mvcc_rec_header, &mvcc_info);
    }

  if (prm_get_bool_value (PRM_ID_LOG_BTREE_OPS))
    {
      if (cls_oid == NULL)
	{
	  cls_oid = (OID *) (&oid_Null_oid);
	}
      _er_log_debug (ARG_FILE_LINE,
		     "BTREE_INSERT: Start insert object %d|%d|%d, class_oid %d|%d|%d, insert MVCCID=%llu into "
		     "index (%d, %d|%d), op_type=%d.\n", oid->volid, oid->pageid, oid->slotid, cls_oid->volid,
		     cls_oid->pageid, cls_oid->slotid,
		     p_mvcc_rec_header != NULL ? MVCC_GET_INSID (p_mvcc_rec_header) : MVCCID_ALL_VISIBLE,
		     btid->root_pageid, btid->vfid.volid, btid->vfid.fileid, op_type);
    }

  /* Safe guard. */
  assert (!BTREE_MVCC_INFO_IS_DELID_VALID (&mvcc_info));

  return btree_insert_internal (thread_p, btid, key, cls_oid, oid, op_type, unique_stat_info, unique, &mvcc_info, NULL,
				BTREE_OP_INSERT_NEW_OBJECT);
}

/*
 * btree_mvcc_delete () - MVCC logical delete. Adds delete MVCCID to an existing object.
 *
 * return		  : Error code.
 * thread_p (in)	  : Thread entry.
 * btid (in)		  : B-tree identifier.
 * key (in)		  : Key value.
 * cls_oid (in)		  : Class OID.
 * oid (in)		  : Instance OID.
 * op_type (in)		  : Single-multi row operations.
 * unique_stat_info (in)  : Statistics collector used multi row operations.
 * unique (out)		  : Outputs if b-tree is unique when not NULL.
 * p_mvcc_rec_header (in) : Heap MVCC record header.
 */
int
btree_mvcc_delete (THREAD_ENTRY * thread_p, BTID * btid, DB_VALUE * key, OID * class_oid, OID * oid, int op_type,
		   btree_unique_stats * unique_stat_info, int *unique, MVCC_REC_HEADER * p_mvcc_rec_header)
{
  BTREE_MVCC_INFO mvcc_info = BTREE_MVCC_INFO_INITIALIZER;

  /* Assert expected arguments. */
  assert (oid != NULL);
  assert (p_mvcc_rec_header != NULL);

  if (prm_get_bool_value (PRM_ID_LOG_BTREE_OPS))
    {
      if (class_oid == NULL)
	{
	  class_oid = (OID *) (&oid_Null_oid);
	}
      _er_log_debug (ARG_FILE_LINE,
		     "BTREE_INSERT: Start MVCC delete object %d|%d|%d, class_oid %d|%d|%d, delete MVCCID=%llu into "
		     "index (%d, %d|%d), op_type=%d.\n", oid->volid, oid->pageid, oid->slotid, class_oid->volid,
		     class_oid->pageid, class_oid->slotid, MVCC_GET_DELID (p_mvcc_rec_header), btid->root_pageid,
		     btid->vfid.volid, btid->vfid.fileid, op_type);
    }

  btree_mvcc_info_from_heap_mvcc_header (p_mvcc_rec_header, &mvcc_info);

  /* Safe guard. */
  assert (BTREE_MVCC_INFO_IS_DELID_VALID (&mvcc_info));

  return btree_insert_internal (thread_p, btid, key, class_oid, oid, op_type, unique_stat_info, unique, &mvcc_info,
				NULL, BTREE_OP_INSERT_MVCC_DELID);
}

/*
 * btree_insert_internal () - Generic index function that inserts new data in a b-tree key.
 *
 * return		     : Error code.
 * thread_p (in)	     : Thread entry.
 * btid (in)		     : B-tree identifier.
 * key (in)		     : Key value.
 * class_oid (in)	     : Class OID.
 * oid (in)		     : Instance OID.
 * op_type (in)		     : Single/Multi row operation type.
 * unique_stat_info (in/out) : Unique stats info, used to track changes during multi-update operation.
 * unique (out)		     : Outputs true if index was unique, false otherwise.
 * mvcc_info (in)	     : B-tree MVCC information.
 * undo_nxlsa (in)	     : UNDO next lsa for logical compensate.
 * purpose (in)		     : B-tree insert purpose
 */
static int
btree_insert_internal (THREAD_ENTRY * thread_p, BTID * btid, DB_VALUE * key, OID * class_oid, OID * oid, int op_type,
		       btree_unique_stats * unique_stat_info, int *unique, BTREE_MVCC_INFO * mvcc_info,
		       LOG_LSA * undo_nxlsa, BTREE_OP_PURPOSE purpose)
{
  int error_code = NO_ERROR;	/* Error code. */
  BTID_INT btid_int;		/* B-tree info. */
  /* Search key helper which will point to where data should inserted. */
  BTREE_SEARCH_KEY_HELPER search_key = BTREE_SEARCH_KEY_HELPER_INITIALIZER;
  /* Insert helper. */
  BTREE_INSERT_HELPER insert_helper;
  /* Processing key function: can insert an object or just a delete MVCCID. */
  BTREE_PROCESS_KEY_FUNCTION *key_insert_func = NULL;

  /* Assert expected arguments. */
  assert (btid != NULL);
  assert (oid != NULL);
  /* Assert class OID is valid or not required; not required for undo delete */
  assert (purpose == BTREE_OP_INSERT_UNDO_PHYSICAL_DELETE || (class_oid != NULL && !OID_ISNULL (class_oid)));

  PERF_UTIME_TRACKER_START (thread_p, &insert_helper.time_track);

  /* Save OID, class OID and MVCC info in insert helper. */
  COPY_OID (BTREE_INSERT_OID (&insert_helper), oid);
  if (class_oid != NULL)
    {
      COPY_OID (BTREE_INSERT_CLASS_OID (&insert_helper), class_oid);
    }
  else
    {
      OID_SET_NULL (BTREE_INSERT_CLASS_OID (&insert_helper));
    }
  *BTREE_INSERT_MVCC_INFO (&insert_helper) = *mvcc_info;

  /* Is key NULL? */
  insert_helper.is_null = key == NULL || DB_IS_NULL (key) || btree_multicol_key_is_null (key);

  /* Set key function. */
  switch (purpose)
    {
    case BTREE_OP_INSERT_UNDO_PHYSICAL_DELETE:
      /* Set undo_nxlsa. */
      assert (undo_nxlsa != NULL);
      LSA_COPY (&insert_helper.compensate_undo_nxlsa, undo_nxlsa);
      /* Fall through. */
    case BTREE_OP_INSERT_NEW_OBJECT:
      key_insert_func = btree_key_insert_new_object;
      break;
    case BTREE_OP_INSERT_MVCC_DELID:
    case BTREE_OP_INSERT_MARK_DELETED:
#if defined (SA_MODE)
      /* We should not be here */
      assert (false);
#endif /* SA_MODE */
      key_insert_func = btree_key_find_and_insert_delete_mvccid;
      break;
    default:
      assert (false);
      return ER_FAILED;
    }
  insert_helper.purpose = purpose;

  /* Set operation type. */
  insert_helper.op_type = op_type;
  /* Set unique stats info. */
  insert_helper.unique_stats_info = unique_stat_info;

  /* Do we log the operations? Use for debug only. */
  insert_helper.log_operations = prm_get_bool_value (PRM_ID_LOG_BTREE_OPS);

  /* Is this an unique index and is operation type MULTI_ROW_UPDATE? Unique constraint violation will be treated
   * slightly different. */
  insert_helper.is_unique_multi_update = unique_stat_info != NULL && op_type == MULTI_ROW_UPDATE;
  /* Is HA enabled? The above exception will no longer apply. */
  insert_helper.is_ha_enabled = !HA_DISABLED ();

  /* Add more insert_helper initialization here. */

  /* Search for key leaf page and insert data. */
  error_code =
    btree_search_key_and_apply_functions (thread_p, btid, &btid_int, key, btree_fix_root_for_insert, &insert_helper,
					  btree_split_node_and_advance, &insert_helper, key_insert_func, &insert_helper,
					  &search_key, NULL);

  /* Free allocated resources. */
  if (insert_helper.printed_key != NULL)
    {
      db_private_free (thread_p, insert_helper.printed_key);
    }

#if defined (SERVER_MODE)
  /* Saved locked OID keeps the object that used to be first in unique key before new object was inserted. In either
   * case, if error occurred or if inserting new object was successful, keeping this lock is no longer necessary. If
   * insert was successful, key is protected by the newly inserted object, which is already locked. */
  if (!OID_ISNULL (&insert_helper.saved_locked_oid))
    {
      lock_unlock_object_donot_move_to_non2pl (thread_p, &insert_helper.saved_locked_oid,
					       &insert_helper.saved_locked_class_oid, X_LOCK);
    }
#endif /* SERVER_MODE */

  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      return error_code;
    }

  perfmon_inc_stat (thread_p, PSTAT_BT_NUM_INSERTS);

  if (unique != NULL)
    {
      /* Output unique. */
      *unique = (BTREE_IS_UNIQUE (btid_int.unique_pk) && error_code == NO_ERROR) ? 1 : 0;
    }

  if (BTREE_IS_UNIQUE (btid_int.unique_pk) && insert_helper.is_unique_multi_update && !insert_helper.is_ha_enabled
      && !insert_helper.is_unique_key_added_or_deleted)
    {
      assert (op_type == MULTI_ROW_UPDATE);
      assert (unique_stat_info != NULL);

      /* Key was not inserted/deleted. Correct unique_stat_info (which assumed that key will be inserted/deleted). */
      if (purpose == BTREE_OP_INSERT_NEW_OBJECT)
	{
	  // revert
	  unique_stat_info->delete_key_and_row ();
	  // insert just row
	  unique_stat_info->add_row ();
	}
      else if (purpose == BTREE_OP_INSERT_MVCC_DELID || purpose == BTREE_OP_INSERT_MARK_DELETED)
	{
	  // revert
	  unique_stat_info->insert_key_and_row ();
	  // delete only row
	  unique_stat_info->delete_row ();
	}
      else
	{
	  /* Unexpected. */
	  assert_release (false);
	  return ER_FAILED;
	}
    }
  if (insert_helper.is_unique_multi_update && !insert_helper.is_ha_enabled)
    {
      btree_insert_log (&insert_helper, "BTREE UNIQUE MULTI-UPDATE STATS: %s \n"
			BTREE_INSERT_HELPER_MSG ("\t")
			"\t" BTREE_ID_MSG "\n"
			"\t" "%s: new stats = %lld keys, %lld objects, %lld nulls.",
			(btree_is_insert_object_purpose (insert_helper.purpose)) ? "Insert" : "MVCC Delete",
			BTREE_INSERT_HELPER_AS_ARGS (&insert_helper), BTID_AS_ARGS (btid_int.sys_btid),
			(btree_is_insert_object_purpose (insert_helper.purpose)) ?
			(insert_helper.is_unique_key_added_or_deleted ? "Added new key" : "Did not add new key") :
			(insert_helper.is_unique_key_added_or_deleted) ? "Removed key" : "Did not remove key",
			unique_stat_info->get_key_count (), unique_stat_info->get_row_count (),
			unique_stat_info->get_null_count ());
    }

  return NO_ERROR;
}

/*
 * btree_fix_root_for_insert () - BTREE_ROOT_WITH_KEY_FUNCTION - fix root before inserting data in b-tree.
 *
 * return	       : Error code.
 * thread_p (in)       : Thread entry.
 * btid (in)	       : B-tree identifier.
 * btid_int (out)      : BTID_INT (B-tree data).
 * key (in)	       : Key value.
 * root_page (out)     : Output b-tree root page.
 * is_leaf (out)       : Output true if root is leaf page.
 * search_key (out)    : Output key search result (if root is also leaf).
 * stop (out)	       : Output true if advancing in b-tree should stop.
 * restart (out)       : Output true if advancing in b-tree should be restarted.
 * other_args (in/out) : BTREE_INSERT_HELPER *.
 *
 * NOTE: Besides fixing root page, this function can also modify the root header. This must be done only once.
 */
static int
btree_fix_root_for_insert (THREAD_ENTRY * thread_p, BTID * btid, BTID_INT * btid_int, DB_VALUE * key,
			   PAGE_PTR * root_page, bool * is_leaf, BTREE_SEARCH_KEY_HELPER * search_key, bool * stop,
			   bool * restart, void *other_args)
{
  BTREE_INSERT_HELPER *insert_helper = (BTREE_INSERT_HELPER *) other_args;
  BTREE_ROOT_HEADER *root_header = NULL;
  OID *notification_class_oid;
  int error_code;
  int key_len;

  /* Assert expected arguments. */
  assert (insert_helper != NULL);
  assert (root_page != NULL && *root_page == NULL);
  assert (btid != NULL);
  assert (btid_int != NULL);
  assert (search_key != NULL);

  /* Possible insert data operations: 1. Insert a new object along with other necessary informations (class OID and/or
   * insert MVCCID. 2. Undo of physical delete. If an object is physically removed from b-tree and operation must be
   * undone, the object with all its additional information existing before delete must be inserted. 3. Logical delete,
   * which inserts a delete MVCCID. */
  assert (btree_is_insert_data_purpose (insert_helper->purpose));

  /* Fixing root page. */
  insert_helper->is_root = true;
  if (insert_helper->is_first_try)
    {
      /* Fix root and get header/b-tree info to do some additional operations on b-tree. */
      *root_page =
	btree_fix_root_with_info (thread_p, btid, insert_helper->nonleaf_latch_mode, NULL, &root_header, btid_int);
      if (*root_page == NULL)
	{
	  ASSERT_ERROR_AND_SET (error_code);
	  goto error;
	}
    }
  else
    {
      /* Just fix root page. */
      *root_page = btree_fix_root_with_info (thread_p, btid, insert_helper->nonleaf_latch_mode, NULL, NULL, NULL);
      if (*root_page == NULL)
	{
	  ASSERT_ERROR_AND_SET (error_code);
	  goto error;
	}
      /* Root fixed. */
      /* Reset other flags relevant for traversal. */
      insert_helper->is_crt_node_write_latched = false;
      insert_helper->need_update_max_key_len = false;
      return NO_ERROR;
    }
  assert (*root_page != NULL);
  assert (root_header != NULL);
  assert (insert_helper->is_null
	  || TP_ARE_COMPARABLE_KEY_TYPES (DB_VALUE_DOMAIN_TYPE (key), btid_int->key_type->type->id));

  /* Do additional operations. */
  /* Next time this function is called, it must be just a restart of b-tree traversal and the additional operations
   * must not be executed again. Mark insert_helper to know to skip this part. */
  insert_helper->is_first_try = false;

  /* Set complete domain for MIDXKEYS. */
  if (key != NULL && DB_VALUE_DOMAIN_TYPE (key) == DB_TYPE_MIDXKEY)
    {
      key->data.midxkey.domain = btid_int->key_type;
    }
  if (insert_helper->log_operations && insert_helper->printed_key == NULL)
    {
      /* This is postponed here to make sure midxkey domain was initialized. */
      insert_helper->printed_key = pr_valstring (key);
      (void) SHA1Compute ((unsigned char *) insert_helper->printed_key, strlen (insert_helper->printed_key),
			  &insert_helper->printed_key_sha1);
    }

  if (insert_helper->purpose == BTREE_OP_INSERT_UNDO_PHYSICAL_DELETE
      || insert_helper->purpose == BTREE_OP_ONLINE_INDEX_UNDO_TRAN_DELETE)
    {
      /* Stop here. */
      /* Code after this: 1. Update unique statistics. In this case, they are updated by undone log records. 2. Create
       * overflow key file. Undoing a physical delete cannot create overflow file (the file should already exist if
       * that's the case). */
      /* Safe guard: there should be no physical delete of NULL keys. */
      assert (!insert_helper->is_null);

      if (BTREE_IS_UNIQUE (btid_int->unique_pk) && OID_ISNULL (BTREE_INSERT_CLASS_OID (insert_helper)))
	{
	  /* Top class OID is not packed for recovery. Save it here. */
	  COPY_OID (BTREE_INSERT_CLASS_OID (insert_helper), &btid_int->topclass_oid);
	}
      key_len = btree_get_disk_size_of_key (key);
      insert_helper->key_len_in_page = BTREE_GET_KEY_LEN_IN_PAGE (key_len);
      return NO_ERROR;
    }

  /* Update nulls, oids, keys statistics for unique indexes. */
  /* If transaction is not active (being rolled back), statistics don't need manual updating. They will be reverted
   * automatically by undo logs. NOTE that users to see the header statistics may have the transient values. */
  if (BTREE_IS_UNIQUE (btid_int->unique_pk))
    {
      btree_unique_stats incr;

      if (insert_helper->purpose == BTREE_OP_INSERT_MVCC_DELID
	  || insert_helper->purpose == BTREE_OP_INSERT_MARK_DELETED)
	{
	  /* Object is being logically deleted. */
	  if (insert_helper->is_null)
	    {
	      incr.delete_null_and_row ();
	    }
	  else
	    {
	      incr.delete_key_and_row ();
	    }
	}
      else
	{
	  /* Object is being inserted. */
	  if (insert_helper->is_null)
	    {
	      incr.insert_null_and_row ();
	    }
	  else
	    {
	      incr.insert_key_and_row ();
	    }
	}

      /* Update statistics. */
      /* Based on type of operation - single or multi, update the unique_stats_info structure or update the transaction
       * collected statistics. They will be reflected into global statistics later. */
      if (BTREE_IS_MULTI_ROW_OP (insert_helper->op_type))
	{
	  /* Update unique_stats_info. */
	  if (insert_helper->unique_stats_info == NULL)
	    {
	      assert_release (false);
	      error_code = ER_FAILED;
	      goto error;
	    }
	  (*insert_helper->unique_stats_info) += incr;
	}
      else
	{
	  /* Update transactions collected statistics. */
	  if (!btree_is_online_index_loading (insert_helper->purpose))
	    {
	      error_code = logtb_tran_update_unique_stats (thread_p, *btid, incr, true);
	      if (error_code != NO_ERROR)
		{
		  ASSERT_ERROR ();
		  goto error;
		}
	    }
	}
    }

  if (insert_helper->is_null)
    {
      /* Stop here. Object is not inserted in b-tree. */
      *stop = true;
      pgbuf_unfix_and_init (thread_p, *root_page);

      btree_insert_log (insert_helper, "A NULL object was %s. \n" BTREE_INSERT_HELPER_MSG ("\t")
			"\t" BTREE_ID_MSG,
			(insert_helper->purpose == BTREE_OP_INSERT_MVCC_DELID
			 || insert_helper->purpose == BTREE_OP_INSERT_MARK_DELETED) ? "deleted" : "inserted",
			BTREE_INSERT_HELPER_AS_ARGS (insert_helper), BTID_AS_ARGS (btid_int->sys_btid));
      return NO_ERROR;
    }

  if (insert_helper->purpose == BTREE_OP_INSERT_MVCC_DELID || insert_helper->purpose == BTREE_OP_INSERT_MARK_DELETED)
    {
      /* This is a deleted object. From here on, the code is for inserting keys only. */
      return NO_ERROR;
    }

  assert (btree_is_insert_object_purpose (insert_helper->purpose));

  /* Check if key length is too big and if an overflow key file needs to be created. */
  key_len = btree_get_disk_size_of_key (key);
  if (key_len >= BTREE_MAX_KEYLEN_INPAGE && VFID_ISNULL (&btid_int->ovfid))
    {
      /* Promote latch (if required). */
      error_code = pgbuf_promote_read_latch (thread_p, root_page, PGBUF_PROMOTE_SHARED_READER);
      if (error_code == ER_PAGE_LATCH_PROMOTE_FAIL)
	{
	  /* Unfix and re-fix root page. */
	  pgbuf_unfix_and_init (thread_p, *root_page);
	  *root_page = btree_fix_root_with_info (thread_p, btid, PGBUF_LATCH_WRITE, NULL, &root_header, btid_int);
	  if (*root_page == NULL)
	    {
	      ASSERT_ERROR_AND_SET (error_code);
	      goto error;
	    }
	}
      else if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto error;
	}
      else if (*root_page == NULL)
	{
	  ASSERT_ERROR_AND_SET (error_code);
	  goto error;
	}
      /* Root is write latched. */
      insert_helper->is_crt_node_write_latched = true;
      /* Check that overflow key file was not created by another. */
      if (VFID_ISNULL (&btid_int->ovfid))
	{
	  /* Create overflow key file. */

	  /* Start a system operation. */
	  log_sysop_start (thread_p);

	  /* Create file. */
	  error_code = btree_create_overflow_key_file (thread_p, btid_int);
	  if (error_code != NO_ERROR)
	    {
	      ASSERT_ERROR ();
	      log_sysop_abort (thread_p);
	      goto error;
	    }

	  /* Notification. */
	  if (!OID_ISNULL (BTREE_INSERT_CLASS_OID (insert_helper)))
	    {
	      notification_class_oid = BTREE_INSERT_CLASS_OID (insert_helper);
	    }
	  else
	    {
	      notification_class_oid = &btid_int->topclass_oid;
	    }
	  BTREE_SET_CREATED_OVERFLOW_KEY_NOTIFICATION (thread_p, key, BTREE_INSERT_OID (insert_helper),
						       notification_class_oid, btid, NULL);

	  /* Change the root header. */
	  log_append_undoredo_data2 (thread_p, RVBT_UPDATE_OVFID, &btid_int->sys_btid->vfid, *root_page, HEADER,
				     sizeof (VFID), sizeof (VFID), &root_header->ovfid, &btid_int->ovfid);
	  VFID_COPY (&root_header->ovfid, &btid_int->ovfid);
	  pgbuf_set_dirty (thread_p, *root_page, DONT_FREE);

	  /* Finish system operation. */
	  log_sysop_commit (thread_p);
	}
    }

  insert_helper->key_len_in_page = BTREE_GET_KEY_LEN_IN_PAGE (key_len);

  /* Success. */
  return NO_ERROR;

error:
  assert (error_code != NO_ERROR);
  ASSERT_ERROR ();
  if (*root_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, *root_page);
    }
  return error_code;
}

/*
 * btree_get_max_new_data_size () - Get new data size required based on node type and operation.
 *
 * return		  : Maximum require size for operation.
 * thread_p (in)	  : Thread entry.
 * btid_int (in)	  : B-tree info.
 * page (in)		  : B-tree node.
 * node_type (in)	  : B-tree node type.
 * key_len (in)		  : Key length to be considered for new entries.
 * helper (in)		  : B-tree insert helper.
 * known_to_be_found (in) : True if key was searched and found.
 */
static int
btree_get_max_new_data_size (THREAD_ENTRY * thread_p, BTID_INT * btid_int, PAGE_PTR page, BTREE_NODE_TYPE node_type,
			     int key_len, BTREE_INSERT_HELPER * helper, bool known_to_be_found)
{
  assert (btid_int != NULL);
  assert (page != NULL);
  assert (node_type == BTREE_NON_LEAF_NODE || node_type == BTREE_LEAF_NODE);
  assert (key_len > 0);
  assert (helper != NULL);

  if (node_type == BTREE_NON_LEAF_NODE)
    {
      return NON_LEAF_ENTRY_MAX_SIZE (key_len) + spage_slot_size ();
    }

  /* TODO: We can always know if key is found for leaf nodes. */
  switch (helper->purpose)
    {
    case BTREE_OP_INSERT_NEW_OBJECT:
    case BTREE_OP_INSERT_UNDO_PHYSICAL_DELETE:
    case BTREE_OP_ONLINE_INDEX_IB_INSERT:
    case BTREE_OP_ONLINE_INDEX_TRAN_INSERT:
    case BTREE_OP_ONLINE_INDEX_UNDO_TRAN_DELETE:
    case BTREE_OP_ONLINE_INDEX_TRAN_INSERT_DF:
      if (known_to_be_found)
	{
	  /* Possible inserted data: 1. New object (consider maximum size including all info). 2. Link to overflow page
	   * (and setting first object to max size).  In worst case scenario it will insert same data as a fixed size
	   * object. */
	  return BTREE_OBJECT_FIXED_SIZE (btid_int);
	}
      else
	{
	  /* A new entry max size (including new slot). */
	  return LEAF_ENTRY_MAX_SIZE (key_len) + spage_slot_size ();
	}

    case BTREE_OP_INSERT_MVCC_DELID:
    case BTREE_OP_INSERT_MARK_DELETED:
      /* Always a delete MVCCID is added. */
      return OR_MVCCID_SIZE;

    default:
      /* Unhandled. */
      assert_release (false);
      return ER_FAILED;
    }
}

/*
 * btree_split_node_and_advance () - BTREE_ADVANCE_WITH_KEY_FUNCTION used by btree_insert_internal while advancing
 *				     following key. It also has the role to make sure b-tree has enough space to
 *				     insert new data.
 *
 * return		 : Error code.
 * thread_p (in)	 : Thread entry.
 * btid_int (in)	 : B-tree data.
 * key (in)		 : Search key value.
 * crt_page (in)	 : Page of current node.
 * advance_to_page (out) : Fixed page of child node found by following key.
 * is_leaf (out)	 : Output true if current page is leaf node.
 * key_slotid (out)	 : Output slotid of key if found, otherwise NULL_SLOTID.
 * stop (out)		 : Output true if advancing in b-tree should be stopped.
 * restart (out)	 : Output true if advancing in b-tree should be restarted from top.
 * other_args (in/out)	 : BTREE_INSERT_HELPER *.
 */
static int
btree_split_node_and_advance (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key, PAGE_PTR * crt_page,
			      PAGE_PTR * advance_to_page, bool * is_leaf, BTREE_SEARCH_KEY_HELPER * search_key,
			      bool * stop, bool * restart, void *other_args)
{
  /* Insert helper: used to store insert specific data that can be used during the call off
   * btree_search_key_and_apply_functions. */
  BTREE_INSERT_HELPER *insert_helper = (BTREE_INSERT_HELPER *) other_args;
  int max_new_data_size = 0;	/* The maximum possible size of data to be inserted in current node. */
  int max_key_len = 0;		/* Maximum key length of a new entry in node. */
  int error_code = NO_ERROR;	/* Error code. */
  int key_count = 0;		/* Node key count. */
  BTREE_NODE_TYPE node_type;	/* Node type. */
  BTREE_NODE_HEADER *node_header = NULL;	/* Node header. */
  /* VPID's of newly allocated pages for split. Both can be used if the root is split, only first is used if non-root
   * node is split. */
  VPID new_page_vpid1 = VPID_INITIALIZER, new_page_vpid2 = VPID_INITIALIZER;
  VPID child_vpid = VPID_INITIALIZER;	/* VPID of child (based on the direction set by key). */
  VPID *crt_vpid = NULL;	/* VPID pointer for current node. */
  VPID advance_vpid = VPID_INITIALIZER;	/* VPID to advance to (hinted by split functions). */
  PAGE_PTR child_page = NULL;	/* Page pointer of child node. */
  PAGE_PTR new_page1 = NULL, new_page2 = NULL;	/* Page pointers to newly allocated pages. Both can be used if root is
						 * split, only first is used if non-root node is split. */
  PGSLOTID child_slotid;	/* Slot ID that points to child node. */
  bool is_new_key_possible = false;	/* Set to true if insert operation can add new keys to b-tree (and not just
					 * data in existing keys). */
  bool need_split = false;	/* Set to true if split is required. */
  bool need_update_max_key_len = false;	/* Set to true if the node max key length must be updated to the length of new
					 * key. */
  bool is_system_op_started = false;	/* Set to true when a system operations is started. Set to false when it is
					 * ended. Used to properly end system operation in case of errors. */
  bool is_child_leaf = false;	/* Set to true when current node fathers a leaf node. It is treated differently and it
				 * must be determined before fixing the child node page. */

#if !defined (NDEBUG)
  int parent_max_key_len = 0;	/* Used by debug to check the rule that parent max key length is always bigger or equal
				 * to child max key length. */
  int parent_node_level = 0;	/* Used by debug to check that level of parent node is always the incremented value of
				 * level of child node. */
#endif /* !NDEBUG */

  LOG_LSA save_lsa = LSA_INITIALIZER;
  LOG_LSA save_child_lsa = LSA_INITIALIZER;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (key != NULL && !DB_IS_NULL (key) && !btree_multicol_key_is_null (key));
  assert (crt_page != NULL && *crt_page != NULL);
  assert (advance_to_page != NULL && *advance_to_page == NULL);
  assert (is_leaf != NULL);
  assert (search_key != NULL);
  assert (stop != NULL);
  assert (restart != NULL);
  assert (insert_helper != NULL);

  page_key_boundary *page_boundaries =
    (insert_helper->insert_list != NULL && insert_helper->insert_list->m_use_page_boundary_check)
    ? &insert_helper->insert_list->m_boundaries : NULL;

#if defined (SERVER_MODE)
  if (LOG_ISRESTARTED ()
      && (insert_helper->purpose == BTREE_OP_INSERT_NEW_OBJECT || insert_helper->purpose == BTREE_OP_INSERT_MVCC_DELID))
    {
      /* vacuum will probably follow same path */
      pgbuf_notify_vacuum_follows (thread_p, *crt_page);
    }
#endif /* SERVER_MODE */

  /* Get informations on current node. */
  /* Node header. */
  node_header = btree_get_node_header (thread_p, *crt_page);
  if (node_header == NULL)
    {
      assert_release (false);
      error_code = ER_FAILED;
      goto error;
    }
  /* Leaf/Non-leaf node type. */
  node_type = (node_header->node_level == 1) ? BTREE_LEAF_NODE : BTREE_NON_LEAF_NODE;
  /* Key count. */
  key_count = btree_node_number_of_keys (thread_p, *crt_page);
  /* Safe guard. */
  assert (key_count >= 0);
  assert (key_count > 0 || node_type == BTREE_LEAF_NODE);

  /* Is new key possible? True if inserting new object or if undoing the removal of some key/object. */
  is_new_key_possible = btree_is_insert_object_purpose (insert_helper->purpose);

  /* Split algorithm: There are two types of splits: root split and normal split. 1. Root split: If there is not enough
   * space for new data in root, split it into three nodes: two nodes containing all previous entries and a new root
   * node to point to these nodes. This will increase the b-tree level.  After split, function will continue with one
   * of the two newly created nodes. 2. Normal split: If child doesn't have enough space to handle new insert data,
   * split it into two nodes and update current node entries. Current node will gain one additional entry, so the split
   * algorithm should make sure it always has enough space before checking its children. One of the two children
   * resulted from the split will be chosen to advance to. */
  /* Part of split algorithm is to keep the maximum key length for each node. The value kept by a node is actually the
   * maximum length of all keys found in all leaf pages of the sub-tree fathered by current node. One resulting rule is
   * that the maximum key length value for one node is always bigger than or equal to the maximum key length value for
   * any of its children. Maximum key length is used to estimate the size of future entries (in a defensive way). */
  /* NOTE 1: To optimize b-tree access, the algorithm assumes that no change is required and READ latch on nodes is
   * normally used. However if max key length must be update or if split is needed, latches must then be promoted to
   * write/exclusive. Promotion may sometimes fail (e.g. when there is already another promoter in waiting list). This
   * case is considered to be an exceptional and rare case, therefore it is allowed to restart b-tree traversal.
   * However, to avoid repeating traversals indefinetly, the second traversal is done using exclusive latches (which
   * should guarantee success). NOTE 2: Leaf nodes are always latched using exclusive latches (because they are changed
   * almost every time and using promotion can actually lead to poor performance). NOTE 3: Promotion of current page is
   * always done using ONLY_READER. This prevents dead-latches between three or more threads like the following: T1:
   * Holds READ on P1 and P2, waits on T2 for P1 promotion T2: Holds READ on P1, waits on T3 for READ on P2 T3: Holds
   * READ on P2 and another page, waits on T1 for P2 promotion */

  /* Root case. */
  if (insert_helper->is_root)
    {
      /* Check if root needs to split or update max key length. */

      /* Updating max key length is possible if new key can be added and if the length of the new key exceeds the
       * current max key length. */
      need_update_max_key_len = is_new_key_possible && insert_helper->key_len_in_page > node_header->max_key_len;

      /* Get maximum key length for a possible new entry in node. */
      max_key_len = need_update_max_key_len ? insert_helper->key_len_in_page : node_header->max_key_len;

      /* Compute the maximum possible size of data being inserted in node. */
      max_new_data_size =
	btree_get_max_new_data_size (thread_p, btid_int, *crt_page, node_type, max_key_len, insert_helper, false);

      /* Split is needed if there is a risk that inserted data doesn't fit the root node. */
      need_split = (max_new_data_size > spage_get_free_space_without_saving (thread_p, *crt_page, NULL));

      /* If root node should suffer changes, its latch must be promoted to exclusive. */
      if (insert_helper->nonleaf_latch_mode == PGBUF_LATCH_READ
	  /* root has read. */
	  && (need_split || need_update_max_key_len || node_type == BTREE_LEAF_NODE)
	  /* and requires write. */ )
	{
	  /* Promote latch. */
	  error_code = pgbuf_promote_read_latch (thread_p, crt_page, PGBUF_PROMOTE_SHARED_READER);
	  if (error_code == ER_PAGE_LATCH_PROMOTE_FAIL)
	    {
	      /* Retry fix with write latch. */
	      pgbuf_unfix_and_init (thread_p, *crt_page);
	      insert_helper->nonleaf_latch_mode = PGBUF_LATCH_WRITE;
	      *restart = true;
	      return NO_ERROR;
	    }
	  else if (error_code != NO_ERROR)
	    {
	      ASSERT_ERROR ();
	      goto error;
	    }
	  else if (*crt_page == NULL)
	    {
	      ASSERT_ERROR_AND_SET (error_code);
	      goto error;
	    }
	  assert (pgbuf_get_latch_mode (*crt_page) == PGBUF_LATCH_WRITE);
	  insert_helper->is_crt_node_write_latched = true;
	}

      if (need_update_max_key_len)
	{
	  assert (pgbuf_get_latch_mode (*crt_page) == PGBUF_LATCH_WRITE);

	  save_lsa = *pgbuf_get_lsa (*crt_page);

	  /* Update max key length. */
	  node_header->max_key_len = insert_helper->key_len_in_page;
	  error_code = btree_change_root_header_delta (thread_p, &btid_int->sys_btid->vfid, *crt_page, 0, 0, 0);
	  if (error_code != NO_ERROR)
	    {
	      ASSERT_ERROR ();
	      goto error;
	    }
	  pgbuf_set_dirty (thread_p, *crt_page, DONT_FREE);

	  btree_insert_log (insert_helper, "Update max_key_length to %d. \n"
			    "\t" PGBUF_PAGE_MODIFY_MSG ("root page") "\n" "\t" BTREE_ID_MSG,
			    node_header->max_key_len, PGBUF_PAGE_MODIFY_ARGS (*crt_page, &save_lsa),
			    BTID_AS_ARGS (btid_int->sys_btid));

	  /* If this node required to update its max key length, then also the children we meet will require to update
	   * their max key length. (rule being that parent->max_key_len >= child->max_key_len). */
	  insert_helper->need_update_max_key_len = true;
	  /* Set insert_helper->is_crt_node_write_latched to avoid trying promotion on current node. */
	  insert_helper->is_crt_node_write_latched = true;
	}

      if (need_split)
	{
	  assert (pgbuf_get_latch_mode (*crt_page) == PGBUF_LATCH_WRITE);

	  /* Split root node. */
	  assert (key_count >= 3);

	  /* Start system operation. */
	  log_sysop_start (thread_p);
	  is_system_op_started = true;

	  /* Create two new b-tree pages. */
	  /* First page. */
	  crt_vpid = pgbuf_get_vpid_ptr (*crt_page);
	  new_page1 = btree_get_new_page (thread_p, btid_int, &new_page_vpid1, crt_vpid);
	  if (new_page1 == NULL)
	    {
	      ASSERT_ERROR_AND_SET (error_code);
	      goto error;
	    }
	  /* Second page. */
	  new_page2 = btree_get_new_page (thread_p, btid_int, &new_page_vpid2, crt_vpid);
	  if (new_page2 == NULL)
	    {
	      ASSERT_ERROR_AND_SET (error_code);
	      goto error;
	    }

	  save_lsa = *pgbuf_get_lsa (*crt_page);

	  /* Split the root. */
	  error_code =
	    btree_split_root (thread_p, btid_int, *crt_page, new_page1, new_page2, crt_vpid, &new_page_vpid1,
			      &new_page_vpid2, node_type, key, insert_helper, &advance_vpid);
	  if (error_code != NO_ERROR)
	    {
	      ASSERT_ERROR ();
	      goto error;
	    }

	  btree_insert_log (insert_helper, "Split root page and create two children. \n"
			    PGBUF_PAGE_MODIFY_MSG ("root page") "\n"
			    "\t" PGBUF_PAGE_STATE_MSG ("left child page") "\n"
			    "\t" PGBUF_PAGE_STATE_MSG ("right child page") "\n"
			    "\t" BTREE_ID_MSG, PGBUF_PAGE_MODIFY_ARGS (*crt_page, &save_lsa),
			    PGBUF_PAGE_STATE_ARGS (new_page1), PGBUF_PAGE_STATE_ARGS (new_page2),
			    BTID_AS_ARGS (btid_int->sys_btid));

#if !defined(NDEBUG)
	  /* Safe guard checks */
	  (void) spage_check_num_slots (thread_p, *crt_page);
	  (void) spage_check_num_slots (thread_p, new_page1);
	  (void) spage_check_num_slots (thread_p, new_page2);
#endif

	  /* Unfix root and choose adequate child to advance to (based on given key). The child is hinted by
	   * btree_split_root through advance_vpid. */
	  pgbuf_unfix_and_init (thread_p, *crt_page);
	  insert_helper->is_crt_node_write_latched = false;	/* because of unfix */

	  /* Which child? */
	  if (VPID_EQ (&advance_vpid, &new_page_vpid1))
	    {
	      /* Go to new page 1. */
	      /* Unfix the other child. */
	      pgbuf_unfix_and_init (thread_p, new_page2);

	      /* End opened system operation. */
	      log_sysop_commit (thread_p);
	      is_system_op_started = false;

	      /* Choose child 1 to advance. */
	      *crt_page = new_page1;
	      new_page1 = NULL;

	      /* Set insert_helper->is_crt_node_write_latched to avoid trying promotion on current node. */
	      insert_helper->is_crt_node_write_latched = true;
	      assert (pgbuf_get_latch_mode (*crt_page) == PGBUF_LATCH_WRITE);
	    }
	  else if (VPID_EQ (&advance_vpid, &new_page_vpid2))
	    {
	      /* Go to new page 1. */
	      /* Unfix the other child. */
	      pgbuf_unfix_and_init (thread_p, new_page1);

	      /* End opened system operation. */
	      log_sysop_commit (thread_p);
	      is_system_op_started = false;

	      /* Choose child 2 to advance. */
	      *crt_page = new_page2;
	      new_page2 = NULL;

	      insert_helper->is_crt_node_write_latched = true;
	      assert (pgbuf_get_latch_mode (*crt_page) == PGBUF_LATCH_WRITE);
	    }
	  else
	    {
	      /* Impossible! */
	      assert_release (false);

	      pgbuf_unfix_and_init (thread_p, new_page1);
	      pgbuf_unfix_and_init (thread_p, new_page2);

	      /* Error */
	      error_code = ER_FAILED;
	      goto error;
	    }
	  assert (*crt_page != NULL);

	  /* Re-obtain node header. */
	  node_header = btree_get_node_header (thread_p, *crt_page);
	  if (node_header == NULL)
	    {
	      /* Unexpected. */
	      assert (false);
	      error_code = ER_FAILED;
	      goto error;
	    }

	  node_type = ((node_header->node_level == 1) ? BTREE_LEAF_NODE : BTREE_NON_LEAF_NODE);
	  insert_helper->is_root = false;
	}
      assert (node_type != BTREE_LEAF_NODE || pgbuf_get_latch_mode (*crt_page) == PGBUF_LATCH_WRITE);
    }

  /* Here, node represented by *crt_page has enough space to handle a child split. Either because it was root and was
   * split into two nodes in this call or because it was non-root and was split in previous iteration (if split was
   * required of course). */

  if (node_type == BTREE_LEAF_NODE)
    {
      assert (pgbuf_get_latch_mode (*crt_page) == PGBUF_LATCH_WRITE);

      /* No other child. Notify called this is a leaf node and return the slot of new key. */
      error_code = btree_search_leaf_page (thread_p, btid_int, *crt_page, key, search_key);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto error;
	}
      *is_leaf = true;
      return NO_ERROR;
    }

  /* Node is non-leaf. */
  /* Check if the child we would normally advance to from this node requires splitting. Also check if child should
   * update its max key length. */

  /* If next child is leaf, it must be treated differently. See NOTE 2,3 from the big comment. */
  is_child_leaf = (node_header->node_level == 2);

  /* Find and fix the child to advance to. Use write latch if the child is leaf or if it is already known that it will
   * require an update of max key length. */
  error_code = btree_search_nonleaf_page (thread_p, btid_int, *crt_page, key, &child_slotid, &child_vpid,
					  page_boundaries);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto error;
    }
  child_page = pgbuf_fix (thread_p, &child_vpid, OLD_PAGE, ((is_child_leaf || insert_helper->need_update_max_key_len)
							    ? PGBUF_LATCH_WRITE : insert_helper->nonleaf_latch_mode),
			  PGBUF_UNCONDITIONAL_LATCH);
  if (child_page == NULL)
    {
      ASSERT_ERROR_AND_SET (error_code);
      goto error;
    }

#if !defined (NDEBUG)
  /* Save parent max key length and node level. */
  parent_max_key_len = node_header->max_key_len;
  parent_node_level = node_header->node_level;
#endif

  insert_helper->is_root = false;

  /* Get child node header */
  node_header = btree_get_node_header (thread_p, child_page);
  if (node_header == NULL)
    {
      assert (false);
      error_code = er_errid ();
      goto error;
    }
  node_type = is_child_leaf ? BTREE_LEAF_NODE : BTREE_NON_LEAF_NODE;
  key_count = btree_node_number_of_keys (thread_p, child_page);
  assert (key_count >= 0);
  assert (key_count > 0 || is_child_leaf);

  assert (parent_max_key_len >= node_header->max_key_len);
  assert (parent_node_level == node_header->node_level + 1);

  /* Safe guard: if current node max key length was updated, it should be write latched. So either its max key length
   * was not updated or used latch mode must be write mode. */
  assert (!insert_helper->need_update_max_key_len || insert_helper->is_crt_node_write_latched);

  /* Make sure page is write latched if insert_helper indicates it is. Otherwise, we may do write-mode operations on
   * read-latched page. If insert_helper doesn't indicate the page is write-latched and it is, all we risk to do is an
   * unnecessary promote call. */
  assert ((!insert_helper->is_crt_node_write_latched && insert_helper->nonleaf_latch_mode != PGBUF_LATCH_WRITE)
	  || (pgbuf_get_latch_mode (*crt_page) == PGBUF_LATCH_WRITE));

  /* Is updating max key length necessary? True if: 1. Parent node already needed an update
   * (insert_helper->need_update_max_key_len is set to true). 2. Current node. */
  need_update_max_key_len = (insert_helper->need_update_max_key_len
			     || (is_new_key_possible && insert_helper->key_len_in_page > node_header->max_key_len));

  max_key_len = need_update_max_key_len ? insert_helper->key_len_in_page : node_header->max_key_len;
  max_new_data_size =
    btree_get_max_new_data_size (thread_p, btid_int, child_page, node_type, max_key_len, insert_helper, false);

  need_split = max_new_data_size > spage_get_free_space_without_saving (thread_p, child_page, NULL);

  /* If split is needed, we first need to make sure current node is latched exclusively. A new entry must be added.
   * Promoting latch from read to write may be required if the node is not already latched exclusively. Node is not
   * already exclusive if: 1. traversal is done in read mode (insert_helper->nonleaf_latch_mode). 2. node was not part
   * of a split and did not need an update of max key length. */
  if (need_split && insert_helper->nonleaf_latch_mode == PGBUF_LATCH_READ && !insert_helper->is_crt_node_write_latched)
    {
      /* Promote mode is always ONLY_READER */
      error_code = pgbuf_promote_read_latch (thread_p, crt_page, PGBUF_PROMOTE_ONLY_READER);
      if (error_code == ER_PAGE_LATCH_PROMOTE_FAIL)
	{
	  /* Could not promote. Restart insert from root by using write latch directly. */
	  insert_helper->nonleaf_latch_mode = PGBUF_LATCH_WRITE;
	  *restart = true;
	  pgbuf_unfix_and_init (thread_p, child_page);
	  pgbuf_unfix_and_init (thread_p, *crt_page);
	  insert_helper->is_crt_node_write_latched = false;
	  return NO_ERROR;
	}
      else if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto error;
	}
      else if (*crt_page == NULL)
	{
	  ASSERT_ERROR_AND_SET (error_code);
	  goto error;
	}
      assert (pgbuf_get_latch_mode (*crt_page) == PGBUF_LATCH_WRITE);
      insert_helper->is_crt_node_write_latched = true;
    }

  /* Do we need to promote child node latch mode? It must currently be read and should be promoted to write. */
  if ((need_split || need_update_max_key_len)	/* need write latch */
      && (insert_helper->nonleaf_latch_mode == PGBUF_LATCH_READ && !insert_helper->need_update_max_key_len
	  && !is_child_leaf) /* and had read latch */ )
    {
      error_code = pgbuf_promote_read_latch (thread_p, &child_page, PGBUF_PROMOTE_SHARED_READER);
      if (error_code == ER_PAGE_LATCH_PROMOTE_FAIL)
	{
	  /* Could not promote. Restart insert from root by using write latch directly. */
	  insert_helper->nonleaf_latch_mode = PGBUF_LATCH_WRITE;
	  *restart = true;
	  pgbuf_unfix_and_init (thread_p, child_page);
	  pgbuf_unfix_and_init (thread_p, *crt_page);
	  insert_helper->is_crt_node_write_latched = false;
	  return NO_ERROR;
	}
      else if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto error;
	}
      else if (child_page == NULL)
	{
	  ASSERT_ERROR_AND_SET (error_code);
	  goto error;
	}
    }

  if (need_update_max_key_len)
    {
      save_lsa = *pgbuf_get_lsa (child_page);

      /* Update max key length. */
      node_header->max_key_len = insert_helper->key_len_in_page;
      error_code = btree_node_header_redo_log (thread_p, &btid_int->sys_btid->vfid, child_page);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto error;
	}
      pgbuf_set_dirty (thread_p, child_page, DONT_FREE);

      btree_insert_log (insert_helper, "Update max key length to %d. \n"
			"\t" PGBUF_PAGE_MODIFY_MSG ("b-tree node page") "\n"
			"\t" BTREE_ID_MSG, node_header->max_key_len, PGBUF_PAGE_MODIFY_ARGS (child_page, &save_lsa),
			BTID_AS_ARGS (btid_int->sys_btid));

      /* If this node required to update its max key length, then also the children we meet will require to update
       * their max key length. (rule being that parent->max_key_len >= child->max_key_len). */
      insert_helper->need_update_max_key_len = true;
      insert_helper->is_crt_node_write_latched = true;
    }

  if (need_split)
    {
      log_sysop_start (thread_p);
      is_system_op_started = true;

      /* Get a new page */
      crt_vpid = pgbuf_get_vpid_ptr (*crt_page);
      new_page1 = btree_get_new_page (thread_p, btid_int, &new_page_vpid1, crt_vpid);
      if (new_page1 == NULL)
	{
	  ASSERT_ERROR_AND_SET (error_code);
	  goto error;
	}

      save_lsa = *pgbuf_get_lsa (*crt_page);
      save_child_lsa = *pgbuf_get_lsa (child_page);

      /* Split the node. */
      error_code =
	btree_split_node (thread_p, btid_int, *crt_page, child_page, new_page1, crt_vpid, &child_vpid, &new_page_vpid1,
			  child_slotid, node_type, key, insert_helper, &advance_vpid);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto error;
	}

      btree_insert_log (insert_helper, "Split child node, max key length =  %d. \n"
			"\t" PGBUF_PAGE_MODIFY_MSG ("parent node page") "\n"
			"\t" PGBUF_PAGE_MODIFY_MSG ("split node page") "\n"
			"\t" PGBUF_PAGE_STATE_MSG ("new node page") "\n"
			"\t" BTREE_ID_MSG, node_header->max_key_len,
			PGBUF_PAGE_MODIFY_ARGS (*crt_page, &save_lsa),
			PGBUF_PAGE_MODIFY_ARGS (child_page, &save_child_lsa),
			PGBUF_PAGE_STATE_ARGS (new_page1), BTID_AS_ARGS (btid_int->sys_btid));

      /* Choose which of the split nodes we need to advance to. */
      if (VPID_EQ (&advance_vpid, &child_vpid))
	{
	  /* Go to current child. */

	  /* Unfix newly created page. */
	  pgbuf_unfix_and_init (thread_p, new_page1);

	  /* End opened system operation. */
	  log_sysop_commit (thread_p);
	  is_system_op_started = false;

	  *advance_to_page = child_page;
	  insert_helper->is_crt_node_write_latched = true;

	  return NO_ERROR;
	}
      else if (VPID_EQ (&advance_vpid, &new_page_vpid1))
	{
	  /* Go to newly allocated node. */

	  /* Unfix current child page. */
	  pgbuf_unfix_and_init (thread_p, child_page);

	  /* End opened system operation. */
	  log_sysop_commit (thread_p);
	  is_system_op_started = false;

	  *advance_to_page = new_page1;
	  insert_helper->is_crt_node_write_latched = true;

	  return NO_ERROR;
	}
      else
	{
	  /* Impossible. */
	  assert_release (false);

	  pgbuf_unfix_and_init (thread_p, child_page);
	  pgbuf_unfix_and_init (thread_p, new_page1);
	  pgbuf_unfix_and_init (thread_p, *crt_page);

	  error_code = ER_FAILED;
	  goto error;
	}
    }
  assert (!need_split);
  /* Split was not required. Just advance to current child. */

  if (!need_update_max_key_len && insert_helper->nonleaf_latch_mode == PGBUF_LATCH_READ)
    {
      /* Node was fixed with read latch. */
      insert_helper->is_crt_node_write_latched = false;
    }
  *advance_to_page = child_page;

  /* Finished successfully. */
  return NO_ERROR;

error:
  /* Error. */
  if (new_page1 != NULL)
    {
      pgbuf_unfix_and_init (thread_p, new_page1);
    }
  if (new_page2 != NULL)
    {
      pgbuf_unfix_and_init (thread_p, new_page2);
    }
  if (is_system_op_started)
    {
      /*
       * Abort system operation, before after unfixing newpage1 and newpage2 and before unfixing child page.
       * Thus, new_page1 and newpage2 are deallocated during abort, so fix count must be 0.
       * Also, we have to be sure that no other transaction modify the child page, in order to correctly restore it.
       */
      log_sysop_abort (thread_p);
    }
  if (child_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, child_page);
    }
  assert (*advance_to_page == NULL);
  assert (error_code != NO_ERROR);
  ASSERT_ERROR ();
  return error_code;
}

/*
 * btree_key_insert_new_object () - BTREE_PROCESS_KEY_FUNCTION used for inserting new object in b-tree.
 *
 * return	   : Error code.
 * thread_p (in)   : Thread entry.
 * btid_int (in)   : B-tree info.
 * record (in)	   : B-tree leaf/overflow record.
 * object_ptr (in) : Pointer to object in record data.
 * oid (in)	   : Object OID.
 * class_oid (in)  : Object class OID.
 * mvcc_info (in)  : Object MVCC info.
 * stop (out)	   : Set to true if index is unique and visible object is found and if this is not a debug build.
 * args (in/out)   : BTREE_INSERT_HELPER *.
 */
static int
btree_key_insert_new_object (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key, PAGE_PTR * leaf_page,
			     BTREE_SEARCH_KEY_HELPER * search_key, bool * restart, void *other_args)
{
  /* B-tree insert helper used as argument for different btree insert functions. */
  BTREE_INSERT_HELPER *insert_helper = (BTREE_INSERT_HELPER *) other_args;
  int error_code = NO_ERROR;	/* Error code. */
  RECDES leaf_record;		/* Record descriptor for leaf key record. */
  char data_buffer[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];	/* Data buffer used to copy record data. */
  LEAF_REC leaf_info;		/* Leaf record info. */
  int offset_after_key;		/* Offset in record data where packed key is ended. */
  bool dummy_clear_key;		/* Dummy field used as argument for btree_read_record. */

  /* Recovery structures. */
  char rv_undo_data_buffer[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  char *rv_undo_data_bufalign = PTR_ALIGN (rv_undo_data_buffer, BTREE_MAX_ALIGN);
  int rv_undo_data_capacity = IO_MAX_PAGE_SIZE;

  char rv_redo_data_buffer[BTREE_RV_BUFFER_SIZE + BTREE_MAX_ALIGN];

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (key != NULL && !DB_IS_NULL (key) && !btree_multicol_key_is_null (key));
  assert (leaf_page != NULL && *leaf_page != NULL && pgbuf_get_latch_mode (*leaf_page) == PGBUF_LATCH_WRITE);
  assert (search_key != NULL);
  assert (search_key->slotid > 0 && search_key->slotid <= btree_node_number_of_keys (thread_p, *leaf_page) + 1);
  assert (restart != NULL);
  assert (insert_helper != NULL);
  assert (btree_is_insert_object_purpose (insert_helper->purpose));

  /* Do not allow inserting a deleted object. It should never happen Insert new object should insert objects with no
   * delete MVCCID. Rollback of object physical removal, cannot reach here with a deleted object. There are three
   * types of physical removal: - Delete object (should not have a delete MVCCID). - Rollback insert (should not have a
   * delete MVCCID). - Vacuum (deleted object). However, vacuum is not rollbacked. */
  assert (!BTREE_MVCC_INFO_IS_DELID_VALID (BTREE_INSERT_MVCC_INFO (insert_helper)));

  btree_perf_track_traverse_time (thread_p, insert_helper);

  /* Prepare log data */
  insert_helper->leaf_addr.offset = search_key->slotid;
  insert_helper->leaf_addr.pgptr = *leaf_page;
  insert_helper->leaf_addr.vfid = &btid_int->sys_btid->vfid;
  /* Based on recovery index it is know if this is MVCC-like operation or not. Particularly important for vacuum. */
  /* Undo physical delete will add a compensate record and doesn't require undo recovery data. */
  /* Prepare undo data. */
  if (insert_helper->purpose == BTREE_OP_INSERT_NEW_OBJECT
      || insert_helper->purpose == BTREE_OP_ONLINE_INDEX_TRAN_INSERT
      || insert_helper->purpose == BTREE_OP_ONLINE_INDEX_TRAN_INSERT_DF)
    {
      insert_helper->rcvindex =
	BTREE_MVCC_INFO_IS_INSID_NOT_ALL_VISIBLE (BTREE_INSERT_MVCC_INFO (insert_helper)) ? RVBT_MVCC_INSERT_OBJECT :
	RVBT_NON_MVCC_INSERT_OBJECT;
      insert_helper->rv_keyval_data = rv_undo_data_bufalign;
      error_code =
	btree_rv_save_keyval_for_undo (btid_int, key, BTREE_INSERT_CLASS_OID (insert_helper),
				       BTREE_INSERT_OID (insert_helper), BTREE_INSERT_MVCC_INFO (insert_helper),
				       insert_helper->purpose, rv_undo_data_bufalign, &insert_helper->rv_keyval_data,
				       &rv_undo_data_capacity, &insert_helper->rv_keyval_data_length);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto error;
	}
    }
  else				/* BTREE_OP_INSERT_UNDO_PHYSICAL_DELETE */
    {
      insert_helper->rcvindex = RVBT_RECORD_MODIFY_COMPENSATE;
    }
  insert_helper->rv_redo_data = PTR_ALIGN (rv_redo_data_buffer, BTREE_MAX_ALIGN);
  insert_helper->rv_redo_data_ptr = insert_helper->rv_redo_data;

  /* Does key already exist? */
  if (search_key->result != BTREE_KEY_FOUND)
    {
      /* Key doesn't exist. Insert new key. */
      error_code = btree_key_insert_new_key (thread_p, btid_int, key, *leaf_page, insert_helper, search_key);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto error;
	}
      if (insert_helper->rv_keyval_data != NULL && insert_helper->rv_keyval_data != rv_undo_data_bufalign)
	{
	  db_private_free_and_init (thread_p, insert_helper->rv_keyval_data);
	}
      btree_perf_track_time (thread_p, insert_helper);
      return NO_ERROR;
    }
  /* Key was found. Append new object to existing key. */

  /* Initialize leaf record */
  leaf_record.type = REC_HOME;
  leaf_record.area_size = DB_PAGESIZE;
  leaf_record.data = PTR_ALIGN (data_buffer, BTREE_MAX_ALIGN);

  if (BTREE_IS_UNIQUE (btid_int->unique_pk) && insert_helper->purpose == BTREE_OP_INSERT_NEW_OBJECT)
    {
      /* Call unique insert function. */
      error_code =
	btree_key_lock_and_append_object_unique (thread_p, btid_int, key, leaf_page, restart, search_key, insert_helper,
						 &leaf_record);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto error;
	}
      if (*restart == true)
	{
	  goto exit;
	}
    }
  else
    {
      /* Get record and call non-unique insert function. */
      if (spage_get_record (thread_p, *leaf_page, search_key->slotid, &leaf_record, COPY) != S_SUCCESS)
	{
	  assert_release (false);
	  error_code = ER_FAILED;
	  goto error;
	}
#if !defined (NDEBUG)
      (void) btree_check_valid_record (thread_p, btid_int, &leaf_record, BTREE_LEAF_NODE, NULL);
#endif /* !NDEBUG */

      error_code =
	btree_read_record (thread_p, btid_int, *leaf_page, &leaf_record, NULL, &leaf_info, BTREE_LEAF_NODE,
			   &dummy_clear_key, &offset_after_key, PEEK_KEY_VALUE, NULL);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto error;
	}

#if !defined (NDEBUG)
      if (oid_is_db_class (BTREE_INSERT_CLASS_OID (insert_helper)))
	{
	  /* Although the indexes on _db_class and _db_attribute are not unique, they cannot have duplicate OID's.
	   * Check here this consistency (no visible objects should exist). */
	  btree_key_record_check_no_visible (thread_p, btid_int, *leaf_page, search_key->slotid);
	}
#endif /* !NDEBUG */

      error_code =
	btree_key_append_object_non_unique (thread_p, btid_int, key, *leaf_page, search_key, &leaf_record,
					    offset_after_key, &leaf_info, &insert_helper->obj_info, insert_helper);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto error;
	}
    }

#if !defined (NDEBUG)
  (void) btree_verify_node (thread_p, btid_int, *leaf_page);
#endif /* !NDEBUG */

exit:
  if (insert_helper->rv_keyval_data != NULL && insert_helper->rv_keyval_data != rv_undo_data_bufalign)
    {
      db_private_free_and_init (thread_p, insert_helper->rv_keyval_data);
    }
  insert_helper->rv_keyval_data = NULL;

  btree_perf_track_time (thread_p, insert_helper);
  return error_code;

error:
  assert_release (error_code != NO_ERROR);
  goto exit;
}

/*
 * btree_key_insert_new_key () - Insert new key in b-tree.
 *
 * return	      : Error code.
 * thread_p (in)      : Thread entry.
 * btid_int (in)      : B-tree info.
 * key (in)	      : Key value.
 * leaf_page (in)     : Leaf node page.
 * insert_helper (in) : Insert helper.
 * search_key (in)    : Search key result.
 */
static int
btree_key_insert_new_key (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key, PAGE_PTR leaf_page,
			  BTREE_INSERT_HELPER * insert_helper, BTREE_SEARCH_KEY_HELPER * search_key)
{
  int error_code = NO_ERROR;
  int key_len;
  int key_type = BTREE_NORMAL_KEY;
  int key_cnt;
  DB_VALUE local_key;
  RECDES record;
  char data_buffer[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  BTREE_NODE_HEADER *node_header;
  int rv_redo_data_length;
  bool update_max_key_length = false;
  DB_VALUE *new_key = key;

  LOG_LSA prev_lsa;

  /* Redo recovery. */
  /* One page size buffer can handle one b-tree record entirely and any additional recovery data (e.g. debug info). */
  char rv_redo_recovery_buffer[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  char *rv_redo_data = PTR_ALIGN (rv_redo_recovery_buffer, BTREE_MAX_ALIGN);
  char *rv_redo_data_ptr = rv_redo_data;
  /* Do not use insert_helper redo structures since they may not be able to handle the entire record. */

  /* Insert new key into search_key->slotid. */
  insert_helper->is_unique_key_added_or_deleted = true;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (key != NULL && !DB_IS_NULL (key) && !btree_multicol_key_is_null (key));
  assert (leaf_page != NULL && btree_get_node_level (thread_p, leaf_page) == 1
	  && pgbuf_get_latch_mode (leaf_page) == PGBUF_LATCH_WRITE);
  assert (insert_helper != NULL);
  assert (search_key != NULL && search_key->result != BTREE_KEY_FOUND);
  assert (search_key->slotid > 0 && search_key->slotid <= btree_node_number_of_keys (thread_p, leaf_page) + 1);
  assert (insert_helper->rv_redo_data != NULL && insert_helper->rv_redo_data_ptr != NULL);
  assert (insert_helper->is_system_op_started == false);
#if defined (SERVER_MODE)
  assert ((btree_is_online_index_loading (insert_helper->purpose)) || !BTREE_IS_UNIQUE (btid_int->unique_pk)
	  || log_is_in_crash_recovery () || btree_check_locking_for_insert_unique (thread_p, insert_helper));
#endif /* SERVER_MODE */

  /* Insert new key. */
  db_make_null (&local_key);

  key_len = btree_get_disk_size_of_key (key);
  if (key_len >= BTREE_MAX_KEYLEN_INPAGE)
    {
      key_type = BTREE_OVERFLOW_KEY;

      log_sysop_start (thread_p);
      insert_helper->is_system_op_started = true;
    }
  else
    {
      int diff_column;

      diff_column = btree_node_common_prefix (thread_p, btid_int, leaf_page);
      if (diff_column > 0)
	{
	  /* Remove columns from key value. */
	  /* Use local_key as buffer. */
	  new_key = &local_key;
	  pr_clone_value (key, new_key);
	  pr_midxkey_remove_prefix (new_key, diff_column);
	}
      else if (diff_column < 0)
	{
	  ASSERT_ERROR ();
	  return diff_column;
	}
    }
  record.type = REC_HOME;
  record.data = PTR_ALIGN (data_buffer, MAX_ALIGNMENT);
  record.area_size = DB_PAGESIZE;
  error_code =
    btree_write_record (thread_p, btid_int, NULL, new_key, BTREE_LEAF_NODE, key_type, key_len, false,
			BTREE_INSERT_CLASS_OID (insert_helper), BTREE_INSERT_OID (insert_helper),
			BTREE_INSERT_MVCC_INFO (insert_helper), &record);
  if (new_key == &local_key)
    {
      pr_clear_value (&local_key);
    }
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto error;
    }

#if !defined (NDEBUG)
  (void) btree_check_valid_record (thread_p, btid_int, &record, BTREE_LEAF_NODE, NULL);
#endif

  /* Node header will be updated. */
  node_header = btree_get_node_header (thread_p, leaf_page);
  if (node_header == NULL)
    {
      assert_release (false);
      error_code = ER_FAILED;
      goto error;
    }

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  /* Nothing should fail after spage_insert_at! */
  if (spage_insert_at (thread_p, leaf_page, search_key->slotid, &record) != SP_SUCCESS)
    {
      assert_release (false);
      error_code = ER_FAILED;
      goto error;
    }

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  key_cnt = btree_node_number_of_keys (thread_p, leaf_page);
  key_len = BTREE_GET_KEY_LEN_IN_PAGE (key_len);
  /* Do not write log for updating header. Redo recovery function of insert key will know to update it. */
  if (key_len > node_header->max_key_len)
    {
      update_max_key_length = true;
      node_header->max_key_len = key_len;
    }


  assert (node_header->split_info.pivot >= 0 && key_cnt > 0);
  btree_split_next_pivot (&node_header->split_info, (float) search_key->slotid / key_cnt, key_cnt);

  /* Log */
  assert (insert_helper->leaf_addr.offset == search_key->slotid);

  /* Redo logging. */
  LOG_RV_RECORD_SET_MODIFY_MODE (&insert_helper->leaf_addr, LOG_RV_RECORD_INSERT);
#if !defined (NDEBUG)
  /* For debugging info. */
  BTREE_RV_REDO_SET_DEBUG_INFO (&insert_helper->leaf_addr, rv_redo_data_ptr, btid_int, BTREE_RV_DEBUG_ID_INS_KEY);
#endif /* !NDEBUG */
  if (update_max_key_length)
    {
      /* Put key length. */
      rv_redo_data_ptr = or_pack_int (rv_redo_data_ptr, key_len);
      BTREE_RV_SET_UPDATE_MAX_KEY_LEN (&insert_helper->leaf_addr);
    }
  /* Put record data. */
  memcpy (rv_redo_data_ptr, record.data, record.length);
  rv_redo_data_ptr += record.length;

  /* We need to log previous lsa. */
  LSA_COPY (&prev_lsa, pgbuf_get_lsa (leaf_page));

  /* Add logging. */
  rv_redo_data_length = CAST_BUFLEN (rv_redo_data_ptr - rv_redo_data);
  assert (rv_redo_data_length < DB_PAGESIZE);

  btree_rv_log_insert_object (thread_p, *insert_helper, insert_helper->leaf_addr, 0, rv_redo_data_length, NULL,
			      rv_redo_data);

  if (insert_helper->is_system_op_started)
    {
      // also end sysop
      btree_insert_sysop_end (thread_p, insert_helper);
    }

  if (insert_helper->log_operations)
    {
      if (key_type == BTREE_OVERFLOW_KEY)
	{
	  OR_BUF buf_vpid_key;
	  VPID vpid_key = VPID_INITIALIZER;
	  int rc = NO_ERROR;

	  OR_BUF_INIT (buf_vpid_key, record.data + record.length - DISK_VPID_ALIGNED_SIZE, DISK_VPID_ALIGNED_SIZE);
	  vpid_key.pageid = or_get_int (&buf_vpid_key, &rc);
	  vpid_key.volid = or_get_short (&buf_vpid_key, &rc);

	  assert (!VPID_ISNULL (&vpid_key));
	  btree_insert_log (insert_helper, BTREE_INSERT_MODIFY_MSG ("New overflow key %d|%d"),
			    VPID_AS_ARGS (&vpid_key),
			    BTREE_INSERT_MODIFY_ARGS (thread_p, insert_helper, leaf_page, &prev_lsa, true,
						      search_key->slotid, record.length, btid_int->sys_btid));
	}
      else
	{
	  btree_insert_log (insert_helper, BTREE_INSERT_MODIFY_MSG ("New key"),
			    BTREE_INSERT_MODIFY_ARGS (thread_p, insert_helper, leaf_page, &prev_lsa, true,
						      search_key->slotid, record.length, btid_int->sys_btid));
	}
    }

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  pgbuf_set_dirty (thread_p, leaf_page, DONT_FREE);

#if !defined(NDEBUG)
  if (prm_get_integer_value (PRM_ID_ER_BTREE_DEBUG) & BTREE_DEBUG_DUMP_SIMPLE)
    {
      VPID *vpid = pgbuf_get_vpid_ptr (leaf_page);
      fprintf (stdout, "btree insert at (%d:%d:%d) with key:", vpid->volid, vpid->pageid, search_key->slotid);
      db_value_print (key);
      fprintf (stdout, "\n");
    }
#endif

#if !defined(NDEBUG)
  (void) btree_verify_node (thread_p, btid_int, leaf_page);
#endif

  return NO_ERROR;

error:
  assert (error_code != NO_ERROR);

  if (insert_helper->is_system_op_started)
    {
      log_sysop_abort (thread_p);
      insert_helper->is_system_op_started = false;
    }
  return error_code;
}

/*
 * btree_key_insert_does_leaf_need_split () - Check if there is not enough space in leaf node to handle new object.
 *
 * return	      : True if there is not enough space in page.
 * thread_p (in)      : Thread entry.
 * btid_int (in)      : B-tree info.
 * leaf_page (in)     : Leaf page.
 * insert_helper (in) : Insert helper.
 * search_key (in)    : Search key result.
 */
static bool
btree_key_insert_does_leaf_need_split (THREAD_ENTRY * thread_p, BTID_INT * btid_int, PAGE_PTR leaf_page,
				       BTREE_INSERT_HELPER * insert_helper, BTREE_SEARCH_KEY_HELPER * search_key)
{
  int max_new_data_size = 0;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (leaf_page != NULL && btree_get_node_level (thread_p, leaf_page) == 1);
  assert (insert_helper != NULL);
  assert (search_key != NULL);

  if (search_key->result == BTREE_KEY_FOUND)
    {
      /* Does a new object fit the page? */
      return (BTREE_OBJECT_MAX_SIZE > spage_get_free_space_without_saving (thread_p, leaf_page, NULL));
    }
  else
    {
      /* Does a new key fit the page? */
      max_new_data_size = BTREE_NEW_ENTRY_MAX_SIZE (insert_helper->key_len_in_page, BTREE_LEAF_NODE);
      return (max_new_data_size > spage_max_space_for_new_record (thread_p, leaf_page));
    }
}

/*
 * btree_key_lock_and_append_object_unique () - Append new object into an existing unique index key.
 *						New objects are always inserted at the beginning of
 *						the key (as long as unique constraint is not violated).
 *
 * return	       : Error code.
 * thread_p (in)       : Thread entry.
 * btid_int (in)       : B-tree info.
 * key (in)	       : Inserted key.
 * leaf (in/out)       : Pointer to leaf page (can be re-fixed).
 * restart (out)       : Outputs true when restarting from b-tree root is required.
 * search_key (in/out) : Search key result.
 * insert_helper (in)  : Insert operation helper structure.
 * leaf_record (in)    : Preallocated record descriptor used to read b-tree record.
 */
static int
btree_key_lock_and_append_object_unique (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key, PAGE_PTR * leaf,
					 bool * restart, BTREE_SEARCH_KEY_HELPER * search_key,
					 BTREE_INSERT_HELPER * insert_helper, RECDES * leaf_record)
{
  int error_code = NO_ERROR;	/* Error code. */
  BTREE_OBJECT_INFO first_object;	/* Current first object in record. It will be replaced. */
  LEAF_REC leaf_info;		/* Leaf record info. */
  int offset_after_key;		/* Offset in record where packed key ends. */
  bool dummy_clear_key;		/* Dummy */
  /* Used by btree_key_find_and_lock_unique. */
  BTREE_FIND_UNIQUE_HELPER find_unique_helper = BTREE_FIND_UNIQUE_HELPER_INITIALIZER;
  MVCC_SNAPSHOT mvcc_snapshot_dirty;	/* Dirty snapshot used to count visible objects for multi-update. */
  bool is_key_record_read = false;	/* Set to true when key record is read (btree_read_record function was called). */
  int max_visible_oids = 1;	/* Used to check visible OID's for REPEATABLE READ isolation. */
  MVCC_SNAPSHOT *mvcc_snapshot = NULL;	/* Used to check visibility for REPEATABLE READ isolation. */
  int num_visible = 0;		/* Used to count number of visible objects. */

#if defined (SERVER_MODE)
  LOG_LSA saved_leaf_lsa;	/* Save page LSA before locking the first object in record. If LSA is changed, it is no
				 * longer guaranteed that page has enough space for new key/object. We need to be
				 * conservative and check it. */
#endif /* SERVER_MODE */

  /* Assert expected arguments. */
  assert (btid_int != NULL && BTREE_IS_UNIQUE (btid_int->unique_pk));
  assert (key != NULL);
  assert (leaf != NULL);
  assert (restart != NULL);
  assert (search_key != NULL && search_key->result == BTREE_KEY_FOUND);
  assert (insert_helper->rv_redo_data != NULL && insert_helper->rv_redo_data_ptr != NULL);
  assert (insert_helper->purpose == BTREE_OP_INSERT_NEW_OBJECT);
#if defined (SERVER_MODE)
  assert (log_is_in_crash_recovery () || btree_check_locking_for_insert_unique (thread_p, insert_helper));
#endif /* SERVER_MODE */

  /* Insert object in the beginning of leaf record if unique constraint is not violated. Step 1: Protect key by
   * locking its first object. Every transaction that insert or delete objects will follow this rule. So, the inserter
   * must first lock the first object, check its status and decide if insert is possible or if it would violation
   * unique constraint.  After locking the first object, if it is deleted and committed, then unique constraint would
   * not be violated. Otherwise, if the object is not deleted (and nobody else is trying to delete it), inserting new
   * object is no longer accepted.  Use btree_key_find_and_lock_unique_of_unique to find and lock the first object.
   * Step 2: Once the first object is locked and it is established that unique constraint is preserved, adding object
   * to key record can be done.  Because the first object is always considered last key version, inserting new object
   * must be done in the beginning of leaf record. So, the current first object must be relocated (it simulates a
   * regular insert and follows the regular insert rules).  Then, the first object is replaced with new object. */

#if defined (SERVER_MODE)
  /* Transfer locked object from insert helper to find unique helper. */
  COPY_OID (&find_unique_helper.locked_oid, &insert_helper->saved_locked_oid);
  COPY_OID (&find_unique_helper.locked_class_oid, &insert_helper->saved_locked_class_oid);

  LSA_COPY (&saved_leaf_lsa, pgbuf_get_lsa (*leaf));
#endif /* SERVER_MODE */

  find_unique_helper.lock_mode = X_LOCK;
  error_code =
    btree_key_find_and_lock_unique_of_unique (thread_p, btid_int, key, leaf, search_key, restart, &find_unique_helper);
#if defined (SERVER_MODE)
  /* Transfer locked object from find unique helper to insert helper. */
  COPY_OID (&insert_helper->saved_locked_oid, &find_unique_helper.locked_oid);
  COPY_OID (&insert_helper->saved_locked_class_oid, &find_unique_helper.locked_class_oid);
#endif /* SERVER_MODE */

  if (error_code != NO_ERROR || *restart)
    {
      /* Error occurred or failed to lock key object and keep a relevant leaf node. Return now. */
      return error_code;
    }
  /* No error, object was locked and key leaf node is held. */
  assert (*leaf != NULL);

  /* Slot ID and page pointer may have changed. Update insert_helper->leaf_addr. */
  insert_helper->leaf_addr.offset = search_key->slotid;
  insert_helper->leaf_addr.pgptr = *leaf;

#if defined (SERVER_MODE)
  if (!LSA_EQ (&saved_leaf_lsa, pgbuf_get_lsa (*leaf)))
    {
      /* Does leaf need split? */
      if (btree_key_insert_does_leaf_need_split (thread_p, btid_int, *leaf, insert_helper, search_key))
	{
	  /* We need to go back from top and split leaf. */
	  *restart = true;
	  return NO_ERROR;
	}
    }
#endif /* SERVER_MODE */

  if (search_key->result != BTREE_KEY_FOUND)
    {
      /* Key was deleted or vacuumed. */
      /* Insert key directly. */
      return btree_key_insert_new_key (thread_p, btid_int, key, *leaf, insert_helper, search_key);
    }

  if (!find_unique_helper.found_object && logtb_find_current_isolation (thread_p) >= TRAN_REPEATABLE_READ)
    {
      /* This could be an object deleted but still visible to me. */
      /* The problem is reading the object next time. Old object, even if it was deleted, on the next read will be
       * visible to me. This object is inserted by me, so it is also visible to me. This means I will see two different
       * objects that have this key, which is obviously a violation of unique constraint. READ COMMITTED doesn't have
       * this problem, since on the next statement it will refresh its snapshot and old object will no longer be
       * visible (even if it was with this snapshot). */
      /* TODO: Is this required in STAND ALONE? */

      /* Get current key record. */
      if (spage_get_record (thread_p, *leaf, search_key->slotid, leaf_record, COPY) != S_SUCCESS)
	{
	  assert_release (false);
	  return ER_FAILED;
	}

#if !defined (NDEBUG)
      (void) btree_check_valid_record (thread_p, btid_int, leaf_record, BTREE_LEAF_NODE, key);
#endif

      /* Read record. */
      error_code =
	btree_read_record (thread_p, btid_int, *leaf, leaf_record, NULL, &leaf_info, BTREE_LEAF_NODE, &dummy_clear_key,
			   &offset_after_key, PEEK_KEY_VALUE, NULL);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return error_code;
	}
      /* Don't repeat key record read. */
      is_key_record_read = true;

      /* Count visible objects considering transaction snapshot. */
      mvcc_snapshot = logtb_get_mvcc_snapshot (thread_p);
      error_code =
	btree_get_num_visible_from_leaf_and_ovf (thread_p, btid_int, leaf_record, offset_after_key, &leaf_info,
						 &max_visible_oids, mvcc_snapshot, &num_visible);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return error_code;
	}
      else if (num_visible > 0)
	{
	  /* Unique constraint violation. */
	  if (prm_get_bool_value (PRM_ID_UNIQUE_ERROR_KEY_VALUE))
	    {
	      char *keyval = pr_valstring (key);
	      er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_UNIQUE_VIOLATION_WITHKEY, 1,
		      (keyval == NULL) ? "(null)" : keyval);
	      if (keyval != NULL)
		{
		  db_private_free (thread_p, keyval);
		}
	      return ER_UNIQUE_VIOLATION_WITHKEY;
	    }
	  else
	    {
	      /* Object already exists. Unique constraint violation. */
	      BTREE_SET_UNIQUE_VIOLATION_ERROR (thread_p, key, BTREE_INSERT_OID (insert_helper),
						BTREE_INSERT_CLASS_OID (insert_helper), btid_int->sys_btid, NULL);
	      return ER_BTREE_UNIQUE_FAILED;
	    }
	}
    }
  /* No visible objects or isolation not >= RR */

  /* Unique constraint may be violated if there is already a visible object and if this is not recovery
   * (BTREE_OP_INSERT_UNDO_PHYSICAL_DELETE). Unique constraint is violated in this case, except if op_type is
   * MULTI-ROW-UPDATE. In this case, a duplicate key can be allowed, as long as it will be deleted until the end of
   * query execution (this is checked with unique_stats_info). Even in this case, never allow more than two visible
   * objects. If HA is enabled, never allow more than one visible object. */
  if (find_unique_helper.found_object && insert_helper->purpose == BTREE_OP_INSERT_NEW_OBJECT)
    {
      mvcc_snapshot_dirty.snapshot_fnc = mvcc_satisfies_dirty;

      if (insert_helper->is_unique_multi_update)
	{
	  /* This should be MULTI-ROW-UPDATE. Get key record and count visible objects. */

	  /* Get current key record. */
	  if (spage_get_record (thread_p, *leaf, search_key->slotid, leaf_record, COPY) != S_SUCCESS)
	    {
	      assert_release (false);
	      return ER_FAILED;
	    }

#if !defined (NDEBUG)
	  (void) btree_check_valid_record (thread_p, btid_int, leaf_record, BTREE_LEAF_NODE, key);
#endif

	  /* Read record. */
	  error_code =
	    btree_read_record (thread_p, btid_int, *leaf, leaf_record, NULL, &leaf_info, BTREE_LEAF_NODE,
			       &dummy_clear_key, &offset_after_key, PEEK_KEY_VALUE, NULL);
	  if (error_code != NO_ERROR)
	    {
	      ASSERT_ERROR ();
	      return error_code;
	    }
	  /* Don't repeat key record read. */
	  is_key_record_read = true;

	  /* Count visible (not dirty) objects. */
	  error_code =
	    btree_get_num_visible_from_leaf_and_ovf (thread_p, btid_int, leaf_record, offset_after_key, &leaf_info,
						     NULL, &mvcc_snapshot_dirty, &num_visible);
	  if (error_code != NO_ERROR)
	    {
	      ASSERT_ERROR ();
	      return error_code;
	    }
	}

      /* Should we consider this a unique constraint violation? */
      if (!insert_helper->is_unique_multi_update || num_visible > 1)
	{
	  /* Not multi-update operation or there would be more than two objects visible. Unique constraint violation. */
	  if (prm_get_bool_value (PRM_ID_UNIQUE_ERROR_KEY_VALUE))
	    {
	      char *keyval = pr_valstring (key);
	      er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, ER_UNIQUE_VIOLATION_WITHKEY, 1,
		      (keyval == NULL) ? "(null)" : keyval);
	      if (keyval != NULL)
		{
		  db_private_free (thread_p, keyval);
		}
	      return ER_UNIQUE_VIOLATION_WITHKEY;
	    }
	  else
	    {
	      /* Object already exists. Unique constraint violation. */
	      BTREE_SET_UNIQUE_VIOLATION_ERROR (thread_p, key, BTREE_INSERT_OID (insert_helper),
						BTREE_INSERT_CLASS_OID (insert_helper), btid_int->sys_btid, NULL);
	      return ER_BTREE_UNIQUE_FAILED;
	    }
	}
      else if (insert_helper->is_ha_enabled)
	{
	  /* When HA is enabled, unique constraint can never be violated. */
	  error_code = ER_REPL_MULTI_UPDATE_UNIQUE_VIOLATION;
	  er_set (ER_ERROR_SEVERITY, ARG_FILE_LINE, error_code, 0);
	  return error_code;
	}

      /* Cannot consider this a new key. */
      insert_helper->is_unique_key_added_or_deleted = false;
#if defined (SERVER_MODE)
      /* We don't want to unlock the object we will relocate. Others cannot delete it until we are finished. */
      OID_SET_NULL (&insert_helper->saved_locked_oid);
#endif
    }
  else
    {
      /* All existing objects are deleted. Proceed */
      insert_helper->is_unique_key_added_or_deleted = true;
    }
  /* Unique constraint not violated (yet). */
  /* New object can be inserted. */

  /* Slot ID points to key in page. */
  assert (search_key->slotid > 0 && (search_key->slotid <= btree_node_number_of_keys (thread_p, *leaf) + 1));

  if (!is_key_record_read)
    {
      /* Get current key record. */
      if (spage_get_record (thread_p, *leaf, search_key->slotid, leaf_record, COPY) != S_SUCCESS)
	{
	  assert_release (false);
	  return ER_FAILED;
	}

#if !defined (NDEBUG)
      (void) btree_check_valid_record (thread_p, btid_int, leaf_record, BTREE_LEAF_NODE, key);
#endif

      /* Read record. */
      error_code = btree_read_record (thread_p, btid_int, *leaf, leaf_record, NULL, &leaf_info, BTREE_LEAF_NODE,
				      &dummy_clear_key, &offset_after_key, PEEK_KEY_VALUE, NULL);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return error_code;
	}
    }

  /* Get current first object and its info */
  error_code =
    btree_leaf_get_first_object (btid_int, leaf_record, &first_object.oid, &first_object.class_oid,
				 &first_object.mvcc_info);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      return error_code;
    }

  /* Do we need to bring back the existing first object on undo? We normally should. We don't have to do it if the
   * first record is deleted and committed. Opposite to that is either object is not deleted (and this is
   * multi-update) or the object is deleted by current transaction. If it happens to be one of these cases, then
   * we have to bring the first object back on undo to ensure unique constraint.
   */
  if ((!insert_helper->is_unique_key_added_or_deleted
       || (BTREE_MVCC_INFO_DELID (&first_object.mvcc_info)
	   == BTREE_MVCC_INFO_INSID (BTREE_INSERT_MVCC_INFO (insert_helper))))
      && insert_helper->rcvindex == RVBT_MVCC_INSERT_OBJECT)
    {
      /* We need to log two objects: the one that is being inserted and the one that was first before. Undo will return
       * the visible object to its place. */
      char *rv_keyval_data_buf = NULL;
      int rv_keyval_data_capacity = IO_MAX_PAGE_SIZE;

      insert_helper->rcvindex = RVBT_MVCC_INSERT_OBJECT_UNQ;
      if (insert_helper->rv_keyval_data_length <= IO_MAX_PAGE_SIZE)
	{
	  /* Undo data uses preallocated data buffer. */
	  rv_keyval_data_buf = insert_helper->rv_keyval_data;
	}
      else
	{
	  /* Undo data was reallocated and its capacity matches its size. */
	  rv_keyval_data_capacity = insert_helper->rv_keyval_data_length;
	}
      error_code =
	btree_rv_save_keyval_for_undo_two_objects (btid_int, key, &insert_helper->obj_info, &first_object,
						   insert_helper->purpose, rv_keyval_data_buf,
						   &insert_helper->rv_keyval_data, &rv_keyval_data_capacity,
						   &insert_helper->rv_keyval_data_length);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return error_code;
	}
    }

  /* Now we are ready to insert new version. */
  error_code =
    btree_key_append_object_unique (thread_p, btid_int, key, *leaf, search_key, leaf_record, &leaf_info,
				    offset_after_key, insert_helper, &first_object);

  /* Success. */
  return error_code;
}

/*
 * btree_key_append_object_non_unique () - Append a new object in an existing b-tree key.
 *
 * return		 : Error code.
 * thread_p (in)	 : Thread entry.
 * btid_int (in)	 : B-tree info.
 * key (in)		 : Key value.
 * leaf (in)		 : Leaf node.
 * search_key (in)	 : Search key result.
 * leaf_record (in)	 : Key's leaf record.
 * offset_after_key (in) : Offset to where packed key is ended in leaf record data.
 * leaf_info (in)	 : Leaf record info.
 * btree_obj (in)	 : B-tree object info.
 * insert_helper (in)	 : B-tree insert helper.
 */
static int
btree_key_append_object_non_unique (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key, PAGE_PTR leaf,
				    BTREE_SEARCH_KEY_HELPER * search_key, RECDES * leaf_record, int offset_after_key,
				    LEAF_REC * leaf_info, BTREE_OBJECT_INFO * btree_obj,
				    BTREE_INSERT_HELPER * insert_helper)
{
  int n_objects;		/* Current number of leaf objects. If maximum size is reached, next object is inserted
				 * in overflows. */
  int error_code = NO_ERROR;	/* Error code. */
  int n_objects_limit = 0;
  int rv_redo_data_length = 0;

  LOG_LSA prev_lsa;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (key != NULL);
  assert (leaf != NULL);
  assert (search_key != NULL && search_key->slotid > 0
	  && search_key->slotid <= btree_node_number_of_keys (thread_p, leaf));
  assert (leaf_record != NULL);
  assert (leaf_info != NULL);
  assert (btree_obj != NULL);
  assert (btree_is_insert_object_purpose (insert_helper->purpose));
  assert (insert_helper->rv_redo_data != NULL && insert_helper->rv_redo_data_ptr != NULL);

  if (BTREE_IS_UNIQUE (btid_int->unique_pk))
    {
      /* Append OID means this is not first and must be fixed size. */
      BTREE_MVCC_INFO_SET_FIXED_SIZE (&btree_obj->mvcc_info);
    }

  /* Append new object to list of OID's for this key. First it should try to add the object to leaf record. Due to
   * split algorithm the page should always have enough space to add it. However, there is a limit of objects that can
   * be inserted in a leaf record. If that limit is reached, then the new object will be inserted in an overflow OID's
   * page. If there is none or if all existing pages are full, a new page is created and appended to current OID's
   * pages. */

  /* The OID list size on leaf page is limited to threshold number. */
  n_objects = btree_record_get_num_oids (thread_p, btid_int, leaf_record, offset_after_key, BTREE_LEAF_NODE);
  n_objects_limit = BTREE_MAX_OIDCOUNT_IN_LEAF_RECORD (btid_int);
  /* Is inserting another object possible? */
  if (n_objects < n_objects_limit)
    {
      /* Insert in leaf record is possible. */

#if !defined (NDEBUG)
      BTREE_RV_REDO_SET_DEBUG_INFO (&insert_helper->leaf_addr, insert_helper->rv_redo_data_ptr, btid_int,
				    BTREE_RV_DEBUG_ID_NON_UNIQUE);
#endif /* !NDEBUG */
      LOG_RV_RECORD_SET_MODIFY_MODE (&insert_helper->leaf_addr, LOG_RV_RECORD_UPDATE_PARTIAL);

      /* Append object at the end of leaf record. */
      btree_record_append_object (thread_p, btid_int, leaf_record, BTREE_LEAF_NODE, btree_obj, NULL,
				  &insert_helper->rv_redo_data_ptr);

      /* Update should work. */
      if (spage_update (thread_p, leaf, search_key->slotid, leaf_record) != S_SUCCESS)
	{
	  assert_release (false);
	  return ER_FAILED;
	}

      FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

      /* We need to log previous lsa. */
      LSA_COPY (&prev_lsa, pgbuf_get_lsa (leaf));

      /* Log changes. */
      BTREE_RV_GET_DATA_LENGTH (insert_helper->rv_redo_data_ptr, insert_helper->rv_redo_data, rv_redo_data_length);
      btree_rv_log_insert_object (thread_p, *insert_helper, insert_helper->leaf_addr, 0, rv_redo_data_length,
				  NULL, insert_helper->rv_redo_data);
      pgbuf_set_dirty (thread_p, leaf, DONT_FREE);

      btree_insert_log (insert_helper, BTREE_INSERT_MODIFY_MSG ("append object at the end"),
			BTREE_INSERT_MODIFY_ARGS (thread_p, insert_helper, leaf, &prev_lsa, true, search_key->slotid,
						  leaf_record->length, btid_int->sys_btid));

      return NO_ERROR;
    }

  /* Insert into overflow. */
  /* Overflow OID's have fixed size. */
  BTREE_MVCC_INFO_SET_FIXED_SIZE (&btree_obj->mvcc_info);

  error_code =
    btree_key_append_object_into_ovf (thread_p, btid_int, key, leaf, search_key, leaf_record, leaf_info, insert_helper,
				      btree_obj);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      return error_code;
    }

  /* Success. */
  return NO_ERROR;
}

/*
 * btree_key_append_object_unique () - Append new version in unique key.
 *
 * return		 : Error code.
 * thread_p (in)	 : Thread entry.
 * btid_int (in)	 : B-tree info.
 * key (in)		 : Key value.
 * leaf (in)		 : Leaf page.
 * search_key (in)	 : Search key result.
 * leaf_record (in)	 : Leaf record.
 * leaf_record_info (in) : Leaf record info.
 * offset_after_key (in) : Offset in record after packed key value.
 * insert_helper (in)	 : B-tree insert helper.
 * first_object (in)	 : First object read from record.
 *
 * Prerequisite: read leaf record and its first object.
 */
static int
btree_key_append_object_unique (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key, PAGE_PTR leaf,
				BTREE_SEARCH_KEY_HELPER * search_key, RECDES * leaf_record, LEAF_REC * leaf_record_info,
				int offset_after_key, BTREE_INSERT_HELPER * insert_helper,
				BTREE_OBJECT_INFO * first_object)
{
  int error_code = NO_ERROR;
  int rv_redo_data_length = 0;
  LOG_LSA prev_lsa;

  assert (btid_int != NULL);
  assert (BTREE_IS_UNIQUE (btid_int->unique_pk));
  assert (key != NULL);
  assert (search_key != NULL && search_key->result == BTREE_KEY_FOUND);
  assert (leaf_record != NULL);
  assert (leaf_record_info != NULL);
  assert (offset_after_key > 0);
  assert (btree_is_insert_object_purpose (insert_helper->purpose));
  assert (insert_helper->rv_redo_data != NULL);
  assert (insert_helper->rv_keyval_data != NULL && insert_helper->rv_keyval_data_length > 0);
  assert (insert_helper->leaf_addr.offset != 0 && insert_helper->leaf_addr.pgptr == leaf);
  assert (insert_helper->rcvindex == RVBT_MVCC_INSERT_OBJECT
	  || insert_helper->rcvindex == RVBT_NON_MVCC_INSERT_OBJECT
	  || insert_helper->rcvindex == RVBT_MVCC_INSERT_OBJECT_UNQ);
  assert (first_object != NULL && !OID_ISNULL (&first_object->oid));

  /* First object must be relocated at the end of leaf record. First we need to make sure there is enough room to do
   * so. If there isn't, last object in leaf record must be relocated to an overflow page. NOTE: Initially, the first
   * object was relocated directly into overflow. However, current logging system is quite limited when it comes to
   * using system operations and logical undo together. For that reason, the entire operation was split into two
   * sub-operations: 1. Relocate last object in leaf record using a system operation and physical undo/redo logging. 2.
   * Relocate first object at the end of leaf record and replace with new object. This is logged using logical undo.
   * The log size used is not optimal, but it is the only correct way. */
  if (btree_record_get_num_oids (thread_p, btid_int, leaf_record, offset_after_key, BTREE_LEAF_NODE) >=
      BTREE_MAX_OIDCOUNT_IN_LEAF_RECORD (btid_int))
    {
      assert (btree_record_get_num_oids (thread_p, btid_int, leaf_record, offset_after_key, BTREE_LEAF_NODE) ==
	      BTREE_MAX_OIDCOUNT_IN_LEAF_RECORD (btid_int));

      /* Relocate last object in leaf record to make room for a new object. */
      error_code =
	btree_key_relocate_last_into_ovf (thread_p, btid_int, key, leaf, search_key, leaf_record, leaf_record_info,
					  offset_after_key, insert_helper);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return error_code;
	}
    }

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  /* Relocate first object at the end of the leaf record and replace it with new object. */
  /* Prepare logging. */
  insert_helper->leaf_addr.offset = search_key->slotid;
  insert_helper->rv_redo_data_ptr = insert_helper->rv_redo_data;
#if !defined (NDEBUG)
  BTREE_RV_REDO_SET_DEBUG_INFO (&insert_helper->leaf_addr, insert_helper->rv_redo_data_ptr, btid_int,
				BTREE_RV_DEBUG_ID_UNIQUE);
#endif /* !NDEBUG */
  LOG_RV_RECORD_SET_MODIFY_MODE (&insert_helper->leaf_addr, LOG_RV_RECORD_UPDATE_PARTIAL);

  /* Relocate first object to the end of leaf record. */
  BTREE_MVCC_INFO_SET_FIXED_SIZE (&first_object->mvcc_info);
  btree_record_append_object (thread_p, btid_int, leaf_record, BTREE_LEAF_NODE, first_object, NULL,
			      &insert_helper->rv_redo_data_ptr);
  /* Replace first object with new object. */
  btree_leaf_change_first_object (thread_p, leaf_record, btid_int, BTREE_INSERT_OID (insert_helper),
				  BTREE_INSERT_CLASS_OID (insert_helper), BTREE_INSERT_MVCC_INFO (insert_helper), NULL,
				  NULL, &insert_helper->rv_redo_data_ptr);

  /* Update leaf record in page. */
  if (spage_update (thread_p, leaf, search_key->slotid, leaf_record) != SP_SUCCESS)
    {
      assert_release (false);
      return ER_FAILED;
    }

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  /* Log changes. */
  LSA_COPY (&prev_lsa, pgbuf_get_lsa (leaf));
  BTREE_RV_GET_DATA_LENGTH (insert_helper->rv_redo_data_ptr, insert_helper->rv_redo_data, rv_redo_data_length);
  log_append_undoredo_data (thread_p, insert_helper->rcvindex, &insert_helper->leaf_addr,
			    insert_helper->rv_keyval_data_length, rv_redo_data_length, insert_helper->rv_keyval_data,
			    insert_helper->rv_redo_data);

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);
  pgbuf_set_dirty (thread_p, leaf, DONT_FREE);

  btree_insert_log (insert_helper, BTREE_INSERT_MODIFY_MSG ("replace first object and relocate it at the end")
		    "\t" BTREE_OBJINFO_MSG ("replaced object"),
		    BTREE_INSERT_MODIFY_ARGS (thread_p, insert_helper, leaf, &prev_lsa, true, search_key->slotid,
					      leaf_record->length, btid_int->sys_btid),
		    BTREE_OBJINFO_AS_ARGS (first_object));

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);
  return NO_ERROR;
}

/*
 * btree_key_relocate_last_into_ovf () - Move last object in leaf record into an overflow page.
 *
 * return		 : Error code.
 * thread_p (in)	 : Thread entry.
 * btid_int (in)	 : B-tree info.
 * key (in)		 : Key value.
 * leaf (in)		 : Leaf page.
 * search_key (in)	 : Search key result.
 * leaf_record (in)	 : Leaf record.
 * leaf_record_info (in) : Leaf record info.
 * offset_after_key (in) : Offset in record after packed key value.
 * insert_helper (in)	 : B-tree insert helper.
 */
static int
btree_key_relocate_last_into_ovf (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key, PAGE_PTR leaf,
				  BTREE_SEARCH_KEY_HELPER * search_key, RECDES * leaf_record,
				  LEAF_REC * leaf_record_info, int offset_after_key,
				  BTREE_INSERT_HELPER * insert_helper)
{
  int error_code = NO_ERROR;
  BTREE_OBJECT_INFO last_object;
  int offset_to_last_object = 0;

  char rv_undo_data_buffer[BTREE_RV_BUFFER_SIZE + BTREE_MAX_ALIGN];
  char *rv_undo_data = PTR_ALIGN (rv_undo_data_buffer, BTREE_MAX_ALIGN);
  char *rv_undo_data_ptr = rv_undo_data;
  int rv_undo_data_length = 0;
  int rv_redo_data_length = 0;

  LOG_LSA prev_lsa = LSA_INITIALIZER;

  assert (btid_int != NULL);
  assert (BTREE_IS_UNIQUE (btid_int->unique_pk));
  assert (key != NULL);
  assert (leaf != NULL);
  assert (search_key != NULL && search_key->result == BTREE_KEY_FOUND);
  assert (leaf_record != NULL);
  assert (leaf_record_info != NULL);
  assert (offset_after_key > 0);
  assert (insert_helper != NULL);
  assert (btree_is_insert_object_purpose (insert_helper->purpose));
  assert (insert_helper->leaf_addr.offset != 0 && insert_helper->leaf_addr.pgptr == leaf);

  /* Relocate last object object in leaf record into an overflow page. */

  /* Get last object. */
  error_code =
    btree_record_get_last_object (thread_p, btid_int, leaf_record, BTREE_LEAF_NODE, offset_after_key, &last_object.oid,
				  &last_object.class_oid, &last_object.mvcc_info, &offset_to_last_object);
  if (error_code != NO_ERROR)
    {
      assert_release (false);
      return ER_FAILED;
    }
  assert (offset_to_last_object > 0);

  /* We need to change leaf page and at least one overflow page. Start a system operation. */
  log_sysop_start (thread_p);
  insert_helper->is_system_op_started = true;

  /* Copy last object into an overflow page. */
  error_code =
    btree_key_append_object_into_ovf (thread_p, btid_int, key, leaf, search_key, leaf_record, leaf_record_info,
				      insert_helper, &last_object);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto exit;
    }
  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  if (VPID_ISNULL (&leaf_record_info->ovfl) && btree_leaf_is_flaged (leaf_record, BTREE_LEAF_RECORD_OVERFLOW_OIDS))
    {
      /* First overflow page was added. */
      /* The last object may have been relocated. Read its offset again. */
      bool dummy_clear_key = false;
      error_code =
	btree_read_record (thread_p, btid_int, leaf, leaf_record, NULL, leaf_record_info, BTREE_LEAF_NODE,
			   &dummy_clear_key, &offset_after_key, PEEK_KEY_VALUE, NULL);
      error_code =
	btree_record_get_last_object (thread_p, btid_int, leaf_record, BTREE_LEAF_NODE, offset_after_key,
				      &last_object.oid, &last_object.class_oid, &last_object.mvcc_info,
				      &offset_to_last_object);
      if (error_code != NO_ERROR)
	{
	  assert_release (false);
	  goto exit;
	}
    }

  /* Remove last object from leaf record. */
  /* Prepare logging. */
  insert_helper->leaf_addr.offset = search_key->slotid;
  insert_helper->rv_redo_data_ptr = insert_helper->rv_redo_data;
#if !defined (NDEBUG)
  BTREE_RV_UNDOREDO_SET_DEBUG_INFO (&insert_helper->leaf_addr, insert_helper->rv_redo_data_ptr, rv_undo_data_ptr,
				    btid_int, BTREE_RV_DEBUG_ID_INS_REM_LEAF_LAST);
#endif /* !NDEBUG */
  LOG_RV_RECORD_SET_MODIFY_MODE (&insert_helper->leaf_addr, LOG_RV_RECORD_UPDATE_PARTIAL);
  btree_record_remove_last_object (thread_p, btid_int, leaf_record, BTREE_LEAF_NODE, offset_to_last_object,
				   &rv_undo_data_ptr, &insert_helper->rv_redo_data_ptr);
  /* Update leaf record. */
  if (spage_update (thread_p, leaf, search_key->slotid, leaf_record) != SP_SUCCESS)
    {
      assert_release (false);
      error_code = ER_FAILED;
      goto exit;
    }
  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  /* Log changes. */
  LSA_COPY (&prev_lsa, pgbuf_get_lsa (leaf));
  BTREE_RV_GET_DATA_LENGTH (rv_undo_data_ptr, rv_undo_data, rv_undo_data_length);
  BTREE_RV_GET_DATA_LENGTH (insert_helper->rv_redo_data_ptr, insert_helper->rv_redo_data, rv_redo_data_length);
  log_append_undoredo_data (thread_p, RVBT_RECORD_MODIFY_UNDOREDO, &insert_helper->leaf_addr, rv_undo_data_length,
			    rv_redo_data_length, rv_undo_data, insert_helper->rv_redo_data);

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);
  pgbuf_set_dirty (thread_p, leaf, DONT_FREE);

  btree_insert_log (insert_helper, BTREE_INSERT_MODIFY_MSG ("removed last object from leaf record")
		    "\t" BTREE_OBJINFO_MSG ("last object"),
		    BTREE_INSERT_MODIFY_ARGS (thread_p, insert_helper, leaf, &prev_lsa, true, search_key->slotid,
					      leaf_record->length, btid_int->sys_btid),
		    BTREE_OBJINFO_AS_ARGS (&last_object));

  /* Safe guard: another object can now be added to leaf record. */
  assert (btree_record_get_num_oids (thread_p, btid_int, leaf_record, offset_after_key, BTREE_LEAF_NODE) <
	  BTREE_MAX_OIDCOUNT_IN_LEAF_RECORD (btid_int));

  /* Success. */
  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

exit:
  if (insert_helper->is_system_op_started)
    {
      if (error_code == NO_ERROR)
	{
	  log_sysop_commit (thread_p);
	}
      else
	{
	  ASSERT_ERROR ();
	  log_sysop_abort (thread_p);
	}
    }

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);
  return error_code;
}

/*
 * btree_key_relocate_last_into_ovf () - Append a new object in overflow OID's pages.
 *
 * return		 : Error code.
 * thread_p (in)	 : Thread entry.
 * btid_int (in)	 : B-tree info.
 * key (in)		 : Key value.
 * leaf (in)		 : Leaf page.
 * search_key (in)	 : Search key result.
 * leaf_record (in)	 : Leaf record.
 * leaf_record_info (in) : Leaf record info.
 * insert_helper (in)	 : B-tree insert helper.
 * append_object (in)	 : Object to append to overflow.
 */
static int
btree_key_append_object_into_ovf (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key, PAGE_PTR leaf,
				  BTREE_SEARCH_KEY_HELPER * search_key, RECDES * leaf_record,
				  LEAF_REC * leaf_record_info, BTREE_INSERT_HELPER * insert_helper,
				  BTREE_OBJECT_INFO * append_object)
{
  int error_code = NO_ERROR;
  PAGE_PTR overflow_page = NULL;

  assert (btid_int != NULL);
  assert (key != NULL);
  assert (leaf != NULL);
  assert (search_key != NULL && search_key->result == BTREE_KEY_FOUND);
  assert (leaf_record != NULL);
  assert (leaf_record_info != NULL);
  assert (insert_helper != NULL);
  assert (btree_is_insert_object_purpose (insert_helper->purpose));
  assert (append_object != NULL);

  /* Is there enough space in existing overflow pages? */
  error_code = btree_find_free_overflow_oids_page (thread_p, btid_int, &leaf_record_info->ovfl, &overflow_page);
  if (error_code != NO_ERROR)
    {
      assert (overflow_page == NULL);
      ASSERT_ERROR ();
      return error_code;
    }
  if (overflow_page == NULL)
    {
      /* Could not find free space for object. Create overflow page. */
      OID *notification_class_oid;

      if (!OID_ISNULL (&append_object->class_oid))
	{
	  notification_class_oid = &append_object->class_oid;
	}
      else
	{
	  notification_class_oid = &btid_int->topclass_oid;
	}

      /* Notification */
      BTREE_SET_CREATED_OVERFLOW_PAGE_NOTIFICATION (thread_p, key, &append_object->oid, notification_class_oid,
						    btid_int->sys_btid);
      error_code =
	btree_key_append_object_as_new_overflow (thread_p, btid_int, leaf, append_object, insert_helper, search_key,
						 leaf_record, &leaf_record_info->ovfl);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return error_code;
	}

      if (insert_helper->insert_list != NULL)
	{
	  insert_helper->insert_list->m_ovf_appends_new_page++;
	}
    }
  else
    {
      error_code =
	btree_key_append_object_to_overflow (thread_p, btid_int, overflow_page, append_object, insert_helper);
      pgbuf_unfix_and_init (thread_p, overflow_page);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return error_code;
	}
      if (insert_helper->insert_list != NULL)
	{
	  insert_helper->insert_list->m_ovf_appends++;
	}
    }
  assert (overflow_page == NULL);

  /* Success. */
  return NO_ERROR;
}

/*
 * btree_key_find_and_insert_delete_mvccid () - BTREE_ADVANCE_WITH_KEY_FUNCTION used for MVCC logical delete.
 *						An object is found and an MVCCID is added to its MVCC info.
 *
 * return	   : Error code.
 * thread_p (in)   : Thread entry.
 * btid_int (in)   : B-tree identifier.
 * key (in)	   : Key value.
 * leaf_page (in)  : Pointer to leaf node page.
 * search_key (in) : Search key result.
 * restart (in)	   : Not used.
 * other_args (in) : BTREE_INSERT_HELPER *
 */
static int
btree_key_find_and_insert_delete_mvccid (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
					 PAGE_PTR * leaf_page, BTREE_SEARCH_KEY_HELPER * search_key, bool * restart,
					 void *other_args)
{
  BTREE_INSERT_HELPER *insert_helper = (BTREE_INSERT_HELPER *) other_args;
  int error_code = NO_ERROR;
  RECDES record;
  char data_buffer[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  LEAF_REC leaf_info;
  int offset_after_key;
  int offset_to_found_object;
  BTREE_MVCC_INFO mvcc_info;
  bool dummy_clear_key;

  PAGE_PTR found_page = NULL;

  int num_visible = 0;
  MVCC_SNAPSHOT snapshot_dirty;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (key != NULL && !DB_IS_NULL (key) && !btree_multicol_key_is_null (key));
  assert (leaf_page != NULL && *leaf_page != NULL);
  assert (search_key != NULL);
  assert (insert_helper != NULL);
  assert (insert_helper->purpose == BTREE_OP_INSERT_MVCC_DELID
	  || insert_helper->purpose == BTREE_OP_INSERT_MARK_DELETED);

  btree_perf_track_traverse_time (thread_p, insert_helper);

  if (search_key->result != BTREE_KEY_FOUND)
    {
      /* Impossible. Object and key should exist in b-tree. */
      assert (false);
      btree_set_unknown_key_error (thread_p, btid_int->sys_btid, key, "btree_key_find_and_insert_delete_mvccid");
      return ER_BTREE_UNKNOWN_KEY;
    }

  /* Prepare leaf record descriptor to read from b-tree. */
  record.type = REC_HOME;
  record.area_size = DB_PAGESIZE;
  record.data = PTR_ALIGN (data_buffer, BTREE_MAX_ALIGN);

  /* Get & read record. */
  if (spage_get_record (thread_p, *leaf_page, search_key->slotid, &record, COPY) != S_SUCCESS)
    {
      /* Unexpected. */
      assert_release (false);
      return ER_FAILED;
    }
#if !defined (NDEBUG)
  /* Check valid record before changing it. */
  (void) btree_check_valid_record (thread_p, btid_int, &record, BTREE_LEAF_NODE, key);
#endif
  error_code =
    btree_read_record (thread_p, btid_int, *leaf_page, &record, NULL, &leaf_info, BTREE_LEAF_NODE, &dummy_clear_key,
		       &offset_after_key, PEEK_KEY_VALUE, NULL);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto exit;
    }

  if (insert_helper->is_unique_multi_update && !insert_helper->is_ha_enabled && BTREE_IS_UNIQUE (btid_int->unique_pk))
    {
      snapshot_dirty.snapshot_fnc = mvcc_satisfies_dirty;
      error_code =
	btree_get_num_visible_from_leaf_and_ovf (thread_p, btid_int, &record, offset_after_key, &leaf_info, NULL,
						 &snapshot_dirty, &num_visible);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto exit;
	}
      /* Even though multiple visible objects are allowed, they cannot exceed two visible objects (insert does not
       * allow it). Also, there should be at least one object to delete. */
      assert (num_visible > 0);
      assert (num_visible <= 2);
      /* The key is considered deleted only if there is one visible object (which will be deleted). */
      insert_helper->is_unique_key_added_or_deleted = (num_visible == 1);
    }

  error_code =
    btree_find_oid_and_its_page (thread_p, btid_int, BTREE_INSERT_OID (insert_helper), *leaf_page,
				 insert_helper->purpose, NULL, &record, &leaf_info, offset_after_key, &found_page, NULL,
				 &offset_to_found_object, &mvcc_info);
  if (error_code != NO_ERROR)
    {
      /* Error. */
      ASSERT_ERROR ();
      assert (found_page == NULL);

      goto exit;
    }
  if (offset_to_found_object == NOT_FOUND)
    {
      assert (found_page == NULL);
      assert (false);
      btree_set_unknown_key_error (thread_p, btid_int->sys_btid, key, "btree_key_find_and_insert_delete_mvccid");
      error_code = ER_BTREE_UNKNOWN_KEY;
      goto exit;
    }
  /* Object was found. */
  assert (!BTREE_MVCC_INFO_IS_DELID_VALID (&mvcc_info));
  /* Copy insert ID into object info. */
  if (BTREE_MVCC_INFO_IS_INSID_NOT_ALL_VISIBLE (&mvcc_info))
    {
      BTREE_MVCC_INFO_SET_INSID (BTREE_INSERT_MVCC_INFO (insert_helper), mvcc_info.insert_mvccid);
    }

  /* Delete its delete MVCCID. */
  error_code =
    btree_key_insert_delete_mvccid (thread_p, btid_int, key, *leaf_page, search_key, insert_helper, &record, found_page,
				    offset_to_found_object);
  if (found_page != NULL && found_page != *leaf_page)
    {
      pgbuf_unfix_and_init (thread_p, found_page);
    }
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto exit;
    }

#if !defined (NDEBUG)
  if (oid_is_db_class (BTREE_INSERT_CLASS_OID (insert_helper)))
    {
      /* Although the indexes on _db_class and _db_attribute are not unique, they cannot have duplicate OID's. Check
       * here this consistency (no visible objects should exist). */
      btree_key_record_check_no_visible (thread_p, btid_int, *leaf_page, search_key->slotid);
    }
#endif /* !NDEBUG */

exit:

  btree_perf_track_time (thread_p, insert_helper);
  return error_code;
}

/*
 * btree_key_insert_delete_mvccid () - Insert delete MVCCID for a b-tree object.
 *
 * return		       : Error code.
 * thread_p (in)	       : Thread entry.
 * btid_int (in)	       : B-tree info.
 * key (in)		       : Key value.
 * leaf_page (in)	       : Leaf page.
 * search_key (in)	       : Search key result.
 * insert_helper (in)	       : B-tree insert helper.
 * leaf_record (in)	       : Leaf record.
 * object_page (in)	       : Page of object that is being deleted.
 * offset_to_found_object (in) : Offset to object that is being deleted.
 */
static int
btree_key_insert_delete_mvccid (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key, PAGE_PTR leaf_page,
				BTREE_SEARCH_KEY_HELPER * search_key, BTREE_INSERT_HELPER * insert_helper,
				RECDES * leaf_record, PAGE_PTR object_page, int offset_to_found_object)
{
  int error_code = NO_ERROR;
  RECDES overflow_record;
  char overflow_record_buffer[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];

  if (object_page == leaf_page)
    {
      /* Found in leaf page. */

      /* Unique index can only delete the first object. Exception: If this is multi-row update, it is allowed to have
       * more than one visible objects. Second visible object may be deleted later, thus preserving the unique
       * constraint. */
      assert (!BTREE_IS_UNIQUE (btid_int->unique_pk) || offset_to_found_object == 0
	      || insert_helper->op_type == MULTI_ROW_UPDATE);

      /* Object was found in leaf page and can be deleted. */
      error_code =
	btree_insert_mvcc_delid_into_page (thread_p, btid_int, leaf_page, BTREE_LEAF_NODE, key, insert_helper,
					   search_key->slotid, leaf_record, offset_to_found_object);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return error_code;
	}

      /* Success */
      return NO_ERROR;
    }
  /* Found in overflow page. */

  /* Get overflow record. */
  overflow_record.data = PTR_ALIGN (overflow_record_buffer, BTREE_MAX_ALIGN);
  overflow_record.area_size = DB_PAGESIZE;
  if (spage_get_record (thread_p, object_page, 1, &overflow_record, COPY) != S_SUCCESS)
    {
      assert_release (false);
      return ER_FAILED;
    }
  /* Insert delete MVCCID. */
  error_code =
    btree_insert_mvcc_delid_into_page (thread_p, btid_int, object_page, BTREE_OVERFLOW_NODE, key, insert_helper, 1,
				       &overflow_record, offset_to_found_object);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      return error_code;
    }

  /* Success */
  return NO_ERROR;
}

#if !defined (NDEBUG)
/*
 * btree_key_record_check_no_visible () - Check b-tree record has no visible objects. Debug only.
 *
 * thread_p (in)  : Thread entry.
 * btid_int (in)  : B-tree info.
 * leaf_page (in) : Leaf page.
 * slotid (in)	  : Record slot ID.
 */
static void
btree_key_record_check_no_visible (THREAD_ENTRY * thread_p, BTID_INT * btid_int, PAGE_PTR leaf_page, PGSLOTID slotid)
{
  RECDES record;
  LEAF_REC leaf_rec_info;
  int offset_after_key;
  bool dummy_clear_key;
  int num_visible;
  MVCC_SNAPSHOT dirty_snapshot;
  int error_code = NO_ERROR;

  dirty_snapshot.snapshot_fnc = mvcc_satisfies_dirty;

  if (spage_get_record (thread_p, leaf_page, slotid, &record, PEEK) != S_SUCCESS)
    {
      assert (false);
      return;
    }
  if (btree_read_record (thread_p, btid_int, leaf_page, &record, NULL, &leaf_rec_info, BTREE_LEAF_NODE,
			 &dummy_clear_key, &offset_after_key, PEEK_KEY_VALUE, NULL) != NO_ERROR)
    {
      assert (false);
      return;
    }

  error_code = btree_get_num_visible_from_leaf_and_ovf (thread_p, btid_int, &record, offset_after_key, &leaf_rec_info,
							NULL, &dirty_snapshot, &num_visible);

  assert ((error_code == NO_ERROR && num_visible == 0) || error_code != NO_ERROR);
}
#endif /* !NDEBUG */

/*
 * btree_mvcc_info_from_heap_mvcc_header () - Convert an MVCC record header (used for heap records) into
 *					      a b-tree MVCC info structure (used to store an object in b-tree).
 *
 * return	    : Void.
 * mvcc_header (in) : Heap record MVCC header.
 * mvcc_info (out)  : B-tree MVCC info.
 */
void
btree_mvcc_info_from_heap_mvcc_header (MVCC_REC_HEADER * mvcc_header, BTREE_MVCC_INFO * mvcc_info)
{
  /* Assert expected arguments. */
  assert (mvcc_header != NULL);
  assert (mvcc_info != NULL);

  mvcc_info->flags = 0;
  if (MVCC_IS_FLAG_SET (mvcc_header, OR_MVCC_FLAG_VALID_INSID))
    {
      mvcc_info->flags |= BTREE_OID_HAS_MVCC_INSID;
      mvcc_info->insert_mvccid = MVCC_GET_INSID (mvcc_header);
    }
  else
    {
      mvcc_info->insert_mvccid = MVCCID_ALL_VISIBLE;
    }
  if (MVCC_IS_FLAG_SET (mvcc_header, OR_MVCC_FLAG_VALID_DELID))
    {
      mvcc_info->flags |= BTREE_OID_HAS_MVCC_DELID;
      mvcc_info->delete_mvccid = MVCC_GET_DELID (mvcc_header);
    }
  else
    {
      mvcc_info->delete_mvccid = MVCCID_NULL;
    }
}

/*
 * btree_mvcc_info_to_heap_mvcc_header () - Convert a b-tree MVCC info structure into a heap record MVCC header.
 *
 * return	     : Void.
 * mvcc_info (in)    : B-tree MVCC info.
 * mvcc_header (out) : Heap record MVCC header.
 */
void
btree_mvcc_info_to_heap_mvcc_header (BTREE_MVCC_INFO * mvcc_info, MVCC_REC_HEADER * mvcc_header)
{
  /* Assert expected arguments. */
  assert (mvcc_header != NULL);
  assert (mvcc_info != NULL);

  mvcc_header->mvcc_flag = 0;
  if (BTREE_MVCC_INFO_IS_INSID_NOT_ALL_VISIBLE (mvcc_info))
    {
      mvcc_header->mvcc_flag |= OR_MVCC_FLAG_VALID_INSID;
      MVCC_SET_INSID (mvcc_header, mvcc_info->insert_mvccid);
    }
  else
    {
      MVCC_SET_INSID (mvcc_header, MVCCID_ALL_VISIBLE);
    }
  if (BTREE_MVCC_INFO_IS_DELID_VALID (mvcc_info))
    {
      mvcc_header->mvcc_flag |= OR_MVCC_FLAG_VALID_DELID;
      MVCC_SET_DELID (mvcc_header, mvcc_info->delete_mvccid);
    }
  else
    {
      MVCC_SET_DELID (mvcc_header, MVCCID_NULL);
    }
}

/*
 * btree_rv_redo_record_modify () - Redo recovery of b-tree key records.
 *
 * return	 : Error code.
 * thread_p (in) : Thread entry.
 * rcv (in)	 : Recovery data.
 */
int
btree_rv_redo_record_modify (THREAD_ENTRY * thread_p, LOG_RCV * rcv)
{
  return btree_rv_record_modify_internal (thread_p, rcv, false);
}

/*
 * btree_rv_undo_record_modify () - Undo recovery of b-tree key records.
 *
 * return	 : Error code.
 * thread_p (in) : Thread entry.
 * rcv (in)	 : Recovery data.
 */
int
btree_rv_undo_record_modify (THREAD_ENTRY * thread_p, LOG_RCV * rcv)
{
  return btree_rv_record_modify_internal (thread_p, rcv, true);
}

/*
 * btree_rv_record_modify_internal () - Undoredo recovery of b-tree key records.
 *
 * return	 : Error code.
 * thread_p (in) : Thread entry.
 * rcv (in)	 : Recovery data.
 * is_undo (in)  : True if undo recovery, false if redo recovery.
 */
static int
btree_rv_record_modify_internal (THREAD_ENTRY * thread_p, LOG_RCV * rcv, bool is_undo)
{
  short flags;			/* Flags set into rcv->offset. */
  PGSLOTID slotid;		/* Slot ID stored in rcv->offset. */
  BTREE_NODE_HEADER *node_header = NULL;	/* Node header. */
  int key_cnt;			/* Node key count. */
  RECDES update_record;		/* Used to store modified record. */
  /* Buffer to store modified record data. */
  char data_buffer[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  char *rcv_data_ptr = NULL;	/* Current pointer in recovery data. */
  BTID_INT btid_int_for_debug;	/* B-tree info structure used to store unique flag and top class OID. */
  BTREE_NODE_TYPE node_type;	/* Node type. */
  int error_code = NO_ERROR;	/* Error code. */
  /* True when b-tree operations should be logged. For debugging. */
  bool log_btree_ops = prm_get_bool_value (PRM_ID_LOG_BTREE_OPS);
  bool has_debug_info = false;

  /* >>>>>>>>>>>> */
  /* Debug ID to help developers find the source of bug in logging/recovery code. */
  BTREE_RV_DEBUG_ID rv_debug_id = BTREE_RV_REDO_NO_ID;
  /* <<<<<<<<<<<< */

  /* Get flags and slot ID. */
  flags = rcv->offset & BTREE_RV_FLAGS_MASK;
  slotid = rcv->offset & (~BTREE_RV_FLAGS_MASK);

  /* There are four major cases here:
   * 1. LOG_RV_RECORD_DELETE: Key is removed completely.
   * 2. LOG_RV_RECORD_UPDATE_ALL:
   *    Entire record is updated (overflow header).
   * 3. LOG_RV_RECORD_INSERT: Key is inserted or overflow is created.
   * 4. LOG_RV_RECORD_UPDATE_PARTIAL: Record is updated by bits.
   * If is_undo flag is true, the cases are reversed. */

  /* Case 1: Is key being removed completely? */
  /* Logged by: btree_delete_key_from_leaf or btree_key_insert_new_key */
  if ((!is_undo && LOG_RV_RECORD_IS_DELETE (flags)) || (is_undo && LOG_RV_RECORD_IS_INSERT (flags)))
    {
      /* Record is completely removed from page. Redo of key removal from leaf page, when all its objects have been
       * deleted or undo of new key being inserted. */

      /* Delete key record. */
      node_header = btree_get_node_header (thread_p, rcv->pgptr);
      if (node_header == NULL)
	{
	  assert_release (false);
	  return ER_FAILED;
	}
      assert (slotid > 0);
      if (spage_delete (thread_p, rcv->pgptr, slotid) != slotid)
	{
	  assert_release (false);
	  return ER_FAILED;
	}

      /* Update the page header */
      key_cnt = btree_node_number_of_keys (thread_p, rcv->pgptr);
      if (key_cnt == 0)
	{
	  node_header->max_key_len = 0;
	}
      pgbuf_set_dirty (thread_p, rcv->pgptr, DONT_FREE);

      if (log_btree_ops)
	{
	  _er_log_debug (ARG_FILE_LINE,
			 "%s: remove slotid=%d from leaf page %d|%d, lsa=%lld|%d, in an unknown index.\n",
			 is_undo ? "BTREE_UNDO" : "BTREE_REDO", slotid, PGBUF_PAGE_STATE_ARGS (rcv->pgptr));
	}
      return NO_ERROR;
    }
  /* Case 1 is ruled out. Cases 2, 3, 4. These cases may also require unpacking debug info and running sanity checks
   * after modifying record. */

  /* First get debug info if any. */
  rcv_data_ptr = (char *) rcv->data;

  /* First check if there is debug info stored. */
  if (BTREE_RV_HAS_DEBUG_INFO (flags))
    {
      has_debug_info = true;

      /* Get BTREE_RV_DEBUG_ID */
      rv_debug_id = (BTREE_RV_DEBUG_ID) OR_GET_INT (rcv_data_ptr);
      rcv_data_ptr += OR_INT_SIZE;

      /* Read unique_pk flag. */
      btid_int_for_debug.unique_pk = OR_GET_INT (rcv_data_ptr);
      rcv_data_ptr += OR_INT_SIZE;

      /* Set top class OID. */
      if (BTREE_IS_UNIQUE (btid_int_for_debug.unique_pk))
	{
	  OR_GET_OID (rcv_data_ptr, &btid_int_for_debug.topclass_oid);
	  rcv_data_ptr += OR_OID_SIZE;
	}
      else
	{
	  OID_SET_NULL (&btid_int_for_debug.topclass_oid);
	}

      /* Read key type. */
      ASSERT_ALIGN (rcv_data_ptr, INT_ALIGNMENT);
      rcv_data_ptr = or_unpack_domain (rcv_data_ptr, &btid_int_for_debug.key_type, NULL);
      rcv_data_ptr = PTR_ALIGN (rcv_data_ptr, INT_ALIGNMENT);
    }

  /* Get node type. */
  if (flags & BTREE_RV_OVERFLOW_FLAG)
    {
      node_type = BTREE_OVERFLOW_NODE;
    }
  else
    {
      node_type = BTREE_LEAF_NODE;
    }

  /* Case 2: Is entire record being updated? */
  /* Logged by: btree_modify_overflow_link. btree_overflow_record_replace_object. */
  if (LOG_RV_RECORD_IS_UPDATE_ALL (flags))
    {
      /* Update entire record. */
      /* The remaining recovery data is updated record data. */
      update_record.data = (char *) rcv_data_ptr;
      update_record.length = rcv->length - CAST_BUFLEN (rcv_data_ptr - rcv->data);
      update_record.type = REC_HOME;

#if !defined (NDEBUG)
      if (has_debug_info)
	{
	  (void) btree_check_valid_record (thread_p, &btid_int_for_debug, &update_record, node_type, NULL);
	}
#endif /* NDEBUG */

      /* Update record in page. */
      if (spage_update (thread_p, rcv->pgptr, slotid, &update_record) != SP_SUCCESS)
	{
	  assert_release (false);
	  return ER_FAILED;
	}
      pgbuf_set_dirty (thread_p, rcv->pgptr, DONT_FREE);

      if (log_btree_ops)
	{
	  _er_log_debug (ARG_FILE_LINE,
			 "%s: update slotid=%d from page %d|%d, lsa=%lld|%d in an unknown index."
			 "Record length = %d.\n", is_undo ? "BTREE_UNDO" : "BTREE_REDO", slotid,
			 PGBUF_PAGE_STATE_ARGS (rcv->pgptr), update_record.length);
	}
      return NO_ERROR;
    }
  /* Case 2 is ruled out. Cases 3 and 4. */

  /* Case 3: 1. New overflow page. Logged by: btree_start_overflow_page. 2. New key in leaf record. Logged by:
   * btree_key_insert_new_key. */
  if ((!is_undo && LOG_RV_RECORD_IS_INSERT (flags)) || (is_undo && LOG_RV_RECORD_IS_DELETE (flags)))
    {
      if (node_type == BTREE_OVERFLOW_NODE)
	{
	  /* Actually two records are inserted: overflow header and record containing one object. */
	  BTREE_OVERFLOW_HEADER overflow_header;

	  /* Insert overflow header. */
	  OR_GET_VPID (rcv_data_ptr, &overflow_header.next_vpid);
	  rcv_data_ptr += DISK_VPID_ALIGNED_SIZE;

	  update_record.type = REC_HOME;
	  update_record.data = (char *) &overflow_header;
	  update_record.length = sizeof (overflow_header);
	  if (spage_insert_at (thread_p, rcv->pgptr, HEADER, &update_record) != SP_SUCCESS)
	    {
	      assert_release (false);
	      return ER_FAILED;
	    }

	  /* Insert object record. */
	  update_record.data = rcv_data_ptr;
	  update_record.length = rcv->length - CAST_BUFLEN (rcv_data_ptr - rcv->data);

#if !defined (NDEBUG)
	  if (has_debug_info)
	    {
	      assert (update_record.length == BTREE_OBJECT_FIXED_SIZE (&btid_int_for_debug));
	      (void) btree_check_valid_record (thread_p, &btid_int_for_debug, &update_record, BTREE_OVERFLOW_NODE,
					       NULL);
	    }
#endif /* !NDEDBUG */

	  if (spage_insert_at (thread_p, rcv->pgptr, 1, &update_record) != SP_SUCCESS)
	    {
	      assert_release (false);
	      (void) spage_delete (thread_p, rcv->pgptr, HEADER);
	      return ER_FAILED;
	    }
	  pgbuf_set_dirty (thread_p, rcv->pgptr, DONT_FREE);

	  if (log_btree_ops)
	    {
	      if (has_debug_info)
		{
		  OID oid = OID_INITIALIZER;
		  OID class_oid = OID_INITIALIZER;
		  BTREE_MVCC_INFO mvcc_info = BTREE_MVCC_INFO_INITIALIZER;

		  btree_unpack_object (update_record.data, &btid_int_for_debug, node_type, &update_record, 0, &oid,
				       &class_oid, &mvcc_info);
		  _er_log_debug (ARG_FILE_LINE,
				 "%s: create new overflow page %d|%d, lsa=%lld|%d, in an unknown index. "
				 "Insert object=%d|%d|%d, class_oid=%d|%d|%d, mvcc_info=%llu|%llu."
				 "Record length = %d.\n", is_undo ? "BTREE_UNDO" : "BTREE_REDO",
				 PGBUF_PAGE_STATE_ARGS (rcv->pgptr), oid.volid, oid.pageid, oid.slotid,
				 class_oid.volid, class_oid.pageid, class_oid.slotid,
				 (unsigned long long int) mvcc_info.insert_mvccid,
				 (unsigned long long int) mvcc_info.delete_mvccid, update_record.length);
		}
	      else
		{
		  _er_log_debug (ARG_FILE_LINE,
				 "%s: create new overflow page %d|%d, lsa=%lld|%d, in an unknown index."
				 "Record length = %d.\n", is_undo ? "BTREE_UNDO" : "BTREE_REDO",
				 PGBUF_PAGE_STATE_ARGS (rcv->pgptr), update_record.length);
		}
	    }
	}
      else
	{
	  /* Insert key into leaf page. */
	  int key_length;
	  int key_count;
	  BTREE_NODE_HEADER *node_header = NULL;

	  node_header = btree_get_node_header (thread_p, rcv->pgptr);
	  if (node_header == NULL)
	    {
	      assert_release (false);
	      return ER_FAILED;
	    }

	  if (BTREE_RV_IS_UPDATE_MAX_KEY_LEN (flags))
	    {
	      rcv_data_ptr = or_unpack_int (rcv_data_ptr, &key_length);
	    }

	  update_record.type = REC_HOME;
	  update_record.data = rcv_data_ptr;
	  update_record.length = rcv->length - CAST_BUFLEN (rcv_data_ptr - rcv->data);

#if !defined (NDEBUG)
	  if (has_debug_info)
	    {
	      (void) btree_check_valid_record (thread_p, &btid_int_for_debug, &update_record, node_type, NULL);
	    }
#endif /* !NDEBUG */

	  if (spage_insert_at (thread_p, rcv->pgptr, slotid, &update_record) != SP_SUCCESS)
	    {
	      assert_release (false);
	      return ER_FAILED;
	    }

	  if (BTREE_RV_IS_UPDATE_MAX_KEY_LEN (flags))
	    {
	      assert (key_length > node_header->max_key_len);
	      node_header->max_key_len = key_length;
	    }

	  key_count = btree_node_number_of_keys (thread_p, rcv->pgptr);

	  assert (node_header->split_info.pivot >= 0 && key_count > 0);
	  btree_split_next_pivot (&node_header->split_info, (float) slotid / key_count, key_count);

	  pgbuf_set_dirty (thread_p, rcv->pgptr, DONT_FREE);

	  if (log_btree_ops)
	    {
	      if (has_debug_info && !btree_leaf_is_flaged (&update_record, BTREE_LEAF_RECORD_OVERFLOW_KEY))
		{
		  OID oid = OID_INITIALIZER;
		  OID class_oid = OID_INITIALIZER;
		  BTREE_MVCC_INFO mvcc_info = BTREE_MVCC_INFO_INITIALIZER;
		  LEAF_REC leaf_rec_info;
		  int offset_after_key = 0;
		  DB_VALUE key;
		  bool clear_key;
		  char *printed_key = NULL;

		  btree_init_temp_key_value (&clear_key, &key);
		  (void) btree_read_record (thread_p, &btid_int_for_debug, rcv->pgptr, &update_record, &key,
					    &leaf_rec_info, node_type, &clear_key, &offset_after_key, PEEK_KEY_VALUE,
					    NULL);
		  printed_key = pr_valstring (&key);
		  btree_clear_key_value (&clear_key, &key);

		  (void) btree_unpack_object (update_record.data, &btid_int_for_debug, node_type, &update_record,
					      offset_after_key, &oid, &class_oid, &mvcc_info);
		  _er_log_debug (ARG_FILE_LINE,
				 "%s: insert slotid=%d in leaf page %d|%d, lsa=%lld|%d, in an unknown index. "
				 "Object=%d|%d|%d, class_oid=%d|%d|%d, mvcc_info=%lld|%lld, key=%s."
				 "Record length = %d.\n", is_undo ? "BTREE_UNDO" : "BTREE_REDO", slotid,
				 PGBUF_PAGE_STATE_ARGS (rcv->pgptr), oid.volid, oid.pageid, oid.slotid,
				 class_oid.volid, class_oid.pageid, class_oid.slotid,
				 (unsigned long long int) mvcc_info.insert_mvccid,
				 (unsigned long long int) mvcc_info.delete_mvccid,
				 printed_key != NULL ? printed_key : "unknown", update_record.length);
		  if (printed_key != NULL)
		    {
		      db_private_free (thread_p, printed_key);
		    }
		}
	      else
		{
		  _er_log_debug (ARG_FILE_LINE,
				 "%s: insert slotid=%d in leaf page %d|%d, lsa=%lld|%d, "
				 "in an unknown index. Record length = %d.\n", is_undo ? "BTREE_UNDO" : "BTREE_REDO",
				 slotid, PGBUF_PAGE_STATE_ARGS (rcv->pgptr), update_record.length);
		}
	    }
	}
      return NO_ERROR;
    }
  /* Case 4: Update record by parts. All other b-tree record changes. Logged by: btree_insert_mvcc_delid_into_page
   * btree_key_append_object_as_new_overflow btree_key_append_object_to_overflow
   * btree_key_lock_and_append_object_unique btree_key_append_object_non_unique btree_key_remove_insert_mvccid
   * btree_key_remove_delete_mvccid_unique btree_key_remove_delete_mvccid_non_unique
   * btree_overflow_record_replace_object btree_replace_first_oid_with_ovfl_oid btree_modify_overflow_link
   * btree_leaf_record_replace_first_with_last btree_record_remove_object */
  assert (LOG_RV_RECORD_IS_UPDATE_PARTIAL (flags));

  /* Check there is at least one change logged. */
  assert (CAST_BUFLEN (rcv_data_ptr - rcv->data) < rcv->length);

  /* Get existing record. */
  update_record.data = PTR_ALIGN (data_buffer, BTREE_MAX_ALIGN);
  update_record.area_size = DB_PAGESIZE;
  if (spage_get_record (thread_p, rcv->pgptr, slotid, &update_record, COPY) != SP_SUCCESS)
    {
      assert_release (false);
      return ER_FAILED;
    }

#if !defined (NDEBUG)
  if (has_debug_info)
    {
      /* Check existing record is valid. */
      (void) btree_check_valid_record (thread_p, &btid_int_for_debug, &update_record, node_type, NULL);
    }
#endif /* !NDEBUG */

  /* Apply changes. */
  error_code =
    log_rv_undoredo_record_partial_changes (thread_p, rcv_data_ptr,
					    rcv->length - CAST_BUFLEN (rcv_data_ptr - rcv->data), &update_record,
					    is_undo);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      return error_code;
    }
  /* Changes applied successfully. */

#if !defined (NDEBUG)
  if (has_debug_info)
    {
      /* Check record validity after changes. */
      (void) btree_check_valid_record (thread_p, &btid_int_for_debug, &update_record, node_type, NULL);
    }
#endif /* !NDEBUG */

  /* Update in page. */
  if (spage_update (thread_p, rcv->pgptr, slotid, &update_record) != SP_SUCCESS)
    {
      assert_release (false);
      return ER_FAILED;
    }
  pgbuf_set_dirty (thread_p, rcv->pgptr, DONT_FREE);

  if (log_btree_ops)
    {
      if (has_debug_info)
	{
	  LEAF_REC leaf_rec_info;
	  int offset_after_key = 0;
	  DB_VALUE key;
	  bool clear_key;
	  char *printed_key = NULL;

	  /* Read key value if node is leaf and if key is not overflow (avoid fixing other pages here since it may
	   * crash). */
	  if (node_type == BTREE_LEAF_NODE && !btree_leaf_is_flaged (&update_record, BTREE_LEAF_RECORD_OVERFLOW_KEY))
	    {
	      btree_init_temp_key_value (&clear_key, &key);
	      (void) btree_read_record (thread_p, &btid_int_for_debug, rcv->pgptr, &update_record, &key, &leaf_rec_info,
					node_type, &clear_key, &offset_after_key, PEEK_KEY_VALUE, NULL);
	      printed_key = pr_valstring (&key);
	      btree_clear_key_value (&clear_key, &key);
	    }

	  _er_log_debug (ARG_FILE_LINE,
			 "%s: update slotid=%d from %s page %d|%d, lsa=%lld|%d, in an unknown index."
			 "key=%s, rv_debug_id=%d. Record length = %d.\n", is_undo ? "BTREE_UNDO" : "BTREE_REDO", slotid,
			 node_type == BTREE_LEAF_NODE ? "leaf" : "overflow", PGBUF_PAGE_STATE_ARGS (rcv->pgptr),
			 printed_key != NULL ? printed_key : "unknown", rv_debug_id, update_record.length);
	  if (printed_key != NULL)
	    {
	      db_private_free (thread_p, printed_key);
	    }
	}
      else
	{
	  _er_log_debug (ARG_FILE_LINE,
			 "%s: update slotid=%d from %s page %d|%d, lsa=%lld|%d, in an unknown index. "
			 "Record length = %d.\n", is_undo ? "BTREE_UNDO" : "BTREE_REDO", slotid,
			 node_type == BTREE_LEAF_NODE ? "leaf" : "overflow", PGBUF_PAGE_STATE_ARGS (rcv->pgptr),
			 update_record.length);
	}
    }
  return NO_ERROR;
}

/*
 * btree_rv_remove_unique_stats () -
 *   return: int
 *   recv(in): Recovery structure
 *
 * Note: Remove unique statistics from global hash
 */
int
btree_rv_remove_unique_stats (THREAD_ENTRY * thread_p, LOG_RCV * recv)
{
  BTID btid;
  LOG_TRAN_BTID_UNIQUE_STATS *unique_stats;
  int ret = NO_ERROR;

  assert (recv->length == sizeof (btid));

  /* unpack the index btid */
  btid = *(BTID *) recv->data;
  ret = logtb_delete_global_unique_stats (thread_p, &btid);
  if (ret != NO_ERROR)
    {
      assert_release (false);
      return ER_FAILED;
    }
  unique_stats = logtb_tran_find_btid_stats (thread_p, &btid, false);
  if (unique_stats != NULL)
    {
      unique_stats->deleted = true;
    }

  if (recv->offset < 0)
    {
      /* logical run postpone or logical compensate. this will end with an end system op log record that it is only
       * executed once. however, if the server crashes, we will have to drop these statistics again.
       * we'll do it by adding a redo log. this redo log record should be executed again and again until we successfully
       * finish recovery and a new checkpoint is created after it. if server crashes again during recovery, the
       * statistics may again show up in the memory. so we are only safe when checkpoint passed this point.
       * the solution was a little hack-ish: we use offset value to separate the logical operation execution and redo
       * execution. another approach is to create two different recovery indexes and functions.
       */
      LOG_DATA_ADDR addr = LOG_DATA_ADDR_INITIALIZER;
      /* should be system op */
      assert (log_check_system_op_is_started (thread_p));
      assert (recv->offset == -1);

      /* append a new RVBT_REMOVE_UNIQUE_STATS redo log record */
      addr.offset = 0;
      log_append_redo_data (thread_p, RVBT_REMOVE_UNIQUE_STATS, &addr, sizeof (btid), &btid);
    }
  else
    {
      /* simple redo. just set page dirty. */
      assert (recv->offset == 0);
    }

  return NO_ERROR;
}

/*
 * btree_physical_delete () - Physically delete an object (unlike MVCC delete, object and all its info are removed).
 *
 * return		 : Error code.
 * thread_p (in)	 : Thread entry.
 * btid (in)		 : B-tree ID.
 * key (in)		 : Key value.
 * oid (in)		 : Object OID.
 * class_oid (in)	 : Object class OID.
 * unique (in)		 : Output if index is unique.
 * op_type (in)		 : Operation type.
 * unique_stat_info (in) : Unique statistics information.
 */
int
btree_physical_delete (THREAD_ENTRY * thread_p, BTID * btid, DB_VALUE * key, OID * oid, OID * class_oid, int *unique,
		       int op_type, btree_unique_stats * unique_stat_info)
{
  BTREE_MVCC_INFO mvcc_info = BTREE_MVCC_INFO_INITIALIZER;

  if (prm_get_bool_value (PRM_ID_LOG_BTREE_OPS))
    {
      _er_log_debug (ARG_FILE_LINE,
		     "BTREE_DELETE: Start physical delete object %d|%d|%d, "
		     "class_oid %d|%d|%d in index (%d, %d|%d).\n", oid->volid, oid->pageid, oid->slotid,
		     class_oid->volid, class_oid->pageid, class_oid->slotid, btid->root_pageid, btid->vfid.volid,
		     btid->vfid.fileid);
    }
#if defined (SERVER_MODE)
  if (oid_is_serial (class_oid))
#else	/* !SERVER_MODE */		   /* SA_MODE */
  if (false)
#endif /* SA_MODE */
    {
      /* Before starting, we have to handle the special case of serials. Since next key locking was removed, deleting a
       * key from serial is not protected. Somebody may insert same key, and if the deleter undoes work, two objects
       * for the same key will be found. Therefore, it is better to postpone deleting object from index after commit.
       * While the deleter is still active, others will be blocked on the key. After deleter commits, it is no longer
       * critical to block new transactions checking the key (since it will not exist anyway). However, object is
       * still accessible to current transaction. Imagine next scenario (auto-commit off): drop serial s1; create
       * serial s1; If we leave the serial "s1" in index, creating it again will fail. Therefore we must also mark
       * existing object as deleted. We'll do this by using MVCC delete system: mark deletion using MVCCID. After
       * commit, the marked object will be removed. If transaction aborts, delete MVCCID will be removed. This should
       * actually apply to all unique indexes of non-MVCC classes. But since we don't have this information yet (we
       * must access the index root page to find out). In the future, maybe index uniqueness can be easily accessible
       * (through a hash or any other system). Then we can apply same rules to all unique non-MVCC indexes. */
      MVCCID tran_mvccid = logtb_get_current_mvccid (thread_p);

      BTREE_MVCC_INFO_SET_DELID (&mvcc_info, tran_mvccid);

      return btree_insert_internal (thread_p, btid, key, class_oid, oid, op_type, unique_stat_info, unique, &mvcc_info,
				    NULL, BTREE_OP_INSERT_MARK_DELETED);
    }
  else
    {
      return btree_delete_internal (thread_p, btid, oid, class_oid, &mvcc_info, key, NULL, unique, op_type,
				    unique_stat_info, NULL, NULL, NULL, BTREE_OP_DELETE_OBJECT_PHYSICAL);
    }
}

/*
 * btree_vacuum_insert_mvccid () - Vacuum the insert MVCCID of object.
 *
 * return	      : Error code.
 * thread_p (in)      : Thread entry.
 * btid (in)	      : B-tree ID.
 * buffered_key (in)  : Key value.
 * oid (in)	      : Object OID.
 * class_oid (in)     : Object class OID.
 * insert_mvccid (in) : Insert MVCCID of object.
 */
int
btree_vacuum_insert_mvccid (THREAD_ENTRY * thread_p, BTID * btid, OR_BUF * buffered_key, OID * oid, OID * class_oid,
			    MVCCID insert_mvccid)
{
  BTREE_MVCC_INFO mvcc_info = BTREE_MVCC_INFO_INITIALIZER;
  BTREE_MVCC_INFO match_mvccinfo = BTREE_MVCC_INFO_INITIALIZER;

  if (prm_get_bool_value (PRM_ID_LOG_BTREE_OPS))
    {
      _er_log_debug (ARG_FILE_LINE,
		     "BTREE_DELETE: Start vacuum insert MVCCID %lld from object %d|%d|%d, class_oid %d|%d|%d in "
		     "index (%d, %d|%d).\n", (long long int) insert_mvccid, oid->volid, oid->pageid, oid->slotid,
		     class_oid->volid, class_oid->pageid, class_oid->slotid, btid->root_pageid, btid->vfid.volid,
		     btid->vfid.fileid);
    }

  BTREE_MVCC_INFO_SET_INSID (&match_mvccinfo, insert_mvccid);
  return btree_delete_internal (thread_p, btid, oid, class_oid, &mvcc_info, NULL, buffered_key, NULL, SINGLE_ROW_MODIFY,
				NULL, &match_mvccinfo, NULL, NULL, BTREE_OP_DELETE_VACUUM_INSID);
}

/*
 * btree_vacuum_object () - Vacuum (remove) deleted object and all its info from b-tree key.
 *
 * return	      : Error code.
 * thread_p (in)      : Thread entry.
 * btid (in)	      : B-tree ID.
 * buffered_key (in)  : Key value.
 * oid (in)	      : Object OID.
 * class_oid (in)     : Object class OID.
 * delete_mvccid (in) : Delete MVCCID of object.
 */
int
btree_vacuum_object (THREAD_ENTRY * thread_p, BTID * btid, OR_BUF * buffered_key, OID * oid, OID * class_oid,
		     MVCCID delete_mvccid)
{
  BTREE_MVCC_INFO mvcc_info = BTREE_MVCC_INFO_INITIALIZER;
  BTREE_MVCC_INFO match_mvccinfo = BTREE_MVCC_INFO_INITIALIZER;

  if (prm_get_bool_value (PRM_ID_LOG_BTREE_OPS))
    {
      _er_log_debug (ARG_FILE_LINE,
		     "BTREE_DELETE: Start vacuum object %d|%d|%d, class_oid %d|%d|%d and delete MVCCID %lld in "
		     "index (%d, %d|%d).\n", oid->volid, oid->pageid, oid->slotid, class_oid->volid, class_oid->pageid,
		     class_oid->slotid, (long long int) delete_mvccid, btid->root_pageid, btid->vfid.volid,
		     btid->vfid.fileid);
    }

  BTREE_MVCC_INFO_SET_DELID (&match_mvccinfo, delete_mvccid);
  return btree_delete_internal (thread_p, btid, oid, class_oid, &mvcc_info, NULL, buffered_key, NULL, SINGLE_ROW_MODIFY,
				NULL, &match_mvccinfo, NULL, NULL, BTREE_OP_DELETE_VACUUM_OBJECT);
}

/*
 * btree_undo_mvcc_delete () - Undo MVCC delete (undo the insert of delete MVCCID).
 *
 * return	       : Error code.
 * thread_p (in)       : Thread entry.
 * btid (in)	       : B-tree ID.
 * buffered_key (in)   : Key value.
 * oid (in)	       : Object OID.
 * class_oid (in)      : Object class OID.
 * match_mvccinfo (in) : The MVCC information to be matched.
 * undo_nxlsa (in)     : UNDO next lsa for logical compensate.
 */
static int
btree_undo_mvcc_delete (THREAD_ENTRY * thread_p, BTID * btid, OR_BUF * buffered_key, OID * oid, OID * class_oid,
			BTREE_MVCC_INFO * match_mvccinfo, LOG_LSA * undo_nxlsa)
{
  BTREE_MVCC_INFO mvcc_info = BTREE_MVCC_INFO_INITIALIZER;

  if (prm_get_bool_value (PRM_ID_LOG_BTREE_OPS))
    {
      _er_log_debug (ARG_FILE_LINE,
		     "BTREE_DELETE: Start undo MVCC delete on object %d|%d|%d, class_oid %d|%d|%d and "
		     "delete MVCCID %lld in index (%d, %d|%d).\n", oid->volid, oid->pageid, oid->slotid,
		     class_oid->volid, class_oid->pageid, class_oid->slotid,
		     (long long int) match_mvccinfo->delete_mvccid, btid->root_pageid, btid->vfid.volid,
		     btid->vfid.fileid);
    }

  return btree_delete_internal (thread_p, btid, oid, class_oid, &mvcc_info, NULL, buffered_key, NULL, SINGLE_ROW_MODIFY,
				NULL, match_mvccinfo, undo_nxlsa, NULL, BTREE_OP_DELETE_UNDO_INSERT_DELID);
}

/*
 * btree_undo_insert_object () - Delete object from index as part of an undo of insert object operation.
 *
 * return	      : Error code.
 * thread_p (in)      : Thread entry.
 * btid (in)	      : B-tree ID.
 * buffered_key (in)  : Key value.
 * oid (in)	      : Object OID.
 * class_oid (in)     : Object class OID.
 * insert_mvccid (in) : Insert MVCCID.
 * undo_nxlsa (in)    : UNDO next lsa for logical compensate.
 */
static int
btree_undo_insert_object (THREAD_ENTRY * thread_p, BTID * btid, OR_BUF * buffered_key, OID * oid, OID * class_oid,
			  MVCCID insert_mvccid, LOG_LSA * undo_nxlsa)
{
  BTREE_MVCC_INFO mvcc_info = BTREE_MVCC_INFO_INITIALIZER;
  BTREE_MVCC_INFO match_mvccinfo = BTREE_MVCC_INFO_INITIALIZER;

  if (prm_get_bool_value (PRM_ID_LOG_BTREE_OPS))
    {
      _er_log_debug (ARG_FILE_LINE,
		     "BTREE_DELETE: Start undo insert object %d|%d|%d, class_oid %d|%d|%d and insert MVCCID %lld "
		     "in index (%d, %d|%d).\n", oid->volid, oid->pageid, oid->slotid, class_oid->volid,
		     class_oid->pageid, class_oid->slotid, (long long int) insert_mvccid, btid->root_pageid,
		     btid->vfid.volid, btid->vfid.fileid);
    }

  if (insert_mvccid != MVCCID_ALL_VISIBLE)
    {
      BTREE_MVCC_INFO_SET_INSID (&match_mvccinfo, insert_mvccid);
    }
  return btree_delete_internal (thread_p, btid, oid, class_oid, &mvcc_info, NULL, buffered_key, NULL, SINGLE_ROW_MODIFY,
				NULL, &match_mvccinfo, undo_nxlsa, NULL, BTREE_OP_DELETE_UNDO_INSERT);
}

/*
 * btree_undo_insert_object_unique_multiupd () - Delete object from unique index as part of an undo of insert object
 *						 operation - the insert moved older visible object during multi-update
 *						 and now it must be returned to first position.
 *
 * return		: Error code.
 * thread_p (in)	: Thread entry.
 * btid (in)		: B-tree ID.
 * buffered_key (in)	: Key value.
 * inserted_object (in) : Inserted object info.
 * second_object (in)	: Second visible object info.
 * insert_mvccid (in)	: Insert MVCCID.
 * undo_nxlsa (in)	: UNDO next lsa for logical compensate.
 */
static int
btree_undo_insert_object_unique_multiupd (THREAD_ENTRY * thread_p, BTID * btid, OR_BUF * buffered_key,
					  BTREE_OBJECT_INFO * inserted_object, BTREE_OBJECT_INFO * second_object,
					  MVCCID insert_mvccid, LOG_LSA * undo_nxlsa)
{
  BTREE_MVCC_INFO mvcc_info = BTREE_MVCC_INFO_INITIALIZER;
  BTREE_MVCC_INFO match_mvccinfo = BTREE_MVCC_INFO_INITIALIZER;

  if (prm_get_bool_value (PRM_ID_LOG_BTREE_OPS))
    {
      _er_log_debug (ARG_FILE_LINE,
		     "BTREE_DELETE: Start undo insert object %d|%d|%d, class_oid %d|%d|%d and insert MVCCID %lld "
		     "in index (%d, %d|%d). Special case of undo from unique "
		     "index when previous visible object must be returned to first position.\n",
		     inserted_object->oid.volid, inserted_object->oid.pageid, inserted_object->oid.slotid,
		     inserted_object->class_oid.volid, inserted_object->class_oid.pageid,
		     inserted_object->class_oid.slotid, (long long int) insert_mvccid, btid->root_pageid,
		     btid->vfid.volid, btid->vfid.fileid);
    }

  if (insert_mvccid != MVCCID_ALL_VISIBLE)
    {
      BTREE_MVCC_INFO_SET_INSID (&match_mvccinfo, insert_mvccid);
    }
  return btree_delete_internal (thread_p, btid, &inserted_object->oid, &inserted_object->class_oid, &mvcc_info, NULL,
				buffered_key, NULL, SINGLE_ROW_MODIFY, NULL, &match_mvccinfo, undo_nxlsa, second_object,
				BTREE_OP_DELETE_UNDO_INSERT_UNQ_MULTIUPD);
}

/*
 * btree_delete_postponed () - Delete b-tree object on postpone.
 *
 * return	      : Error code.
 * thread_p (in)      : Thread entry.
 * btid (in)	      : B-tree ID.
 * buffered_key (in)  : Key value (buffered).
 * btree_obj (in)     : B-tree object info.
 * tran_mvccid (in)   : Transaction MVCCID.
 * reference_lsa (in) : Postpone reference LSA.
 */
static int
btree_delete_postponed (THREAD_ENTRY * thread_p, BTID * btid, OR_BUF * buffered_key, BTREE_OBJECT_INFO * btree_obj,
			MVCCID tran_mvccid, LOG_LSA * reference_lsa)
{
  BTREE_MVCC_INFO match_mvccinfo = BTREE_MVCC_INFO_INITIALIZER;

  assert (MVCCID_IS_VALID (tran_mvccid));

  if (prm_get_bool_value (PRM_ID_LOG_BTREE_OPS))
    {
      _er_log_debug (ARG_FILE_LINE,
		     "BTREE_DELETE: Execute postponed delete: object %d|%d|%d, class_oid %d|%d|%d, "
		     "mvcc_info=%llu|%llu, in index (%d, %d|%d).\n", btree_obj->oid.volid, btree_obj->oid.pageid,
		     btree_obj->oid.slotid, btree_obj->class_oid.volid, btree_obj->class_oid.pageid,
		     btree_obj->class_oid.slotid, (unsigned long long int) btree_obj->mvcc_info.insert_mvccid,
		     (unsigned long long int) btree_obj->mvcc_info.delete_mvccid, btid->root_pageid, btid->vfid.volid,
		     btid->vfid.fileid);
    }

  BTREE_MVCC_INFO_SET_DELID (&match_mvccinfo, tran_mvccid);
  return btree_delete_internal (thread_p, btid, &btree_obj->oid, &btree_obj->class_oid, &btree_obj->mvcc_info, NULL,
				buffered_key, NULL, SINGLE_ROW_MODIFY, NULL, &match_mvccinfo, reference_lsa, NULL,
				BTREE_OP_DELETE_OBJECT_PHYSICAL_POSTPONED);
}

/*
 * btree_delete_internal () - Index internal function to delete data from a b-tree key.
 *
 * return		   : Error code.
 * thread_p (in)	   : Thread entry.
 * btid (in)		   : B-tree ID.
 * oid (in)		   : Object OID.
 * class_oid (in)	   : Object class OID.
 * mvcc_info (in)	   : Object MVCC info.
 * key (in)		   : Object key value.
 * buffered_key (in)	   : Buffered value of key. Must be unpacked.
 * unique (out)		   : Output if index is unique.
 * op_type (in)		   : Operation type.
 * unique_stat_info (in)   : Unique statistics collector.
 * match_mvccinfo (in)	   : B-tree MVCC info to be matched when searching object.
 * ref_lsa (in)		   : UNDO/Postpone reference LSA.
 * second_object_info (in) : B-tree object info for new version after an MVCC update same key.
 * purpose (in)		   : Purpose/context for function call.
 */
static int
btree_delete_internal (THREAD_ENTRY * thread_p, BTID * btid, OID * oid, OID * class_oid, BTREE_MVCC_INFO * mvcc_info,
		       DB_VALUE * key, OR_BUF * buffered_key, int *unique, int op_type,
		       btree_unique_stats * unique_stat_info, BTREE_MVCC_INFO * match_mvccinfo, LOG_LSA * ref_lsa,
		       BTREE_OBJECT_INFO * second_object_info, BTREE_OP_PURPOSE purpose)
{
  /* Structure used by internal functions. */
  BTREE_DELETE_HELPER delete_helper;
  BTID_INT btree_info;		/* B-tree info. */
  int error_code = NO_ERROR;	/* Error code. */
  bool old_check_interrupt = false;	/* Save check interrupt before setting it to false. */
  BTREE_PROCESS_KEY_FUNCTION *key_func = NULL;	/* Internal function called to manipulate key. */
  DB_VALUE local_key;		/* Local storage for DB_VALUE if key is buffered. */

  /* Assert expected arguments. */
  assert (btid != NULL && !BTREE_INVALID_INDEX_ID (btid));
  assert ((key == NULL && buffered_key != NULL) || (key != NULL && buffered_key == NULL));
  assert (oid != NULL);
  assert (op_type == SINGLE_ROW_DELETE || op_type == MULTI_ROW_DELETE || op_type == SINGLE_ROW_UPDATE
	  || op_type == MULTI_ROW_UPDATE || op_type == SINGLE_ROW_MODIFY);

  PERF_UTIME_TRACKER_START (thread_p, &delete_helper.time_track);

  /* Choose internal function based on purpose. */
  switch (purpose)
    {
    case BTREE_OP_DELETE_OBJECT_PHYSICAL_POSTPONED:
    case BTREE_OP_DELETE_UNDO_INSERT:
      /* Set ref_lsa. */
      assert (ref_lsa != NULL);
      LSA_COPY (&delete_helper.reference_lsa, ref_lsa);
      /* Fall through. */
    case BTREE_OP_DELETE_OBJECT_PHYSICAL:
    case BTREE_OP_DELETE_VACUUM_OBJECT:
      key_func = btree_key_delete_remove_object;
      break;
    case BTREE_OP_DELETE_UNDO_INSERT_UNQ_MULTIUPD:
      key_func = btree_key_remove_object_and_keep_visible_first;
      /* Set ref_lsa. */
      assert (ref_lsa != NULL);
      LSA_COPY (&delete_helper.reference_lsa, ref_lsa);
      break;
    case BTREE_OP_DELETE_VACUUM_INSID:
      key_func = btree_key_remove_insert_mvccid;
      break;
    case BTREE_OP_DELETE_UNDO_INSERT_DELID:
      /* Set ref_lsa. */
      assert (ref_lsa != NULL);
      LSA_COPY (&delete_helper.reference_lsa, ref_lsa);
      key_func = btree_key_remove_delete_mvccid;
      break;
    default:
      /* Unhandled or unexpected. */
      assert_release (false);
      return ER_FAILED;
    }

  /* Initialize delete helper. */
  COPY_OID (BTREE_DELETE_OID (&delete_helper), oid);
  COPY_OID (BTREE_DELETE_CLASS_OID (&delete_helper), class_oid);
  *BTREE_DELETE_MVCC_INFO (&delete_helper) = *mvcc_info;
  delete_helper.purpose = purpose;

  /* Set operation type. */
  delete_helper.op_type = op_type;

  /* Set unique stats information. */
  delete_helper.unique_stats_info = unique_stat_info;

  /* Set MVCCID to be matched. */
  if (match_mvccinfo != NULL)
    {
      delete_helper.match_mvccinfo = *match_mvccinfo;
    }

  /* Is key buffered? */
  if (buffered_key != NULL)
    {
      /* Key will be unpacked after fixing root and getting key type. */
      delete_helper.buffered_key = buffered_key;
      key = &local_key;
      db_make_null (key);
    }

  /* Log b-tree operations? For debugging. */
  delete_helper.log_operations = prm_get_bool_value (PRM_ID_LOG_BTREE_OPS);

  if (second_object_info != NULL)
    {
      delete_helper.second_object_info = *second_object_info;
    }

  /* Add more btree_delete_helper initialization here. */

  old_check_interrupt = logtb_set_check_interrupt (thread_p, false);
  FI_SET (thread_p, FI_TEST_BTREE_MANAGER_PAGE_DEALLOC_FAIL, 1);

  error_code =
    btree_search_key_and_apply_functions (thread_p, btid, &btree_info, key, btree_fix_root_for_delete, &delete_helper,
					  btree_merge_node_and_advance, &delete_helper, key_func, &delete_helper, NULL,
					  NULL);

  (void) logtb_set_check_interrupt (thread_p, old_check_interrupt);
  FI_RESET (thread_p, FI_TEST_BTREE_MANAGER_PAGE_DEALLOC_FAIL);

  if (delete_helper.printed_key != NULL)
    {
      db_private_free (thread_p, delete_helper.printed_key);
    }

  if (buffered_key != NULL)
    {
      assert (key != NULL);
      pr_clear_value (key);
    }

  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();

      btree_delete_log (&delete_helper, "failed operation, error_code = %d \n" BTREE_DELETE_HELPER_MSG ("\t")
			"\t" BTREE_ID_MSG,
			error_code, BTREE_DELETE_HELPER_AS_ARGS (&delete_helper), BTID_AS_ARGS (btid));
      return error_code;
    }

  perfmon_inc_stat (thread_p, PSTAT_BT_NUM_DELETES);

  if (unique != NULL)
    {
      *unique = BTREE_IS_UNIQUE (btree_info.unique_pk);
    }

  if (delete_helper.check_key_deleted && !delete_helper.is_key_deleted)
    {
      /* Correct unique stats info (key is not actually deleted). */
      assert (delete_helper.unique_stats_info != NULL);
      // todo - just remove row, not key from the beginning
      // revert
      delete_helper.unique_stats_info->insert_key_and_row ();
      // delete row
      delete_helper.unique_stats_info->delete_row ();
    }

  return NO_ERROR;
}

/*
 * btree_fix_root_for_delete () - BTREE_ROOT_WITH_KEY_FUNCTION - fix root page before deleting data from a key.
 *
 * return	       : Error code.
 * thread_p (in)       : Thread entry.
 * btid (in)	       : B-tree ID.
 * btid_int (in/out)   : Can output b-tree info.
 * key (in)	       : Not used.
 * root_page (out)     : Fixed root node page.
 * is_leaf (in)	       : Not used.
 * search_key (in)     : Not used.
 * stop (out)	       : Outputs to stop when deleting a NULL key.
 * restart (out)       : Not used.
 * other_args (in/out) : BTREE_DELETE_HELPER *
 */
static int
btree_fix_root_for_delete (THREAD_ENTRY * thread_p, BTID * btid, BTID_INT * btid_int, DB_VALUE * key,
			   PAGE_PTR * root_page, bool * is_leaf, BTREE_SEARCH_KEY_HELPER * search_key, bool * stop,
			   bool * restart, void *other_args)
{
  /* Structure used for internal functions used in btree_delete_internal. */
  BTREE_DELETE_HELPER *delete_helper = (BTREE_DELETE_HELPER *) other_args;
  int error_code = NO_ERROR;	/* Error code. */
  bool is_null = false;		/* Is key null. */

  /* Assert expected arguments. */
  assert (btid != NULL);
  assert (btid_int != NULL);
  assert (root_page != NULL && *root_page == NULL);
  assert (delete_helper != NULL);
  assert (btree_is_delete_data_purpose (delete_helper->purpose));

  /* Root node is being fixed. */
  delete_helper->is_root = true;
  if (delete_helper->is_first_search)
    {
      /* First search: read b-tree info. */
      *root_page = btree_fix_root_with_info (thread_p, btid, delete_helper->nonleaf_latch_mode, NULL, NULL, btid_int);
      if (*root_page == NULL)
	{
	  ASSERT_ERROR_AND_SET (error_code);
	  return error_code;
	}
    }
  else
    {
      /* Just fix root page. */
      *root_page = btree_fix_root_with_info (thread_p, btid, delete_helper->nonleaf_latch_mode, NULL, NULL, NULL);
      if (*root_page == NULL)
	{
	  ASSERT_ERROR_AND_SET (error_code);
	  return error_code;
	}
      return NO_ERROR;
    }
  /* Root page fixed. */
  /* This is first search. */
  /* Reset first search flag. We don't want to repeat next operations. */
  delete_helper->is_first_search = false;

  /* If buffered key is not NULL, key value must be unpacked. */
  if (delete_helper->buffered_key != NULL)
    {
      /* Unpack key from buffer. */
      PR_TYPE *pr_type;
      int key_size = -1;

      /* Assert key is initialized. */
      assert (DB_IS_NULL (key));

      pr_type = btid_int->key_type->type;

      /* Do not copy the string--just use the pointer.  The pr_ routines for strings and sets have different semantics
       * for length. */
      if (pr_type->id == DB_TYPE_MIDXKEY)
	{
	  key_size = CAST_BUFLEN (delete_helper->buffered_key->endptr - delete_helper->buffered_key->ptr);
	}

      /* Read key. */
      error_code = pr_type->index_readval (delete_helper->buffered_key, key, btid_int->key_type, key_size,
					   false /* not copy */ , NULL, 0);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  pgbuf_unfix_and_init (thread_p, *root_page);
	  return error_code;
	}
    }

  if (key != NULL && DB_VALUE_DOMAIN_TYPE (key) == DB_TYPE_MIDXKEY)
    {
      /* Set complete set domain. */
      key->data.midxkey.domain = btid_int->key_type;
    }

  /* Is key NULL? */
  is_null = key == NULL || DB_IS_NULL (key) || btree_multicol_key_is_null (key);

  /* Safe guard: key type matches. */
  assert (is_null || TP_ARE_COMPARABLE_KEY_TYPES (DB_VALUE_DOMAIN_TYPE (key), btid_int->key_type->type->id));

  if (delete_helper->log_operations)
    {
      /* Key must be printed. */
      delete_helper->printed_key = pr_valstring (key);
      (void) SHA1Compute ((unsigned char *) delete_helper->printed_key, strlen (delete_helper->printed_key),
			  &delete_helper->printed_key_sha1);
    }

  /* Safe guard: key cannot always be NULL. */
  assert (!is_null || delete_helper->purpose == BTREE_OP_DELETE_OBJECT_PHYSICAL
	  || delete_helper->purpose == BTREE_OP_ONLINE_INDEX_TRAN_DELETE
	  || delete_helper->purpose == BTREE_OP_ONLINE_INDEX_UNDO_TRAN_INSERT);

  if (delete_helper->purpose == BTREE_OP_DELETE_VACUUM_INSID || delete_helper->purpose == BTREE_OP_DELETE_VACUUM_OBJECT)
    {
      /* Vacuum operations don't need to go further. */
      return NO_ERROR;
    }
  if (delete_helper->purpose == BTREE_OP_DELETE_UNDO_INSERT
      || delete_helper->purpose == BTREE_OP_DELETE_UNDO_INSERT_UNQ_MULTIUPD
      || delete_helper->purpose == BTREE_OP_DELETE_UNDO_INSERT_DELID
      || delete_helper->purpose == BTREE_OP_DELETE_OBJECT_PHYSICAL_POSTPONED
      || delete_helper->purpose == BTREE_OP_ONLINE_INDEX_UNDO_TRAN_INSERT)
    {
      if (BTREE_IS_UNIQUE (btid_int->unique_pk))
	{
	  /* Class OID is not packed for undo when it matches topclass_oid. If it is NULL here, then it must be
	   * replaced with topclass_oid. */
	  if (OID_ISNULL (BTREE_DELETE_CLASS_OID (delete_helper)))
	    {
	      COPY_OID (BTREE_DELETE_CLASS_OID (delete_helper), &btid_int->topclass_oid);

	      /* BTREE_OP_DELETE_OBJECT_PHYSICAL_POSTPONED is used only for non-MVCC classes. */
	      assert (delete_helper->purpose != BTREE_OP_DELETE_OBJECT_PHYSICAL_POSTPONED || !LOG_ISRESTARTED ()
		      || mvcc_is_mvcc_disabled_class (BTREE_DELETE_CLASS_OID (delete_helper)));
	    }
	  if (delete_helper->purpose == BTREE_OP_DELETE_UNDO_INSERT_UNQ_MULTIUPD
	      && OID_ISNULL (&delete_helper->second_object_info.class_oid))
	    {
	      COPY_OID (&delete_helper->second_object_info.class_oid, &btid_int->topclass_oid);
	    }
	}
      else
	{
	  /* BTREE_OP_DELETE_OBJECT_PHYSICAL_POSTPONED is used only for unique indexes. */
	  assert (delete_helper->purpose != BTREE_OP_DELETE_OBJECT_PHYSICAL_POSTPONED);
	}
      /* Undo operations don't need to go further. */
      return NO_ERROR;
    }

  assert (btree_is_delete_object_purpose (delete_helper->purpose));

  /* Update unique statistics. */
  if (BTREE_IS_UNIQUE (btid_int->unique_pk) && delete_helper->purpose == BTREE_OP_DELETE_OBJECT_PHYSICAL)
    {
      /* Do not update statistics when vacuuming or during undo recovery. */
      btree_unique_stats incr;

      if (is_null)
	{
	  incr.delete_null_and_row ();
	}
      else
	{
	  incr.delete_key_and_row ();
	}

      if (BTREE_IS_MULTI_ROW_OP (delete_helper->op_type))
	{
	  /* Collect statistics */
	  assert (delete_helper->unique_stats_info != NULL);
	  (*delete_helper->unique_stats_info) += incr;

	  if (delete_helper->op_type == MULTI_ROW_UPDATE)
	    {
	      /* It is possible that after deleting key, it isn't actually deleted. We must count visible objects and
	       * correct above statistics. */
	      delete_helper->check_key_deleted = true;
	      delete_helper->is_key_deleted = true;
	    }
	}
      else
	{
	  /* Save and log statistics changes. */
	  if (!btree_is_online_index_loading (delete_helper->purpose))
	    {
	      error_code = logtb_tran_update_unique_stats (thread_p, *btid, incr, true);
	      if (error_code != NO_ERROR)
		{
		  ASSERT_ERROR ();
		  return error_code;
		}
	    }
	}
    }

  if (is_null)
    {
      /* Nothing to do anymore. */
      *stop = true;
    }
  return NO_ERROR;
}

/*
 * btree_merge_node_and_advance () - BTREE_ADVANCE_WITH_KEY_FUNCTION used by btree_delete_internal to merge b-tree
 *				     nodes while advancing to delete data from a key.
 *
 * return		 : Error code.
 * thread_p (in)	 : Thread entry.
 * btid_int (in)	 : B-tree info.
 * key (in)		 : Key to follow while advancing.
 * crt_page (in)	 : Pointer to current node's page.
 * advance_to_page (out) : Outputs next node page to advance to.
 * is_leaf (out)	 : Outputs whether current node is leaf.
 * search_key (out)	 : Outputs search key result when current node is leaf.
 * stop (out)		 : Outputs to end advancing (not used).
 * restart (out)	 : Outputs to restart from root.
 * other_args (in/out)	 : BTREE_DELETE_HELPER *
 */
static int
btree_merge_node_and_advance (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key, PAGE_PTR * crt_page,
			      PAGE_PTR * advance_to_page, bool * is_leaf, BTREE_SEARCH_KEY_HELPER * search_key,
			      bool * stop, bool * restart, void *other_args)
{
  /* Delete helper used by internal functions of btree_delete_internal. */
  BTREE_DELETE_HELPER *delete_helper = (BTREE_DELETE_HELPER *) other_args;
  PAGE_PTR left_page = NULL;	/* Left page to merge. */
  PAGE_PTR right_page = NULL;	/* Right page to merge. */
  VPID left_vpid = VPID_INITIALIZER;	/* VPID of left page to merge. */
  VPID right_vpid = VPID_INITIALIZER;	/* VPID of right page to merge. */
  int left_used = 0;		/* Space used in left page. */
  int right_used = 0;		/* Space used in right page. */
  int error_code = NO_ERROR;	/* Error code. */
  int key_count = 0;		/* Node key count. */
  BTREE_NODE_HEADER *node_header = NULL;	/* B-tree node header. */
  RECDES left_recdes, right_recdes;	/* Record descriptors to read links to left/right pages. */
  NON_LEAF_REC non_leaf_rec_info;	/* Non-leaf record info used to read links to left/right pages. */
  PGBUF_LATCH_MODE child_latch = PGBUF_LATCH_READ;	/* Latch mode for children of current node. */
  PAGE_FETCH_MODE neighbor_fetch_mode = OLD_PAGE;	/* fetch mode for neighbors checked on merge. */
  PGBUF_PROMOTE_CONDITION promote_cond;	/* Promote condition when write latch is required on nodes. */
  VPID child_vpid;		/* VPID of next child by following key argument. */
  VPID child_vpid_after_merge;	/* VPID of next by following key argument after merge is done. */
  PAGE_PTR child_page = NULL;	/* Next page by following key argument. */
  BTREE_MERGE_STATUS merge_status;	/* Status that tells when nodes can be merged. */
  bool need_root_merge = false;	/* Set to true when root can be merged. */
  bool force_root_merge = false;	/* Set to true when root must be merged. */
  bool is_system_op_started = false;	/* Set to true when a system operation is started to be properly aborted in
					 * case of errors. */

  LOG_LSA save_lsa = LSA_INITIALIZER;
  LOG_LSA save_child_lsa = LSA_INITIALIZER;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (key != NULL && !DB_IS_NULL (key) && !btree_multicol_key_is_null (key));
  assert (crt_page != NULL && *crt_page != NULL);
  assert (advance_to_page != NULL && *advance_to_page == NULL);
  assert (is_leaf != NULL);
  assert (search_key != NULL);
  assert (restart != NULL);
  assert (delete_helper != NULL);

  /* Merge algorithm: There are two types of merges: root merge and normal merge. 1. Root merge: If root has only two
   * keys and a level more than 2, it could be merged if all keys stored in leaf page pass the size check.  All three
   * nodes are merged into current root.  After merging, function will continue to check the merged node similarly with
   * any non-leaf nodes.  NOTE: I don't really know why the root_level has to be greater than 2. This means the b-tree
   * will never be reduced back to one node. It may not be a real issue, since the index is too small to worry about
   * performance. 2. Normal merge: Two nodes are merged if they pass the size check or if any of them is empty. Both
   * are merged to "left" node and their parent is updated.  During delete, the child node found by following key
   * argument is tested against its neighbors. A node is merged only once (if it was merged to the right node, it will
   * not be merged to left node too). To optimize b-tree access, the algorithm assumes that no change is required
   * (nodes are not merged) and uses READ latch on non-leaf nodes (leaf nodes still require WRITE latch since they are
   * very likely to be changed). Instead, if merge is required, latches are then promoted to WRITE. If promotions fail,
   * the algorithm has two choices: 1. Skip merging and just advance to child page. 2. Restart b-tree traversal using
   * exclusive access and force the merge.  Second choice is decided when the two nodes use together less than one
   * third of a page or when one of them is completely empty. Normally, promotions use shared reader condition
   * (multiple readers are allowed to promote, but no other promoters). On level 2 of b-tree, single reader condition
   * is used for promotion. The restriction is explained in btree_split_node_and_advance. */

  /* Get current node header. */
  node_header = btree_get_node_header (thread_p, *crt_page);
  if (node_header == NULL)
    {
      assert_release (false);
      return ER_FAILED;
    }
  if (node_header->node_level == 1)
    {
      /* This is a leaf node. Advancing can stop. Search key, promote latch and return. */
      error_code = btree_search_leaf_page (thread_p, btid_int, *crt_page, key, search_key);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return error_code;
	}
      if (delete_helper->is_root && delete_helper->nonleaf_latch_mode != PGBUF_LATCH_WRITE)
	{
	  /* Promote latch. */
	  error_code = pgbuf_promote_read_latch (thread_p, crt_page, PGBUF_PROMOTE_SHARED_READER);
	  if (error_code == ER_PAGE_LATCH_PROMOTE_FAIL)
	    {
	      /* Promotion failed. Restart using write latch directly. */
	      *restart = true;
	      delete_helper->nonleaf_latch_mode = PGBUF_LATCH_WRITE;
	      return NO_ERROR;
	    }
	  else if (error_code != NO_ERROR)
	    {
	      /* Error promoting. */
	      ASSERT_ERROR ();
	      return error_code;
	    }
	  else if (*crt_page == NULL)
	    {
	      /* Promoting has failed. Make sure an error has been set. */
	      ASSERT_ERROR_AND_SET (error_code);
	      return error_code;
	    }
	}
      else
	{
	  /* Leaf node should already have exclusive latch. */
	  assert (pgbuf_get_latch_mode (*crt_page) >= PGBUF_LATCH_WRITE);
	}
      /* Successful. */
      *is_leaf = true;
      return NO_ERROR;
    }
  /* Not a leaf page. */

  /* Get key count. */
  key_count = btree_node_number_of_keys (thread_p, *crt_page);

  /* Check if current node is root and must be merged. */
  if (delete_helper->is_root	/* Current node is root. */
      && node_header->node_level > 2	/* Its level is more than two. */
      && btree_node_number_of_keys (thread_p, *crt_page) == 2 /* Has only two keys */ )
    {
      /* Save root max key length. */
      int root_max_key_length = node_header->max_key_len;

      /* Since the root has at least level 2, its children are non-leaf. */

      /* Read the first record. */
      if (spage_get_record (thread_p, *crt_page, 1, &left_recdes, PEEK) != S_SUCCESS)
	{
	  assert_release (false);
	  error_code = ER_FAILED;
	  goto error;
	}
      btree_read_fixed_portion_of_non_leaf_record (&left_recdes, &non_leaf_rec_info);
      /* Fix left child. */
      VPID_COPY (&left_vpid, &non_leaf_rec_info.pnt);
      assert (!VPID_ISNULL (&left_vpid));
      left_page =
	pgbuf_fix (thread_p, &left_vpid, OLD_PAGE, delete_helper->nonleaf_latch_mode, PGBUF_UNCONDITIONAL_LATCH);
      if (left_page == NULL)
	{
	  ASSERT_ERROR_AND_SET (error_code);
	  goto error;
	}
#if !defined (NDEBUG)
      (void) pgbuf_check_page_ptype (thread_p, left_page, PAGE_BTREE);
#endif /* !NDEBUG */
      left_used = DB_PAGESIZE - spage_get_free_space (thread_p, left_page);

      /* Read second record. */
      if (spage_get_record (thread_p, *crt_page, 2, &right_recdes, PEEK) != S_SUCCESS)
	{
	  assert_release (false);
	  error_code = ER_FAILED;
	  goto error;
	}
      btree_read_fixed_portion_of_non_leaf_record (&right_recdes, &non_leaf_rec_info);
      /* Fix right child. */
      VPID_COPY (&right_vpid, &non_leaf_rec_info.pnt);
      assert (!VPID_ISNULL (&right_vpid));
      right_page =
	pgbuf_fix (thread_p, &right_vpid, OLD_PAGE, delete_helper->nonleaf_latch_mode, PGBUF_UNCONDITIONAL_LATCH);
      if (right_page == NULL)
	{
	  ASSERT_ERROR_AND_SET (error_code);
	  goto error;
	}
#if !defined (NDEBUG)
      (void) pgbuf_check_page_ptype (thread_p, right_page, PAGE_BTREE);
#endif /* !NDEBUG */
      right_used = DB_PAGESIZE - spage_get_free_space (thread_p, right_page);

      /* Is merge needed? Should be forced if promotion fails? */
      /* We need to consider the largest key size since merge will use a key from root page as the middle key. It may
       * be larger than any key in its children. This may be overly defensive, but it doesn't seem so bad for root
       * merges. TODO: The above comment may be part of a legacy code. Currently, Merging root algorithm doesn't show
       * any extra key being required. Consider removing root_max_key_length. */
      need_root_merge = (left_used + right_used + CAN_MERGE_WHEN_EMPTY + root_max_key_length) < DB_PAGESIZE;
      /* If latch promotions fail, merge might be skipped. However, it is not desirable to skip all merges in a highly
       * accessed index. So we have two levels of how much space can be wasted before merge is executed: - one level
       * when merge is attempted with latch promotion. - one level, when more space was wasted and we need to force
       * restarting b-tree traversal using exclusive latches and making sure that merge is executed. */
      force_root_merge = (left_used + right_used + FORCE_MERGE_WHEN_EMPTY + root_max_key_length) < DB_PAGESIZE;

      /* If merge is required, promote latches. */
      if (need_root_merge)
	{
	  /* Need merge. */
	  /* All pages must be write latched. */

	  if (delete_helper->nonleaf_latch_mode == PGBUF_LATCH_READ)
	    {
	      /* Promote latches. */

	      /* First promote root. */
	      error_code = pgbuf_promote_read_latch (thread_p, crt_page, PGBUF_PROMOTE_ONLY_READER);

	      if (error_code == NO_ERROR && *crt_page != NULL)
		{
		  /* Root successfully promoted. Promote left page. */
		  error_code = pgbuf_promote_read_latch (thread_p, &left_page, PGBUF_PROMOTE_SHARED_READER);
		  if (error_code == NO_ERROR && left_page != NULL)
		    {
		      /* Left page successfully promoted. Promote right page. */
		      error_code = pgbuf_promote_read_latch (thread_p, &right_page, PGBUF_PROMOTE_SHARED_READER);
		    }
		}
	    }
	  else
	    {
	      /* Pages already latched exclusively. Fall through to continue merging. */
	    }
	  if (error_code == ER_PAGE_LATCH_PROMOTE_FAIL)
	    {
	      /* Not all nodes could be promoted. */
	      if (force_root_merge)
		{
		  /* Restart b-tree traversal with exclusive access. */
		  delete_helper->nonleaf_latch_mode = PGBUF_LATCH_WRITE;
		  *restart = true;
		  if (left_page != NULL)
		    {
		      pgbuf_unfix_and_init (thread_p, left_page);
		    }
		  if (right_page != NULL)
		    {
		      pgbuf_unfix_and_init (thread_p, right_page);
		    }
		  return NO_ERROR;
		}
	      /* Skip merging. */
	      /* Fall through to advance to child. */
	    }
	  else if (error_code != NO_ERROR)
	    {
	      ASSERT_ERROR ();
	      goto error;
	    }
	  else if (*crt_page == NULL || left_page == NULL || right_page == NULL)
	    {
	      ASSERT_ERROR_AND_SET (error_code);
	      goto error;
	    }
	  else
	    {
	      /* All pages are write latched. Merge the nodes. */
	      assert ((pgbuf_get_latch_mode (*crt_page) >= PGBUF_LATCH_WRITE)
		      && (pgbuf_get_latch_mode (left_page) >= PGBUF_LATCH_WRITE)
		      && (pgbuf_get_latch_mode (right_page) >= PGBUF_LATCH_WRITE));

	      /* Start system operation. */
	      log_sysop_start (thread_p);
	      is_system_op_started = true;

	      /* Merge the three nodes into root node. */
	      error_code = btree_merge_root (thread_p, btid_int, *crt_page, left_page, right_page);
	      if (error_code != NO_ERROR)
		{
		  ASSERT_ERROR ();
		  goto error;
		}
#if !defined (NDEBUG)
	      (void) spage_check_num_slots (thread_p, *crt_page);
#endif /* !NDEBUG */

	      pgbuf_unfix_and_init (thread_p, left_page);
	      error_code = file_dealloc (thread_p, &btid_int->sys_btid->vfid, &left_vpid, FILE_BTREE);
	      if (error_code != NO_ERROR)
		{
		  ASSERT_ERROR ();
		  goto error;
		}
	      pgbuf_unfix_and_init (thread_p, right_page);
	      error_code = file_dealloc (thread_p, &btid_int->sys_btid->vfid, &right_vpid, FILE_BTREE);
	      if (error_code != NO_ERROR)
		{
		  ASSERT_ERROR ();
		  goto error;
		}

	      /* Merge successfully finished. */
	      log_sysop_commit (thread_p);
	      is_system_op_started = false;

	      /* Nodes have been merged into root. Repeat loop in case we can merge root again. */
	      *advance_to_page = *crt_page;
	      *crt_page = NULL;
	      return NO_ERROR;
	    }
	}
      /* Root was not merged. */
      /* Advance to one of the children. */
      error_code = btree_search_nonleaf_page (thread_p, btid_int, *crt_page, key, &search_key->slotid, &child_vpid,
					      NULL);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto error;
	}
      assert (search_key->slotid == 1 || search_key->slotid == 2);
      pgbuf_unfix_and_init (thread_p, *crt_page);
      if (search_key->slotid == 1)
	{
	  *crt_page = left_page;
	  left_page = NULL;
	  pgbuf_unfix_and_init (thread_p, right_page);
	}
      else
	{
	  *crt_page = right_page;
	  right_page = NULL;
	  pgbuf_unfix_and_init (thread_p, left_page);
	}
      /* We advanced to one of the children. Proceed to check non-leaf node. */

      /* Get node header. */
      node_header = btree_get_node_header (thread_p, *crt_page);
      if (node_header == NULL)
	{
	  assert_release (false);
	  return ER_FAILED;
	}
      /* This cannot be a leaf node. */
      assert (node_header->node_level > 1);
      /* Get key count. */
      key_count = btree_node_number_of_keys (thread_p, *crt_page);
    }
  assert (left_page == NULL);
  assert (right_page == NULL);

  /* Choose the node to advance to. Then check whether it can be merged with any of its neighbors. */
  error_code = btree_search_nonleaf_page (thread_p, btid_int, *crt_page, key, &search_key->slotid, &child_vpid, NULL);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto error;
    }
  if (node_header->node_level == 2)
    {
      /* Next child is leaf and must be latched using write latch mode directly. Promote condition is single reader to
       * avoid dead-latch (see the comment explaining promote condition in btree_split_node_and_advance). */
      child_latch = PGBUF_LATCH_WRITE;
      promote_cond = PGBUF_PROMOTE_ONLY_READER;
    }
  else
    {
      /* Use non-leaf latch mode. */
      /* Promote when non-leaf latch mode is PGBUF_LATCH_READ can be shared reader. If latch mode is PGBUF_LATCH_WRITE,
       * no promotion is required. */
      child_latch = delete_helper->nonleaf_latch_mode;
      promote_cond = PGBUF_PROMOTE_SHARED_READER;
    }
  /* Fix child node. */
  child_page = pgbuf_fix (thread_p, &child_vpid, OLD_PAGE, child_latch, PGBUF_UNCONDITIONAL_LATCH);
  if (child_page == NULL)
    {
      ASSERT_ERROR_AND_SET (error_code);
      goto error;
    }
#if !defined (NDEBUG)
  (void) pgbuf_check_page_ptype (thread_p, child_page, PAGE_BTREE);
#endif /* !NDEBUG */

  /* Get header of child. */
  node_header = btree_get_node_header (thread_p, child_page);
  if (node_header == NULL)
    {
      assert_release (false);
      error_code = ER_FAILED;
      goto error;
    }

  /* todo: do another cleanup of this code!! */

  /* let's try merge with right node..
   * note: we will try to avoid checking merges uselessly. The whole check can be very expensive if we also have to load
   *       the node from disk. I am talking from (bad) experience here. The merges are usually done by vacuum, following
   *       the path of active workers. In huge indexes, that can be several levels in height, the lower levels
   *       neighboring nodes can be cold. The problem is not really reading the page from disk (which is relatively
   *       fast), but finding a viable bcb to victimize and replace with this cold page. Usually writes are slower, and
   *       if the IO write does not keep up, bcb allocation becomes the main bottleneck. And this expensive check makes
   *       vacuum fall behind, which is usually followed by constantly degrading overall performance.
   *       So, in such systems, it might be better to rather give up the merge. */
  if (search_key->slotid < key_count && spage_get_free_space (thread_p, child_page) > DB_PAGESIZE / 2)
    {
      /* this can cause a lot of problems. but we need it to know that page was not fixed because not in buffer and not
       * because some error occurred. */
      er_clear ();

      /* Check merges. */
      /* Check right merge. */

      /* Get link to right page. */
      if (spage_get_record (thread_p, *crt_page, search_key->slotid + 1, &right_recdes, PEEK) != S_SUCCESS)
	{
	  assert_release (false);
	  error_code = ER_FAILED;
	  goto error;
	}
      btree_read_fixed_portion_of_non_leaf_record (&right_recdes, &non_leaf_rec_info);
      /* Fix right page. */
      VPID_COPY (&right_vpid, &non_leaf_rec_info.pnt);
#if defined (SERVER_MODE)
      if (pgbuf_is_io_stressful () && spage_get_free_space (thread_p, child_page) < (int) (DB_PAGESIZE * 0.75f)
	  && spage_number_of_slots (child_page) > 2)
	{
	  /* avoid fetching "cold" neighbor pages, that are not in page buffer. at the same time, we should avoid doing
	   * zero merges. so if we have a strong indicator that merge is possible (e.g. current page is almost empty)
	   * force fixing the page.
	   * I set an experimental value of 75% free space to try the merge. I don't know what a good value is (or if
	   * there is any). */
	  neighbor_fetch_mode = OLD_PAGE_IF_IN_BUFFER;
	}
#endif /* SERVER_MODE */
      right_page = pgbuf_fix (thread_p, &right_vpid, neighbor_fetch_mode, child_latch, PGBUF_UNCONDITIONAL_LATCH);
      if (right_page == NULL)
	{
	  error_code = er_errid ();

	  if (error_code != NO_ERROR)
	    {
	      goto error;
	    }
	  /* page not in buffer */
	  /* fall through */
	}
      else
	{
#if !defined (NDEBUG)
	  (void) pgbuf_check_page_ptype (thread_p, right_page, PAGE_BTREE);
#endif /* !NDEBUG */

	  /* Can child page be merged with its right page? */
	  merge_status = btree_node_mergeable (thread_p, btid_int, child_page, right_page);
	  if (merge_status != BTREE_MERGE_NO)
	    {
	      /* Try to merge. */

	      /* Exclusive latch is required on all nodes. */
	      if (delete_helper->nonleaf_latch_mode != PGBUF_LATCH_WRITE)
		{
		  /* Promote latch on current node. */
		  error_code = pgbuf_promote_read_latch (thread_p, crt_page, PGBUF_PROMOTE_ONLY_READER);
		  if (error_code == NO_ERROR && *crt_page != NULL && child_latch != PGBUF_LATCH_WRITE)
		    {
		      /* Promote latches on children. */

		      /* Promote latch on child. */
		      error_code = pgbuf_promote_read_latch (thread_p, &child_page, promote_cond);
		      if (error_code == NO_ERROR && child_page != NULL)
			{
			  /* Promote latch on right page. */
			  error_code = pgbuf_promote_read_latch (thread_p, &right_page, promote_cond);
			}
		    }
		}
	      /* Are all pages successfully write latched? */
	      if (error_code == ER_PAGE_LATCH_PROMOTE_FAIL)
		{
		  /* Failed to promote all latches to exclusive. */
		  if (merge_status != BTREE_MERGE_TRY)
		    {
		      /* Merge must be executed. Restart using exclusive access. */
		      delete_helper->nonleaf_latch_mode = PGBUF_LATCH_WRITE;
		      *restart = true;
		      if (right_page != NULL)
			{
			  pgbuf_unfix_and_init (thread_p, right_page);
			}
		      if (child_page != NULL)
			{
			  pgbuf_unfix_and_init (thread_p, child_page);
			}
		      return NO_ERROR;
		    }
		  /* Merge can be skipped. Fall through. */
		}
	      else if (error_code != NO_ERROR)
		{
		  ASSERT_ERROR ();
		  goto error;
		}
	      else if (*crt_page == NULL || child_page == NULL || right_page == NULL)
		{
		  ASSERT_ERROR_AND_SET (error_code);
		  goto error;
		}
	      else
		{
		  /* All pages are write latched. */
		  assert ((pgbuf_get_latch_mode (*crt_page) >= PGBUF_LATCH_WRITE)
			  && (pgbuf_get_latch_mode (child_page) >= PGBUF_LATCH_WRITE)
			  && (pgbuf_get_latch_mode (right_page) >= PGBUF_LATCH_WRITE));

		  /* Start system operation. */
		  log_sysop_start (thread_p);
		  is_system_op_started = true;

		  save_lsa = *pgbuf_get_lsa (*crt_page);
		  save_child_lsa = *pgbuf_get_lsa (child_page);

		  /* Merge children and update parent. */
		  error_code =
		    btree_merge_node (thread_p, btid_int, *crt_page, child_page, right_page, search_key->slotid + 1,
				      &child_vpid_after_merge, merge_status);
		  if (error_code != NO_ERROR)
		    {
		      ASSERT_ERROR ();
		      goto error;
		    }

		  btree_delete_log (delete_helper, "Merged nodes into left. \n"
				    "\t" PGBUF_PAGE_MODIFY_MSG ("parent node page") "\n"
				    "\t" PGBUF_PAGE_MODIFY_MSG ("left node page") "\n"
				    "\t" "right node vpid = %d|%d",
				    PGBUF_PAGE_MODIFY_ARGS (*crt_page, &save_lsa),
				    PGBUF_PAGE_MODIFY_ARGS (child_page, &save_child_lsa), VPID_AS_ARGS (&right_vpid));

		  /* Children are merged to the "left" node which is our case is the child page. */
		  assert (!VPID_ISNULL (&child_vpid_after_merge));
		  assert (VPID_EQ (&child_vpid_after_merge, &child_vpid));

#if !defined(NDEBUG)
		  (void) spage_check_num_slots (thread_p, *crt_page);
		  (void) spage_check_num_slots (thread_p, child_page);
#endif

		  /* Deallocate right page. */
		  pgbuf_unfix_and_init (thread_p, right_page);
		  error_code = file_dealloc (thread_p, &btid_int->sys_btid->vfid, &right_vpid, FILE_BTREE);
		  if (error_code != NO_ERROR)
		    {
		      ASSERT_ERROR ();
		      goto error;
		    }

		  log_sysop_commit (thread_p);
		  is_system_op_started = false;

		  /* Advance to child page. */
		  *advance_to_page = child_page;
		  pgbuf_unfix_and_init (thread_p, *crt_page);
		  delete_helper->is_root = false;
		  return NO_ERROR;
		}
	    }
	  /* Merge not executed. Unfix right page. */
	  pgbuf_unfix_and_init (thread_p, right_page);
	}
    }
  /* No merge has been executed. */
  assert (left_page == NULL);
  assert (right_page == NULL);

  /* Advance to current child. */
  *advance_to_page = child_page;
  pgbuf_unfix_and_init (thread_p, *crt_page);
  delete_helper->is_root = false;

  return NO_ERROR;

error:
  assert_release (error_code != NO_ERROR);

  if (is_system_op_started)
    {
      /* Abort system operation, before unfixing the pages to be sure that no other transaction modify the pages. */
      log_sysop_abort (thread_p);
    }

  /* Unfix used pages. */
  assert (*advance_to_page == NULL);
  if (left_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, left_page);
    }
  if (right_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, right_page);
    }
  if (child_page != NULL)
    {
      pgbuf_unfix_and_init (thread_p, child_page);
    }

  return error_code;
}

/*
 * btree_key_delete_remove_object () - Remove one object and all its info from b-tree key.
 *
 * return	   : Error code.
 * thread_p (in)   : Thread entry.
 * btid_int (in)   : B-tree info.
 * key (in)	   : Key value.
 * leaf_page (in)  : Leaf page.
 * search_key (in) : Search key result.
 * restart (in)	   : Not used.
 * other_args (in) : BTREE_DELETE_HELPER *
 */
static int
btree_key_delete_remove_object (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key, PAGE_PTR * leaf_page,
				BTREE_SEARCH_KEY_HELPER * search_key, bool * restart, void *other_args)
{
  /* btree_delete_internal helper. */
  BTREE_DELETE_HELPER *delete_helper = (BTREE_DELETE_HELPER *) other_args;
  int error_code = NO_ERROR;	/* Error code. */
  RECDES leaf_record;		/* Copy leaf record. */
  /* Buffer used to copy leaf record. */
  char record_data_buffer[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  LEAF_REC leaf_rec_info;	/* Leaf record info. */
  int offset_after_key = 0;	/* Offset after key in leaf record. */
  bool dummy_clear_value = false;	/* Dummy. */
  PAGE_PTR found_page = NULL;	/* Page where object being removed is found. */
  PAGE_PTR prev_found_page = NULL;	/* Previous page to the page where object being removed is found. Saved in case
					 * that object is last in an overflow page and page must be deallocated. */
  int offset_to_object = NOT_FOUND;	/* Offset in record where object to be removed is found. */
  BTREE_NODE_TYPE node_type;

  /* Recovery structures. */
  /* Undo recovery structures. */
  char rv_undo_data_buffer[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  char *rv_undo_data_bufalign = PTR_ALIGN (rv_undo_data_buffer, BTREE_MAX_ALIGN);
  int rv_undo_data_capacity = IO_MAX_PAGE_SIZE;
  /* Redo recovery structures. */
  char rv_redo_data_buffer[BTREE_RV_BUFFER_SIZE + BTREE_MAX_ALIGN];

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (key != NULL && !DB_IS_NULL (key) && !btree_multicol_key_is_null (key));
  assert (leaf_page != NULL && *leaf_page != NULL && pgbuf_get_latch_mode (*leaf_page) >= PGBUF_LATCH_WRITE);
  assert (search_key != NULL);
  assert (delete_helper != NULL);
  assert (btree_is_delete_object_purpose (delete_helper->purpose)
	  && delete_helper->purpose != BTREE_OP_DELETE_UNDO_INSERT_UNQ_MULTIUPD);

  btree_perf_track_traverse_time (thread_p, delete_helper);

  if (search_key->result == BTREE_KEY_FOUND)
    {
      /* Key was found. We need to find OID. */
      /* Read key record. */
      leaf_record.data = PTR_ALIGN (record_data_buffer, BTREE_MAX_ALIGN);
      leaf_record.area_size = DB_PAGESIZE;
      if (spage_get_record (thread_p, *leaf_page, search_key->slotid, &leaf_record, COPY) != S_SUCCESS)
	{
	  assert_release (false);
	  return ER_FAILED;
	}
      error_code =
	btree_read_record (thread_p, btid_int, *leaf_page, &leaf_record, NULL, &leaf_rec_info, BTREE_LEAF_NODE,
			   &dummy_clear_value, &offset_after_key, PEEK_KEY_VALUE, NULL);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto exit;
	}
      /* Find OID and output its location/MVCC info. */
      error_code =
	btree_find_oid_and_its_page (thread_p, btid_int, BTREE_DELETE_OID (delete_helper), *leaf_page,
				     delete_helper->purpose, &delete_helper->match_mvccinfo, &leaf_record,
				     &leaf_rec_info, offset_after_key, &found_page, &prev_found_page, &offset_to_object,
				     BTREE_DELETE_MVCC_INFO (delete_helper));
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto exit;
	}
    }
  else
    {
      /* Key was not found. Fall through to handle the case. */
    }
  if (offset_to_object == NOT_FOUND)
    {
      /* Key/object was not found. */
      assert (found_page == NULL && prev_found_page == NULL);

      if (delete_helper->purpose == BTREE_OP_DELETE_VACUUM_OBJECT)
	{
	  /* Most probably, object was already vacuumed. One uncommon, but yet possible case when this can happen: 1.
	   * OID1, reusable object in a b-tree overflow page. 2. OID1 is marked as deleted to be vacuumed later. 3.
	   * OID1 is vacuumed from heap and its slot can be reused. 4. OID1 is reused and is inserted in the same
	   * overflow page. The algorithm recognizes that the old version is just not vacuumed yet and replaces it.
	   * OID's cannot be repeated in overflow pages. 5. Vacuum will not find the old OID1 to remove. */
	  vacuum_er_log_warning (VACUUM_ER_LOG_BTREE | VACUUM_ER_LOG_WORKER,
				 "Could not find object %d|%d|%d in key=%s to vacuum it.",
				 delete_helper->object_info.oid.volid, delete_helper->object_info.oid.pageid,
				 delete_helper->object_info.oid.slotid,
				 delete_helper->printed_key != NULL ? delete_helper->printed_key : "(unknown)");
	  btree_delete_log (delete_helper, "could not find object to vacuum \n"
			    BTREE_DELETE_HELPER_MSG ("\t"), BTREE_DELETE_HELPER_AS_ARGS (delete_helper));
	  goto exit;
	}
      else
	{
	  /* Key/oid should be found. */
	  assert_release (false);
	  btree_set_unknown_key_error (thread_p, btid_int->sys_btid, key,
				       "btree_key_delete_remove_object: key was not found.");
	  error_code = ER_BTREE_UNKNOWN_KEY;
	  goto exit;
	}
    }
  /* Object was found. */

#if defined (SERVER_MODE)
  /* When do we need to have a lock on object to protect it? 1. If this is not vacuum. 2. If this is not crash
   * recovery. 3. If object is not a rollback of insert into non-unique index. 4. If object is not inserted by current
   * transaction into non-unique index. All other cases must have lock on object. */
  assert (delete_helper->purpose == BTREE_OP_DELETE_VACUUM_OBJECT || log_is_in_crash_recovery ()
	  || (!BTREE_IS_UNIQUE (btid_int->unique_pk)
	      && (delete_helper->purpose == BTREE_OP_DELETE_UNDO_INSERT
		  || BTREE_MVCC_INFO_INSID (BTREE_DELETE_MVCC_INFO (delete_helper)) ==
		  logtb_find_current_mvccid (thread_p)))
	  /* Cannot check if class OID is NULL. Get it in debug mode. */
	  || OID_ISNULL (BTREE_DELETE_CLASS_OID (delete_helper))
	  || btree_check_locking_for_delete_unique (thread_p, delete_helper));
#endif /* SERVER_MODE */

  /* Safe guard: if the index is unique and we want to physically delete the object and if operation type is not
   * MULTI_ROW_UPDATE, then object must be first in record. */
  assert (!BTREE_IS_UNIQUE (btid_int->unique_pk) || delete_helper->purpose != BTREE_OP_DELETE_OBJECT_PHYSICAL
	  || delete_helper->op_type == MULTI_ROW_UPDATE || (found_page == *leaf_page && offset_to_object == 0));

  /* Prepare logging. */
  delete_helper->leaf_addr.pgptr = *leaf_page;
  delete_helper->leaf_addr.offset = search_key->slotid;
  delete_helper->leaf_addr.vfid = &btid_int->sys_btid->vfid;

  /* Undo logging. */
  /* Vacuum doesn't require undo logging - vacuum may sometime open a system operation to handle complex actions, like
   * deallocating overflow pages. However, the object is removal is last and if successful, then the entire operation
   * is considered successful. Object removal does not require undo logging. BTREE_OP_DELETE_UNDO_INSERT will append a
   * compensate log record and also requires only redo recovery data. */
  if (delete_helper->purpose == BTREE_OP_DELETE_OBJECT_PHYSICAL)
    {
      delete_helper->rv_keyval_data = rv_undo_data_bufalign;
      error_code =
	btree_rv_save_keyval_for_undo (btid_int, key, BTREE_DELETE_CLASS_OID (delete_helper),
				       BTREE_DELETE_OID (delete_helper), BTREE_DELETE_MVCC_INFO (delete_helper),
				       delete_helper->purpose, rv_undo_data_bufalign, &delete_helper->rv_keyval_data,
				       &rv_undo_data_capacity, &delete_helper->rv_keyval_data_length);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto exit;
	}
    }
  else
    {
      /* No need for undo data. */
      delete_helper->rv_keyval_data = NULL;
      delete_helper->rv_keyval_data_length = 0;
    }

  /* Redo logging. */
  delete_helper->rv_redo_data = PTR_ALIGN (rv_redo_data_buffer, BTREE_MAX_ALIGN);
  delete_helper->rv_redo_data_ptr = delete_helper->rv_redo_data;

  /* Where was object found? */
  node_type = *leaf_page == found_page ? BTREE_LEAF_NODE : BTREE_OVERFLOW_NODE;
  error_code =
    btree_key_remove_object (thread_p, key, btid_int, delete_helper, *leaf_page, &leaf_record, &leaf_rec_info,
			     offset_after_key, search_key, &found_page, prev_found_page, node_type, offset_to_object);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      goto exit;
    }
  if (found_page != NULL && found_page != *leaf_page)
    {
      pgbuf_unfix_and_init (thread_p, found_page);
    }
  if (prev_found_page != NULL && prev_found_page != *leaf_page)
    {
      pgbuf_unfix_and_init (thread_p, prev_found_page);
    }

  if (delete_helper->check_key_deleted)
    {
      /* Check key is really deleted (it may still have visible objects). */
      int num_visible_oids;
      int max_visible_oids = 1;
      MVCC_SNAPSHOT mvcc_snapshot_dirty;

      assert (delete_helper->purpose == BTREE_OP_DELETE_OBJECT_PHYSICAL);

      mvcc_snapshot_dirty.snapshot_fnc = mvcc_satisfies_dirty;

      /* Re-read leaf record. */
      if (spage_get_record (thread_p, *leaf_page, search_key->slotid, &leaf_record, PEEK) != S_SUCCESS)
	{
	  assert_release (false);
	  error_code = ER_FAILED;
	  goto exit;
	}
      error_code =
	btree_read_record (thread_p, btid_int, *leaf_page, &leaf_record, NULL, &leaf_rec_info, BTREE_LEAF_NODE,
			   &dummy_clear_value, &offset_after_key, PEEK_KEY_VALUE, NULL);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto exit;
	}
      error_code =
	btree_get_num_visible_from_leaf_and_ovf (thread_p, btid_int, &leaf_record, offset_after_key, &leaf_rec_info,
						 &max_visible_oids, &mvcc_snapshot_dirty, &num_visible_oids);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto exit;
	}
      else if (num_visible_oids > 0)
	{
	  /* Key still has visible objects and is not deleted. */
	  delete_helper->is_key_deleted = false;
	}
      else
	{
	  /* Key is deleted. */
	  assert (delete_helper->is_key_deleted);
	}
    }
  /* Success. */

exit:

  if (found_page != NULL && found_page != *leaf_page)
    {
      pgbuf_unfix_and_init (thread_p, found_page);
    }
  if (prev_found_page != NULL && prev_found_page != *leaf_page)
    {
      pgbuf_unfix_and_init (thread_p, prev_found_page);
    }
  if (delete_helper->rv_keyval_data != NULL && delete_helper->rv_keyval_data != rv_undo_data_bufalign)
    {
      db_private_free_and_init (thread_p, delete_helper->rv_keyval_data);
    }
  delete_helper->rv_keyval_data = NULL;

  btree_perf_track_time (thread_p, delete_helper);
  return error_code;
}

/*
 * btree_key_remove_object_and_keep_visible_first () - Remove one object and all its info from b-tree key. Then find
 *						       other visible version and move it first in leaf record.
 *                                                     Special case of unique index.
 *
 * return	   : Error code.
 * thread_p (in)   : Thread entry.
 * btid_int (in)   : B-tree info.
 * key (in)	   : Key value.
 * leaf_page (in)  : Leaf page.
 * search_key (in) : Search key result.
 * restart (in)	   : Not used.
 * other_args (in) : BTREE_DELETE_HELPER *
 */
static int
btree_key_remove_object_and_keep_visible_first (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
						PAGE_PTR * leaf_page, BTREE_SEARCH_KEY_HELPER * search_key,
						bool * restart, void *other_args)
{
  /* btree_delete_internal helper. */
  BTREE_DELETE_HELPER *delete_helper = (BTREE_DELETE_HELPER *) other_args;
  int error_code = NO_ERROR;	/* Error code. */
  RECDES leaf_record;		/* Copy leaf record. */
  /* Buffer used to copy leaf record. */
  char record_data_buffer[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  LEAF_REC leaf_rec_info;	/* Leaf record info. */
  int offset_after_key = 0;	/* Offset after key in leaf record. */
  bool dummy_clear_value = false;	/* Dummy. */
  PAGE_PTR found_page = NULL;	/* Page where object being removed is found. */
  PAGE_PTR prev_found_page = NULL;	/* Previous page to the page where object being removed is found. Saved in case
					 * that object is last in an overflow page and page must be deallocated. */
  int offset_to_object = NOT_FOUND;	/* Offset in record where object to be removed is found. */
  int offset_to_second_object = NOT_FOUND;	/* Offset to second visible object. */
  BTREE_OP_PURPOSE second_object_search_purpose;	/* Purpose used for searching second object. */
  BTREE_MVCC_INFO match_2nd_obj_mvccinfo;	/* MVCC info of second object to be matched. */

  /* Recovery structures. */
  /* Undo recovery structures. */
  char rv_undo_data_buffer[BTREE_RV_BUFFER_SIZE + BTREE_MAX_ALIGN];
  char *rv_undo_data = PTR_ALIGN (rv_undo_data_buffer, BTREE_MAX_ALIGN);
  char *rv_undo_data_ptr = NULL;
  int rv_undo_data_length = 0;
  /* Redo recovery structures. */
  char rv_redo_data_buffer[BTREE_RV_BUFFER_SIZE + BTREE_MAX_ALIGN];
  char *rv_redo_data = PTR_ALIGN (rv_redo_data_buffer, BTREE_MAX_ALIGN);
  char *rv_redo_data_ptr = NULL;
  int rv_redo_data_length = 0;
  char helper_rv_redo_data_buffer[BTREE_RV_BUFFER_SIZE + BTREE_MAX_ALIGN];

  LOG_LSA prev_lsa;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (BTREE_IS_UNIQUE (btid_int->unique_pk));
  assert (key != NULL && !DB_IS_NULL (key) && !btree_multicol_key_is_null (key));
  assert (leaf_page != NULL && *leaf_page != NULL && pgbuf_get_latch_mode (*leaf_page) >= PGBUF_LATCH_WRITE);
  assert (search_key != NULL);
  assert (delete_helper != NULL);
  assert (delete_helper->purpose == BTREE_OP_DELETE_UNDO_INSERT_UNQ_MULTIUPD);

  if (search_key->result == BTREE_KEY_FOUND)
    {
      /* Key was found. We need to find OID. */
      /* Read key record. */
      leaf_record.data = PTR_ALIGN (record_data_buffer, BTREE_MAX_ALIGN);
      leaf_record.area_size = DB_PAGESIZE;
      if (spage_get_record (thread_p, *leaf_page, search_key->slotid, &leaf_record, COPY) != S_SUCCESS)
	{
	  assert_release (false);
	  return ER_FAILED;
	}
      error_code =
	btree_read_record (thread_p, btid_int, *leaf_page, &leaf_record, NULL, &leaf_rec_info, BTREE_LEAF_NODE,
			   &dummy_clear_value, &offset_after_key, PEEK_KEY_VALUE, NULL);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto exit;
	}
      /* Find OID and output its location/MVCC info. */
      error_code =
	btree_find_oid_and_its_page (thread_p, btid_int, BTREE_DELETE_OID (delete_helper), *leaf_page,
				     delete_helper->purpose, &delete_helper->match_mvccinfo, &leaf_record,
				     &leaf_rec_info, offset_after_key, &found_page, &prev_found_page, &offset_to_object,
				     BTREE_DELETE_MVCC_INFO (delete_helper));
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto exit;
	}
    }
  else
    {
      /* Key was not found. Fall through to handle the case. */
    }
  if (offset_to_object == NOT_FOUND)
    {
      /* Key/object was not found. */
      assert (found_page == NULL && prev_found_page == NULL);

      /* Key/oid should be found. */
      assert_release (false);
      btree_set_unknown_key_error (thread_p, btid_int->sys_btid, key,
				   "btree_key_remove_object_and_keep_visible_first: key wasn't found.");
      error_code = ER_BTREE_UNKNOWN_KEY;
      goto exit;
    }
  /* Object was found. */

  /* Prepare logging. */
  delete_helper->leaf_addr.pgptr = *leaf_page;
  delete_helper->leaf_addr.offset = search_key->slotid;
  delete_helper->leaf_addr.vfid = &btid_int->sys_btid->vfid;
  delete_helper->rv_redo_data = PTR_ALIGN (helper_rv_redo_data_buffer, BTREE_MAX_ALIGN);
  delete_helper->rv_redo_data_ptr = delete_helper->rv_redo_data;

  if (offset_to_object != 0 || found_page != *leaf_page)
    {
      /* Object is normally expected to be first. */
      /* But there is this case: create table t (a int unique); insert into t values (1), (2); update t set a=a+1 where
       * a > 0; rollback; First a new version of object from key 1 is inserted in key 2. Then the other object in key
       * 2 is updated to key 3. The version in key 2 is deleted (marked as deleted). On undo/rollback, the second
       * object old version delete MVCCID is removed first. The algorithm for undo MVCC delete in unique index makes
       * sure it is brought back to the first position in key. The inserted version is relocated to another position. */
      BTREE_NODE_TYPE node_type;

#if !defined (NDEBUG)
      {
	/* Let's confirm the above theory. The first object in leaf record must be same with the object we wanted to
	 * bring first. */
	BTREE_OBJECT_INFO first_object;
	btree_leaf_get_first_object (btid_int, &leaf_record, &first_object.oid, &first_object.class_oid,
				     &first_object.mvcc_info);
	assert (OID_EQ (&first_object.oid, &delete_helper->second_object_info.oid));
      }
#endif /* !NDEBUG */

      /* Just remove inserted object. */
      node_type = (*leaf_page == found_page) ? BTREE_LEAF_NODE : BTREE_OVERFLOW_NODE;
      error_code =
	btree_key_remove_object (thread_p, key, btid_int, delete_helper, *leaf_page, &leaf_record, &leaf_rec_info,
				 offset_after_key, search_key, &found_page, prev_found_page, node_type,
				 offset_to_object);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	}
      /* Skip the rest of the function. The code handles the case when inserted version was first. */
      goto exit;
    }

  /* Find second visible version (which must be moved first). */
  assert (prev_found_page == NULL);
  found_page = NULL;

  if (BTREE_MVCC_INFO_HAS_DELID (&delete_helper->second_object_info.mvcc_info))
    {
      /* This must be an object deleted by current transaction. */
      assert (BTREE_MVCC_INFO_DELID (&delete_helper->second_object_info.mvcc_info)
	      == delete_helper->match_mvccinfo.insert_mvccid);
      /* Search with matching delete MVCCID. */
      second_object_search_purpose = BTREE_OP_DELETE_UNDO_INSERT_DELID;

      /* We should not have insert MVCCID set. */
      assert (!BTREE_MVCC_INFO_IS_INSID_NOT_ALL_VISIBLE (&delete_helper->second_object_info.mvcc_info));
    }
  else
    {
      /* Previous object was not deleted. Search as if we'd want to delete it. */
      second_object_search_purpose = BTREE_OP_DELETE_OBJECT_PHYSICAL;
    }
  /* Copy second object MVCC info we want to match (so it is not overwritten). */
  match_2nd_obj_mvccinfo = delete_helper->second_object_info.mvcc_info;
  error_code =
    btree_find_oid_and_its_page (thread_p, btid_int, &delete_helper->second_object_info.oid, *leaf_page,
				 second_object_search_purpose, &match_2nd_obj_mvccinfo, &leaf_record, &leaf_rec_info,
				 offset_after_key, &found_page, &prev_found_page, &offset_to_second_object,
				 &delete_helper->second_object_info.mvcc_info);
  if (error_code != NO_ERROR)
    {
      assert_release (false);
      error_code = ER_FAILED;
      goto exit;
    }
  if (offset_to_second_object == NOT_FOUND)
    {
      assert (false);
      error_code = ER_FAILED;
      goto exit;
    }

  /* Prepare leaf page logging. */
  rv_redo_data_ptr = rv_redo_data;

  if (found_page == *leaf_page)
    {
#if !defined (NDEBUG)
      BTREE_RV_REDO_SET_DEBUG_INFO (&delete_helper->leaf_addr, rv_redo_data_ptr, btid_int,
				    BTREE_RV_DEBUG_ID_UNDO_INS_UNQ_MUPD);
#endif /* !NDEBUG */
      LOG_RV_RECORD_SET_MODIFY_MODE (&delete_helper->leaf_addr, LOG_RV_RECORD_UPDATE_PARTIAL);

      /* Remove record from leaf. */
      btree_record_remove_object_internal (thread_p, btid_int, &leaf_record, BTREE_LEAF_NODE, offset_to_second_object,
					   NULL, &rv_redo_data_ptr, NULL);
    }
  else
    {
      /* Leaf and overflow OID's page are going to be changed. A system operation and undo logging is required. */
      log_sysop_start (thread_p);
      delete_helper->is_system_op_started = true;

      error_code =
	btree_overflow_remove_object (thread_p, key, btid_int, delete_helper, &found_page, prev_found_page, *leaf_page,
				      &leaf_record, search_key, offset_to_second_object);
      if (error_code != NO_ERROR)
	{
	  assert_release (false);
	  goto exit;
	}

      rv_undo_data_ptr = rv_undo_data;
      rv_redo_data_ptr = rv_redo_data;

#if !defined (NDEBUG)
      /* Leaf may have been logged if object was removed from overflow page. Reset logging structures for new logging.
       */
      delete_helper->leaf_addr.offset = search_key->slotid;
      BTREE_RV_UNDOREDO_SET_DEBUG_INFO (&delete_helper->leaf_addr, rv_redo_data_ptr, rv_undo_data_ptr, btid_int,
					BTREE_RV_DEBUG_ID_UNDO_INS_UNQ_MUPD);
#endif /* !NDEBUG */
      LOG_RV_RECORD_SET_MODIFY_MODE (&delete_helper->leaf_addr, LOG_RV_RECORD_UPDATE_PARTIAL);
    }

  /* Replace inserted object with second visible object. */
  btree_leaf_change_first_object (thread_p, &leaf_record, btid_int, &delete_helper->second_object_info.oid,
				  &delete_helper->second_object_info.class_oid,
				  &delete_helper->second_object_info.mvcc_info, NULL, &rv_undo_data_ptr,
				  &rv_redo_data_ptr);

  /* Update record in page. */
  if (spage_update (thread_p, *leaf_page, search_key->slotid, &leaf_record) != SP_SUCCESS)
    {
      assert_release (false);
      error_code = ER_FAILED;
      goto exit;
    }

  /* Add logging for leaf page. */
  LSA_COPY (&prev_lsa, pgbuf_get_lsa (*leaf_page));
  BTREE_RV_GET_DATA_LENGTH (rv_redo_data_ptr, rv_redo_data, rv_redo_data_length);
  if (delete_helper->is_system_op_started)
    {
      BTREE_RV_GET_DATA_LENGTH (rv_undo_data_ptr, rv_undo_data, rv_undo_data_length);
      log_append_undoredo_data (thread_p, RVBT_RECORD_MODIFY_UNDOREDO, &delete_helper->leaf_addr, rv_undo_data_length,
				rv_redo_data_length, rv_undo_data, rv_redo_data);
    }
  else
    {
      log_append_compensate_with_undo_nxlsa (thread_p, RVBT_RECORD_MODIFY_COMPENSATE, pgbuf_get_vpid_ptr (*leaf_page),
					     delete_helper->leaf_addr.offset, *leaf_page, rv_redo_data_length,
					     rv_redo_data, LOG_FIND_CURRENT_TDES (thread_p),
					     &delete_helper->reference_lsa);
    }

  /* Success. */
  btree_delete_log (delete_helper, BTREE_DELETE_MODIFY_MSG ("unique undo insert, brought back previous first object")
		    "\t" BTREE_OBJINFO_MSG ("first object"),
		    BTREE_DELETE_MODIFY_ARGS (thread_p, delete_helper, *leaf_page, &prev_lsa, true, search_key->slotid,
					      leaf_record.length, btid_int->sys_btid),
		    BTREE_OBJINFO_AS_ARGS (&delete_helper->second_object_info));

exit:

  if (delete_helper->is_system_op_started)
    {
      assert_release (error_code == NO_ERROR);
      btree_delete_sysop_end (thread_p, delete_helper);
    }
  if (found_page != NULL && found_page != *leaf_page)
    {
      pgbuf_unfix_and_init (thread_p, found_page);
    }
  if (prev_found_page != NULL && prev_found_page != *leaf_page)
    {
      pgbuf_unfix_and_init (thread_p, prev_found_page);
    }

  return error_code;
}

/*
 * btree_leaf_record_replace_first_with_last () - Remove first object by replacing it with last.
 *
 * return		      : Error code.
 * thread_p (in)	      : Thread entry.
 * btid_int (in)	      : B-tree identifier.
 * key (in)		      : Key value.
 * delete_helper (in)	      : B-tree delete helper.
 * leaf_page (in)	      : Leaf page.
 * leaf_record (in)	      : Key leaf record.
 * search_key (in)	      : Search key result.
 * last_oid (in)	      : Last object OID.
 * last_class_oid (in)	      : Last object class OID.
 * last_mvcc_info (in)	      : Last object MVCC info.
 * offset_to_last_object (in) : Offset to last object.
 */
static int
btree_leaf_record_replace_first_with_last (THREAD_ENTRY * thread_p, BTID_INT * btid_int,
					   BTREE_DELETE_HELPER * delete_helper, PAGE_PTR leaf_page,
					   RECDES * leaf_record, BTREE_SEARCH_KEY_HELPER * search_key, OID * last_oid,
					   OID * last_class_oid, BTREE_MVCC_INFO * last_mvcc_info,
					   int offset_to_last_object)
{
  char rv_undo_data_buffer[BTREE_RV_BUFFER_SIZE + BTREE_MAX_ALIGN];
  char *rv_undo_data = PTR_ALIGN (rv_undo_data_buffer, BTREE_MAX_ALIGN);
  char *rv_undo_data_ptr = NULL;
  int rv_undo_data_length = 0;
  int rv_redo_data_length = 0;

  LOG_LSA prev_lsa;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (delete_helper != NULL);
  assert (leaf_page != NULL && pgbuf_get_latch_mode (leaf_page) >= PGBUF_LATCH_WRITE);
  assert (leaf_record != NULL);
  assert (search_key != NULL);
  assert (last_oid != NULL);
  assert (last_class_oid != NULL);
  assert (last_mvcc_info != NULL);
  assert (offset_to_last_object > 0 && offset_to_last_object < leaf_record->length);
  assert (btree_is_delete_object_purpose (delete_helper->purpose)
	  && delete_helper->purpose != BTREE_OP_DELETE_UNDO_INSERT_UNQ_MULTIUPD);
  assert (delete_helper->rv_redo_data != NULL && delete_helper->rv_redo_data_ptr != NULL);

#if !defined (NDEBUG)
  /* For debugging recovery. */
  BTREE_RV_UNDOREDO_SET_DEBUG_INFO (&delete_helper->leaf_addr, delete_helper->rv_redo_data_ptr, rv_undo_data_ptr,
				    btid_int, BTREE_RV_DEBUG_ID_LAST_OID);
#endif /* !NDEBUG */
  LOG_RV_RECORD_SET_MODIFY_MODE (&delete_helper->leaf_addr, LOG_RV_RECORD_UPDATE_PARTIAL);

  /* Replace first object with last object. */
  /* First remove last object (so its offset doesn't change. */
  btree_record_remove_last_object (thread_p, btid_int, leaf_record, BTREE_LEAF_NODE, offset_to_last_object,
				   &rv_undo_data_ptr, &delete_helper->rv_redo_data_ptr);
  /* Replace first. */
  btree_leaf_change_first_object (thread_p, leaf_record, btid_int, last_oid, last_class_oid, last_mvcc_info, NULL,
				  &rv_undo_data_ptr, &delete_helper->rv_redo_data_ptr);

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  /* Update record. */
  if (spage_update (thread_p, leaf_page, search_key->slotid, leaf_record) != SP_SUCCESS)
    {
      /* Should not fail. */
      assert_release (false);
      return ER_FAILED;
    }

  /* We need to log previous lsa. */
  LSA_COPY (&prev_lsa, pgbuf_get_lsa (leaf_page));

  /* Log changes. */
  BTREE_RV_GET_DATA_LENGTH (delete_helper->rv_redo_data_ptr, delete_helper->rv_redo_data, rv_redo_data_length);
  assert (!delete_helper->is_system_op_started || delete_helper->purpose != BTREE_OP_DELETE_OBJECT_PHYSICAL);
  btree_rv_log_delete_object (thread_p, *delete_helper, delete_helper->leaf_addr, rv_undo_data_length,
			      rv_redo_data_length, rv_undo_data_ptr, delete_helper->rv_redo_data);

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  pgbuf_set_dirty (thread_p, leaf_page, DONT_FREE);

  btree_delete_log (delete_helper, BTREE_DELETE_MODIFY_MSG ("delete object in leaf record by replacing with last")
		    "\t" BTREE_OBJINFO_MSG ("replacement object"),
		    BTREE_DELETE_MODIFY_ARGS (thread_p, delete_helper, leaf_page, &prev_lsa, true, search_key->slotid,
					      leaf_record->length, btid_int->sys_btid),
		    OID_AS_ARGS (last_oid), OID_AS_ARGS (last_class_oid), BTREE_MVCC_INFO_AS_ARGS (last_mvcc_info));

  /* Success */
  return NO_ERROR;
}

/*
 * btree_record_remove_object () - Remove object from b-tree leaf or overflow record.
 *
 * return		    : Error code.
 * thread_p (in)	    : Thread entry.
 * btid_int (in)	    : B-tree info.
 * delete_helper (in)	    : B-tree delete helper.
 * page (in)		    : Leaf or overflow page.
 * record (in)		    : Leaf or overflow record.
 * search_key (in)	    : Search key result.
 * node_type (in)	    : Leaf or overflow node type.
 * offset_to_object (in)    : Offset to object being removed.
 * addr (in)		    : Leaf or overflow log address.
 */
static int
btree_record_remove_object (THREAD_ENTRY * thread_p, BTID_INT * btid_int, BTREE_DELETE_HELPER * delete_helper,
			    PAGE_PTR page, RECDES * record, BTREE_SEARCH_KEY_HELPER * search_key,
			    BTREE_NODE_TYPE node_type, int offset_to_object, LOG_DATA_ADDR * addr)
{
  char rv_undo_data_buffer[BTREE_RV_BUFFER_SIZE + BTREE_MAX_ALIGN];
  char *rv_undo_data = PTR_ALIGN (rv_undo_data_buffer, BTREE_MAX_ALIGN);
  char *rv_undo_data_ptr = NULL;
  int rv_undo_data_length = 0;
  int rv_redo_data_length = 0;

  LOG_LSA prev_lsa;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (delete_helper != NULL);
  assert (page != NULL);
  assert (record != NULL);
  assert (search_key != NULL && search_key->result == BTREE_KEY_FOUND && search_key->slotid > 0);
  assert (addr != NULL && addr->offset != 0 && addr->pgptr == page);
  assert (btree_is_delete_object_purpose (delete_helper->purpose));
  assert (delete_helper->rv_redo_data != NULL && delete_helper->rv_redo_data_ptr != NULL);

  /* Safe guard: first object in leaf record cannot be handled here. */
  assert (offset_to_object > 0 || node_type == BTREE_OVERFLOW_NODE);

  if (delete_helper->is_system_op_started)
    {
      /* Undoredo logging is required. */
      rv_undo_data_ptr = rv_undo_data;
    }

#if !defined (NDEBUG)
  /* For debugging recovery. */
  BTREE_RV_UNDOREDO_SET_DEBUG_INFO (addr, delete_helper->rv_redo_data_ptr, rv_undo_data_ptr, btid_int,
				    BTREE_RV_DEBUG_ID_REM_OBJ);
#endif /* !NDEBUG */
  LOG_RV_RECORD_SET_MODIFY_MODE (addr, LOG_RV_RECORD_UPDATE_PARTIAL);
  if (node_type == BTREE_OVERFLOW_NODE)
    {
      BTREE_RV_SET_OVERFLOW_NODE (addr);
    }

  btree_record_remove_object_internal (thread_p, btid_int, record, node_type, offset_to_object, &rv_undo_data_ptr,
				       &delete_helper->rv_redo_data_ptr, NULL);

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  /* Update page. */
  /* NOTE: Overflow record slotid is always 1. */
  if (spage_update (thread_p, page, node_type == BTREE_LEAF_NODE ? search_key->slotid : 1, record) != SP_SUCCESS)
    {
      /* No error is expected. */
      assert_release (false);
      return ER_FAILED;
    }

  /* We need to log previous lsa. */
  LSA_COPY (&prev_lsa, pgbuf_get_lsa (page));

  /* Add logging. */
  BTREE_RV_GET_DATA_LENGTH (delete_helper->rv_redo_data_ptr, delete_helper->rv_redo_data, rv_redo_data_length);
  assert (rv_redo_data_length > 0);
  assert (!delete_helper->is_system_op_started || delete_helper->purpose != BTREE_OP_DELETE_OBJECT_PHYSICAL);
  btree_rv_log_delete_object (thread_p, *delete_helper, *addr, rv_undo_data_length, rv_redo_data_length,
			      rv_undo_data, delete_helper->rv_redo_data);
  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  /* Set page dirty. */
  pgbuf_set_dirty (thread_p, page, DONT_FREE);

  btree_delete_log (delete_helper, BTREE_DELETE_MODIFY_MSG ("remove object from record"),
		    BTREE_DELETE_MODIFY_ARGS (thread_p, delete_helper, page, &prev_lsa, node_type == BTREE_LEAF_NODE,
					      node_type == BTREE_LEAF_NODE ? search_key->slotid : 1, record->length,
					      btid_int->sys_btid));

  /* Success. */
  return NO_ERROR;
}

/*
 * btree_record_remove_object_internal () - Remove object and all it's info from b-tree record.
 *
 * return		 : Void.
 * thread_p (in)	 : Thread entry.
 * btid_int (in)	 : B-tree info.
 * record (in)		 : Record.
 * node_type (in)	 : Node type.
 * offset_to_object (in) : Offset to object being removed.
 * rv_undo_data (out)	 : Output undo recovery data.
 * rv_redo_data (out)	 : Output redo recovery data.
 * displacement (out)	 : Output displacement of the rest of the record.
 */
static void
btree_record_remove_object_internal (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * record,
				     BTREE_NODE_TYPE node_type, int offset_to_object, char **rv_undo_data,
				     char **rv_redo_data, int *displacement)
{
  int object_info_size = OR_OID_SIZE;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (record != NULL);
  assert (node_type == BTREE_LEAF_NODE || node_type == BTREE_OVERFLOW_NODE);
  assert (offset_to_object >= 0 && offset_to_object < record->length);
  /* We cannot remove here the first object of leaf record. */
  assert (node_type == BTREE_OVERFLOW_NODE || offset_to_object > 0);

  if (BTREE_IS_UNIQUE (btid_int->unique_pk))
    {
      object_info_size += OR_OID_SIZE;
    }
  object_info_size +=
    BTREE_GET_MVCC_INFO_SIZE_FROM_FLAGS (btree_record_object_get_mvcc_flags (record->data + offset_to_object));

  /* Undo logging. */
  if (rv_undo_data != NULL && *rv_undo_data != NULL)
    {
      *rv_undo_data =
	log_rv_pack_undo_record_changes (*rv_undo_data, offset_to_object, object_info_size, 0,
					 record->data + offset_to_object);
    }

  /* Update record. */
  RECORD_MOVE_DATA (record, offset_to_object, offset_to_object + object_info_size);

  /* Redo logging. */
  if (rv_redo_data != NULL && *rv_redo_data != NULL)
    {
      *rv_redo_data = log_rv_pack_redo_record_changes (*rv_redo_data, offset_to_object, object_info_size, 0, NULL);
    }

  if (displacement != NULL)
    {
      *displacement = -object_info_size;
    }

#if !defined (NDEBUG)
  (void) btree_check_valid_record (thread_p, btid_int, record, node_type, NULL);
#endif /* !NDEBUG */
}

/*
 * btree_key_remove_object () - Remove object from key. Function is interface for btree_leaf_remove_object and
 *				btree_overflow_remove_object.
 *
 * return		    : Error code.
 * thread_p (in)	    : Thread entry.
 * key (in)		    : Key value.
 * btid_int (in)	    : B-tree info.
 * delete_helper (in)	    : B-tree delete helper.
 * leaf_page (in)	    : Leaf page.
 * leaf_record (in)	    : Leaf record.
 * leaf_info (in)	    : Leaf record info.
 * offset_after_key (in)    : Offset to where packed key is ended in leaf record.
 * search_key (in)	    : Search key result.
 * overflow_page (in)	    : Overflow page.
 * prev_page (in)	    : Previous page to overflow page.
 * node_type (in)	    : Node type where object is found.
 * offset_to_object (in)    : Offset in record where object is found.
 */
static int
btree_key_remove_object (THREAD_ENTRY * thread_p, DB_VALUE * key, BTID_INT * btid_int,
			 BTREE_DELETE_HELPER * delete_helper, PAGE_PTR leaf_page, RECDES * leaf_record,
			 LEAF_REC * leaf_info, int offset_after_key, BTREE_SEARCH_KEY_HELPER * search_key,
			 PAGE_PTR * overflow_page, PAGE_PTR prev_page, BTREE_NODE_TYPE node_type, int offset_to_object)
{
  int error_code = NO_ERROR;

  if (node_type == BTREE_LEAF_NODE)
    {
      error_code =
	btree_leaf_remove_object (thread_p, key, btid_int, delete_helper, leaf_page, leaf_record, leaf_info,
				  offset_after_key, search_key, offset_to_object);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	}
    }
  else
    {
      error_code =
	btree_overflow_remove_object (thread_p, key, btid_int, delete_helper, overflow_page, prev_page, leaf_page,
				      leaf_record, search_key, offset_to_object);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	}
    }
  return error_code;
}

/*
 * btree_overflow_remove_object () - Remove an object from overflow page.
 *
 * return		    : Error code.
 * thread_p (in)	    : Thread entry.
 * key (in)		    : Key value.
 * btid_int (in)	    : B-tree info.
 * delete_helper (in)	    : B-tree delete helper.
 * overflow_page (in)	    : Overflow page (can be set to NULL).
 * prev_page (in)	    : Page previous to overflow page (can be leaf page or another overflow page).
 * leaf_page (in)	    : Leaf page.
 * leaf_record (in)	    : Leaf record.
 * search_key (in)	    : Search key result.
 * offset_to_object (in)    : Offset to object being removed.
 */
static int
btree_overflow_remove_object (THREAD_ENTRY * thread_p, DB_VALUE * key, BTID_INT * btid_int,
			      BTREE_DELETE_HELPER * delete_helper, PAGE_PTR * overflow_page, PAGE_PTR prev_page,
			      PAGE_PTR leaf_page, RECDES * leaf_record, BTREE_SEARCH_KEY_HELPER * search_key,
			      int offset_to_object)
{
  int error_code = NO_ERROR;	/* Error code. */
  OID *notification_class_oid;
  RECDES overflow_record;	/* Overflow record. */
  /* Buffer to copy overflow record data. */
  char overflow_record_data_buffer[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  bool save_system_op_started = false;	/* Save previous is_system_op_started. */
  VPID overflow_vpid = VPID_INITIALIZER;	/* VPID of overflow page. */
  VPID next_overflow_vpid = VPID_INITIALIZER;	/* VPID of next overflow page. */
  LOG_DATA_ADDR ovf_addr;	/* Address for logging. */

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (delete_helper != NULL);
  assert (overflow_page != NULL && *overflow_page != NULL);
  assert (prev_page != NULL);
  assert (leaf_page != NULL);
  assert (leaf_record != NULL);
  assert (search_key != NULL && search_key->result == BTREE_KEY_FOUND && search_key->slotid > 0);
  assert (btree_is_delete_object_purpose (delete_helper->purpose));

  /* Read overflow record. */
  overflow_record.area_size = DB_PAGESIZE;
  overflow_record.data = PTR_ALIGN (overflow_record_data_buffer, BTREE_MAX_ALIGN);
  if (spage_get_record (thread_p, *overflow_page, 1, &overflow_record, COPY) != S_SUCCESS)
    {
      /* Unexpected. */
      assert_release (false);
      return ER_FAILED;
    }

#if !defined (NDEBUG)
  (void) btree_check_valid_record (thread_p, btid_int, &overflow_record, BTREE_OVERFLOW_NODE, NULL);
#endif /* !NDEBUG */

  save_system_op_started = delete_helper->is_system_op_started;

  if (overflow_record.length == BTREE_OBJECT_FIXED_SIZE (btid_int))
    {
      /* Only one object. */
      /* Remove page completely. */

      /* Safe guard: only first object can be deleted. */
      assert (offset_to_object == 0);

      /* Get VPID of next overflow page. */
      error_code = btree_get_next_overflow_vpid (thread_p, *overflow_page, &next_overflow_vpid);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return error_code;
	}
      /* Unfix the page before deallocating. */
      pgbuf_get_vpid (*overflow_page, &overflow_vpid);
      pgbuf_unfix_and_init (thread_p, *overflow_page);

      /* we need system op to deallocate pages. */
      if (!delete_helper->is_system_op_started)
	{
	  log_sysop_start (thread_p);
	  delete_helper->is_system_op_started = true;
	}

      /* todo: we always need a system operation to deallocate page. otherwise the page may be "leaked" on rollback.
       * fixme when replacing the old system operation system */
      /* Deallocate page. */
      error_code = file_dealloc (thread_p, &btid_int->sys_btid->vfid, &overflow_vpid, FILE_BTREE);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto error;
	}
      /* Notification. */
      if (!OID_ISNULL (BTREE_DELETE_CLASS_OID (delete_helper)))
	{
	  notification_class_oid = BTREE_DELETE_CLASS_OID (delete_helper);
	}
      else
	{
	  notification_class_oid = &btid_int->topclass_oid;
	}
      BTREE_SET_DELETED_OVERFLOW_PAGE_NOTIFICATION (thread_p, key, BTREE_DELETE_OID (delete_helper),
						    notification_class_oid, btid_int->sys_btid);

      FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

      /* Update previous page link. */
      if (prev_page == leaf_page)
	{
	  /* Update leaf record link. */
	  error_code =
	    btree_modify_leaf_ovfl_vpid (thread_p, btid_int, delete_helper, leaf_page, leaf_record, search_key,
					 &next_overflow_vpid);
	  if (error_code != NO_ERROR)
	    {
	      ASSERT_ERROR ();
	      goto error;
	    }
	}
      else			/* prev_page != leaf_page. */
	{
	  /* Update link in an overflow page. */
	  error_code = btree_modify_overflow_link (thread_p, btid_int, delete_helper, prev_page, &next_overflow_vpid);
	  if (error_code != NO_ERROR)
	    {
	      ASSERT_ERROR ();
	      goto error;
	    }
	}

      FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

      /* End system operation. */
      if (delete_helper->is_system_op_started && !save_system_op_started)
	{
	  btree_delete_sysop_end (thread_p, delete_helper);
	}
    }
  else
    {
      /* More than one object. */

      /* Just remove object from record. */
      ovf_addr.offset = 1;
      ovf_addr.pgptr = *overflow_page;
      ovf_addr.vfid = &btid_int->sys_btid->vfid;

      error_code =
	btree_record_remove_object (thread_p, btid_int, delete_helper, *overflow_page, &overflow_record, search_key,
				    BTREE_OVERFLOW_NODE, offset_to_object, &ovf_addr);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto error;
	}
    }

  /* Success. */
  return NO_ERROR;

error:
  if (delete_helper->is_system_op_started && !save_system_op_started)
    {
      assert (delete_helper->purpose != BTREE_OP_DELETE_UNDO_INSERT
	      && delete_helper->purpose != BTREE_OP_DELETE_UNDO_INSERT_UNQ_MULTIUPD
	      && delete_helper->purpose != BTREE_OP_DELETE_OBJECT_PHYSICAL_POSTPONED);
      btree_delete_sysop_end (thread_p, delete_helper);
    }
  assert_release (error_code != NO_ERROR);
  return error_code;
}

/*
 * btree_leaf_remove_object () - Remove an object from leaf record.
 *
 * return		    : Error code.
 * thread_p (in)	    : Thread entry.
 * key (in)		    : Key value.
 * btid_int (in)	    : B-tree info.
 * delete_helper (in)	    : B-tree delete helper.
 * leaf_page (in)	    : Leaf page.
 * leaf_record (in)	    : Leaf record.
 * leaf_rec_info (in)	    : Leaf record info.
 * offset_after_key (in)    : Offset in leaf record where packed key ends.
 * search_key (in)	    : Search key result.
 * offset_to_object (in)    : Offset to object being removed.
 * leaf_addr (in)	    : Log address for leaf record.
 */
static int
btree_leaf_remove_object (THREAD_ENTRY * thread_p, DB_VALUE * key, BTID_INT * btid_int,
			  BTREE_DELETE_HELPER * delete_helper, PAGE_PTR leaf_page, RECDES * leaf_record,
			  LEAF_REC * leaf_rec_info, int offset_after_key, BTREE_SEARCH_KEY_HELPER * search_key,
			  int offset_to_object)
{
  int error_code = NO_ERROR;	/* Error code. */
  OID last_oid;			/* Last object OID. */
  OID last_class_oid;		/* Last object class OID. */
  BTREE_MVCC_INFO last_mvcc_info;	/* Last object MVCC info. */
  int offset_to_last_object = 0;	/* Offset to last object. */

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (delete_helper != NULL);
  assert (leaf_page != NULL);
  assert (leaf_record != NULL);
  assert (search_key != NULL && search_key->result == BTREE_KEY_FOUND && search_key->slotid > 0);
  assert (btree_is_delete_object_purpose (delete_helper->purpose));

#if !defined (NDEBUG)
  (void) btree_check_valid_record (thread_p, btid_int, leaf_record, BTREE_LEAF_NODE, NULL);
#endif /* NDEBUG */

  /* Remove object from leaf record. */
  if (offset_to_object == 0)
    {
      /* Object to remove is first. */

      /* Get last object in leaf. */
      error_code =
	btree_record_get_last_object (thread_p, btid_int, leaf_record, BTREE_LEAF_NODE, offset_after_key, &last_oid,
				      &last_class_oid, &last_mvcc_info, &offset_to_last_object);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return ER_FAILED;
	}

      if (offset_to_last_object == 0)
	{
	  /* This is the only object in leaf record. */
	  /* Safe guard: first and last are the same object. */
	  assert (OID_EQ (BTREE_DELETE_OID (delete_helper), &last_oid));
	  if (VPID_ISNULL (&leaf_rec_info->ovfl))
	    {
	      /* This is the last key object! */
	      /* Remove key. */
	      error_code =
		btree_delete_key_from_leaf (thread_p, btid_int, leaf_page, leaf_rec_info, delete_helper, search_key);
	      if (error_code != NO_ERROR)
		{
		  ASSERT_ERROR ();
		  return ER_FAILED;
		}
	      /* Key was successfully removed. */

	      /* MULTI_ROW_UPDATE will try to check key was deleted in btree_key_delete_remove_object. Don't allow it
	       * since the key no longer exists. */
	      assert (!delete_helper->check_key_deleted || delete_helper->is_key_deleted);
	      delete_helper->check_key_deleted = false;

	      /* Fall through. */
	    }
	  else			/* !VPID_ISNULL (&leaf_rec_info.ovfl) */
	    {
	      /* Key has overflow objects. Swap one object from first overflow page. */
	      error_code =
		btree_replace_first_oid_with_ovfl_oid (thread_p, btid_int, key, delete_helper, leaf_page, search_key,
						       leaf_record, &leaf_rec_info->ovfl);
	      if (error_code != NO_ERROR)
		{
		  ASSERT_ERROR ();
		  return ER_FAILED;
		}
	      /* First object was successfully replaced. Fall through. */
	    }
	}
      else			/* offset_to_last_object != 0. */
	{
	  /* Replace first object with last object. */
	  error_code =
	    btree_leaf_record_replace_first_with_last (thread_p, btid_int, delete_helper, leaf_page, leaf_record,
						       search_key, &last_oid, &last_class_oid, &last_mvcc_info,
						       offset_to_last_object);
	  if (error_code != NO_ERROR)
	    {
	      ASSERT_ERROR ();
	      return ER_FAILED;
	    }
	}
    }
  else				/* offset_to_object != 0 */
    {
      /* Not the first object. Just remove it. */
      error_code =
	btree_record_remove_object (thread_p, btid_int, delete_helper, leaf_page, leaf_record, search_key,
				    BTREE_LEAF_NODE, offset_to_object, &delete_helper->leaf_addr);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return ER_FAILED;
	}
    }
  /* Success. */
  return NO_ERROR;
}

/*
 * btree_key_remove_insert_mvccid () - Remove insert MVCCID from object info.
 *
 * return	   : Error code.
 * thread_p (in)   : Thread entry.
 * btid_int (in)   : B-tree info.
 * key (in)	   : Key of object.
 * leaf_page (in)  : Leaf page.
 * search_key (in) : Search key result.
 * restart (in)	   : Not used.
 * other_args (in) : BTREE_DELETE_HELPER *
 */
static int
btree_key_remove_insert_mvccid (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key, PAGE_PTR * leaf_page,
				BTREE_SEARCH_KEY_HELPER * search_key, bool * restart, void *other_args)
{
  /* btree_delete_internal helper. */
  BTREE_DELETE_HELPER *delete_helper = (BTREE_DELETE_HELPER *) other_args;
  int offset_to_object = NOT_FOUND;	/* Offset to found object. */
  int error_code = NO_ERROR;	/* Error code. */
  PAGE_PTR found_page = NULL;	/* Page of found object. */
  RECDES record;		/* B-tree record. */
  /* Buffer to copy the b-tree record. */
  char record_data_buffer[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  LEAF_REC leaf_rec_info;	/* Leaf record info. */
  int offset_after_key = 0;	/* Offset after key in leaf record. */
  bool dummy_clear_key = false;	/* Dummy. */
  PGSLOTID slotid;		/* Slot ID of record being updated. It is either search_key->slotid if record is from
				 * leaf or 1 if record is from overflow. */
  BTREE_NODE_TYPE node_type;	/* Page of found object node type. */
  LOG_DATA_ADDR addr;		/* Address for recovery. */

  LOG_LSA prev_lsa;

  /* Redo recovery structures. */
  char rv_redo_data_buffer[BTREE_RV_BUFFER_SIZE + BTREE_MAX_ALIGN];
  char *rv_redo_data = PTR_ALIGN (rv_redo_data_buffer, BTREE_MAX_ALIGN);
  char *rv_redo_data_ptr = rv_redo_data;
  int rv_redo_data_length = 0;
  /* NOTE: No undo logging is required to vacuum insert MVCCID. */

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (key != NULL && !DB_IS_NULL (key) && !btree_multicol_key_is_null (key));
  assert (leaf_page != NULL && *leaf_page != NULL && pgbuf_get_latch_mode (*leaf_page) >= PGBUF_LATCH_WRITE);
  assert (search_key != NULL);
  assert (delete_helper != NULL);
  assert (delete_helper->purpose == BTREE_OP_DELETE_VACUUM_INSID);
  assert (VACUUM_IS_THREAD_VACUUM_WORKER (thread_p));

  btree_perf_track_traverse_time (thread_p, delete_helper);

  if (search_key->result == BTREE_KEY_FOUND)
    {
      /* Key was found. Find the object. */

      /* Get leaf record. */
      record.area_size = DB_PAGESIZE;
      record.data = PTR_ALIGN (record_data_buffer, BTREE_MAX_ALIGN);
      if (spage_get_record (thread_p, *leaf_page, search_key->slotid, &record, COPY) != S_SUCCESS)
	{
	  assert_release (false);
	  return ER_FAILED;
	}

#if !defined (NDEBUG)
      (void) btree_check_valid_record (thread_p, btid_int, &record, BTREE_LEAF_NODE, NULL);
#endif /* !NDEBUG */

      error_code =
	btree_read_record (thread_p, btid_int, *leaf_page, &record, NULL, &leaf_rec_info, BTREE_LEAF_NODE,
			   &dummy_clear_key, &offset_after_key, PEEK_KEY_VALUE, NULL);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto exit;
	}

      /* Search object with insert MVCCID. */
      error_code =
	btree_find_oid_and_its_page (thread_p, btid_int, BTREE_DELETE_OID (delete_helper), *leaf_page,
				     delete_helper->purpose, &delete_helper->match_mvccinfo, &record, &leaf_rec_info,
				     offset_after_key, &found_page, NULL, &offset_to_object,
				     BTREE_DELETE_MVCC_INFO (delete_helper));
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto exit;
	}
    }
  if (offset_to_object == NOT_FOUND)
    {
      /* Key or object not found. */
      /* Object must have been vacuumed/removed already. */
      vacuum_er_log_warning (VACUUM_ER_LOG_BTREE | VACUUM_ER_LOG_WORKER,
			     "Could not find object %d|%d|%d in key=%s to vacuum it.",
			     delete_helper->object_info.oid.volid, delete_helper->object_info.oid.pageid,
			     delete_helper->object_info.oid.slotid,
			     delete_helper->printed_key != NULL ? delete_helper->printed_key : "(unknown)");
      btree_delete_log (delete_helper, "could not find object to vacuum its insert MVCCID \n"
			BTREE_DELETE_HELPER_MSG ("\t"), BTREE_DELETE_HELPER_AS_ARGS (delete_helper));
      return NO_ERROR;
    }
  /* Object was found. */
  node_type = (found_page == *leaf_page) ? BTREE_LEAF_NODE : BTREE_OVERFLOW_NODE;

  if (node_type == BTREE_OVERFLOW_NODE)
    {
      /* Get overflow record. */
      slotid = 1;
      if (spage_get_record (thread_p, found_page, slotid, &record, COPY) != S_SUCCESS)
	{
	  assert_release (false);
	  error_code = ER_FAILED;
	  goto exit;
	}
#if !defined (NDEBUG)
      (void) btree_check_valid_record (thread_p, btid_int, &record, BTREE_OVERFLOW_NODE, NULL);
#endif /* !NDEBUG */
    }
  else
    {
      /* Leaf record was already obtained. */
      slotid = search_key->slotid;
    }

  /* It should have delete MVCCID. */
  assert (BTREE_MVCC_INFO_IS_INSID_NOT_ALL_VISIBLE (BTREE_DELETE_MVCC_INFO (delete_helper)));

  /* Prepare logging. */
  addr.offset = slotid;
  addr.pgptr = found_page;
  addr.vfid = &btid_int->sys_btid->vfid;

#if !defined (NDEBUG)
  /* For debugging recovery. */
  BTREE_RV_REDO_SET_DEBUG_INFO (&addr, rv_redo_data_ptr, btid_int, BTREE_RV_DEBUG_ID_REM_INSID);
#endif
  if (node_type == BTREE_OVERFLOW_NODE)
    {
      BTREE_RV_SET_OVERFLOW_NODE (&addr);
    }
  LOG_RV_RECORD_SET_MODIFY_MODE (&addr, LOG_RV_RECORD_UPDATE_PARTIAL);

  btree_record_remove_insid (thread_p, btid_int, &record, node_type, offset_to_object, NULL, &rv_redo_data_ptr, NULL);
  /* Update in page. */
  if (spage_update (thread_p, found_page, slotid, &record) != SP_SUCCESS)
    {
      /* Unexpected. */
      assert_release (false);
      error_code = ER_FAILED;
      goto exit;
    }

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  /* We need to log previous lsa. */
  LSA_COPY (&prev_lsa, pgbuf_get_lsa (found_page));

  /* Logging. */
  BTREE_RV_GET_DATA_LENGTH (rv_redo_data_ptr, rv_redo_data, rv_redo_data_length);
  log_append_redo_data (thread_p, RVBT_RECORD_MODIFY_NO_UNDO, &addr, rv_redo_data_length, rv_redo_data);

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  pgbuf_set_dirty (thread_p, found_page, DONT_FREE);

  btree_delete_log (delete_helper, BTREE_DELETE_MODIFY_MSG ("removed insert MVCCID"),
		    BTREE_DELETE_MODIFY_ARGS (thread_p, delete_helper, found_page, &prev_lsa,
					      node_type == BTREE_LEAF_NODE, slotid, record.length, btid_int->sys_btid));

exit:
  if (found_page != NULL && found_page != *leaf_page)
    {
      pgbuf_unfix_and_init (thread_p, found_page);
    }

  btree_perf_track_time (thread_p, delete_helper);
  return error_code;
}

/*
 * btree_key_remove_delete_mvccid () - Remove delete MVCCID from object info.
 *
 * return	   : Error code.
 * thread_p (in)   : Thread entry.
 * btid_int (in)   : B-tree info.
 * key (in)	   : Key of object.
 * leaf_page (in)  : Leaf page.
 * search_key (in) : Search key result.
 * restart (in)	   : Not used.
 * other_args (in) : BTREE_DELETE_HELPER *
 */
static int
btree_key_remove_delete_mvccid (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key, PAGE_PTR * leaf_page,
				BTREE_SEARCH_KEY_HELPER * search_key, bool * restart, void *other_args)
{
  /* btree_delete_internal helper. */
  BTREE_DELETE_HELPER *delete_helper = (BTREE_DELETE_HELPER *) other_args;
  int offset_to_object = NOT_FOUND;	/* Offset to found object. */
  int error_code = NO_ERROR;	/* Error code. */
  PAGE_PTR found_page = NULL;	/* Page of found object. */
  RECDES leaf_record;		/* B-tree leaf record. */
  RECDES overflow_record;	/* B-tree overflow record. */
  /* Buffers to copy b-tree records. */
  char leaf_record_data_buffer[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  char ovf_record_data_buffer[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  LEAF_REC leaf_rec_info;	/* Leaf leaf_record info. */
  int offset_after_key = 0;	/* Offset after key in leaf leaf_record. */
  bool dummy_clear_key = false;	/* Dummy. */
  PGSLOTID slotid;		/* Slot ID of leaf_record being updated. It is either search_key->slotid if leaf_record
				 * is from leaf or 1 if leaf_record is from overflow. */
  BTREE_NODE_TYPE node_type;	/* Page of found object node type. */

  /* Redo recovery structures. */
  char rv_redo_data_buffer[BTREE_RV_BUFFER_SIZE + BTREE_MAX_ALIGN];

  /* No undo logging is required during rollback. */

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (key != NULL && !DB_IS_NULL (key) && !btree_multicol_key_is_null (key));
  assert (leaf_page != NULL && *leaf_page != NULL && pgbuf_get_latch_mode (*leaf_page) >= PGBUF_LATCH_WRITE);
  assert (search_key != NULL);
  assert (delete_helper != NULL);
  assert (delete_helper->purpose == BTREE_OP_DELETE_UNDO_INSERT_DELID);

  btree_perf_track_traverse_time (thread_p, delete_helper);

  if (search_key->result == BTREE_KEY_FOUND)
    {
      /* Key was found. Try to find object. */

      /* Get leaf leaf record. */
      leaf_record.area_size = DB_PAGESIZE;
      leaf_record.data = PTR_ALIGN (leaf_record_data_buffer, BTREE_MAX_ALIGN);
      if (spage_get_record (thread_p, *leaf_page, search_key->slotid, &leaf_record, COPY) != S_SUCCESS)
	{
	  assert_release (false);
	  return ER_FAILED;
	}

#if !defined (NDEBUG)
      (void) btree_check_valid_record (thread_p, btid_int, &leaf_record, BTREE_LEAF_NODE, NULL);
#endif /* !NDEBUG */

      error_code =
	btree_read_record (thread_p, btid_int, *leaf_page, &leaf_record, NULL, &leaf_rec_info, BTREE_LEAF_NODE,
			   &dummy_clear_key, &offset_after_key, PEEK_KEY_VALUE, NULL);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto exit;
	}

      /* Find object. */
      error_code =
	btree_find_oid_and_its_page (thread_p, btid_int, BTREE_DELETE_OID (delete_helper), *leaf_page,
				     delete_helper->purpose, &delete_helper->match_mvccinfo, &leaf_record,
				     &leaf_rec_info, offset_after_key, &found_page, NULL, &offset_to_object,
				     BTREE_DELETE_MVCC_INFO (delete_helper));
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto exit;
	}
    }
  if (offset_to_object == NOT_FOUND)
    {
      /* Key or object not found, but it should have been found. */
      assert_release (false);
      btree_set_unknown_key_error (thread_p, btid_int->sys_btid, key,
				   "btree_key_remove_delete_mvccid: key was not found.");
      error_code = ER_BTREE_UNKNOWN_KEY;
      goto exit;
    }
  /* Object was found. */

  /* Prepare logging. */
  delete_helper->rv_redo_data = PTR_ALIGN (rv_redo_data_buffer, BTREE_MAX_ALIGN);
  delete_helper->rv_redo_data_ptr = delete_helper->rv_redo_data;

  /* Where was object found? */
  node_type = (found_page == *leaf_page) ? BTREE_LEAF_NODE : BTREE_OVERFLOW_NODE;

  if (node_type == BTREE_OVERFLOW_NODE)
    {
      /* Get overflow record. */
      slotid = 1;
      overflow_record.data = PTR_ALIGN (ovf_record_data_buffer, BTREE_MAX_ALIGN);
      overflow_record.area_size = DB_PAGESIZE;
      if (spage_get_record (thread_p, found_page, slotid, &overflow_record, COPY) != S_SUCCESS)
	{
	  assert_release (false);
	  error_code = ER_FAILED;
	  goto exit;
	}
#if !defined (NDEBUG)
      (void) btree_check_valid_record (thread_p, btid_int, &overflow_record, BTREE_OVERFLOW_NODE, NULL);
#endif /* !NDEBUG */
    }
  else
    {
      /* Leaf leaf_record was already obtained. */
      slotid = search_key->slotid;
    }

  if (BTREE_IS_UNIQUE (btid_int->unique_pk))
    {
      PAGE_PTR overflow_page = node_type == BTREE_OVERFLOW_NODE ? found_page : NULL;
      RECDES *ovf_record_p = node_type == BTREE_OVERFLOW_NODE ? &overflow_record : NULL;

      error_code =
	btree_key_remove_delete_mvccid_unique (thread_p, btid_int, delete_helper, search_key, *leaf_page, &leaf_record,
					       overflow_page, ovf_record_p, node_type, offset_to_object);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto exit;
	}
    }
  else
    {
      RECDES *recdes_p = node_type == BTREE_OVERFLOW_NODE ? &overflow_record : &leaf_record;

      error_code =
	btree_key_remove_delete_mvccid_non_unique (thread_p, btid_int, delete_helper, found_page, recdes_p, slotid,
						   node_type, offset_to_object);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto exit;
	}
    }

exit:
  if (found_page != NULL && found_page != *leaf_page)
    {
      pgbuf_unfix_and_init (thread_p, found_page);
    }

  btree_perf_track_time (thread_p, delete_helper);
  return error_code;
}

/*
 * btree_key_remove_delete_mvccid_unique () - Remove delete MVCCID from an object in unique index as part of undoing a
 *					      MVCC delete operation.
 *
 * return		 : Error code.
 * thread_p (in)	 : Thread entry.
 * btid_int (in)	 : B-tree info.
 * delete_helper (in)	 : B-tree delete helper.
 * search_key (in)	 : Search key result.
 * leaf_page (in)	 : Leaf node page.
 * leaf_record (in)	 : Key's leaf record.
 * overflow_page (in)	 : Overflow node page (if object was found in overflow page).
 * overflow_record (in)  : Overflow record (if object was found in overflow page).
 * node_type (in)	 : Node type of page where object was found.
 * offset_to_object (in) : Offset to object in its record.
 */
static int
btree_key_remove_delete_mvccid_unique (THREAD_ENTRY * thread_p, BTID_INT * btid_int,
				       BTREE_DELETE_HELPER * delete_helper, BTREE_SEARCH_KEY_HELPER * search_key,
				       PAGE_PTR leaf_page, RECDES * leaf_record, PAGE_PTR overflow_page,
				       RECDES * overflow_record, BTREE_NODE_TYPE node_type, int offset_to_object)
{
  int error_code = NO_ERROR;	/* Error code. */
  LOG_DATA_ADDR leaf_addr;	/* Leaf record address for logging. */

  LOG_LSA prev_lsa;

  char rv_undo_data_buffer[BTREE_RV_BUFFER_SIZE + BTREE_MAX_ALIGN];
  char *rv_undo_data = PTR_ALIGN (rv_undo_data_buffer, BTREE_MAX_ALIGN);
  char *rv_undo_data_ptr = NULL;
  int rv_undo_data_length = 0;
  int rv_redo_data_length = 0;	/* Length of redo recovery data. */

  /* Assert expected arguments. */
  assert (btid_int != NULL && BTREE_IS_UNIQUE (btid_int->unique_pk));
  assert (delete_helper != NULL);
  assert (delete_helper->purpose == BTREE_OP_DELETE_UNDO_INSERT_DELID);
  assert (leaf_page != NULL);
  assert (leaf_record != NULL && leaf_record->data != NULL);
  assert (search_key != NULL && search_key->slotid > 0);
  assert (node_type == BTREE_LEAF_NODE || node_type == BTREE_OVERFLOW_NODE);
  assert (node_type == BTREE_LEAF_NODE || (overflow_page != NULL && overflow_record != NULL));
  assert (offset_to_object >= 0
	  && offset_to_object < (node_type == BTREE_LEAF_NODE ? leaf_record->length : overflow_record->length));
  assert (BTREE_MVCC_INFO_HAS_DELID (BTREE_DELETE_MVCC_INFO (delete_helper)));

  /* Prepare logging for leaf record. */
  leaf_addr.offset = search_key->slotid;
  leaf_addr.pgptr = leaf_page;
  leaf_addr.vfid = &btid_int->sys_btid->vfid;

  if (node_type == BTREE_OVERFLOW_NODE)
    {
      /* Two pages will be modified, system operation is required and undoredo logging. */
      log_sysop_start (thread_p);
      delete_helper->is_system_op_started = true;
      rv_undo_data_ptr = rv_undo_data;
    }

#if !defined (NDEBUG)
  BTREE_RV_UNDOREDO_SET_DEBUG_INFO (&leaf_addr, delete_helper->rv_redo_data_ptr, rv_undo_data_ptr, btid_int,
				    BTREE_RV_DEBUG_ID_REM_DELID_UNIQUE);
#endif /* !NDEBUG */
  LOG_RV_RECORD_SET_MODIFY_MODE (&leaf_addr, LOG_RV_RECORD_UPDATE_PARTIAL);

  /* Remove delete MVCCID & swap with first object in leaf record. */
  error_code =
    btree_remove_delete_mvccid_unique_internal (thread_p, btid_int, delete_helper, leaf_page, leaf_record, node_type,
						overflow_page, overflow_record, offset_to_object, &rv_undo_data_ptr,
						&delete_helper->rv_redo_data_ptr);
  if (error_code != NO_ERROR)
    {
      assert_release (false);
      if (delete_helper->is_system_op_started)
	{
	  log_sysop_abort (thread_p);
	}
      return error_code;
    }

  /* Update in page. */
  if (spage_update (thread_p, leaf_page, search_key->slotid, leaf_record) != SP_SUCCESS)
    {
      assert_release (false);
      if (delete_helper->is_system_op_started)
	{
	  log_sysop_abort (thread_p);
	}
      return ER_FAILED;
    }

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  /* We need to log previous lsa. */
  LSA_COPY (&prev_lsa, pgbuf_get_lsa (leaf_page));

  /* Add compensate log. */
  BTREE_RV_GET_DATA_LENGTH (delete_helper->rv_redo_data_ptr, delete_helper->rv_redo_data, rv_redo_data_length);
  if (delete_helper->is_system_op_started)
    {
      BTREE_RV_GET_DATA_LENGTH (rv_undo_data_ptr, rv_undo_data, rv_undo_data_length);
      log_append_undoredo_data (thread_p, RVBT_RECORD_MODIFY_UNDOREDO, &leaf_addr, rv_undo_data_length,
				rv_redo_data_length, rv_undo_data, delete_helper->rv_redo_data);

      btree_delete_sysop_end (thread_p, delete_helper);
    }
  else
    {
      log_append_compensate_with_undo_nxlsa (thread_p, RVBT_RECORD_MODIFY_COMPENSATE, pgbuf_get_vpid_ptr (leaf_page),
					     leaf_addr.offset, leaf_page, rv_redo_data_length,
					     delete_helper->rv_redo_data, LOG_FIND_CURRENT_TDES (thread_p),
					     &delete_helper->reference_lsa);
    }
  pgbuf_set_dirty (thread_p, leaf_page, DONT_FREE);

  btree_delete_log (delete_helper, BTREE_DELETE_MODIFY_MSG ("unique remove delete MVCCID"),
		    BTREE_DELETE_MODIFY_ARGS (thread_p, delete_helper, leaf_page, &prev_lsa, true, search_key->slotid,
					      leaf_record->length, btid_int->sys_btid));

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  /* Success. */
  return NO_ERROR;
}

/*
 * btree_remove_delete_mvccid_unique_internal () - Internal function that will remove delete MVCCID for an object in an
 *						   unique index. It will take care to also move the object to the
 *						   first position in leaf record.
 *
 * return		 : Error code.
 * thread_p (in)	 : Thread entry.
 * btid_int (in)	 : B-tree info.
 * helper (in)		 : B-tree delete helper.
 * leaf_page (in)	 : Leaf node (where object key is found).
 * leaf_record (in)	 : Leaf record.
 * node_type (in)	 : Node type where object is found (leaf or overflow).
 * overflow_page (in)    : Page pointer to overflow node. Only used if object is in an overflow node.
 * overflow_record (in)  : Overflow record. Only used if object is in an overflow node.
 * offset_to_object (in) : Offset to object in its record.
 * rv_undo_data (out)	 : If not NULL, outputs undo data recovery for leaf node changes.
 * rv_redo_data (out)	 : If not NULL, outputs redo data recovery for leaf node changes.
 */
static int
btree_remove_delete_mvccid_unique_internal (THREAD_ENTRY * thread_p, BTID_INT * btid_int, BTREE_DELETE_HELPER * helper,
					    PAGE_PTR leaf_page, RECDES * leaf_record, BTREE_NODE_TYPE node_type,
					    PAGE_PTR overflow_page, RECDES * overflow_record, int offset_to_object,
					    char **rv_undo_data, char **rv_redo_data)
{
  int error_code = NO_ERROR;
  BTREE_OBJECT_INFO first_object = BTREE_OBJECT_INFO_INITIALIZER;

  /* Not the first object in leaf. */
  assert (btid_int != NULL);
  assert (helper != NULL);
  assert (helper->purpose == BTREE_OP_DELETE_UNDO_INSERT_DELID);
  assert (leaf_page != NULL);
  assert (leaf_record != NULL);
  assert (node_type == BTREE_LEAF_NODE || (overflow_page != NULL && overflow_record != NULL));
  assert (offset_to_object >= 0);

  /* Undoing MVCC delete should consider one rule for unique index: the non-dirty visible object should always be
   * first. When this object was deleted, it may have been relocated from the first position in leaf record. If that's
   * the case, we now have to move it back. */

  /* Get the first object in leaf record. */
  error_code =
    btree_leaf_get_first_object (btid_int, leaf_record, &first_object.oid, &first_object.class_oid,
				 &first_object.mvcc_info);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      return error_code;
    }

  if (node_type == BTREE_LEAF_NODE && offset_to_object == 0)
    {
      /* Object is already first in leaf record. We need no swapping, just remove its delete MVCCID. */
      btree_record_remove_delid (thread_p, btid_int, leaf_record, BTREE_LEAF_NODE, offset_to_object, rv_undo_data,
				 rv_redo_data);
      return NO_ERROR;
    }
  /* Object is not first and must be swapped with first. */

  /* Since first object is going to be relocated, it will have fixed size. */
  BTREE_MVCC_INFO_SET_FIXED_SIZE (&first_object.mvcc_info);

  /* Since our object becomes first, if there are no overflow OID's, having fixed size is no longer required. */
  if (!btree_leaf_is_flaged (leaf_record, BTREE_LEAF_RECORD_OVERFLOW_OIDS))
    {
      /* Clear unnecessary MVCC info. */
      BTREE_MVCC_INFO_CLEAR_FIXED_SIZE (BTREE_DELETE_MVCC_INFO (helper));
    }
  /* Remove delete MVCCID from object. */
  BTREE_MVCC_INFO_CLEAR_DELID (BTREE_DELETE_MVCC_INFO (helper));

  /* Object are ready to be swapped. */

  /* Where is object found (leaf or overflow node). */
  if (node_type == BTREE_LEAF_NODE)
    {
      /* Object belongs to leaf. */
      /* Replace our object with first object. */
      char *oid_ptr = leaf_record->data + offset_to_object;
      int object_fixed_size = BTREE_OBJECT_FIXED_SIZE (btid_int);

      /* Objects are fixed size, therefore replacing data is the same size. Just pack first object info where our
       * object used to be. */

      /* Undo logging */
      if (rv_undo_data != NULL && *rv_undo_data != NULL)
	{
	  *rv_undo_data =
	    log_rv_pack_undo_record_changes (*rv_undo_data, offset_to_object, object_fixed_size, object_fixed_size,
					     oid_ptr);
	}

      (void) btree_pack_object (oid_ptr, btid_int, BTREE_LEAF_NODE, leaf_record, &first_object);
#if !defined (NDEBUG)
      (void) btree_check_valid_record (thread_p, btid_int, leaf_record, node_type, NULL);
#endif /* !NDEBUG */

      /* Redo logging. */
      if (rv_redo_data != NULL && *rv_redo_data != NULL)
	{
	  *rv_redo_data =
	    log_rv_pack_redo_record_changes (*rv_redo_data, offset_to_object, object_fixed_size, object_fixed_size,
					     oid_ptr);
	}

      btree_delete_log (helper, "swapped first object (logging is postponed) \n"
			"\t" BTREE_OBJINFO_MSG ("first object") "\n"
			"\t" PGBUF_PAGE_STATE_MSG ("leaf page") "\n\t" BTREE_ID_MSG,
			BTREE_OBJINFO_AS_ARGS (&first_object), PGBUF_PAGE_STATE_ARGS (leaf_page),
			BTID_AS_ARGS (btid_int->sys_btid));
    }
  else
    {
      /* Object belongs to overflow. */
      assert (helper->is_system_op_started);

      /* Swap first object to overflow page and replace it with our object. */
      error_code =
	btree_overflow_record_replace_object (thread_p, btid_int, helper, overflow_page, overflow_record,
					      &offset_to_object, &first_object);
      if (error_code != NO_ERROR)
	{
	  assert_release (false);
	  return error_code;
	}
    }

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  /* Replace first object. */
  btree_leaf_change_first_object (thread_p, leaf_record, btid_int, BTREE_DELETE_OID (helper),
				  BTREE_DELETE_CLASS_OID (helper), BTREE_DELETE_MVCC_INFO (helper), NULL, rv_undo_data,
				  rv_redo_data);

  btree_delete_log (helper, "successfully moved object and removed its delete MVCCID %llu (logging is postponed) \n"
		    BTREE_DELETE_HELPER_MSG ("\t") "\t" PGBUF_PAGE_STATE_MSG ("leaf page") "\n\t" BTREE_ID_MSG,
		    (unsigned long long int) helper->match_mvccinfo.delete_mvccid,
		    BTREE_DELETE_HELPER_AS_ARGS (helper), PGBUF_PAGE_STATE_ARGS (leaf_page),
		    BTID_AS_ARGS (btid_int->sys_btid));

  /* Success */
  return NO_ERROR;
}

/*
 * btree_key_remove_delete_mvccid_non_unique () - Remove delete MVCCID from an index object as part of undoing a MVCC
 *						  delete operation.
 *
 * return		 : Error code.
 * thread_p (in)	 : Thread entry.
 * btid_int (in)	 : B-tree info.
 * delete_helper (in)	 : B-tree delete helper.
 * page (in)		 : Leaf or overflow page.
 * record (in)		 : Leaf or overflow record.
 * slotid (in)		 : Slot ID of record.
 * node_type (in)	 : BTREE_LEAF_NODE or BTREE_OVERFLOW_NODE.
 * offset_to_object (in) : Offset to object in its record.
 *
 * NOTE: Even though this function is targeted for non-unique indexes, it can be used in one case for unique indexes:
 *	 when the object being undone is already first in leaf record and does not require relocation.
 */
static int
btree_key_remove_delete_mvccid_non_unique (THREAD_ENTRY * thread_p, BTID_INT * btid_int,
					   BTREE_DELETE_HELPER * delete_helper, PAGE_PTR page, RECDES * record,
					   PGSLOTID slotid, BTREE_NODE_TYPE node_type, int offset_to_object)
{
  LOG_DATA_ADDR addr;		/* Log address for record. */
  int rv_redo_data_length = 0;	/* Redo recovery data length. */
  TDE_ALGORITHM tde_algo = TDE_ALGORITHM_NONE;

  LOG_LSA prev_lsa;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (delete_helper != NULL);
  assert (delete_helper->purpose == BTREE_OP_DELETE_UNDO_INSERT_DELID);
  assert (page != NULL);
  assert (record != NULL && record->data != NULL);
  assert (slotid > 0);
  assert (node_type == BTREE_LEAF_NODE || node_type == BTREE_OVERFLOW_NODE);
  assert (offset_to_object >= 0 && offset_to_object < record->length);
  assert (!BTREE_IS_UNIQUE (btid_int->unique_pk) || (node_type == BTREE_LEAF_NODE && offset_to_object == 0));

  /* Prepare logging before starting changes. */
  addr.offset = slotid;
  addr.pgptr = page;
  addr.vfid = &btid_int->sys_btid->vfid;

#if !defined (NDEBUG)
  /* For debugging recovery. */
  BTREE_RV_REDO_SET_DEBUG_INFO (&addr, delete_helper->rv_redo_data_ptr, btid_int,
				BTREE_RV_DEBUG_ID_REM_DELID_NON_UNIQUE);
#endif /* !NDEBUG */
  if (node_type == BTREE_OVERFLOW_NODE)
    {
      BTREE_RV_SET_OVERFLOW_NODE (&addr);
    }
  LOG_RV_RECORD_SET_MODIFY_MODE (&addr, LOG_RV_RECORD_UPDATE_PARTIAL);

  btree_record_remove_delid (thread_p, btid_int, record, node_type, offset_to_object, NULL,
			     &delete_helper->rv_redo_data_ptr);

  /* Update in page. */
  if (spage_update (thread_p, page, slotid, record) != SP_SUCCESS)
    {
      /* Unexpected. */
      assert_release (false);
      return ER_FAILED;
    }

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  /* Add logging. */
  prev_lsa = *pgbuf_get_lsa (page);
  BTREE_RV_GET_DATA_LENGTH (delete_helper->rv_redo_data_ptr, delete_helper->rv_redo_data, rv_redo_data_length);
  log_append_compensate_with_undo_nxlsa (thread_p, RVBT_RECORD_MODIFY_COMPENSATE, pgbuf_get_vpid_ptr (page),
					 addr.offset, page, rv_redo_data_length, delete_helper->rv_redo_data,
					 LOG_FIND_CURRENT_TDES (thread_p), &delete_helper->reference_lsa);

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  pgbuf_set_dirty (thread_p, page, DONT_FREE);

  btree_delete_log (delete_helper, BTREE_DELETE_MODIFY_MSG ("removed delete MVCCID %llu"),
		    (unsigned long long int) delete_helper->object_info.mvcc_info.delete_mvccid,
		    BTREE_DELETE_MODIFY_ARGS (thread_p, delete_helper, page, &prev_lsa, node_type == BTREE_LEAF_NODE,
					      slotid, record->length, btid_int->sys_btid));

  return NO_ERROR;
}

/*
 * btree_overflow_record_replace_object () - Replace an object from an overflow record with another object. Part of
 *					     remove MVCCID algorithm for unique indexes.
 *
 * return			  : Error code.
 * thread_p (in)		  : Thread entry.
 * btid_int (in)		  : B-tree info.
 * delete_helper (in)		  : B-tree delete helper.
 * overflow_page (in)		  : Overflow page.
 * overflow_record (in)		  : Overflow record.
 * offset_to_replaced_object (in) : Offset to object being replaced.
 * replacing_object (in)	  : Object info for replacement.
 */
static int
btree_overflow_record_replace_object (THREAD_ENTRY * thread_p, BTID_INT * btid_int, BTREE_DELETE_HELPER * delete_helper,
				      PAGE_PTR overflow_page, RECDES * overflow_record, int *offset_to_replaced_object,
				      BTREE_OBJECT_INFO * replacing_object)
{
  /* Redo recovery data. */
  LOG_DATA_ADDR overflow_addr;
  char rv_redo_data_buffer[BTREE_RV_BUFFER_SIZE + BTREE_MAX_ALIGN];
  char *rv_redo_data = PTR_ALIGN (rv_redo_data_buffer, BTREE_MAX_ALIGN);
  char *rv_redo_data_ptr = rv_redo_data;
  int rv_redo_data_length = 0;

  char rv_undo_data_buffer[BTREE_RV_BUFFER_SIZE + BTREE_MAX_ALIGN];
  char *rv_undo_data = PTR_ALIGN (rv_undo_data_buffer, BTREE_MAX_ALIGN);
  char *rv_undo_data_ptr = rv_undo_data;
  int rv_undo_data_length = 0;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (delete_helper != NULL);
  assert (btree_is_delete_object_purpose (delete_helper->purpose)
	  || delete_helper->purpose == BTREE_OP_DELETE_UNDO_INSERT_DELID);
  assert (overflow_page != NULL);
  assert (overflow_record != NULL);
  assert (offset_to_replaced_object != NULL);
  assert ((*offset_to_replaced_object) >= 0 && (*offset_to_replaced_object) < overflow_record->length);
  assert (replacing_object != NULL);

  assert (delete_helper->is_system_op_started);

  /* Prepare logging. */
  overflow_addr.offset = 1;
  overflow_addr.pgptr = overflow_page;
  overflow_addr.vfid = &btid_int->sys_btid->vfid;

#if !defined (NDEBUG)
  BTREE_RV_UNDOREDO_SET_DEBUG_INFO (&overflow_addr, rv_redo_data_ptr, rv_undo_data_ptr, btid_int,
				    BTREE_RV_DEBUG_ID_OVF_REPLACE);
#endif /* !NDEBUG */
  BTREE_RV_SET_OVERFLOW_NODE (&overflow_addr);

  btree_record_replace_object (thread_p, btid_int, overflow_record, BTREE_OVERFLOW_NODE, offset_to_replaced_object,
			       replacing_object, &rv_undo_data_ptr, &rv_redo_data_ptr);

  /* Update page. */
  if (spage_update (thread_p, overflow_page, 1, overflow_record) != SP_SUCCESS)
    {
      assert_release (false);
      return ER_FAILED;
    }

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  /* Add undoredo logging. */
  BTREE_RV_GET_DATA_LENGTH (rv_redo_data_ptr, rv_redo_data, rv_redo_data_length);
  BTREE_RV_GET_DATA_LENGTH (rv_undo_data_ptr, rv_undo_data, rv_undo_data_length);
  log_append_undoredo_data (thread_p, RVBT_RECORD_MODIFY_UNDOREDO, &overflow_addr, rv_undo_data_length,
			    rv_redo_data_length, rv_undo_data, rv_redo_data);
  pgbuf_set_dirty (thread_p, overflow_page, DONT_FREE);

  FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

  return NO_ERROR;
}

/*
 * btree_record_remove_insid () - Remove object insert MVCCID from b-tree record.
 *
 * return		 : Void.
 * thread_p (in)	 : Thread entry.
 * btid_int (in)	 : B-tree info.
 * record (in/out)	 : B-tree record.
 * node_type (in)	 : Leaf or overflow node type.
 * offset_to_object (in) : Offset to object in record data.
 * rv_undo_data (out)	 : If not NULL, output redo recovery data for the change.
 * rv_redo_data (out)	 : If not NULL, output redo recovery data for the change.
 * displacement (out)	 : Output the displacement of the rest of the record.
 */
static void
btree_record_remove_insid (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * record, BTREE_NODE_TYPE node_type,
			   int offset_to_object, char **rv_undo_data, char **rv_redo_data, int *displacement)
{
  int insert_mvccid_offset;
  bool has_fixed_size = false;
  MVCCID all_visible_mvccid = MVCCID_ALL_VISIBLE;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (record != NULL);
  assert (node_type == BTREE_LEAF_NODE || node_type == BTREE_OVERFLOW_NODE);
  assert (offset_to_object >= 0 && offset_to_object < record->length);

  has_fixed_size = ((node_type == BTREE_OVERFLOW_NODE)
		    || (offset_to_object > 0 && BTREE_IS_UNIQUE (btid_int->unique_pk))
		    || (offset_to_object == 0 && btree_leaf_is_flaged (record, BTREE_LEAF_RECORD_OVERFLOW_OIDS)));

  /* Where is insert MVCCID. */
  /* Skip object OID. */
  insert_mvccid_offset = offset_to_object + OR_OID_SIZE;

  if (btree_is_class_oid_packed (btid_int, record, node_type, (offset_to_object == 0)))
    {
      /* Also class OID is stored. */
      insert_mvccid_offset += OR_OID_SIZE;
    }

  if (has_fixed_size)
    {
      btree_set_mvccid (record, insert_mvccid_offset, &all_visible_mvccid, rv_undo_data, rv_redo_data);
    }
  else
    {
      btree_remove_mvccid (record, offset_to_object, insert_mvccid_offset, BTREE_OID_HAS_MVCC_INSID, rv_undo_data,
			   rv_redo_data);

      if (displacement != NULL)
	{
	  *displacement = -OR_MVCCID_SIZE;
	}
    }

#if !defined (NDEBUG)
  (void) btree_check_valid_record (thread_p, btid_int, record, node_type, NULL);
#endif /* !NDEBUG */
}

/*
 * btree_record_remove_delid () - Remove object delete MVCCID from b-tree record.
 *
 * return		 : Void.
 * thread_p (in)	 : Thread entry.
 * btid_int (in)	 : B-tree info.
 * record (in/out)	 : B-tree record.
 * node_type (in)	 : Leaf or overflow node type.
 * offset_to_object (in) : Offset to object in record data.
 * rv_undo_data (out)	 : If not NULL, output undo recovery data for the change.
 * rv_redo_data (out)	 : If not NULL, output redo recovery data for the change.
 */
static void
btree_record_remove_delid (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * record, BTREE_NODE_TYPE node_type,
			   int offset_to_object, char **rv_undo_data, char **rv_redo_data)
{
  int offset_to_delete_mvccid;
  bool has_fixed_size;
  MVCCID null_mvccid = MVCCID_NULL;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (record != NULL);
  assert (node_type == BTREE_LEAF_NODE || node_type == BTREE_OVERFLOW_NODE);
  assert (offset_to_object >= 0 && offset_to_object < record->length);

  /* Safe guard: unique indexes are not allowed to remove delete MVCCID unless it is the first object. Otherwise,
   * object should be relocated to first position. */
  assert (!BTREE_IS_UNIQUE (btid_int->unique_pk) || (node_type == BTREE_LEAF_NODE && offset_to_object == 0));

  has_fixed_size = (node_type == BTREE_OVERFLOW_NODE
		    || (offset_to_object == 0 && btree_leaf_is_flaged (record, BTREE_LEAF_RECORD_OVERFLOW_OIDS)));

  /* Compute offset to delete MVCCID. */
  /* Start with offset_to_object. */
  /* OID is always saved. */
  offset_to_delete_mvccid = offset_to_object + OR_OID_SIZE;

  if (BTREE_IS_UNIQUE (btid_int->unique_pk) && btree_leaf_is_flaged (record, BTREE_LEAF_RECORD_CLASS_OID))
    {
      /* Class OID is also saved. */
      offset_to_delete_mvccid += OR_OID_SIZE;
    }
  if (has_fixed_size || btree_record_object_is_flagged (record->data + offset_to_object, BTREE_OID_HAS_MVCC_INSID))
    {
      /* Insert MVCCID is also saved. */
      offset_to_delete_mvccid += OR_MVCCID_SIZE;
    }

  /* Remove or replace delete MVCCID. */
  if (has_fixed_size)
    {
      btree_set_mvccid (record, offset_to_delete_mvccid, &null_mvccid, rv_undo_data, rv_redo_data);
    }
  else
    {
      btree_remove_mvccid (record, offset_to_object, offset_to_delete_mvccid, BTREE_OID_HAS_MVCC_DELID, rv_undo_data,
			   rv_redo_data);
    }

#if !defined (NDEBUG)
  (void) btree_check_valid_record (thread_p, btid_int, record, node_type, NULL);
#endif /* !NDEBUG */
}

/*
 * btree_record_add_delid () - Add object delete MVCCID to b-tree record.
 *
 * return		 : Void.
 * thread_p (in)	 : Thread entry.
 * btid_int (in)	 : B-tree info.
 * record (in/out)	 : B-tree record.
 * node_type (in)	 : Leaf or overflow node type.
 * offset_to_object (in) : Offset to object in record data.
 * delete_mvccid (in)	 : Delete MVCCID to add.
 * rv_undo_data (out)	 : If not NULL, output undo recovery data for the change.
 * rv_redo_data (out)	 : If not NULL, output redo recovery data for the change.
 */
static void
btree_record_add_delid (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * record, BTREE_NODE_TYPE node_type,
			int offset_to_object, MVCCID delete_mvccid, char **rv_undo_data, char **rv_redo_data)
{
  int offset_to_delete_mvccid;
  char *oid_ptr = NULL;
  char *mvccid_ptr = NULL;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (record != NULL);
  assert (node_type == BTREE_LEAF_NODE || node_type == BTREE_OVERFLOW_NODE);
  assert (offset_to_object >= 0 && offset_to_object < record->length);

  /* Set oid_ptr */
  oid_ptr = record->data + offset_to_object;

  /* Compute offset to delete MVCCID. */
  /* Instance OID is always packed. */
  offset_to_delete_mvccid = offset_to_object + OR_OID_SIZE;
  if (btree_is_class_oid_packed (btid_int, record, node_type, (offset_to_object == 0)))
    {
      /* Class OID is also packed. */
      offset_to_delete_mvccid += OR_OID_SIZE;
    }
  if (btree_record_object_is_flagged (oid_ptr, BTREE_OID_HAS_MVCC_INSID))
    {
      /* Insert MVCCID is also packed. */
      offset_to_delete_mvccid += OR_MVCCID_SIZE;
    }
  /* Set mvccid_ptr. */
  mvccid_ptr = record->data + offset_to_delete_mvccid;

  if (btree_record_object_is_flagged (oid_ptr, BTREE_OID_HAS_MVCC_DELID))
    {
      /* Just replace the MVCCID. */
      btree_set_mvccid (record, offset_to_delete_mvccid, &delete_mvccid, rv_undo_data, rv_redo_data);
    }
  else
    {
      /* Insert delete MVCCID. */
      btree_add_mvccid (record, offset_to_object, offset_to_delete_mvccid, delete_mvccid, BTREE_OID_HAS_MVCC_DELID,
			rv_undo_data, rv_redo_data);
    }
#if !defined (NDEBUG)
  btree_check_valid_record (thread_p, btid_int, record, node_type, NULL);
#endif
}

/*
 * btree_record_replace_object () - Replace object in b-tree record.
 *
 * return			     : Void.
 * thread_p (in)		     : Thread entry.
 * btid_int (in)		     : B-tree info.
 * record (in)			     : B-tree record.
 * node_type (in)		     : Leaf or overflow node type.
 * offset_to_replaced_inout (in/out) : Offset in record to object being replaced. It will output offset to replacing
 *				       object.
 * replacement (in)		     : B-tree object info for replacement.
 * rv_undo_data (out)		     : Output undo data recovery for the change.
 * rv_redo_data (out)		     : Output undo data recovery for the change.
 */
static void
btree_record_replace_object (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * record, BTREE_NODE_TYPE node_type,
			     int *offset_to_replaced_inout, BTREE_OBJECT_INFO * replacement, char **rv_undo_data,
			     char **rv_redo_data)
{
  int old_object_size;
  int new_object_size;
  char *object_ptr;
  char *ptr = NULL;

  bool undo_logging = rv_undo_data != NULL && *rv_undo_data != NULL;
  bool redo_logging = rv_redo_data != NULL && *rv_redo_data != NULL;

  int offset_to_replaced;

  /* Assert expected arguments. */
  assert (btid_int != NULL);
  assert (record != NULL);
  assert (offset_to_replaced_inout != NULL);
  assert (replacement != NULL);

  offset_to_replaced = *offset_to_replaced_inout;
  assert (offset_to_replaced >= 0 && offset_to_replaced < record->length);

  if (node_type == BTREE_LEAF_NODE)
    {
      if (offset_to_replaced == 0)
	{
	  /* First in leaf record. */
	  btree_leaf_change_first_object (thread_p, record, btid_int, &replacement->oid, &replacement->class_oid,
					  &replacement->mvcc_info, NULL, rv_undo_data, rv_redo_data);
	  return;
	}
      /* Not first in leaf record. */
      if (BTREE_IS_UNIQUE (btid_int->unique_pk))
	{
	  /* Fixed size objects. */
	  new_object_size = BTREE_OBJECT_FIXED_SIZE (btid_int);
	  old_object_size = new_object_size;

	  /* Include all MVCC info. */
	  BTREE_MVCC_INFO_SET_FIXED_SIZE (&replacement->mvcc_info);
	}
      else
	{
	  /* Compute old and new object size. */
	  /* Both have instance OID. */
	  old_object_size = new_object_size = OR_OID_SIZE;

	  /* Add old object MVCC info size. */
	  old_object_size +=
	    BTREE_GET_MVCC_INFO_SIZE_FROM_FLAGS (btree_record_object_get_mvcc_flags (record->data
										     + offset_to_replaced));

	  /* Add new object MVCC info size. */
	  new_object_size += BTREE_GET_MVCC_INFO_SIZE_FROM_FLAGS (replacement->mvcc_info.flags);
	}
      /* Change the record. */
      object_ptr = record->data + offset_to_replaced;

      /* Undo logging. */
      if (undo_logging)
	{
	  *rv_undo_data =
	    log_rv_pack_undo_record_changes (*rv_undo_data, offset_to_replaced, old_object_size, new_object_size,
					     object_ptr);
	}

      RECORD_MOVE_DATA (record, offset_to_replaced + new_object_size, offset_to_replaced + old_object_size);
      ptr = btree_pack_object (object_ptr, btid_int, node_type, record, replacement);
      assert (CAST_BUFLEN (ptr - object_ptr) == new_object_size);

      /* Redo logging. */
      if (redo_logging)
	{
	  *rv_redo_data =
	    log_rv_pack_redo_record_changes (*rv_redo_data, offset_to_replaced, old_object_size, new_object_size,
					     object_ptr);
	}

#if !defined (NDEBUG)
      (void) btree_check_valid_record (thread_p, btid_int, record, node_type, NULL);
#endif
    }
  else
    {
      /* Object must be fixed size. */
      int fixed_object_size = BTREE_OBJECT_FIXED_SIZE (btid_int);
      BTREE_MVCC_INFO_SET_FIXED_SIZE (&replacement->mvcc_info);

      if (record->length == fixed_object_size)
	{
	  /* Only one object. Just replace it. */
	  assert (offset_to_replaced == 0);
	  if (undo_logging)
	    {
	      /* Undo logging. */
	      *rv_undo_data =
		log_rv_pack_undo_record_changes (*rv_undo_data, 0, fixed_object_size, fixed_object_size, record->data);
	    }
	  ptr = btree_pack_object (record->data, btid_int, node_type, record, replacement);
	  assert (ptr == record->data + fixed_object_size);
	  if (redo_logging)
	    {
	      /* Redo logging. */
	      *rv_redo_data =
		log_rv_pack_redo_record_changes (*rv_redo_data, 0, fixed_object_size, fixed_object_size, record->data);
	    }
#if !defined (NDEBUG)
	  (void) btree_check_valid_record (thread_p, btid_int, record, node_type, NULL);
#endif
	}
      else
	{
	  /* Remove old object and insert new ordered by OID. */
	  btree_record_remove_object_internal (thread_p, btid_int, record, node_type, offset_to_replaced, rv_undo_data,
					       rv_redo_data, NULL);
	  btree_insert_object_ordered_by_oid (thread_p, record, btid_int, replacement, rv_undo_data, rv_redo_data,
					      offset_to_replaced_inout);
	}
    }
}

/*
 * btree_get_creator_mvccid () - Get MVCCID of creator from root header.
 *
 * return	  : MVCCID of creator.
 * thread_p (in)  : Thread entry.
 * root_page (in) : Root page.
 */
static MVCCID
btree_get_creator_mvccid (THREAD_ENTRY * thread_p, PAGE_PTR root_page)
{
  BTREE_ROOT_HEADER *root_header = NULL;

  assert (root_page != NULL);

  root_header = btree_get_root_header (thread_p, root_page);
  assert (root_header != NULL);

  return root_header->creator_mvccid;
}

/*
 * btree_rv_undo_mark_dealloc_page () - Undo marking index page as deallocated by setting its level back.
 *
 * return	 : Error code.
 * thread_p (in) : Thread entry.
 * rcv (in)	 : Recovery data.
 */
int
btree_rv_undo_mark_dealloc_page (THREAD_ENTRY * thread_p, LOG_RCV * rcv)
{
  BTREE_NODE_HEADER *node_header = btree_get_node_header (thread_p, rcv->pgptr);

  if (node_header == NULL)
    {
      assert (false);
      return ER_FAILED;
    }

  assert (rcv->length == sizeof (node_header->node_level));
  assert (sizeof (short) == sizeof (node_header->node_level));

  node_header->node_level = *(short *) rcv->data;
  pgbuf_set_dirty (thread_p, rcv->pgptr, DONT_FREE);

  return NO_ERROR;
}

/*
 * btree_hash_btid () - Create hash value from btid.
 *
 * return	  : Hash value
 * btid (in)	  : Pointer to b-tree ID.
 * hash_size (in) : Hash size.
 */
unsigned int
btree_hash_btid (void *btid, int hash_size)
{
  return ((BTID *) btid)->vfid.fileid % hash_size;
}

/*
 * btree_create_file () - Create a b-tree file and allocate its root.
 *
 * return	  : Error code
 * thread_p (in)  : Thread entry
 * class_oid (in) : Top class OID
 * attrid (in)	  : Attribute identifier
 * npages (in)	  : Number of pages
 * btid (out)	  : B-tree identifier
 *
 * todo: use table space.
 */
int
btree_create_file (THREAD_ENTRY * thread_p, const OID * class_oid, int attrid, BTID * btid)
{
  FILE_DESCRIPTORS des;
  VPID vpid_root;
  TDE_ALGORITHM tde_algo = TDE_ALGORITHM_NONE;

  int error_code = NO_ERROR;

  memset (&des, 0, sizeof (des));
  des.btree.class_oid = *class_oid;
  des.btree.attr_id = attrid;

  error_code = file_create_with_npages (thread_p, FILE_BTREE, 1, &des, &btid->vfid);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      return error_code;
    }

  error_code = heap_get_class_tde_algorithm (thread_p, class_oid, &tde_algo);
  if (error_code == NO_ERROR)
    {
      /* 
       * It can happen to fail to get the class record.
       * For example, a class record that is assigned but not updated poperly yet.
       * In this case, Setting tde flag is just skipped and it is expected to be done later.
       * see file_apply_tde_to_class_files() 
       */
      error_code = file_apply_tde_algorithm (thread_p, &btid->vfid, tde_algo);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return error_code;
	}
    }
  else
    {
      er_clear ();
    }

  /* index page allocations need to be committed. they are not individually deallocated on undo; all pages are
   * deallocated when the file is destroyed. */
  log_sysop_start (thread_p);
  error_code = file_alloc_sticky_first_page (thread_p, &btid->vfid, btree_initialize_new_page, NULL, &vpid_root, NULL);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      log_sysop_abort (thread_p);
      return error_code;
    }
  if (vpid_root.volid != btid->vfid.volid)
    {
      /* should not happen */
      assert_release (false);
      log_sysop_abort (thread_p);
      return ER_FAILED;
    }
  btid->root_pageid = vpid_root.pageid;

  log_sysop_commit (thread_p);
  return NO_ERROR;
}

/*
 * btree_delete_sysop_end () - end system op used for b-tree delete based on purpose.
 *
 * return          : void
 * thread_p (in)   : thread entry
 * helper (in/out) : delete helper
 */
STATIC_INLINE void
btree_delete_sysop_end (THREAD_ENTRY * thread_p, BTREE_DELETE_HELPER * helper)
{
  if (!helper->is_system_op_started)
    {
      assert_release (false);
      return;
    }

  switch (helper->purpose)
    {
    case BTREE_OP_DELETE_OBJECT_PHYSICAL:
      log_sysop_end_logical_undo (thread_p, RVBT_DELETE_OBJECT_PHYSICAL, helper->leaf_addr.vfid,
				  helper->rv_keyval_data_length, helper->rv_keyval_data);
      break;

    case BTREE_OP_ONLINE_INDEX_TRAN_DELETE:
      log_sysop_end_logical_undo (thread_p, RVBT_ONLINE_INDEX_UNDO_TRAN_DELETE, helper->leaf_addr.vfid,
				  helper->rv_keyval_data_length, helper->rv_keyval_data);
      break;

    case BTREE_OP_DELETE_OBJECT_PHYSICAL_POSTPONED:
      log_sysop_end_logical_run_postpone (thread_p, &helper->reference_lsa);
      break;

    case BTREE_OP_DELETE_UNDO_INSERT:
    case BTREE_OP_DELETE_UNDO_INSERT_UNQ_MULTIUPD:
    case BTREE_OP_DELETE_UNDO_INSERT_DELID:
    case BTREE_OP_ONLINE_INDEX_UNDO_TRAN_INSERT:
      log_sysop_end_logical_compensate (thread_p, &helper->reference_lsa);
      break;

    case BTREE_OP_DELETE_VACUUM_INSID:
      /* system op to just vacuum insert MVCCID? not really expected. */
      assert (false);
      /* fall through to commit on release */

    case BTREE_OP_DELETE_VACUUM_OBJECT:
    case BTREE_OP_ONLINE_INDEX_IB_DELETE:
      log_sysop_commit (thread_p);
      break;

    default:
      assert_release (false);
      log_sysop_abort (thread_p);
      break;
    }

  helper->is_system_op_started = false;
}

/*
 * btree_insert_sysop_end () - end system op used for b-tree insert based on purpose.
 *
 * return          : void
 * thread_p (in)   : thread entry
 * helper (in/out) : insert helper
 */
STATIC_INLINE void
btree_insert_sysop_end (THREAD_ENTRY * thread_p, BTREE_INSERT_HELPER * helper)
{
  if (!helper->is_system_op_started)
    {
      assert_release (false);
      return;
    }

  switch (helper->purpose)
    {
    case BTREE_OP_INSERT_NEW_OBJECT:
      assert (helper->rcvindex != RV_NOT_DEFINED);
      log_sysop_end_logical_undo (thread_p, helper->rcvindex, helper->leaf_addr.vfid, helper->rv_keyval_data_length,
				  helper->rv_keyval_data);
      break;

    case BTREE_OP_ONLINE_INDEX_TRAN_INSERT_DF:
      log_sysop_end_logical_undo (thread_p, RVBT_ONLINE_INDEX_UNDO_TRAN_DELETE, helper->leaf_addr.vfid,
				  helper->rv_keyval_data_length, helper->rv_keyval_data);
      break;

    case BTREE_OP_ONLINE_INDEX_TRAN_INSERT:
      log_sysop_end_logical_undo (thread_p, RVBT_ONLINE_INDEX_UNDO_TRAN_INSERT, helper->leaf_addr.vfid,
				  helper->rv_keyval_data_length, helper->rv_keyval_data);
      break;

    case BTREE_OP_INSERT_UNDO_PHYSICAL_DELETE:
    case BTREE_OP_ONLINE_INDEX_UNDO_TRAN_DELETE:
      log_sysop_end_logical_compensate (thread_p, &helper->compensate_undo_nxlsa);
      break;

    case BTREE_OP_ONLINE_INDEX_IB_INSERT:
      log_sysop_commit (thread_p);
      break;

    case BTREE_OP_INSERT_MVCC_DELID:
    case BTREE_OP_INSERT_MARK_DELETED:
      /* no system ops are expected! */

    default:
      assert_release (false);
      log_sysop_abort (thread_p);
      break;
    }

  helper->is_system_op_started = false;
}

/*
 * btree_purpose_to_string () - purpose to string
 *
 * return       : string
 * purpose (in) : purpose
 */
STATIC_INLINE const char *
btree_purpose_to_string (BTREE_OP_PURPOSE purpose)
{
  switch (purpose)
    {
    case BTREE_OP_INSERT_NEW_OBJECT:
      return "BTREE_OP_INSERT_NEW_OBJECT";
    case BTREE_OP_INSERT_UNDO_PHYSICAL_DELETE:
      return "BTREE_OP_INSERT_UNDO_PHYSICAL_DELETE";
    case BTREE_OP_INSERT_MVCC_DELID:
      return "BTREE_OP_INSERT_MVCC_DELID";
    case BTREE_OP_INSERT_MARK_DELETED:
      return "BTREE_OP_INSERT_MARK_DELETED";
    case BTREE_OP_DELETE_OBJECT_PHYSICAL:
      return "BTREE_OP_DELETE_OBJECT_PHYSICAL";
    case BTREE_OP_DELETE_OBJECT_PHYSICAL_POSTPONED:
      return "BTREE_OP_DELETE_OBJECT_PHYSICAL_POSTPONED";
    case BTREE_OP_DELETE_UNDO_INSERT:
      return "BTREE_OP_DELETE_UNDO_INSERT";
    case BTREE_OP_DELETE_UNDO_INSERT_UNQ_MULTIUPD:
      return "BTREE_OP_DELETE_UNDO_INSERT_UNQ_MULTIUPD";
    case BTREE_OP_DELETE_UNDO_INSERT_DELID:
      return "BTREE_OP_DELETE_UNDO_INSERT_DELID";
    case BTREE_OP_DELETE_VACUUM_INSID:
      return "BTREE_OP_DELETE_VACUUM_INSID";
    case BTREE_OP_DELETE_VACUUM_OBJECT:
      return "BTREE_OP_DELETE_VACUUM_OBJECT";
    case BTREE_OP_ONLINE_INDEX_TRAN_INSERT:
      return "BTREE_OP_ONLINE_INDEX_TRAN_INSERT";
    case BTREE_OP_ONLINE_INDEX_TRAN_INSERT_DF:
      return "BTREE_OP_ONLINE_INDEX_TRAN_INSERT_DF";
    case BTREE_OP_ONLINE_INDEX_UNDO_TRAN_DELETE:
      return "BTREE_OP_ONLINE_INDEX_UNDO_TRAN_DELETE";
    case BTREE_OP_ONLINE_INDEX_TRAN_DELETE:
      return "case BTREE_OP_ONLINE_INDEX_TRAN_DELETE";
    case BTREE_OP_ONLINE_INDEX_UNDO_TRAN_INSERT:
      return "BTREE_OP_ONLINE_INDEX_UNDO_TRAN_INSERT";
    case BTREE_OP_ONLINE_INDEX_IB_INSERT:
      return "BTREE_OP_ONLINE_INDEX_IB_INSERT";
    case BTREE_OP_ONLINE_INDEX_IB_DELETE:
      return "BTREE_OP_ONLINE_INDEX_IB_DELETE";
    default:
      assert (false);
      return "** UNKNOWN PURPOSE **";
    }
}

/*
 * btree_op_type_to_string () - operation type to string
 *
 * return       : string
 * op_type (in) : operation type
 */
STATIC_INLINE const char *
btree_op_type_to_string (int op_type)
{
  switch (op_type)
    {
    case SINGLE_ROW_INSERT:
      return "SINGLE_ROW_INSERT";
    case SINGLE_ROW_DELETE:
      return "SINGLE_ROW_DELETE";
    case SINGLE_ROW_UPDATE:
      return "SINGLE_ROW_UPDATE";
    case SINGLE_ROW_MODIFY:
      return "SINGLE_ROW_MODIFY";
    case MULTI_ROW_INSERT:
      return "MULTI_ROW_INSERT";
    case MULTI_ROW_DELETE:
      return "MULTI_ROW_DELETE";
    case MULTI_ROW_UPDATE:
      return "MULTI_ROW_UPDATE";
    default:
      assert (false);
      return "** UNKNOWN OP TYPE **";
    }
}

/*
 * btree_get_btree_node_type_from_page () -
 *
 *   return:
 *   page_ptr(in):
 *
 */
PERF_PAGE_TYPE
btree_get_perf_btree_page_type (THREAD_ENTRY * thread_p, PAGE_PTR page_ptr)
{
  RECDES header_record;
  SPAGE_HEADER *page_header_p;
  int root_header_fixed_size = (int) offsetof (BTREE_ROOT_HEADER, packed_key_domain);

  assert (page_ptr != NULL);

  page_header_p = (SPAGE_HEADER *) page_ptr;

  if (page_header_p->num_slots <= 0 || spage_get_record (thread_p, page_ptr, HEADER, &header_record, PEEK) != S_SUCCESS)
    {
      return PERF_PAGE_BTREE_GENERIC;
    }

  if (header_record.length == sizeof (BTREE_OVERFLOW_HEADER))
    {
      return PERF_PAGE_BTREE_OVF;
    }
  else if (header_record.length == sizeof (BTREE_NODE_HEADER))
    {
      BTREE_NODE_HEADER *header;

      header = (BTREE_NODE_HEADER *) header_record.data;
      if (header != NULL)
	{
	  if (header->node_level > 1)
	    {
	      return PERF_PAGE_BTREE_NONLEAF;
	    }
	  else
	    {
	      return PERF_PAGE_BTREE_LEAF;
	    }
	}
      else
	{
	  return PERF_PAGE_UNKNOWN;
	}
    }
  else
    {
      assert (header_record.length >= root_header_fixed_size);

      return PERF_PAGE_BTREE_ROOT;
    }
  return PERF_PAGE_BTREE_ROOT;
}

//
// btree_online_index_check_state () - check online index state is valid
//
// state (in) : state
//
static inline void
btree_online_index_check_state (MVCCID state)
{
  assert (state == BTREE_ONLINE_INDEX_NORMAL_FLAG_STATE
	  || state == BTREE_ONLINE_INDEX_INSERT_FLAG_STATE || state == BTREE_ONLINE_INDEX_DELETE_FLAG_STATE);
}

static inline bool
btree_online_index_is_insert_flag_state (MVCCID state)
{
  return state == BTREE_ONLINE_INDEX_INSERT_FLAG_STATE;
}

static inline bool
btree_online_index_is_delete_flag_state (MVCCID state)
{
  return state == BTREE_ONLINE_INDEX_DELETE_FLAG_STATE;
}

static inline bool
btree_online_index_is_normal_state (MVCCID state)
{
  return state == BTREE_ONLINE_INDEX_NORMAL_FLAG_STATE;
}

static inline void
btree_online_index_set_insert_flag_state (MVCCID & state)
{
  state = BTREE_ONLINE_INDEX_INSERT_FLAG_STATE;
}

static inline void
btree_online_index_set_delete_flag_state (MVCCID & state)
{
  state = BTREE_ONLINE_INDEX_DELETE_FLAG_STATE;
}

static inline void
btree_online_index_set_normal_state (MVCCID & state)
{
  state = BTREE_ONLINE_INDEX_NORMAL_FLAG_STATE;
}

//
// btree_online_index_dispatcher () - dispatch online index operation: populate insert/delete helper and choose
//                                    appropriate root/traversal/leaf functions
//
// return         : error code
// thread_p (in)  : thread entry
// btid_int (in)  : b-tree info
// key (in)       : key
// class_oid (in) : class OID
// oid (in)       : instance OID
// unique (in)    : ... todo
// purpose (in)   : function purpose
//
int
btree_online_index_dispatcher (THREAD_ENTRY * thread_p, BTID * btid, DB_VALUE * key, OID * cls_oid,
			       OID * oid, int unique, BTREE_OP_PURPOSE purpose, LOG_LSA * undo_nxlsa)
{
  btree_insert_list one_item_list (key, oid);

  return btree_online_index_list_dispatcher (thread_p, btid, cls_oid, &one_item_list, unique, purpose, undo_nxlsa);
}

//
// btree_online_index_list_dispatcher () - dispatch online index operation with list mode
//
// return         : error code
// thread_p (in)  : thread entry
// btid_int (in)  : b-tree info
// class_oid (in) : class OID
// insert_list (in) : list of pairs key, OID
// unique (in)    :
// purpose (in)   : function purpose
// undo_nxlsa (in):
//
int
btree_online_index_list_dispatcher (THREAD_ENTRY * thread_p, BTID * btid, OID * class_oid,
				    btree_insert_list * insert_list, int unique, BTREE_OP_PURPOSE purpose,
				    LOG_LSA * undo_nxlsa)
{
  int error_code = NO_ERROR;
  /* Search key helper which will point to where data should inserted. */
  BTREE_SEARCH_KEY_HELPER search_key = BTREE_SEARCH_KEY_HELPER_INITIALIZER;
  /* Processing key function: can insert an object or just a delete MVCCID. */
  BTREE_ROOT_WITH_KEY_FUNCTION *root_function = NULL;
  BTREE_ADVANCE_WITH_KEY_FUNCTION *advance_function = NULL;
  BTREE_PROCESS_KEY_FUNCTION *key_function = NULL;
  BTREE_HELPER helper;
  BTID_INT btid_int;

  DB_VALUE *key = insert_list->get_key ();
  OID *oid = insert_list->get_oid ();

  helper.insert_helper.insert_list = insert_list;

  /* Safe guards */
  assert (oid != NULL);
  assert (class_oid != NULL);
  assert (purpose == BTREE_OP_ONLINE_INDEX_IB_INSERT || purpose == BTREE_OP_ONLINE_INDEX_TRAN_INSERT
	  || purpose == BTREE_OP_ONLINE_INDEX_TRAN_DELETE || purpose == BTREE_OP_ONLINE_INDEX_UNDO_TRAN_DELETE
	  || purpose == BTREE_OP_ONLINE_INDEX_UNDO_TRAN_INSERT);

  /* Check for null keys. */
  if (DB_IS_NULL (key) || btree_multicol_key_is_null (key))
    {
      /* We do not store NULL keys but we track them for unique indexes. */
      if (BTREE_IS_UNIQUE (unique))
	{
	  /* In this scenario, we have to write log for the update of local statistics, since we do not
	   * log the physical operation of a NULL key.
	   */
	  if (purpose == BTREE_OP_ONLINE_INDEX_TRAN_DELETE || purpose == BTREE_OP_ONLINE_INDEX_UNDO_TRAN_INSERT)
	    {
	      /* DELETE operation, we decrement oids and nulls. */
	      logtb_tran_update_unique_stats (thread_p, btid, 0, -1, -1, true);
	    }
	  else
	    {
	      /* Insert operation, we increment oids and nulls. */
	      logtb_tran_update_unique_stats (thread_p, btid, 0, 1, 1, true);
	    }
	}

      return NO_ERROR;
    }

  /* Save OID, class OID and MVCC info in insert helper. */
  COPY_OID (BTREE_INSERT_OID (&helper.insert_helper), oid);
  COPY_OID (BTREE_DELETE_OID (&helper.delete_helper), oid);
  if (class_oid != NULL)
    {
      COPY_OID (BTREE_INSERT_CLASS_OID (&helper.insert_helper), class_oid);
      COPY_OID (BTREE_DELETE_CLASS_OID (&helper.delete_helper), class_oid);
    }
  else
    {
      OID_SET_NULL (BTREE_INSERT_CLASS_OID (&helper.insert_helper));
      OID_SET_NULL (BTREE_DELETE_CLASS_OID (&helper.delete_helper));
    }

  if (undo_nxlsa != NULL)
    {
      LSA_COPY (&helper.insert_helper.compensate_undo_nxlsa, undo_nxlsa);
      LSA_COPY (&helper.delete_helper.reference_lsa, undo_nxlsa);
    }

  helper.insert_helper.log_operations = prm_get_bool_value (PRM_ID_LOG_BTREE_OPS);
  helper.delete_helper.log_operations = prm_get_bool_value (PRM_ID_LOG_BTREE_OPS);

  switch (purpose)
    {
    case BTREE_OP_ONLINE_INDEX_IB_INSERT:
      /* This is an insert done by the index builder. */
      helper.insert_helper.op_type = SINGLE_ROW_INSERT;
      helper.insert_helper.purpose = purpose;
      root_function = btree_fix_root_for_insert;
      advance_function = btree_split_node_and_advance;
      key_function = btree_key_online_index_IB_insert_list;
      break;

    case BTREE_OP_ONLINE_INDEX_TRAN_INSERT:
    case BTREE_OP_ONLINE_INDEX_UNDO_TRAN_DELETE:
      helper.insert_helper.op_type = SINGLE_ROW_INSERT;
      helper.insert_helper.purpose = purpose;
      root_function = btree_fix_root_for_insert;
      advance_function = btree_split_node_and_advance;
      key_function = btree_key_online_index_tran_insert;
      break;

    case BTREE_OP_ONLINE_INDEX_TRAN_DELETE:
    case BTREE_OP_ONLINE_INDEX_UNDO_TRAN_INSERT:
      helper.delete_helper.op_type = SINGLE_ROW_DELETE;
      helper.delete_helper.purpose = purpose;
      root_function = btree_fix_root_for_delete;
      advance_function = btree_merge_node_and_advance;
      key_function = btree_key_online_index_tran_delete;

      error_code =
	btree_search_key_and_apply_functions (thread_p, btid, &btid_int, key, root_function, &helper.delete_helper,
					      advance_function, &helper.delete_helper, key_function, &helper,
					      &search_key, NULL);

      if (error_code == NO_ERROR && search_key.result == BTREE_KEY_NOTFOUND)
	{
	  /* We failed to find the object in the index. We must traverse again the btree and treat the operation
	   * as an insert with DELETE_FLAG set.
	   */
	  helper.insert_helper.purpose = purpose;
	  helper.insert_helper.op_type = SINGLE_ROW_INSERT;
	  if (helper.delete_helper.purpose == BTREE_OP_ONLINE_INDEX_TRAN_DELETE)
	    {
	      helper.insert_helper.purpose = BTREE_OP_ONLINE_INDEX_TRAN_INSERT_DF;
	    }
	  root_function = btree_fix_root_for_insert;
	  advance_function = btree_split_node_and_advance;
	  key_function = btree_key_online_index_tran_insert_DF;
	  break;		// Fall through.
	}
      else
	{
	  goto end;
	}

    default:
      /* This should never happen. */
      assert (false);
      return ER_FAILED;
    }

  error_code =
    btree_search_key_and_apply_functions (thread_p, btid, &btid_int, key, root_function, &helper.insert_helper,
					  advance_function, &helper.insert_helper, key_function, &helper, &search_key,
					  NULL);

end:

  if (helper.insert_helper.printed_key != NULL)
    {
      db_private_free (thread_p, helper.insert_helper.printed_key);
    }

  if (helper.delete_helper.printed_key != NULL && helper.delete_helper.printed_key != helper.insert_helper.printed_key)
    {
      db_private_free (thread_p, helper.delete_helper.printed_key);
    }

  return error_code;
}

/*
 * btree_key_online_index_IB_insert_list () - BTREE_PROCESS_KEY_FUNCTION used for inserting a new object in b-tree during
 *                                       online index loading.
 *
 * return          : Error code.
 * thread_p (in)   : Thread entry.
 * btid_int (in)   : B-tree info.
 * key (int)       : Key info
 * leaf_page (in)  : Pointer to the leaf page.
 * search_key (in) : Search helper
 * restart (in/out): Restart
 * args (in/out)   : BTREE_INSERT_HELPER *.
 */
int
btree_key_online_index_IB_insert_list (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
				       PAGE_PTR * leaf_page, BTREE_SEARCH_KEY_HELPER * search_key, bool * restart,
				       void *other_args)
{
  BTREE_HELPER *helper = (BTREE_HELPER *) other_args;
  btree_insert_list *insert_list = helper->insert_helper.insert_list;
  DB_VALUE *curr_key;
  int error_code = NO_ERROR;
  bool first_insert = true;

  curr_key = key;

  assert (insert_list->m_key_type == btid_int->key_type);

  insert_list->m_keep_page_iterations = 0;
  insert_list->m_ovf_appends = 0;
  insert_list->m_ovf_appends_new_page = 0;
  PERF_UTIME_TRACKER time_insert_same_leaf = PERF_UTIME_TRACKER_INITIALIZER;
  PERF_UTIME_TRACKER_START (thread_p, &time_insert_same_leaf);

  while (1)
    {
      error_code = btree_key_online_index_IB_insert (thread_p, btid_int, curr_key, leaf_page, search_key, restart,
						     other_args);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  break;
	}

      if (helper->insert_helper.purpose != BTREE_OP_ONLINE_INDEX_IB_INSERT)
	{
	  assert (insert_list->m_keys_oids.size () == 1);
	  break;
	}

      perfmon_inc_stat (thread_p, PSTAT_BT_ONLINE_NUM_INSERTS);
      if (!first_insert)
	{
	  perfmon_inc_stat (thread_p, PSTAT_BT_ONLINE_NUM_INSERTS_SAME_PAGE_HOLD);
	}

      if (insert_list->next_key () != btree_insert_list::KEY_AVAILABLE)
	{
	  /* no more keys in list */
	  break;
	}

      /* prepare next pair (key, oid) */
      COPY_OID (BTREE_INSERT_OID (&helper->insert_helper), insert_list->get_oid ());
      curr_key = insert_list->get_key ();

      int key_len = btree_get_disk_size_of_key (curr_key);
      BTREE_NODE_HEADER *node_header = btree_get_node_header (thread_p, *leaf_page);

      if (key_len > node_header->max_key_len)
	{
	  /* cannot insert a key having len > max key len : abort and let advance/split algorithm to deal with this */
	  perfmon_inc_stat (thread_p, PSTAT_BT_ONLINE_NUM_RETRY);
	  break;
	}

      /* assuming the key does not exist in page (an existing key requires less space,
       * we may miss adding one more record; this is a less expensive check, we accept the 'loss' */
      bool key_already_in_page = false;
      int new_ent_size = btree_get_max_new_data_size (thread_p, btid_int, *leaf_page, BTREE_LEAF_NODE, key_len,
						      &helper->insert_helper, key_already_in_page);
      if (new_ent_size > spage_get_free_space_without_saving (thread_p, *leaf_page, NULL))
	{
	  /* no more space in page */
	  perfmon_inc_stat (thread_p, PSTAT_BT_ONLINE_NUM_RETRY);
	  break;
	}

      /* compare with boundary keys : NULL keys means INF bound, no check is required */
      if (!insert_list->m_boundaries.m_is_inf_left_key)
	{
	  DB_VALUE_COMPARE_RESULT c;
	  c = btree_compare_key (&insert_list->m_boundaries.m_left_key, curr_key, btid_int->key_type, 1, 1, NULL);
	  if (c != DB_LT && c != DB_EQ)
	    {
	      perfmon_inc_stat (thread_p, PSTAT_BT_ONLINE_NUM_RETRY);
	      break;
	    }
	}

      if (!insert_list->m_boundaries.m_is_inf_right_key)
	{
	  DB_VALUE_COMPARE_RESULT c;
	  c = btree_compare_key (curr_key, &insert_list->m_boundaries.m_right_key, btid_int->key_type, 1, 1, NULL);
	  if (c != DB_LT)
	    {
	      perfmon_inc_stat (thread_p, PSTAT_BT_ONLINE_NUM_RETRY);
	      break;
	    }
	}

      /* early filter-out of out-page-range key : compare with min/max of page
       * it also has the purpose of silencing the debug assertion of btree_search_leaf_page;
       * after this, the 'search_key' structure is incomplete (slot id will be computed by btree_search_leaf_page) */
      if (DB_VALUE_DOMAIN_TYPE (key) == DB_TYPE_MIDXKEY)
	{
	  error_code = btree_leaf_is_key_between_min_max (thread_p, btid_int, *leaf_page, curr_key, search_key);
	  if (error_code != NO_ERROR)
	    {
	      ASSERT_ERROR ();
	      break;
	    }

	  if (search_key->result == BTREE_ERROR_OCCURRED || search_key->result == BTREE_KEY_SMALLER
	      || search_key->result == BTREE_KEY_BIGGER)
	    {
	      if (search_key->result == BTREE_KEY_SMALLER && VPID_ISNULL (&node_header->prev_vpid))
		{
		  /* key is out of range (smaller), but since there is no leaf page to the left, we may continue */
		  ;
		}
	      else if (search_key->result == BTREE_KEY_BIGGER && VPID_ISNULL (&node_header->next_vpid))
		{
		  /* key is out of range (bigger), but since there is no leaf page to the right, we may continue */
		  ;
		}
	      else
		{
		  /* key is out of range (smaller or bigger) and the current leaf page has neighbours :
		   * abort and search from root */
		  perfmon_inc_stat (thread_p, PSTAT_BT_ONLINE_NUM_RETRY);
		  break;
		}
	    }
	}

      /* resolution of where to insert : slot, position relative to this slot and if page has fence keys */
      error_code = btree_search_leaf_page (thread_p, btid_int, *leaf_page, curr_key, search_key);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  break;
	}

      if ((search_key->result == BTREE_KEY_BIGGER || search_key->result == BTREE_KEY_SMALLER)
	  && search_key->has_fence_key == btree_search_key_helper::HAS_FENCE_KEY)
	{
	  /* key is out of range and presence of fence key suggests that next/prev leaf page should be
	   * a better place; no fence means current key is bigger/lesser than all index keys and we can insert here
	   * (this is backed-up by key page boundaries checked before) */
	  perfmon_inc_stat (thread_p, PSTAT_BT_ONLINE_NUM_RETRY);
	  break;
	}
      else if (search_key->result != BTREE_KEY_BETWEEN && search_key->result != BTREE_KEY_FOUND
	       && search_key->result != BTREE_KEY_BIGGER && search_key->result != BTREE_KEY_SMALLER)
	{
	  /* unexpected, abort insert and retry from root page */
	  assert (false);
	  break;
	}

      first_insert = false;
      insert_list->m_keep_page_iterations++;

      if (insert_list->check_release_latch (thread_p, &helper->insert_helper, *leaf_page) == true)
	{
	  perfmon_inc_stat (thread_p, PSTAT_BT_ONLINE_NUM_RETRY_NICE);
	  break;
	}
    }

  insert_list->reset_boundary_keys ();

  PERF_UTIME_TRACKER_TIME (thread_p, &time_insert_same_leaf, PSTAT_BT_ONLINE_INSERT_LEAF);

  return error_code;
}

/*
 * btree_key_online_index_IB_insert () - BTREE_PROCESS_KEY_FUNCTION used for inserting a new object in b-tree during
 *                                       online index loading.
 *
 * return         : Error code.
 * thread_p (in)   : Thread entry.
 * btid_int (in)   : B-tree info.
 * key (int)       : Key info
 * leaf_page (in)  : Pointer to the leaf page.
 * search_key (in) : Search helper
 * restart (in/out): Restart
 * args (in/out)   : BTREE_INSERT_HELPER *.
 */
int
btree_key_online_index_IB_insert (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
				  PAGE_PTR * leaf_page, BTREE_SEARCH_KEY_HELPER * search_key, bool * restart,
				  void *other_args)
{
  BTREE_HELPER *helper = (BTREE_HELPER *) other_args;
  int error_code = NO_ERROR;	/* Error code. */
  RECDES record;		/* Record descriptor for leaf key record. */
  LEAF_REC leaf_info;		/* Leaf record info. */
  int offset_after_key;		/* Offset in record data where packed key is ended. */
  bool dummy_clear_key;		/* Dummy field used as argument for btree_read_record. */
  PAGE_PTR page_found = NULL;
  int offset_to_object = 0;
  BTREE_MVCC_INFO btree_mvcc_info = BTREE_MVCC_INFO_INITIALIZER;
  PAGE_PTR prev_page = NULL;
  BTREE_NODE_TYPE node_type;
  /* Redo recovery structures. */
  char rv_redo_data_buffer[BTREE_RV_BUFFER_SIZE + BTREE_MAX_ALIGN];
  char *rv_redo_data = PTR_ALIGN (rv_redo_data_buffer, BTREE_MAX_ALIGN);
  char *rv_redo_data_ptr = rv_redo_data;
  int rv_redo_data_length = 0;
  LOG_DATA_ADDR addr;
  LOG_LSA prev_lsa;
  PGSLOTID slotid;
  char rec_buf[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  char new_rec_buf[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  RECDES new_record;
  int n_keys = 0;
  int n_oids = 0;

  record.data = PTR_ALIGN (rec_buf, BTREE_MAX_ALIGN);
  record.area_size = IO_MAX_PAGE_SIZE;

  new_record.data = PTR_ALIGN (new_rec_buf, BTREE_MAX_ALIGN);
  new_record.area_size = IO_MAX_PAGE_SIZE;

  /* Redo logging. */
  helper->insert_helper.rv_redo_data = rv_redo_data;
  helper->insert_helper.rv_redo_data_ptr = helper->insert_helper.rv_redo_data;

  helper->insert_helper.leaf_addr.offset = search_key->slotid;
  helper->insert_helper.leaf_addr.pgptr = *leaf_page;
  helper->insert_helper.leaf_addr.vfid = &btid_int->sys_btid->vfid;

  /* We are in leaf level now, and we must inspect if we have found the OID inside the key. */
  if (search_key->result == BTREE_KEY_FOUND)
    {
      /* Get the record. */
      if (spage_get_record (thread_p, *leaf_page, search_key->slotid, &record, COPY) != S_SUCCESS)
	{
	  assert_release (false);
	  error_code = ER_FAILED;
	  return error_code;
	}

      /* Read the record. */
      error_code =
	btree_read_record (thread_p, btid_int, *leaf_page, &record, NULL, &leaf_info, BTREE_LEAF_NODE,
			   &dummy_clear_key, &offset_after_key, PEEK_KEY_VALUE, NULL);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  return error_code;
	}

      error_code =
	btree_find_oid_with_page_and_record (thread_p, btid_int, &helper->insert_helper.obj_info.oid, *leaf_page,
					     helper->insert_helper.purpose, NULL, &record, &leaf_info,
					     offset_after_key, &page_found, &prev_page, &offset_to_object,
					     &btree_mvcc_info, &new_record);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto end;
	}

      node_type = (page_found == *leaf_page) ? BTREE_LEAF_NODE : BTREE_OVERFLOW_NODE;

      if (node_type == BTREE_OVERFLOW_NODE)
	{
	  slotid = 1;
	}
      else
	{
	  slotid = search_key->slotid;
	}

      if (offset_to_object != NOT_FOUND)
	{
	  /* Inspect the object and its MVCC_INFO. */
	  /* This is the index builder, therefore if there is already an OID that matches the one that needs to be
	   * inserted, then the already inserted one should have either DELETE_FLAG or INSERT_FLAG set.
	   */
	  btree_online_index_check_state (btree_mvcc_info.insert_mvccid);

	  if (btree_online_index_is_insert_flag_state (btree_mvcc_info.insert_mvccid))
	    {
	      /* INSERT_FLAG is set. It means we have to remove the flag, according to the state machine. */
	      btree_online_index_set_normal_state (btree_mvcc_info.insert_mvccid);

	      /* Prepare logging data. */
	      addr.offset = slotid;
	      addr.pgptr = page_found;
	      addr.vfid = &btid_int->sys_btid->vfid;

	      if (node_type == BTREE_OVERFLOW_NODE)
		{
		  BTREE_RV_SET_OVERFLOW_NODE (&addr);
		}
	      LOG_RV_RECORD_SET_MODIFY_MODE (&addr, LOG_RV_RECORD_UPDATE_PARTIAL);

	      btree_online_index_change_state (thread_p, btid_int, &new_record, node_type, offset_to_object,
					       btree_mvcc_info.insert_mvccid, NULL,
					       &helper->insert_helper.rv_redo_data_ptr);

	      /* Add the logged info. */
	      /* Update in page. */
	      if (spage_update (thread_p, page_found, slotid, &new_record) != SP_SUCCESS)
		{
		  /* Unexpected. */
		  assert_release (false);
		  error_code = ER_FAILED;
		  goto end;
		}

	      FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

	      /* We need to log previous lsa. */
	      LSA_COPY (&prev_lsa, pgbuf_get_lsa (page_found));

	      /* Logging. */
	      BTREE_RV_GET_DATA_LENGTH (helper->insert_helper.rv_redo_data_ptr, helper->insert_helper.rv_redo_data,
					rv_redo_data_length);
	      log_append_redo_data (thread_p, RVBT_RECORD_MODIFY_NO_UNDO, &addr, rv_redo_data_length,
				    helper->insert_helper.rv_redo_data);

	      btree_insert_log (&helper->insert_helper,
				BTREE_INSERT_MODIFY_MSG ("IB insert change from INSERT_FLAG to NORMAL_STATE"),
				BTREE_INSERT_MODIFY_ARGS (thread_p, &helper->insert_helper, page_found, &prev_lsa,
							  node_type == BTREE_LEAF_NODE, slotid, new_record.length,
							  btid_int->sys_btid));

	      FI_TEST (thread_p, FI_TEST_BTREE_MANAGER_RANDOM_EXIT, 0);

	      pgbuf_set_dirty (thread_p, page_found, DONT_FREE);

	      goto end;
	    }
	  else
	    {
	      assert (btree_online_index_is_delete_flag_state (btree_mvcc_info.insert_mvccid));

	      btree_insert_helper_to_delete_helper (&helper->insert_helper, &helper->delete_helper);
	      helper->delete_helper.purpose = BTREE_OP_ONLINE_INDEX_IB_DELETE;
	      helper->delete_helper.op_type = SINGLE_ROW_DELETE;
	      assert (helper->delete_helper.rv_keyval_data == NULL);	// otherwise, it will be leaked.

	      if (btree_is_single_object_key (thread_p, btid_int, node_type, &new_record, offset_after_key))
		{
		  /* Only one OID in the key, we will remove the key as well. */
		  n_keys = -1;
		}
	      n_oids = -1;

	      error_code =
		btree_key_remove_object (thread_p, key, btid_int, &helper->delete_helper, *leaf_page, &record,
					 &leaf_info, offset_after_key, search_key, &page_found, prev_page,
					 node_type, offset_to_object);
	      goto end;
	    }
	}
      else
	{
	  /* Key was found but the object wasn't. We must append the object to the current key. */

	  /* Safeguards. */
	  assert (search_key->result == BTREE_KEY_FOUND && offset_to_object == NOT_FOUND);

	  n_oids = 1;

	  error_code =
	    btree_key_append_object_non_unique (thread_p, btid_int, key, *leaf_page, search_key, &new_record,
						offset_after_key, &leaf_info, &helper->insert_helper.obj_info,
						&helper->insert_helper);
	}
    }
  else
    {
      /* Key was not found, we must insert it. */
      n_keys = 1;
      n_oids = 1;

      error_code = btree_key_insert_new_key (thread_p, btid_int, key, *leaf_page, &helper->insert_helper, search_key);
    }

end:
  if (error_code == NO_ERROR && BTREE_IS_UNIQUE (btid_int->unique_pk))
    {
      logtb_tran_update_unique_stats (thread_p, btid_int->sys_btid, n_keys, n_oids, 0, false);
    }

  if (page_found != NULL && page_found != *leaf_page)
    {
      pgbuf_unfix_and_init (thread_p, page_found);
    }

  if (prev_page != NULL && prev_page != *leaf_page)
    {
      pgbuf_unfix_and_init (thread_p, prev_page);
    }

  return error_code;
}

/*
 * btree_key_online_index_tran_insert () - BTREE_PROCESS_KEY_FUNCTION used for inserting a new object
 *                                         in b-tree during online index loading.
 *
 * return         : Error code.
 * thread_p (in)   : Thread entry.
 * btid_int (in)   : B-tree info.
 * key (int)       : Key info
 * leaf_page (in)  : Pointer to the leaf page.
 * search_key (in) : Search helper
 * restart (in/out): Restart
 * args (in/out)   : BTREE_INSERT_HELPER *.
 */
static int
btree_key_online_index_tran_insert (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
				    PAGE_PTR * leaf_page, BTREE_SEARCH_KEY_HELPER * search_key, bool * restart,
				    void *other_args)
{
  BTREE_HELPER *helper = (BTREE_HELPER *) other_args;
  int error_code = NO_ERROR;	/* Error code. */
  RECDES record;		/* Record descriptor for leaf key record. */
  LEAF_REC leaf_info;		/* Leaf record info. */
  int offset_after_key;		/* Offset in record data where packed key is ended. */
  bool dummy_clear_key;		/* Dummy field used as argument for btree_read_record. */
  PAGE_PTR page_found = NULL;
  int offset_to_object = 0;
  BTREE_MVCC_INFO btree_mvcc_info = BTREE_MVCC_INFO_INITIALIZER;
  BTREE_NODE_TYPE node_type;
  RECDES new_record;
  PGSLOTID slotid;
  LOG_LSA prev_lsa;

  LOG_DATA_ADDR addr;

  char rec_buf[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  record.data = PTR_ALIGN (rec_buf, BTREE_MAX_ALIGN);
  record.area_size = IO_MAX_PAGE_SIZE;

  char new_rec_buf[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  new_record.data = PTR_ALIGN (new_rec_buf, BTREE_MAX_ALIGN);
  new_record.area_size = IO_MAX_PAGE_SIZE;

  char *rv_undo_data = NULL;
  int rv_undo_data_capacity = IO_MAX_PAGE_SIZE;
  char rv_undo_data_buffer[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  char *rv_undo_data_bufalign = PTR_ALIGN (rv_undo_data_buffer, BTREE_MAX_ALIGN);

  char rv_redo_data_buffer[BTREE_RV_BUFFER_SIZE + BTREE_MAX_ALIGN];
  char *rv_redo_data = PTR_ALIGN (rv_redo_data_buffer, BTREE_MAX_ALIGN);
  char *rv_redo_data_ptr = rv_redo_data;
  int rv_redo_data_length = 0;

  helper->insert_helper.rv_redo_data = rv_redo_data;
  helper->insert_helper.rv_redo_data_ptr = helper->insert_helper.rv_redo_data;

  helper->insert_helper.leaf_addr.offset = search_key->slotid;
  helper->insert_helper.leaf_addr.pgptr = *leaf_page;
  helper->insert_helper.leaf_addr.vfid = &btid_int->sys_btid->vfid;

  helper->insert_helper.rv_keyval_data = rv_undo_data_bufalign;

  /* Undo logging. */
  if (helper->insert_helper.purpose == BTREE_OP_ONLINE_INDEX_TRAN_INSERT
      || helper->insert_helper.purpose == BTREE_OP_ONLINE_INDEX_TRAN_INSERT_DF)
    {
      error_code =
	btree_rv_save_keyval_for_undo (btid_int, key, BTREE_INSERT_CLASS_OID (&helper->insert_helper),
				       BTREE_INSERT_OID (&helper->insert_helper),
				       BTREE_INSERT_MVCC_INFO (&helper->insert_helper), helper->insert_helper.purpose,
				       rv_undo_data_bufalign, &helper->insert_helper.rv_keyval_data,
				       &rv_undo_data_capacity, &helper->insert_helper.rv_keyval_data_length);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto end;
	}
    }

  /* We are in leaf level now, and we must inspect if we have found the OID inside the key. */
  if (search_key->result == BTREE_KEY_FOUND)
    {
      /* We search the key for the OID. If we find it, we should find it with DELETE_FLAG set, therefore we must
       * delete it in place.
       */

      /* Get the record. */
      if (spage_get_record (thread_p, *leaf_page, search_key->slotid, &record, COPY) != S_SUCCESS)
	{
	  assert_release (false);
	  error_code = ER_FAILED;
	  goto end;
	}

      /* Read the record. */
      error_code =
	btree_read_record (thread_p, btid_int, *leaf_page, &record, NULL, &leaf_info, BTREE_LEAF_NODE,
			   &dummy_clear_key, &offset_after_key, PEEK_KEY_VALUE, NULL);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto end;
	}

      error_code =
	btree_find_oid_with_page_and_record (thread_p, btid_int, &helper->insert_helper.obj_info.oid, *leaf_page,
					     helper->insert_helper.purpose, NULL, &record, &leaf_info, offset_after_key,
					     &page_found, NULL, &offset_to_object, &btree_mvcc_info, &new_record);

      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto end;
	}

      node_type = (page_found == *leaf_page) ? BTREE_LEAF_NODE : BTREE_OVERFLOW_NODE;

      if (offset_to_object != NOT_FOUND)
	{
	  /* Inspect the key and its MVCC_INFO. This is the transactional insert, which means that if we can find the
	   * object, then the object must have DELETE_FLAG set.
	   */
	  btree_online_index_check_state (btree_mvcc_info.insert_mvccid);
	  assert (btree_online_index_is_delete_flag_state (btree_mvcc_info.insert_mvccid));

	  /* Here we must change the state to insert flag. */
	  if (node_type == BTREE_LEAF_NODE)
	    {
	      slotid = search_key->slotid;
	    }
	  else
	    {
	      slotid = 1;
	    }

	  /* Prepare logging. */
	  addr.offset = slotid;
	  addr.pgptr = page_found;
	  addr.vfid = &btid_int->sys_btid->vfid;

	  /* Redo logging. */
	  if (node_type == BTREE_OVERFLOW_NODE)
	    {
	      BTREE_RV_SET_OVERFLOW_NODE (&addr);
	    }
	  LOG_RV_RECORD_SET_MODIFY_MODE (&addr, LOG_RV_RECORD_UPDATE_PARTIAL);

	  /* Set the new state to INSERT_FLAG. */
	  btree_online_index_set_insert_flag_state (btree_mvcc_info.insert_mvccid);

	  /* Change the state of the record. */
	  btree_online_index_change_state (thread_p, btid_int, &new_record, node_type, offset_to_object,
					   btree_mvcc_info.insert_mvccid, NULL, &rv_redo_data_ptr);

	  if (spage_update (thread_p, page_found, slotid, &new_record) != SP_SUCCESS)
	    {
	      assert_release (false);
	      error_code = ER_FAILED;
	      goto end;
	    }

	  /* We need to log previous lsa. */
	  LSA_COPY (&prev_lsa, pgbuf_get_lsa (page_found));

	  /* Logging. */
	  BTREE_RV_GET_DATA_LENGTH (rv_redo_data_ptr, rv_redo_data, rv_redo_data_length);

	  btree_insert_log (&helper->insert_helper,
			    BTREE_INSERT_MODIFY_MSG ("Tran insert change from DELETE_FLAG to INSERT_FLAG"),
			    BTREE_INSERT_MODIFY_ARGS (thread_p, &helper->insert_helper, page_found, &prev_lsa,
						      node_type == BTREE_LEAF_NODE, slotid, new_record.length,
						      btid_int->sys_btid));

	  btree_rv_log_insert_object (thread_p, helper->insert_helper, addr, 0, rv_redo_data_length, NULL,
				      rv_redo_data);

	  pgbuf_set_dirty (thread_p, page_found, DONT_FREE);

	  goto end;
	}
      else
	{
	  /* Key was found but the object wasn't. We must append the object to the current key. */
	  /* Safeguards. */
	  assert (search_key->result == BTREE_KEY_FOUND && offset_to_object == NOT_FOUND);

	  error_code =
	    btree_key_append_object_non_unique (thread_p, btid_int, key, *leaf_page, search_key, &new_record,
						offset_after_key, &leaf_info, &helper->insert_helper.obj_info,
						&helper->insert_helper);
	  if (error_code == NO_ERROR && BTREE_IS_UNIQUE (btid_int->unique_pk))
	    {
	      // Append a single object.
	      logtb_tran_update_unique_stats (thread_p, btid_int->sys_btid, 0, 1, 0, false);
	    }

	  goto end;
	}
    }
  else
    {
      /* Key was not found, we must insert it. */
      error_code = btree_key_insert_new_key (thread_p, btid_int, key, *leaf_page, &helper->insert_helper, search_key);
      if (error_code == NO_ERROR && BTREE_IS_UNIQUE (btid_int->unique_pk))
	{
	  /* Insert a key with an object. */
	  logtb_tran_update_unique_stats (thread_p, btid_int->sys_btid, 1, 1, 0, false);
	}

      goto end;
    }

end:
  if (helper->insert_helper.rv_keyval_data != NULL && helper->insert_helper.rv_keyval_data != rv_undo_data_bufalign)
    {
      db_private_free_and_init (thread_p, helper->insert_helper.rv_keyval_data);
    }
  helper->insert_helper.rv_keyval_data = NULL;
  helper->insert_helper.rv_keyval_data_length = 0;

  if (page_found != NULL && page_found != *leaf_page)
    {
      pgbuf_unfix_and_init (thread_p, page_found);
    }

  return error_code;
}

/*
 * btree_key_online_index_tran_delete () - BTREE_PROCESS_KEY_FUNCTION used for deleting an object
 *                                         in b-tree during online index loading.
 *
 * return         : Error code.
 * thread_p (in)   : Thread entry.
 * btid_int (in)   : B-tree info.
 * key (int)       : Key info
 * leaf_page (in)  : Pointer to the leaf page.
 * search_key (in) : Search helper
 * restart (in/out): Restart
 * args (in/out)   : BTREE_INSERT_HELPER *.
 */
static int
btree_key_online_index_tran_delete (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
				    PAGE_PTR * leaf_page, BTREE_SEARCH_KEY_HELPER * search_key, bool * restart,
				    void *other_args)
{
  BTREE_HELPER *helper = (BTREE_HELPER *) other_args;
  int error_code = NO_ERROR;	/* Error code. */
  RECDES record;		/* Record descriptor for leaf key record. */
  LEAF_REC leaf_info;		/* Leaf record info. */
  int offset_after_key;		/* Offset in record data where packed key is ended. */
  bool dummy_clear_key;		/* Dummy field used as argument for btree_read_record. */
  PAGE_PTR page_found = NULL;
  int offset_to_object = 0;
  BTREE_MVCC_INFO btree_mvcc_info = BTREE_MVCC_INFO_INITIALIZER;
  PAGE_PTR prev_page = NULL;
  BTREE_NODE_TYPE node_type;
  char *rv_dummy_undo_data = NULL;
  char rec_buf[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];

  LOG_DATA_ADDR addr;
  LOG_LSA prev_lsa;
  PGSLOTID slotid;
  RECDES new_record;

  char new_rec_buf[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  new_record.data = PTR_ALIGN (new_rec_buf, BTREE_MAX_ALIGN);
  new_record.area_size = IO_MAX_PAGE_SIZE;

  record.data = PTR_ALIGN (rec_buf, BTREE_MAX_ALIGN);
  record.area_size = IO_MAX_PAGE_SIZE;

  char *rv_undo_data = NULL;
  int rv_undo_data_capacity = IO_MAX_PAGE_SIZE;
  char rv_undo_data_buffer[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  char *rv_undo_data_bufalign = PTR_ALIGN (rv_undo_data_buffer, BTREE_MAX_ALIGN);

  char rv_redo_data_buffer[BTREE_RV_BUFFER_SIZE + BTREE_MAX_ALIGN];
  char *rv_redo_data = PTR_ALIGN (rv_redo_data_buffer, BTREE_MAX_ALIGN);
  char *rv_redo_data_ptr = rv_redo_data;
  int rv_redo_data_length = 0;

  int n_keys = 0;
  int n_oids = 0;

  int key_len;

  bool switched_to_insert_helper = false;

  helper->delete_helper.rv_keyval_data = rv_undo_data_bufalign;
  if (helper->delete_helper.purpose == BTREE_OP_ONLINE_INDEX_TRAN_DELETE)
    {
      error_code =
	btree_rv_save_keyval_for_undo (btid_int, key, BTREE_DELETE_CLASS_OID (&helper->delete_helper),
				       BTREE_DELETE_OID (&helper->delete_helper),
				       BTREE_DELETE_MVCC_INFO (&helper->delete_helper), helper->delete_helper.purpose,
				       rv_undo_data_bufalign, &helper->delete_helper.rv_keyval_data,
				       &rv_undo_data_capacity, &helper->delete_helper.rv_keyval_data_length);

      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto end;
	}
    }

  helper->delete_helper.leaf_addr.offset = search_key->slotid;
  helper->delete_helper.leaf_addr.pgptr = *leaf_page;
  helper->delete_helper.leaf_addr.vfid = &btid_int->sys_btid->vfid;

  helper->delete_helper.rv_redo_data = rv_redo_data;
  helper->delete_helper.rv_redo_data_ptr = rv_redo_data_ptr;

  /* We are in leaf level now, and we must inspect if we have found the OID inside the key. */
  if (search_key->result == BTREE_KEY_FOUND)
    {
      /* We search the key for the OID. If we find it, we should find it with DELETE_FLAG set, therefore we must
       * delete it in place.
       */

      /* Get the record. */
      if (spage_get_record (thread_p, *leaf_page, search_key->slotid, &record, COPY) != S_SUCCESS)
	{
	  assert_release (false);
	  error_code = ER_FAILED;
	  goto end;
	}

      /* Read the record. */
      error_code =
	btree_read_record (thread_p, btid_int, *leaf_page, &record, NULL, &leaf_info, BTREE_LEAF_NODE,
			   &dummy_clear_key, &offset_after_key, PEEK_KEY_VALUE, NULL);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto end;
	}

      error_code =
	btree_find_oid_with_page_and_record (thread_p, btid_int, &helper->delete_helper.object_info.oid, *leaf_page,
					     helper->delete_helper.purpose, NULL, &record, &leaf_info, offset_after_key,
					     &page_found, &prev_page, &offset_to_object, &btree_mvcc_info, &new_record);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto end;
	}

      node_type = (page_found == *leaf_page) ? BTREE_LEAF_NODE : BTREE_OVERFLOW_NODE;

      if (offset_to_object != NOT_FOUND)
	{
	  /* Inspect the key and its MVCC_INFO. If we find the object, then the object should have either INSERT_FLAG
	   * set, or it should be without any flags set.
	   */
	  btree_online_index_check_state (btree_mvcc_info.insert_mvccid);

	  if (node_type == BTREE_LEAF_NODE)
	    {
	      slotid = search_key->slotid;
	    }
	  else
	    {
	      slotid = 1;
	    }

	  if (btree_online_index_is_insert_flag_state (btree_mvcc_info.insert_mvccid))
	    {
	      /* Insert flag set. We must change the flag to DELETE_FLAG. */

	      /* Prepare Logging. */
	      addr.pgptr = page_found;
	      addr.offset = slotid;
	      addr.vfid = &btid_int->sys_btid->vfid;

	      /* Redo logging. */
	      if (node_type == BTREE_OVERFLOW_NODE)
		{
		  BTREE_RV_SET_OVERFLOW_NODE (&addr);
		}
	      LOG_RV_RECORD_SET_MODIFY_MODE (&addr, LOG_RV_RECORD_UPDATE_PARTIAL);

	      /* Set the new state to DELETE_FLAG. */
	      btree_online_index_set_delete_flag_state (btree_mvcc_info.insert_mvccid);

	      /* Change the state of the record. */
	      btree_online_index_change_state (thread_p, btid_int, &new_record, node_type, offset_to_object,
					       btree_mvcc_info.insert_mvccid, NULL, &rv_redo_data_ptr);

	      if (spage_update (thread_p, page_found, slotid, &new_record) != SP_SUCCESS)
		{
		  assert_release (false);
		  error_code = ER_FAILED;
		  goto end;
		}

	      /* We need to log previous lsa. */
	      LSA_COPY (&prev_lsa, pgbuf_get_lsa (page_found));

	      /* Logging. */
	      BTREE_RV_GET_DATA_LENGTH (rv_redo_data_ptr, rv_redo_data, rv_redo_data_length);

	      btree_delete_log (&helper->delete_helper,
				BTREE_DELETE_MODIFY_MSG ("Tran delete change from INSERT_FLAG to DELETE_FLAG"),
				BTREE_DELETE_MODIFY_ARGS (thread_p, &helper->delete_helper, page_found, &prev_lsa,
							  node_type == BTREE_LEAF_NODE, slotid, new_record.length,
							  btid_int->sys_btid));

	      btree_rv_log_delete_object (thread_p, helper->delete_helper, addr, 0,
					  rv_redo_data_length, NULL, rv_redo_data);

	      pgbuf_set_dirty (thread_p, page_found, DONT_FREE);

	      goto end;
	    }
	  else
	    {
	      /* Normal state. We need to physically delete the object. */
	      assert (btree_online_index_is_normal_state (btree_mvcc_info.insert_mvccid));
	      if (btree_is_single_object_key (thread_p, btid_int, node_type, &new_record, offset_after_key))
		{
		  /* Only one OID in the key, we will remove the key as well. */
		  n_keys = -1;
		}
	      n_oids = -1;

	      error_code =
		btree_key_remove_object (thread_p, key, btid_int, &helper->delete_helper, *leaf_page, &record,
					 &leaf_info, offset_after_key, search_key, &page_found, prev_page, node_type,
					 offset_to_object);

	      if (error_code == NO_ERROR && BTREE_IS_UNIQUE (btid_int->unique_pk))
		{
		  logtb_tran_update_unique_stats (thread_p, btid_int->sys_btid, n_keys, n_oids, 0, false);
		}

	      goto end;
	    }
	}
      else
	{
	  ;			/* Fall through and do the usual case. */
	}
    }

  /* We did not find the object. We have to check if there is enough space in the leaf for the object. If there is,
   * we insert it in place without any restarts.
   */

  btree_delete_helper_to_insert_helper (&helper->delete_helper, &helper->insert_helper);
  switched_to_insert_helper = true;
  helper->insert_helper.purpose = BTREE_OP_ONLINE_INDEX_TRAN_INSERT;
  helper->insert_helper.op_type = SINGLE_ROW_INSERT;

  /* delete_helper does not hold information regarding the length of the key in page.
   * We need this information so that we can check whether we have enough space to insert the new object.
   */

  key_len = btree_get_disk_size_of_key (key);
  helper->insert_helper.key_len_in_page = BTREE_GET_KEY_LEN_IN_PAGE (key_len);

  if (!btree_key_insert_does_leaf_need_split (thread_p, btid_int, *leaf_page, &helper->insert_helper, search_key))
    {
      /* There is enough space. */

      /* We have to check if we have an overflow key and if the btid can handle it. If not, restart the traverse. */
      if (key_len >= BTREE_MAX_KEYLEN_INPAGE && VFID_ISNULL (&btid_int->ovfid))
	{
	  /* We have to restart to ensure the key is correctly handled. */
	  search_key->result = BTREE_KEY_NOTFOUND;
	  goto end;
	}

      /* Set DELETE_FLAG in the helper structure. */
      helper->insert_helper.obj_info.mvcc_info.flags |= BTREE_OID_HAS_MVCC_INSID;
      btree_online_index_set_delete_flag_state (helper->insert_helper.obj_info.mvcc_info.insert_mvccid);

      helper->insert_helper.purpose = BTREE_OP_ONLINE_INDEX_TRAN_INSERT_DF;
      if (search_key->result == BTREE_KEY_FOUND)
	{
	  error_code =
	    btree_key_append_object_non_unique (thread_p, btid_int, key, *leaf_page, search_key, &new_record,
						offset_after_key, &leaf_info, &helper->insert_helper.obj_info,
						&helper->insert_helper);
	}
      else
	{
	  error_code = btree_key_insert_new_key (thread_p, btid_int, key, *leaf_page, &helper->insert_helper,
						 search_key);
	  n_keys = 1;
	}

      n_oids = 1;

      if (error_code == NO_ERROR && BTREE_IS_UNIQUE (btid_int->unique_pk))
	{
	  logtb_tran_update_unique_stats (thread_p, btid_int->sys_btid, n_keys, n_oids, 0, false);
	}

      goto end;
    }

  /* Not enough space. We have to restart the traverse and try to insert the object with DELETE_FLAG set. */
  search_key->result = BTREE_KEY_NOTFOUND;

end:
  if (switched_to_insert_helper)
    {
      if (helper->insert_helper.rv_keyval_data != NULL && helper->insert_helper.rv_keyval_data != rv_undo_data_bufalign)
	{
	  db_private_free_and_init (thread_p, helper->insert_helper.rv_keyval_data);
	}
      helper->insert_helper.rv_keyval_data = NULL;
      helper->insert_helper.rv_keyval_data_length = 0;
    }
  else
    {
      if (helper->delete_helper.rv_keyval_data != NULL && helper->delete_helper.rv_keyval_data != rv_undo_data_bufalign)
	{
	  db_private_free_and_init (thread_p, helper->delete_helper.rv_keyval_data);
	}
      helper->delete_helper.rv_keyval_data = NULL;
      helper->delete_helper.rv_keyval_data_length = 0;
    }

  if (page_found != NULL && page_found != *leaf_page)
    {
      pgbuf_unfix_and_init (thread_p, page_found);
    }

  if (prev_page != NULL && prev_page != *leaf_page)
    {
      pgbuf_unfix_and_init (thread_p, prev_page);
    }

  return error_code;
}

/*
 * btree_key_online_index_tran_insert_DF () -  BTREE_PROCESS_KEY_FUNCTION used for inserting a new object
 *                                             with DELETE_FLAG set in b-tree during online index loading.
 *
 * return         : Error code.
 * thread_p (in)   : Thread entry.
 * btid_int (in)   : B-tree info.
 * key (int)       : Key info
 * leaf_page (in)  : Pointer to the leaf page.
 * search_key (in) : Search helper
 * restart (in/out): Restart
 * args (in/out)   : BTREE_INSERT_HELPER *.
 */
static int
btree_key_online_index_tran_insert_DF (THREAD_ENTRY * thread_p, BTID_INT * btid_int, DB_VALUE * key,
				       PAGE_PTR * leaf_page, BTREE_SEARCH_KEY_HELPER * search_key, bool * restart,
				       void *other_args)
{
  BTREE_HELPER *helper = (BTREE_HELPER *) other_args;
  int error_code = NO_ERROR;	/* Error code. */
  RECDES record;		/* Record descriptor for leaf key record. */
  LEAF_REC leaf_info;		/* Leaf record info. */
  int offset_after_key;		/* Offset in record data where packed key is ended. */
  bool dummy_clear_key;		/* Dummy field used as argument for btree_read_record. */
  PAGE_PTR page_found = NULL;
  int offset_to_object = 0;
  BTREE_MVCC_INFO btree_mvcc_info = BTREE_MVCC_INFO_INITIALIZER;
  PAGE_PTR prev_page = NULL;
  BTREE_NODE_TYPE node_type;

  LOG_DATA_ADDR addr;
  LOG_LSA prev_lsa;
  PGSLOTID slotid;
  RECDES new_record;
  char rec_buf[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  char new_rec_buf[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];

  new_record.data = PTR_ALIGN (new_rec_buf, BTREE_MAX_ALIGN);
  new_record.area_size = IO_MAX_PAGE_SIZE;

  record.data = PTR_ALIGN (rec_buf, BTREE_MAX_ALIGN);
  record.area_size = IO_MAX_PAGE_SIZE;

  char *rv_undo_data = NULL;
  int rv_undo_data_capacity = IO_MAX_PAGE_SIZE;
  char rv_undo_data_buffer[IO_MAX_PAGE_SIZE + BTREE_MAX_ALIGN];
  char *rv_undo_data_bufalign = PTR_ALIGN (rv_undo_data_buffer, BTREE_MAX_ALIGN);

  char rv_redo_data_buffer[BTREE_RV_BUFFER_SIZE + BTREE_MAX_ALIGN];
  char *rv_redo_data = PTR_ALIGN (rv_redo_data_buffer, BTREE_MAX_ALIGN);
  char *rv_redo_data_ptr = rv_redo_data;
  int rv_redo_data_length = 0;

  int n_keys = 0;
  int n_oids = 0;

  bool switched_to_delete_helper = false;

  /* Save the key for undo process. */
  helper->insert_helper.rv_keyval_data = rv_undo_data_bufalign;
  if (helper->insert_helper.purpose == BTREE_OP_ONLINE_INDEX_TRAN_INSERT_DF)
    {
      error_code =
	btree_rv_save_keyval_for_undo (btid_int, key, BTREE_INSERT_CLASS_OID (&helper->insert_helper),
				       BTREE_INSERT_OID (&helper->insert_helper),
				       BTREE_INSERT_MVCC_INFO (&helper->insert_helper), helper->insert_helper.purpose,
				       rv_undo_data_bufalign, &helper->insert_helper.rv_keyval_data,
				       &rv_undo_data_capacity, &helper->insert_helper.rv_keyval_data_length);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto end;
	}
    }

  helper->insert_helper.leaf_addr.offset = search_key->slotid;
  helper->insert_helper.leaf_addr.pgptr = *leaf_page;
  helper->insert_helper.leaf_addr.vfid = &btid_int->sys_btid->vfid;

  /* Redo logging. */
  helper->insert_helper.rv_redo_data = rv_redo_data;
  helper->insert_helper.rv_redo_data_ptr = helper->insert_helper.rv_redo_data;

  /* We are in leaf level now, and we must inspect if we have found the OID inside the key. */
  if (search_key->result == BTREE_KEY_FOUND)
    {
      /* We search the key for the OID. */

      /* Get the record. */
      if (spage_get_record (thread_p, *leaf_page, search_key->slotid, &record, COPY) != S_SUCCESS)
	{
	  assert_release (false);
	  error_code = ER_FAILED;
	  goto end;
	}

      /* Read the record. */
      error_code =
	btree_read_record (thread_p, btid_int, *leaf_page, &record, NULL, &leaf_info, BTREE_LEAF_NODE,
			   &dummy_clear_key, &offset_after_key, PEEK_KEY_VALUE, NULL);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto end;
	}

      error_code =
	btree_find_oid_with_page_and_record (thread_p, btid_int, &helper->insert_helper.obj_info.oid, *leaf_page,
					     helper->insert_helper.purpose, NULL, &record, &leaf_info, offset_after_key,
					     &page_found, &prev_page, &offset_to_object, &btree_mvcc_info, &new_record);
      if (error_code != NO_ERROR)
	{
	  ASSERT_ERROR ();
	  goto end;
	}

      node_type = (page_found == *leaf_page) ? BTREE_LEAF_NODE : BTREE_OVERFLOW_NODE;

      if (offset_to_object != NOT_FOUND)
	{
	  /* Inspect the key and its MVCC_INFO. This is the transactional insert with DELETE_FLAG, which means
	   * that if we can find the object, then the object must have either INSERT_FLAG set, or the object
	   * should be in normal state.
	   */
	  assert (!btree_online_index_is_delete_flag_state (btree_mvcc_info.insert_mvccid));

	  if (node_type == BTREE_LEAF_NODE)
	    {
	      slotid = search_key->slotid;
	    }
	  else
	    {
	      slotid = 1;
	    }

	  if (btree_online_index_is_normal_state (btree_mvcc_info.insert_mvccid))
	    {
	      /* This translates into a physical delete as the object has already been inserted into the btree. */
	      /* Normal state. We need to physically delete the object. */
	      assert (btree_online_index_is_normal_state (btree_mvcc_info.insert_mvccid));

	      btree_insert_helper_to_delete_helper (&helper->insert_helper, &helper->delete_helper);
	      switched_to_delete_helper = true;

	      helper->delete_helper.purpose = BTREE_OP_ONLINE_INDEX_TRAN_DELETE;
	      helper->delete_helper.op_type = SINGLE_ROW_DELETE;

	      if (btree_is_single_object_key (thread_p, btid_int, node_type, &new_record, offset_after_key))
		{
		  /* Only one OID in the key, we will remove the key as well. */
		  n_keys = -1;
		}
	      n_oids = -1;

	      error_code =
		btree_key_remove_object (thread_p, key, btid_int, &helper->delete_helper, *leaf_page, &record,
					 &leaf_info, offset_after_key, search_key, &page_found, prev_page, node_type,
					 offset_to_object);

	      if (error_code == NO_ERROR && BTREE_IS_UNIQUE (btid_int->unique_pk))
		{
		  logtb_tran_update_unique_stats (thread_p, btid_int->sys_btid, n_keys, n_oids, 0, false);
		}
	      goto end;
	    }
	  else
	    {
	      /* We must have INSERT_FLAG set. */
	      assert (btree_online_index_is_insert_flag_state (btree_mvcc_info.insert_mvccid));

	      /* We have to change the state to DELETE_FLAG. */

	      /* Prepare logging. */
	      addr.offset = slotid;
	      addr.pgptr = page_found;
	      addr.vfid = &btid_int->sys_btid->vfid;

	      /* Redo logging. */
	      if (node_type == BTREE_OVERFLOW_NODE)
		{
		  BTREE_RV_SET_OVERFLOW_NODE (&addr);
		}
	      LOG_RV_RECORD_SET_MODIFY_MODE (&addr, LOG_RV_RECORD_UPDATE_PARTIAL);

	      /* Set the new state to INSERT_FLAG. */
	      btree_online_index_set_delete_flag_state (btree_mvcc_info.insert_mvccid);

	      /* Change the state of the record. */
	      btree_online_index_change_state (thread_p, btid_int, &new_record, node_type, offset_to_object,
					       btree_mvcc_info.insert_mvccid, NULL, &rv_redo_data_ptr);

	      if (spage_update (thread_p, page_found, slotid, &new_record) != SP_SUCCESS)
		{
		  assert_release (false);
		  error_code = ER_FAILED;
		  goto end;
		}

	      /* We need to log previous lsa. */
	      LSA_COPY (&prev_lsa, pgbuf_get_lsa (page_found));

	      /* Logging. */
	      BTREE_RV_GET_DATA_LENGTH (rv_redo_data_ptr, rv_redo_data, rv_redo_data_length);

	      btree_insert_log (&helper->insert_helper,
				BTREE_INSERT_MODIFY_MSG ("Tran delete change from INSERT_FLAG to DELETE_FLAG"),
				BTREE_INSERT_MODIFY_ARGS (thread_p, &helper->insert_helper, page_found, &prev_lsa,
							  node_type == BTREE_LEAF_NODE, slotid, new_record.length,
							  btid_int->sys_btid));

	      btree_rv_log_insert_object (thread_p, helper->insert_helper, addr, 0, rv_redo_data_length, NULL,
					  rv_redo_data);

	      pgbuf_set_dirty (thread_p, page_found, DONT_FREE);

	      goto end;
	    }
	}
      else
	{
	  /* Key was found but the object wasn't. We must append the object to the current key. */
	  /* Safeguards. */
	  assert (search_key->result == BTREE_KEY_FOUND && offset_to_object == NOT_FOUND);

	  /* We did not find the object. We have to insert it with DELETE_FLAG set. */
	  helper->insert_helper.obj_info.mvcc_info.flags |= BTREE_OID_HAS_MVCC_INSID;
	  btree_online_index_set_delete_flag_state (helper->insert_helper.obj_info.mvcc_info.insert_mvccid);

	  error_code =
	    btree_key_append_object_non_unique (thread_p, btid_int, key, *leaf_page, search_key, &new_record,
						offset_after_key, &leaf_info, &helper->insert_helper.obj_info,
						&helper->insert_helper);

	  if (error_code == NO_ERROR && BTREE_IS_UNIQUE (btid_int->unique_pk))
	    {
	      logtb_tran_update_unique_stats (thread_p, btid_int->sys_btid, 0, 1, 0, false);
	    }
	}
    }
  else
    {
      /* Key was not found, we must insert it. */
      /* We have to insert it with DELETE_FLAG set. */
      helper->insert_helper.obj_info.mvcc_info.flags |= BTREE_OID_HAS_MVCC_INSID;
      btree_online_index_set_delete_flag_state (helper->insert_helper.obj_info.mvcc_info.insert_mvccid);

      error_code = btree_key_insert_new_key (thread_p, btid_int, key, *leaf_page, &helper->insert_helper, search_key);
      if (error_code == NO_ERROR && BTREE_IS_UNIQUE (btid_int->unique_pk))
	{
	  logtb_tran_update_unique_stats (thread_p, btid_int->sys_btid, 1, 1, 0, false);
	}
    }

end:
  if (switched_to_delete_helper)
    {
      if (helper->delete_helper.rv_keyval_data != NULL && helper->delete_helper.rv_keyval_data != rv_undo_data_bufalign)
	{
	  db_private_free_and_init (thread_p, helper->delete_helper.rv_keyval_data);
	}
      helper->delete_helper.rv_keyval_data = NULL;
      helper->delete_helper.rv_keyval_data_length = 0;
    }
  else
    {
      if (helper->insert_helper.rv_keyval_data != NULL && helper->insert_helper.rv_keyval_data != rv_undo_data_bufalign)
	{
	  db_private_free_and_init (thread_p, helper->insert_helper.rv_keyval_data);
	}
      helper->insert_helper.rv_keyval_data = NULL;
      helper->insert_helper.rv_keyval_data_length = 0;
    }

  if (page_found != NULL && page_found != *leaf_page)
    {
      pgbuf_unfix_and_init (thread_p, page_found);
    }

  if (prev_page != NULL && prev_page != *leaf_page)
    {
      pgbuf_unfix_and_init (thread_p, prev_page);
    }

  return error_code;
}

//
// btree_online_index_change_state () - set new object state during online index
//
// thread_p (in)         : thread entry
// btid_int (in)         : b-tree info
// record (in)           : leaf/overflow record
// node_type (in)        : node type
// offset_to_object (in) : offset_to_object
// new_state (in)        : new object state
// rv_undo_data (in/out) : buffer to append undo log data
// rv_redo_data (in/out) : buffer to append redo log data
//
void
btree_online_index_change_state (THREAD_ENTRY * thread_p, BTID_INT * btid_int, RECDES * record,
				 BTREE_NODE_TYPE node_type, int offset_to_object, MVCCID new_state,
				 char **rv_undo_data, char **rv_redo_data)
{
  int offset_to_insid_mvccid;
  char *oid_ptr = NULL;
  char *mvccid_ptr = NULL;

  oid_ptr = record->data + offset_to_object;

  offset_to_insid_mvccid = offset_to_object + OR_OID_SIZE;
  if (btree_is_class_oid_packed (btid_int, record, node_type, (offset_to_object == 0)))
    {
      /* Class OID is also packed. */
      offset_to_insid_mvccid += OR_OID_SIZE;
    }
  /* Set mvccid_ptr. */
  mvccid_ptr = record->data + offset_to_insid_mvccid;

  /* Assign the new mvcc_insid. */
  if (btree_record_object_is_flagged (oid_ptr, BTREE_OID_HAS_MVCC_INSID))
    {
      // todo - compare to old state and make sure it changes
      /* We have MVCC_INSID. */
      if (!btree_online_index_is_normal_state (new_state)
	  || btree_is_fixed_size (btid_int, record, node_type, (offset_to_object == 0)))
	{
	  /* If we have any state set, except the normal state, or if it is a fixed size record. */
	  btree_set_mvccid (record, offset_to_insid_mvccid, &new_state, rv_undo_data, rv_redo_data);
	}
      else
	{
	  /* We have normal state of the record and the record is not a fixed size one. */
	  /* This translates in removing the state. */
	  btree_record_remove_insid (thread_p, btid_int, record, node_type, offset_to_object, rv_undo_data,
				     rv_redo_data, NULL);
	}
    }
  else if (!btree_online_index_is_normal_state (new_state))
    {
      /* We don't have MVCC_INSID. */
      btree_add_mvccid (record, offset_to_object, offset_to_insid_mvccid, new_state, BTREE_OID_HAS_MVCC_INSID,
			rv_undo_data, rv_redo_data);
    }
  else
    {
      // todo - is this possible? basically state is not changed...
      assert (false);
    }

#if !defined (NDEBUG)
  btree_check_valid_record (thread_p, btid_int, record, node_type, NULL);
#endif
}

//
// btree_is_class_oid_packed () - is class OID packed with object?
//
// return         : true if class oid is packed, false otherwise
// btid_int (in)  : b-tree info
// record (in)    : record descriptor
// node_type (in) : leaf/overflow node type
// is_first (in)  : is object first in record?
//
static bool
btree_is_class_oid_packed (BTID_INT * btid_int, RECDES * record, BTREE_NODE_TYPE node_type, bool is_first)
{
  // class oid is packed if:
  // 1. index is unique and
  // 2.1. is overflow node or
  // 2.2. is not first in leaf record or
  // 2.3. is first in leaf record and record is flagged with BTREE_LEAF_RECORD_CLASS_OID

  if (!btid_int->unique_pk)
    {
      // not unique, no class is saved
      return false;
    }

  // is unique

  if (node_type == BTREE_OVERFLOW_NODE)
    {
      // all overflow objects save class
      return true;
    }

  // is leaf

  if (!is_first)
    {
      // non-first in leaf record saves class
      return true;
    }

  // first saves class only if flagged
  return btree_leaf_is_flaged (record, BTREE_LEAF_RECORD_CLASS_OID);
}

static inline bool
btree_is_fixed_size (BTID_INT * btid_int, RECDES * record, BTREE_NODE_TYPE node_type, bool is_first)
{
  return ((node_type == BTREE_OVERFLOW_NODE) || (!is_first && BTREE_IS_UNIQUE (btid_int->unique_pk))
	  || (is_first && btree_leaf_is_flaged (record, BTREE_LEAF_RECORD_OVERFLOW_OIDS)));
}

static bool
btree_is_insert_data_purpose (BTREE_OP_PURPOSE purpose)
{
  switch (purpose)
    {
    case BTREE_OP_INSERT_NEW_OBJECT:
    case BTREE_OP_INSERT_MVCC_DELID:
    case BTREE_OP_INSERT_MARK_DELETED:
    case BTREE_OP_INSERT_UNDO_PHYSICAL_DELETE:
    case BTREE_OP_ONLINE_INDEX_IB_INSERT:
    case BTREE_OP_ONLINE_INDEX_TRAN_INSERT:
    case BTREE_OP_ONLINE_INDEX_UNDO_TRAN_DELETE:
    case BTREE_OP_ONLINE_INDEX_TRAN_INSERT_DF:
      return true;
    default:
      return false;
    }
}

static bool
btree_is_insert_object_purpose (BTREE_OP_PURPOSE purpose)
{
  switch (purpose)
    {
    case BTREE_OP_INSERT_NEW_OBJECT:
    case BTREE_OP_INSERT_UNDO_PHYSICAL_DELETE:
    case BTREE_OP_ONLINE_INDEX_IB_INSERT:
    case BTREE_OP_ONLINE_INDEX_TRAN_INSERT:
    case BTREE_OP_ONLINE_INDEX_UNDO_TRAN_DELETE:
    case BTREE_OP_ONLINE_INDEX_TRAN_INSERT_DF:
      return true;
    default:
      return false;
    }
}

static bool
btree_is_insert_delid_purpose (BTREE_OP_PURPOSE purpose)
{
  switch (purpose)
    {
    case BTREE_OP_INSERT_MVCC_DELID:
    case BTREE_OP_INSERT_MARK_DELETED:
      return true;
    default:
      return false;
    }
}

static bool
btree_is_delete_data_purpose (BTREE_OP_PURPOSE purpose)
{
  switch (purpose)
    {
    case BTREE_OP_DELETE_OBJECT_PHYSICAL:
    case BTREE_OP_DELETE_OBJECT_PHYSICAL_POSTPONED:
    case BTREE_OP_DELETE_UNDO_INSERT:
    case BTREE_OP_DELETE_UNDO_INSERT_UNQ_MULTIUPD:
    case BTREE_OP_DELETE_UNDO_INSERT_DELID:
    case BTREE_OP_DELETE_VACUUM_OBJECT:
    case BTREE_OP_DELETE_VACUUM_INSID:
    case BTREE_OP_ONLINE_INDEX_IB_DELETE:
    case BTREE_OP_ONLINE_INDEX_TRAN_DELETE:
    case BTREE_OP_ONLINE_INDEX_UNDO_TRAN_INSERT:
      return true;
    default:
      return false;
    }
}

static bool
btree_is_delete_object_purpose (BTREE_OP_PURPOSE purpose)
{
  switch (purpose)
    {
    case BTREE_OP_DELETE_OBJECT_PHYSICAL:
    case BTREE_OP_DELETE_OBJECT_PHYSICAL_POSTPONED:
    case BTREE_OP_DELETE_UNDO_INSERT:
    case BTREE_OP_DELETE_UNDO_INSERT_UNQ_MULTIUPD:
    case BTREE_OP_DELETE_VACUUM_OBJECT:
    case BTREE_OP_ONLINE_INDEX_IB_DELETE:
    case BTREE_OP_ONLINE_INDEX_TRAN_DELETE:
    case BTREE_OP_ONLINE_INDEX_UNDO_TRAN_INSERT:
      return true;
    default:
      return false;
    }
}

//
// btree_rv_log_delete_object () - log b-tree delete operation according to purpose
//
// thread_p (in)      : thread entry
// delete_helper (in) : delete helper
// addr (in)          : address for logging
// undo_length (in)   : physical undo log size
// redo_length (in)   : redo log size (is always physical)
// undo_data (in)     : physical undo log
// redo_data (in)     : redo log (is always physical)
//
static void
btree_rv_log_delete_object (THREAD_ENTRY * thread_p, const BTREE_DELETE_HELPER & delete_helper, LOG_DATA_ADDR & addr,
			    int undo_length, int redo_length, const char *undo_data, const char *redo_data)
{
  TDE_ALGORITHM tde_algo = TDE_ALGORITHM_NONE;
  assert (btree_is_delete_object_purpose (delete_helper.purpose));

  if (delete_helper.is_system_op_started)
    {
      // we need to log undoredo physical
      log_append_undoredo_data (thread_p, RVBT_RECORD_MODIFY_UNDOREDO, &addr, undo_length, redo_length, undo_data,
				redo_data);
    }
  else
    {
      switch (delete_helper.purpose)
	{
	case BTREE_OP_DELETE_OBJECT_PHYSICAL:
	  // log undo logical, log redo physical
	  log_append_undoredo_data (thread_p, RVBT_DELETE_OBJECT_PHYSICAL, &addr, delete_helper.rv_keyval_data_length,
				    redo_length, delete_helper.rv_keyval_data, redo_data);
	  break;
	case BTREE_OP_ONLINE_INDEX_TRAN_DELETE:
	  log_append_undoredo_data (thread_p, RVBT_ONLINE_INDEX_UNDO_TRAN_DELETE, &addr,
				    delete_helper.rv_keyval_data_length, redo_length, delete_helper.rv_keyval_data,
				    redo_data);
	  break;
	case BTREE_OP_DELETE_OBJECT_PHYSICAL_POSTPONED:
	  log_append_run_postpone (thread_p, RVBT_DELETE_OBJECT_PHYSICAL, &addr, pgbuf_get_vpid_ptr (addr.pgptr),
				   redo_length, redo_data, &delete_helper.reference_lsa);
	  break;
	case BTREE_OP_DELETE_UNDO_INSERT:
	case BTREE_OP_DELETE_UNDO_INSERT_UNQ_MULTIUPD:
	case BTREE_OP_ONLINE_INDEX_UNDO_TRAN_INSERT:
	  log_append_compensate_with_undo_nxlsa (thread_p, RVBT_RECORD_MODIFY_COMPENSATE,
						 pgbuf_get_vpid_ptr (addr.pgptr), addr.offset, addr.pgptr, redo_length,
						 redo_data, LOG_FIND_CURRENT_TDES (thread_p),
						 &delete_helper.reference_lsa);
	  break;
	case BTREE_OP_DELETE_VACUUM_OBJECT:
	case BTREE_OP_ONLINE_INDEX_IB_DELETE:
	  log_append_redo_data (thread_p, RVBT_DELETE_OBJECT_PHYSICAL, &addr, redo_length, redo_data);
	  break;
	default:
	  assert (false);
	  break;
	}
    }
}

//
// btree_rv_log_insert_object () - log b-tree insert operation according to purpose
//
// thread_p (in)      : thread entry
// insert_helper (in) : insert helper
// addr (in)          : address for logging
// undo_length (in)   : physical undo log size
// redo_length (in)   : redo log size (is always physical)
// undo_data (in)     : physical undo log
// redo_data (in)     : redo log (is always physical)
//
static void
btree_rv_log_insert_object (THREAD_ENTRY * thread_p, const BTREE_INSERT_HELPER & insert_helper, LOG_DATA_ADDR & addr,
			    int undo_length, int redo_length, const char *undo_data, const char *redo_data)
{
  TDE_ALGORITHM tde_algo = TDE_ALGORITHM_NONE;
  assert (btree_is_insert_object_purpose (insert_helper.purpose));

  if (insert_helper.is_system_op_started)
    {
      // undo/redo physical
      log_append_undoredo_data (thread_p, RVBT_RECORD_MODIFY_UNDOREDO, &addr, undo_length, redo_length, undo_data,
				redo_data);
    }
  else
    {
      switch (insert_helper.purpose)
	{
	case BTREE_OP_INSERT_NEW_OBJECT:
	  // undo logical, redo physical
	  log_append_undoredo_data (thread_p, insert_helper.rcvindex, &addr, insert_helper.rv_keyval_data_length,
				    redo_length, insert_helper.rv_keyval_data, redo_data);
	  break;

	case BTREE_OP_ONLINE_INDEX_TRAN_INSERT_DF:
	  /* Safeguard */
	  assert (btree_online_index_is_delete_flag_state (insert_helper.obj_info.mvcc_info.insert_mvccid));

	  /* Insert with DELETE_FLAG. */
	  log_append_undoredo_data (thread_p, RVBT_ONLINE_INDEX_UNDO_TRAN_DELETE, &addr,
				    insert_helper.rv_keyval_data_length, redo_length, insert_helper.rv_keyval_data,
				    redo_data);

	  break;
	case BTREE_OP_ONLINE_INDEX_TRAN_INSERT:
	  /* Normal insert. */
	  log_append_undoredo_data (thread_p, RVBT_ONLINE_INDEX_UNDO_TRAN_INSERT, &addr,
				    insert_helper.rv_keyval_data_length, redo_length, insert_helper.rv_keyval_data,
				    redo_data);

	  break;
	case BTREE_OP_ONLINE_INDEX_IB_INSERT:
	  // redo logging
	  log_append_redo_data (thread_p, RVBT_RECORD_MODIFY_NO_UNDO, &addr, redo_length, redo_data);
	  break;
	case BTREE_OP_INSERT_UNDO_PHYSICAL_DELETE:
	case BTREE_OP_ONLINE_INDEX_UNDO_TRAN_DELETE:
	  log_append_compensate_with_undo_nxlsa (thread_p, RVBT_RECORD_MODIFY_COMPENSATE,
						 pgbuf_get_vpid_ptr (addr.pgptr), addr.offset, addr.pgptr,
						 redo_length, redo_data, LOG_FIND_CURRENT_TDES (thread_p),
						 &insert_helper.compensate_undo_nxlsa);
	  break;
	default:
	  assert (false);
	  break;
	}
    }
}

/*
 * btree_find_oid_with_page_and_record () - Find OID in leaf/overflow pages and output its position and the record.
 *
 * return		  : Error code.
 * thread_p (in)	  : Thread entry.
 * btid_int (in)	  : B-tree info.
 * oid (in)		  : Object OID.
 * leaf_page (in)	  : Fixed leaf page (where object's key is found).
 * purpose (in)		  : Purpose/context for the function call.
 * match_mvccinfo (in)	  : Non-null value to be matched or null if it doesn't matter.
 * record (in)	  : Key leaf record.
 * leaf_rec_info (in)	  : Key leaf record info.
 * after_key_offset (in)  : Offset in leaf record where packed key is ended.
 * found_page (out)	  : Outputs leaf or overflow page where object is found.
 * prev_page (out)	  : Previous page of the overflow page where object object is found. If object is in leaf it
 *			    will output NULL. If object is in first overflow, it will output leaf page.
 *			    If argument is NULL, previous overflow page is unfixed.
 * offset_to_object (out) : Offset to object in the record of leaf/overflow.
 * new_record (out)       : The new record in case of overflow pages.
 *
 */
static int
btree_find_oid_with_page_and_record (THREAD_ENTRY * thread_p, BTID_INT * btid_int, OID * oid, PAGE_PTR leaf_page,
				     BTREE_OP_PURPOSE purpose, BTREE_MVCC_INFO * match_mvccinfo, RECDES * record,
				     LEAF_REC * leaf_info, int offset_after_key, PAGE_PTR * found_page,
				     PAGE_PTR * prev_page, int *offset_to_object, BTREE_MVCC_INFO * object_mvcc_info,
				     RECDES * new_record)
{
  int error_code = NO_ERROR;

  error_code = btree_find_oid_and_its_page (thread_p, btid_int, oid, leaf_page, purpose, NULL, record, leaf_info,
					    offset_after_key, found_page, prev_page, offset_to_object,
					    object_mvcc_info);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      return error_code;
    }


  if (*offset_to_object == NOT_FOUND)
    {
      /* Object not found, end this. */

      *new_record = *record;
      return error_code;
    }

  /* We found the object. */

  if (*found_page == leaf_page)
    {
      /* No overflow, set new_record to the record. */
      *new_record = *record;
      return error_code;
    }

  /* Overflow page. */

  /* Get the new record. */
  if (spage_get_record (thread_p, *found_page, 1, new_record, COPY) != S_SUCCESS)
    {
      assert_release (false);
      return ER_FAILED;
    }

  return error_code;
}

/*
 * btree_rv_keyval_undo_online_index_tran_delete () -
 *   return: int
 *   recv(in): Recovery structure
 *
 * Note: undo the deletion of a <key, val> pair to the B+tree,
 * by inserting the <key, val> pair to the tree during an online index operation.
 */
int
btree_rv_keyval_undo_online_index_tran_delete (THREAD_ENTRY * thread_p, LOG_RCV * recv)
{
  BTID_INT btid;
  BTID sys_btid;
  DB_VALUE key;
  OID cls_oid;
  OID oid;
  char *datap;
  int datasize;
  BTREE_MVCC_INFO mvcc_info;
  int error_code = NO_ERROR;

  /* btid needs a place to unpack the sys_btid into.  We'll use stack space. */
  btid.sys_btid = &sys_btid;

  /* extract the stored btid, key, oid data */
  datap = (char *) recv->data;
  datasize = recv->length;
  error_code = btree_rv_read_keyval_info_nocopy (thread_p, datap, datasize, &btid, &cls_oid, &oid, &mvcc_info, &key);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      return error_code;
    }

  assert (!OID_ISNULL (&oid));

  /* Insert object and all its info. */
  error_code = btree_online_index_dispatcher (thread_p, btid.sys_btid, &key, &cls_oid, &oid, btid.unique_pk,
					      BTREE_OP_ONLINE_INDEX_UNDO_TRAN_DELETE, &recv->reference_lsa);
  if (error_code != NO_ERROR)
    {
      ASSERT_ERROR ();
      pr_clear_value (&key);
      return error_code;
    }

  pr_clear_value (&key);

  return NO_ERROR;
}

/*
 * btree_rv_keyval_undo_online_index_tran_insert () - Undo insert operation for btree during online index.
 *
 * return		  : Error code.
 * thread_p (in)	  : Thread entry.
 * recv (in)		  : Recovery data.
 */
int
btree_rv_keyval_undo_online_index_tran_insert (THREAD_ENTRY * thread_p, LOG_RCV * recv)
{
  BTID_INT btid;
  BTID sys_btid;
  OID cls_oid;
  OID oid;
  char *datap;
  int datasize;
  BTREE_MVCC_INFO dummy_mvcc_info;
  int err = NO_ERROR;
  DB_VALUE key;

  /* btid needs a place to unpack the sys_btid into.  We'll use stack space. */
  btid.sys_btid = &sys_btid;

  /* extract the stored btid, key, oid data */
  datap = (char *) recv->data;
  datasize = recv->length;
  err = btree_rv_read_keyval_info_nocopy (thread_p, datap, datasize, &btid, &cls_oid, &oid, &dummy_mvcc_info, &key);
  if (err != NO_ERROR)
    {
      ASSERT_ERROR ();
      return err;
    }

  assert (!OID_ISNULL (&oid));

  /* Undo insert: just delete object and all its information. */
  err = btree_online_index_dispatcher (thread_p, btid.sys_btid, &key, &cls_oid, &oid, btid.unique_pk,
				       BTREE_OP_ONLINE_INDEX_UNDO_TRAN_INSERT, &recv->reference_lsa);
  if (err != NO_ERROR)
    {
      ASSERT_ERROR ();
      pr_clear_value (&key);
      return err;
    }

  pr_clear_value (&key);

  return NO_ERROR;
}

void
btree_insert_helper_to_delete_helper (BTREE_INSERT_HELPER * insert_helper, BTREE_DELETE_HELPER * delete_helper)
{
  /* oid, classoid and mvcc info */
  delete_helper->object_info.oid = insert_helper->obj_info.oid;
  delete_helper->object_info.class_oid = insert_helper->obj_info.class_oid;
  delete_helper->object_info.mvcc_info = insert_helper->obj_info.mvcc_info;

  /* save the LSA needed for recovery */
  LSA_COPY (&delete_helper->reference_lsa, &insert_helper->compensate_undo_nxlsa);

  /* Leaf addr. */
  delete_helper->leaf_addr.offset = insert_helper->leaf_addr.offset;
  delete_helper->leaf_addr.pgptr = insert_helper->leaf_addr.pgptr;
  delete_helper->leaf_addr.vfid = insert_helper->leaf_addr.vfid;

  /* Undo logging. */
  delete_helper->rv_keyval_data = insert_helper->rv_keyval_data;
  delete_helper->rv_keyval_data_length = insert_helper->rv_keyval_data_length;

  /* Redo logging. */
  delete_helper->rv_redo_data = insert_helper->rv_redo_data;
  delete_helper->rv_redo_data_ptr = delete_helper->rv_redo_data;

  /* Error logging. */
  delete_helper->log_operations = insert_helper->log_operations;
  delete_helper->printed_key = insert_helper->printed_key;
  delete_helper->printed_key_sha1 = insert_helper->printed_key_sha1;
}

void
btree_delete_helper_to_insert_helper (BTREE_DELETE_HELPER * delete_helper, BTREE_INSERT_HELPER * insert_helper)
{
  /* oid, classoid and mvcc info */
  insert_helper->obj_info.oid = delete_helper->object_info.oid;
  insert_helper->obj_info.class_oid = delete_helper->object_info.class_oid;
  insert_helper->obj_info.mvcc_info = delete_helper->object_info.mvcc_info;

  /* save the LSA needed for recovery */
  LSA_COPY (&insert_helper->compensate_undo_nxlsa, &delete_helper->reference_lsa);

  /* Leaf addr. */
  insert_helper->leaf_addr.offset = delete_helper->leaf_addr.offset;
  insert_helper->leaf_addr.pgptr = delete_helper->leaf_addr.pgptr;
  insert_helper->leaf_addr.vfid = delete_helper->leaf_addr.vfid;

  /* Undo logging. */
  insert_helper->rv_keyval_data = delete_helper->rv_keyval_data;
  insert_helper->rv_keyval_data_length = delete_helper->rv_keyval_data_length;

  /* Redo logging. */
  insert_helper->rv_redo_data = delete_helper->rv_redo_data;
  insert_helper->rv_redo_data_ptr = insert_helper->rv_redo_data;

  /* Error logging. */
  insert_helper->log_operations = delete_helper->log_operations;
  insert_helper->printed_key = delete_helper->printed_key;
  insert_helper->printed_key_sha1 = delete_helper->printed_key_sha1;
}

static inline bool
btree_is_online_index_loading (BTREE_OP_PURPOSE purpose)
{
  switch (purpose)
    {
    case BTREE_OP_ONLINE_INDEX_IB_INSERT:
    case BTREE_OP_ONLINE_INDEX_IB_DELETE:
    case BTREE_OP_ONLINE_INDEX_TRAN_INSERT:
    case BTREE_OP_ONLINE_INDEX_TRAN_INSERT_DF:
    case BTREE_OP_ONLINE_INDEX_TRAN_DELETE:
    case BTREE_OP_ONLINE_INDEX_UNDO_TRAN_DELETE:
    case BTREE_OP_ONLINE_INDEX_UNDO_TRAN_INSERT:
      return true;
    default:
      return false;
    }

  return false;
}

int
btree_online_index_check_unique_constraint (THREAD_ENTRY * thread_p, BTID * btid, const char *index_name,
					    OID * class_oid)
{
  int ret = NO_ERROR;
  int g_num_oids = 0, g_num_nulls = 0, g_num_keys = 0;
  LOG_TRAN_BTID_UNIQUE_STATS *unique_stats = logtb_tran_find_btid_stats (thread_p, btid, true);

  if (unique_stats == NULL)
    {
      return ER_FAILED;
    }

  ret = logtb_get_global_unique_stats (thread_p, btid, &g_num_oids, &g_num_nulls, &g_num_keys);
  if (ret != NO_ERROR)
    {
      ASSERT_ERROR ();
      return ret;
    }

  if ((g_num_oids + unique_stats->tran_stats.num_oids)
      != (g_num_keys + unique_stats->tran_stats.num_keys) + (g_num_nulls + unique_stats->tran_stats.num_nulls))
    {
      /* Unique constraint violation. */
      BTREE_SET_UNIQUE_VIOLATION_ERROR (thread_p, NULL, NULL, class_oid, btid, index_name);
      return ER_BTREE_UNIQUE_FAILED;
    }

  return NO_ERROR;
}

int
btree_get_class_oid_of_unique_btid (THREAD_ENTRY * thread_p, BTID * btid, OID * class_oid)
{
  PAGE_PTR root_page;
  BTREE_ROOT_HEADER *root_header = NULL;

  OID_SET_NULL (class_oid);

  root_page = btree_fix_root_with_info (thread_p, btid, PGBUF_LATCH_READ, NULL, &root_header, NULL);
  if (root_page == NULL)
    {
      return ER_FAILED;
    }

  if (BTREE_IS_UNIQUE (root_header->unique_pk))
    {
      /* Copy the class oid */
      COPY_OID (class_oid, &root_header->topclass_oid);
    }

  pgbuf_unfix_and_init (thread_p, root_page);

  return NO_ERROR;
}

bool
btree_is_btid_online_index (THREAD_ENTRY * thread_p, OID * class_oid, BTID * btid)
{
  OR_CLASSREP *rep = NULL;
  int idx_incache = -1;
  bool result = false;
  int i;

  rep = heap_classrepr_get (thread_p, class_oid, NULL, NULL_REPRID, &idx_incache);
  if (rep == NULL)
    {
      assert (false);
      return false;
    }

  /* Iterate through indexes of current class_oid and check if the one matching the btid is an online one. */
  for (i = 0; i < rep->n_indexes; i++)
    {
      if (BTID_IS_EQUAL (btid, &rep->indexes[i].btid))
	{
	  if (rep->indexes[i].index_status == OR_ONLINE_INDEX_BUILDING_IN_PROGRESS)
	    {
	      result = true;
	    }
	  break;
	}
    }

  heap_classrepr_free_and_init (rep, &idx_incache);

  return result;
}

//
// btree_is_single_object_key () - returns true if there is only one object in key, false otherwise; parameters
//                                 offer details on object location
//
// return                : true if single object
// thread_p (in)         : thread entry
// btid_int (in)         : b-tree info
// node_type (in)        : node type - overflow or leaf
// record (in)           : current record (overflow or leaf)
// offset_after_key (in) : offset after key (only for leaf)
//
static bool
btree_is_single_object_key (THREAD_ENTRY * thread_p, BTID_INT * btid_int, BTREE_NODE_TYPE node_type,
			    RECDES * record, int offset_after_key)
{
  if (node_type == BTREE_OVERFLOW_NODE)
    {
      // has overflows, must have at least two
      return false;
    }
  // leaf
  assert (node_type == BTREE_LEAF_NODE);
  if (offset_after_key < record->length)
    {
      // it has more than one object!
      // this is a hack to avoid counting objects; maybe it is not safe
      return false;
    }
  assert (offset_after_key == record->length);
  return true;
}

static bool
btree_check_locking_for_insert_unique (THREAD_ENTRY * thread_p, const BTREE_INSERT_HELPER * insert_helper)
{
  int has_class_bu_lock;
  int has_instance_lock;

  /*  The insert operation in index has to check if the object is currently inserting is locked by the transaction.
   *  However, after the introduction of the BU_LOCK this is no longer valid. For this case, the inserter should
   *  make sure that he has a BU_LOCK on the class he is inserting into.
   *
   *  Now in order to correctly insert into the b-tree the transaction should either have and X_LOCK on the object,
   *  or a BU_LOCK on the class.
   */

  has_class_bu_lock = lock_has_lock_on_object (BTREE_INSERT_CLASS_OID (insert_helper), oid_Root_class_oid, BU_LOCK);
  if (has_class_bu_lock > 0)
    {
      return true;
    }

  has_instance_lock = lock_has_lock_on_object (BTREE_INSERT_OID (insert_helper),
					       BTREE_INSERT_CLASS_OID (insert_helper), X_LOCK);
  if (has_instance_lock > 0)
    {
      return true;
    }

  return false;
}

static bool
btree_check_locking_for_delete_unique (THREAD_ENTRY * thread_p, const BTREE_DELETE_HELPER * delete_helper)
{
  int has_class_bu_lock;
  int has_instance_lock;

  /*  The insert operation in index has to check if the object is currently inserting is locked by the transaction.
   *  However, after the introduction of the BU_LOCK this is no longer valid. For this case, the inserter should
   *  make sure that he has a BU_LOCK on the class he is inserting into.
   *
   *  Now in order to correctly insert into the b-tree the transaction should either have and X_LOCK on the object,
   *  or a BU_LOCK on the class.
   */

  has_class_bu_lock = lock_has_lock_on_object (BTREE_DELETE_CLASS_OID (delete_helper), oid_Root_class_oid, BU_LOCK);
  if (LOG_ISTRAN_ABORTED (LOG_FIND_CURRENT_TDES (thread_p)) && has_class_bu_lock > 0)
    {
      return true;
    }

  has_instance_lock = lock_has_lock_on_object (BTREE_DELETE_OID (delete_helper),
					       BTREE_DELETE_CLASS_OID (delete_helper), X_LOCK);
  if (has_instance_lock > 0)
    {
      return true;
    }

  return false;
}

// *INDENT-OFF*
page_key_boundary::page_key_boundary ()
  : m_is_inf_left_key (true)
  , m_is_inf_right_key (true)
{
  db_make_null (&m_left_key);
  db_make_null (&m_right_key);
}

page_key_boundary::~page_key_boundary ()
{
  pr_clear_value (&m_left_key);
  pr_clear_value (&m_right_key);
}

void
page_key_boundary::set_value (DB_VALUE &dest_value, DB_VALUE &src_value, bool &clear_src_value)
{
  pr_clear_value (&dest_value);
  pr_clone_value (&src_value, &dest_value);
  btree_clear_key_value (&clear_src_value, &src_value);
}

int
page_key_boundary::set_value (THREAD_ENTRY * thread_p, DB_VALUE &dest_value, BTID_INT * btid, PAGE_PTR page_ptr,
                              const INT16 slot)
{
  RECDES rec;
  if (spage_get_record (thread_p, page_ptr, slot, &rec, PEEK) != S_SUCCESS)
    {
      return ER_FAILED;
    }

  return set_value (thread_p, dest_value, btid, page_ptr, rec);
}

int
page_key_boundary::set_value (THREAD_ENTRY * thread_p, DB_VALUE &dest_value, BTID_INT * btid, PAGE_PTR page_ptr,
                              RECDES &rec)
{
  DB_VALUE boundary_value;
  NON_LEAF_REC non_leaf_rec;
  bool clear_boundary_value = false;
  int offset;

  db_make_null (&boundary_value);

  pr_clear_value (&dest_value);

  if (btree_read_record_without_decompression (thread_p, btid, &rec, &boundary_value, &non_leaf_rec,
					       BTREE_NON_LEAF_NODE, &clear_boundary_value, &offset,
					       PEEK_KEY_VALUE) != NO_ERROR)
    {
      return ER_FAILED;
    }

  pr_clone_value (&boundary_value, &dest_value);

  return NO_ERROR;
}

/*
 * update_boundary_eq : helper function used in context of btree insert advance functions
 *                      Updates the left/right boundary values of the search path down to a leaf page.
 *                      This handles the case when the key to insert is equal to current value stored
 *                      in non-leaf record.
 *
 * thread_p (in) :
 * btid (in) :
 * page_ptr (in) : current page (should be a non-leaf)
 * subtree_value (in) : value of non-leaf record pointing to a descending sub-tree
 * clear_subtree_value (in) : flag to clear subtree_value
 * subtree_slot(in): slot of the non-leaf pointer record
 */
int
page_key_boundary::update_boundary_eq (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR page_ptr,
                                       DB_VALUE &subtree_value, bool &clear_subtree_value, const INT16 subtree_slot)
{
  int error = NO_ERROR;

  /* value [subtree_slot - 1] < search_key <= subtree_value
   * search_key == subtree_value */
  set_value (m_right_key, subtree_value, clear_subtree_value);
  m_is_inf_right_key = false;

  /* update left value boundary only if there is a slot sitting left to current subtree entry */
  if (subtree_slot > 0)
    {
      error = set_value (thread_p, m_left_key, btid, page_ptr, subtree_slot - 1);
      m_is_inf_left_key = false;
    }

  return error;
}

/*
 * update_boundary_lt : helper function used in context of btree insert advance functions
 *                      Updates the left/right boundary values of the search path down to a leaf page.
 *                      This handles the case when the key to insert is less than the value of current sub-tree.
 *
 * thread_p (in) :
 * btid (in) :
 * page_ptr (in) : current page (should be a non-leaf)
 * left_subtree_rec (in) : record left to current subtree value
 * subtree_value (in) : value of current non-leaf record pointing to a descending sub-tree
 * clear_subtree_value (in) : flag to clear subtree_value
 */
int
page_key_boundary::update_boundary_lt (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR page_ptr,
                                       RECDES &left_subtree_rec, DB_VALUE &subtree_value, bool &clear_subtree_value)
{
  int error = NO_ERROR;

  /* value (left_subtree_rec) < search_key <= subtree_value */
  set_value (m_right_key, subtree_value, clear_subtree_value);
  m_is_inf_right_key = false;

  error = set_value (thread_p, m_left_key, btid, page_ptr, left_subtree_rec);
  m_is_inf_left_key = false;

  return error;
}

/*
 * update_boundary_gt_or_eq : helper function used in context of btree insert advance functions
 *                      Updates the left/right boundary values of the search path down to a leaf page.
 *                      This handles the case when the key to insert is greater of equal than the value
 *                      of current sub-tree.
 *
 * thread_p (in) :
 * btid (in) :
 * page_ptr (in) : current page (should be a non-leaf)
 * subtree_value (in) : value of current non-leaf record pointing to a descending sub-tree
 * clear_subtree_value (in) : flag to clear subtree_value
 * subtree_slot (in): slot location of current subtree value
 * key_cnt (in): number of keys in non-leaf page
 */
int
page_key_boundary::update_boundary_gt_or_eq (THREAD_ENTRY * thread_p, BTID_INT * btid, PAGE_PTR page_ptr,
                                             DB_VALUE &subtree_value, bool &clear_subtree_value,
                                             const INT16 subtree_slot, const int key_cnt)
{
  int error = NO_ERROR;

  /* subtree_value <= search_key < value [subtree_slot + 1] */
  set_value (m_left_key, subtree_value, clear_subtree_value);
  m_is_inf_left_key = false;

  if (subtree_slot + 1 < key_cnt)
    {
      error = set_value (thread_p, m_right_key, btid, page_ptr, subtree_slot + 1);
      m_is_inf_right_key = false;
    }

  return error;
}

btree_insert_list::btree_insert_list (DB_VALUE *key, OID *oid)
  : m_curr_pos (0)
  , m_key_type (&tp_Null_domain)
  , m_use_page_boundary_check (false)
  , m_use_sorted_bulk_insert (false)
{
  m_curr_key = key;
  m_curr_oid = oid;
}

size_t
btree_insert_list::add_key (const DB_VALUE *key, const OID &oid)
{
  size_t memsize = 0;
  m_keys_oids.emplace_back ();

  m_keys_oids.back ().m_oid = oid;

  db_value &last_key = m_keys_oids.back ().m_key;
  db_make_null (&last_key);

  THREAD_ENTRY *thread_p = thread_get_thread_entry_info ();

  /* Switch to global heapID. */
  HL_HEAPID prev_id = db_change_private_heap (thread_p, 0);

  qdata_copy_db_value (&last_key, key);
  memsize += m_key_type->type->get_disk_size_of_value (&last_key);

  /* reset back to previous heapID. */
  db_change_private_heap (thread_p, prev_id);

  memsize += OR_OID_SIZE;
  memsize = DB_ALIGN (memsize, BTREE_MAX_ALIGN);

  return memsize;
}

int btree_insert_list::next_key ()
{
  assert (m_use_sorted_bulk_insert);

  if (m_curr_key == NULL)
    {
      assert (m_curr_oid == NULL);

      assert (m_sorted_keys_oids.size () > 0);

      m_curr_pos = 0;
      m_curr_oid = &m_sorted_keys_oids[m_curr_pos]->m_oid;
      m_curr_key = &m_sorted_keys_oids[m_curr_pos]->m_key;

      return KEY_AVAILABLE;
    }
  else if (++m_curr_pos < (int) m_sorted_keys_oids.size ())
    {
      m_curr_oid = &m_sorted_keys_oids[m_curr_pos]->m_oid;
      m_curr_key = &m_sorted_keys_oids[m_curr_pos]->m_key;

      return KEY_AVAILABLE;
    }

  return KEY_NOT_AVAILABLE;
}

btree_insert_list::~btree_insert_list ()
{
  HL_HEAPID save_id;

  save_id = db_change_private_heap (NULL, 0);

  for (auto key_oid : m_keys_oids)
    {
      pr_clear_value (&key_oid.m_key);
    }

  (void) db_change_private_heap (NULL, save_id);

  reset_boundary_keys ();
}

void btree_insert_list::reset_boundary_keys ()
{
  if (!m_boundaries.m_is_inf_left_key)
    {
      pr_clear_value (&m_boundaries.m_left_key);
      m_boundaries.m_is_inf_left_key = true;
    }

  if (!m_boundaries.m_is_inf_right_key)
    {
      pr_clear_value (&m_boundaries.m_right_key);
      m_boundaries.m_is_inf_right_key = true;
    }
}

void btree_insert_list::prepare_list (void)
{
  /* initialize sorted list with the same order as unsorted */
  for (auto &key_oid : m_keys_oids)
    {
      m_sorted_keys_oids.push_back (&key_oid);
    }

  auto compare_fn = [&] (key_oid *a, key_oid *b)
    {
      DB_VALUE_COMPARE_RESULT result;
      result = btree_compare_key (&a->m_key, &b->m_key, const_cast<TP_DOMAIN *>(m_key_type), 1, 1, NULL);

      return (result == DB_LT) ? true : false;
    };

  std::sort (m_sorted_keys_oids.begin (), m_sorted_keys_oids.end (), compare_fn);
  m_use_sorted_bulk_insert = true;
  m_use_page_boundary_check = true;

  int status = next_key ();
  assert (status == KEY_AVAILABLE);
}

bool btree_insert_list::check_release_latch (THREAD_ENTRY * thread_p, void *arg, PAGE_PTR leaf_page)
{
  bool check_latch_waiters = false;
  BTREE_INSERT_HELPER *insert_helper = (BTREE_INSERT_HELPER *)arg;

  assert (insert_helper != NULL);
  assert (insert_helper->insert_list == this);

  int cost = m_keep_page_iterations + m_ovf_appends * 10 + m_ovf_appends_new_page * 1000;

  if (insert_helper->is_root)
    {
      if (cost > 50)
        {
          check_latch_waiters = true;
        }
    }
  else
    {
      if (cost > 100 && cost > (int) btree_get_node_header (thread_p, leaf_page)->node_level * 1000)
        {
          check_latch_waiters = true;
        }
    }

  if (check_latch_waiters)
    {
      return pgbuf_has_any_waiters (leaf_page);
    }

  return false;
}
// *INDENT-ON*
